Honored to be a part of this wonderful unit at NYU. Truly a pioneering interdisciplinary effort
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Every graduate course I took at CDS was very high quality.

My only hope is that more courses (and universities) embrace open-source lecture materials like 
@ylecun
 and 
@alfcnz
’s undergraduate deep learning course has. Such high quality material shouldn’t be behind a $70k paywall.
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Want less grey?
Get more blue and more green.
------
 Ranked: EU countries by share of #cleanelectricity in 2022

How does your country measure up?

https://ember-climate.org/insights/research/european-electricity-review-2023…
------
Let's do it.
------
One of NASA's favourite space projects is a plan to fit a 1 km radio telescope inside a crater on the far side of the Moon, which would be the largest radio telescope in the Solar System 

[read more: https://buff.ly/2xaypqJ]
------
Mind the gap...
...between the learning efficiencies of LLMs and children.
------
Bridging the data gap between children and large language models

By @mcxfrank 

Free access until October 20th: https://authors.elsevier.com/a/1hgpQ4sIRvPN2q…
------
One of AI’s  biggest contributions to humanity will be in the life sciences and medicine 

The cumulative investment in AI drug discovery  is at least $25 billion 

Cc: 
@Noahpinion
 
@mustafasuleyman
 
@ylecun
 
@erikbryn
------
You can now get a PhD at Harvard in Artificial Intelligence in Medicine.

Prepare to apply this fall and come work with me and my incredible colleagues.

http://bit.ly/AIM_PHD
Info session coming up: http://bit.ly/AIM-info
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Get to know Copilot a little better 

For mental health providers, the detailed documenters, and anyone with a particularly quotable patient 

 This one’s for you: directly add the patient’s words to your clinical notes to refer back to what they said, exactly how they said… Show more
------
Get ready for the 2023 Open Catalyst Challenge! 

 Test dataset drops in ~3 weeks (Sept. 20) with submissions due in 5 weeks (Oct. 6)

For ideas/low hanging fruit check out the overview video https://youtu.be/KFBFvLk3WVI?si=UIcpcRLUKTgfHhd0… or visit office hours
------
Announcing Belebele, a first-of-its-kind multilingual reading comprehension dataset. This dataset is parallel for 122 language variants, enabling direct comparison of how well models understand different languages.

Dataset  https://bit.ly/47UTSAh
------
Amusing.
------
lolllll

if not for ASML

the whole continent would only produce vapidity
------
Fun with DINOv2
------
Do try out the new depth estimation parallax view, it's trippy
------
What happened in the open-source AI world in August? August is traditionally a slow month...but not for AI it seems! Here is a recap!

Code goes wild
- Just 6 months after LLaMA, 
@MetaAI
 releases Code Llama, a family of LLMs for code https://ai.meta.com/blog/code-llama-large-language-model-coding/…. You can now… Show more
------
My friend and former AT&T colleague John S. Denker designed this game while he was an undergrad at Caltech in the mid 1970s.
It was the first handheld microprocessor-driven game.
Then he left his startup to do a PhD in physics at Caltech and then joined Larry Jackel's group at… Show more
------
I mistyped, John did his PhD at Cornell.
------
Honored to be a part of this wonderful unit at NYU. Truly a pioneering interdisciplinary effort
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Every graduate course I took at CDS was very high quality.

My only hope is that more courses (and universities) embrace open-source lecture materials like 
@ylecun
 and 
@alfcnz
’s undergraduate deep learning course has. Such high quality material shouldn’t be behind a $70k paywall.
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Want less grey?
Get more blue and more green.
------
 Ranked: EU countries by share of #cleanelectricity in 2022

How does your country measure up?

https://ember-climate.org/insights/research/european-electricity-review-2023…
------
Let's do it.
------
One of NASA's favourite space projects is a plan to fit a 1 km radio telescope inside a crater on the far side of the Moon, which would be the largest radio telescope in the Solar System 

[read more: https://buff.ly/2xaypqJ]
------
Mind the gap...
...between the learning efficiencies of LLMs and children.
------
Bridging the data gap between children and large language models

By @mcxfrank 

Free access until October 20th: https://authors.elsevier.com/a/1hgpQ4sIRvPN2q…
------
One of AI’s  biggest contributions to humanity will be in the life sciences and medicine 

The cumulative investment in AI drug discovery  is at least $25 billion 

Cc: 
@Noahpinion
 
@mustafasuleyman
 
@ylecun
 
@erikbryn
------
You can now get a PhD at Harvard in Artificial Intelligence in Medicine.

Prepare to apply this fall and come work with me and my incredible colleagues.

http://bit.ly/AIM_PHD
Info session coming up: http://bit.ly/AIM-info
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Get to know Copilot a little better 

For mental health providers, the detailed documenters, and anyone with a particularly quotable patient 

 This one’s for you: directly add the patient’s words to your clinical notes to refer back to what they said, exactly how they said… Show more
------
Get ready for the 2023 Open Catalyst Challenge! 

 Test dataset drops in ~3 weeks (Sept. 20) with submissions due in 5 weeks (Oct. 6)

For ideas/low hanging fruit check out the overview video https://youtu.be/KFBFvLk3WVI?si=UIcpcRLUKTgfHhd0… or visit office hours
------
Announcing Belebele, a first-of-its-kind multilingual reading comprehension dataset. This dataset is parallel for 122 language variants, enabling direct comparison of how well models understand different languages.

Dataset  https://bit.ly/47UTSAh
------
Amusing.
------
lolllll

if not for ASML

the whole continent would only produce vapidity
------
Fun with DINOv2
------
Do try out the new depth estimation parallax view, it's trippy
------
What happened in the open-source AI world in August? August is traditionally a slow month...but not for AI it seems! Here is a recap!

Code goes wild
- Just 6 months after LLaMA, 
@MetaAI
 releases Code Llama, a family of LLMs for code https://ai.meta.com/blog/code-llama-large-language-model-coding/…. You can now… Show more
------
My friend and former AT&T colleague John S. Denker designed this game while he was an undergrad at Caltech in the mid 1970s.
It was the first handheld microprocessor-driven game.
Then he left his startup to do a PhD in physics at Caltech and then joined Larry Jackel's group at… Show more
------
I mistyped, John did his PhD at Cornell.
------
Full F16 precision 34B Code Llama at >20 t/s on M2 Ultra
------
DINOv2, the cutting-edge computer vision model trained through self-supervised learning to produce universal features, is now available under the Apache 2.0 license.

Onward with open source AI.
------
Today we’re announcing two new updates in our computer vision work — a new, expanded license for our DINOv2 model and the release of FACET, a comprehensive new benchmark dataset to help evaluate and improve fairness in vision models.

More details  https://bit.ly/3L35E1U


------
Miles Davis performing “Agitations” with Ron Carter on bass, Herbie Hancock on piano, Wayne Shorter on sax and Tonny Williams on drums live in Sweden, 1967.
#Jazz #MilesDavis
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
Every graduate course I took at CDS was very high quality.

My only hope is that more courses (and universities) embrace open-source lecture materials like 
@ylecun
 and 
@alfcnz
’s undergraduate deep learning course has. Such high quality material shouldn’t be behind a $70k paywall.
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Want less grey?
Get more blue and more green.
------
 Ranked: EU countries by share of #cleanelectricity in 2022

How does your country measure up?

https://ember-climate.org/insights/research/european-electricity-review-2023…
------
Let's do it.
------
One of NASA's favourite space projects is a plan to fit a 1 km radio telescope inside a crater on the far side of the Moon, which would be the largest radio telescope in the Solar System 

[read more: https://buff.ly/2xaypqJ]
------
Mind the gap...
...between the learning efficiencies of LLMs and children.
------
Bridging the data gap between children and large language models

By @mcxfrank 

Free access until October 20th: https://authors.elsevier.com/a/1hgpQ4sIRvPN2q…
------
One of AI’s  biggest contributions to humanity will be in the life sciences and medicine 

The cumulative investment in AI drug discovery  is at least $25 billion 

Cc: 
@Noahpinion
 
@mustafasuleyman
 
@ylecun
 
@erikbryn
------
You can now get a PhD at Harvard in Artificial Intelligence in Medicine.

Prepare to apply this fall and come work with me and my incredible colleagues.

http://bit.ly/AIM_PHD
Info session coming up: http://bit.ly/AIM-info
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Get to know Copilot a little better 

For mental health providers, the detailed documenters, and anyone with a particularly quotable patient 

 This one’s for you: directly add the patient’s words to your clinical notes to refer back to what they said, exactly how they said… Show more
------
Get ready for the 2023 Open Catalyst Challenge! 

 Test dataset drops in ~3 weeks (Sept. 20) with submissions due in 5 weeks (Oct. 6)

For ideas/low hanging fruit check out the overview video https://youtu.be/KFBFvLk3WVI?si=UIcpcRLUKTgfHhd0… or visit office hours
------
Announcing Belebele, a first-of-its-kind multilingual reading comprehension dataset. This dataset is parallel for 122 language variants, enabling direct comparison of how well models understand different languages.

Dataset  https://bit.ly/47UTSAh
------
Amusing.
------
lolllll

if not for ASML

the whole continent would only produce vapidity
------
Fun with DINOv2
------
Do try out the new depth estimation parallax view, it's trippy
------
What happened in the open-source AI world in August? August is traditionally a slow month...but not for AI it seems! Here is a recap!

Code goes wild
- Just 6 months after LLaMA, 
@MetaAI
 releases Code Llama, a family of LLMs for code https://ai.meta.com/blog/code-llama-large-language-model-coding/…. You can now… Show more
------
My friend and former AT&T colleague John S. Denker designed this game while he was an undergrad at Caltech in the mid 1970s.
It was the first handheld microprocessor-driven game.
Then he left his startup to do a PhD in physics at Caltech and then joined Larry Jackel's group at… Show more
------
I mistyped, John did his PhD at Cornell.
------
Full F16 precision 34B Code Llama at >20 t/s on M2 Ultra
------
DINOv2, the cutting-edge computer vision model trained through self-supervised learning to produce universal features, is now available under the Apache 2.0 license.

Onward with open source AI.
------
Today we’re announcing two new updates in our computer vision work — a new, expanded license for our DINOv2 model and the release of FACET, a comprehensive new benchmark dataset to help evaluate and improve fairness in vision models.

More details  https://bit.ly/3L35E1U


------
Miles Davis performing “Agitations” with Ron Carter on bass, Herbie Hancock on piano, Wayne Shorter on sax and Tonny Williams on drums live in Sweden, 1967.
#Jazz #MilesDavis
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
At some point in the 1980s, Americans started getting screwed.
------
Europeans working fewer hours than Americans is a surprisingly recent phenomenon. In 1950, workers in all the 5 biggest Western European countries worked more than Americans. Now all work less.
------
Oldies but goldies: Hopfield, Neural networks and physical systems with emergent collective computational abilities, 1982. Hopfield networks are recurrent networks minimizing an Ising-type energy parameterized by its weights. https://en.wikipedia.org/wiki/Hopfield_network…
------
Mind the gap...
...between the learning efficiencies of LLMs and children.
------
Bridging the data gap between children and large language models

By @mcxfrank 

Free access until October 20th: https://authors.elsevier.com/a/1hgpQ4sIRvPN2q…
------
One of AI’s  biggest contributions to humanity will be in the life sciences and medicine 

The cumulative investment in AI drug discovery  is at least $25 billion 

Cc: 
@Noahpinion
 
@mustafasuleyman
 
@ylecun
 
@erikbryn
------
You can now get a PhD at Harvard in Artificial Intelligence in Medicine.

Prepare to apply this fall and come work with me and my incredible colleagues.

http://bit.ly/AIM_PHD
Info session coming up: http://bit.ly/AIM-info
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Get to know Copilot a little better 

For mental health providers, the detailed documenters, and anyone with a particularly quotable patient 

 This one’s for you: directly add the patient’s words to your clinical notes to refer back to what they said, exactly how they said… Show more
------
Get ready for the 2023 Open Catalyst Challenge! 

 Test dataset drops in ~3 weeks (Sept. 20) with submissions due in 5 weeks (Oct. 6)

For ideas/low hanging fruit check out the overview video https://youtu.be/KFBFvLk3WVI?si=UIcpcRLUKTgfHhd0… or visit office hours
------
Announcing Belebele, a first-of-its-kind multilingual reading comprehension dataset. This dataset is parallel for 122 language variants, enabling direct comparison of how well models understand different languages.

Dataset  https://bit.ly/47UTSAh
------
Amusing.
------
lolllll

if not for ASML

the whole continent would only produce vapidity
------
Fun with DINOv2
------
Do try out the new depth estimation parallax view, it's trippy
------
What happened in the open-source AI world in August? August is traditionally a slow month...but not for AI it seems! Here is a recap!

Code goes wild
- Just 6 months after LLaMA, 
@MetaAI
 releases Code Llama, a family of LLMs for code https://ai.meta.com/blog/code-llama-large-language-model-coding/…. You can now… Show more
------
My friend and former AT&T colleague John S. Denker designed this game while he was an undergrad at Caltech in the mid 1970s.
It was the first handheld microprocessor-driven game.
Then he left his startup to do a PhD in physics at Caltech and then joined Larry Jackel's group at… Show more
------
I mistyped, John did his PhD at Cornell.
------
Full F16 precision 34B Code Llama at >20 t/s on M2 Ultra
------
DINOv2, the cutting-edge computer vision model trained through self-supervised learning to produce universal features, is now available under the Apache 2.0 license.

Onward with open source AI.
------
Today we’re announcing two new updates in our computer vision work — a new, expanded license for our DINOv2 model and the release of FACET, a comprehensive new benchmark dataset to help evaluate and improve fairness in vision models.

More details  https://bit.ly/3L35E1U


------
Miles Davis performing “Agitations” with Ron Carter on bass, Herbie Hancock on piano, Wayne Shorter on sax and Tonny Williams on drums live in Sweden, 1967.
#Jazz #MilesDavis
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
At some point in the 1980s, Americans started getting screwed.
------
Europeans working fewer hours than Americans is a surprisingly recent phenomenon. In 1950, workers in all the 5 biggest Western European countries worked more than Americans. Now all work less.
------
Oldies but goldies: Hopfield, Neural networks and physical systems with emergent collective computational abilities, 1982. Hopfield networks are recurrent networks minimizing an Ising-type energy parameterized by its weights. https://en.wikipedia.org/wiki/Hopfield_network…
------
Open source AI grants from a16z.
------
[New program] a16z Open Source AI Grants

Hackers & independent devs are massively important to the AI ecosystem.

We're starting a grant funding program so they can continue their work without pressure to generate financial returns.

https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/…
------
Speaking with Jocelyn at the AI Natives event in NYC next Thursday, September 7th.
------
Can’t wait! Next Thu 9/7 @ 1 PM ET I get to chat w/ godfather of AI @ylecun about the future of AI and the way research, industry, and entrepreneurship can collectively drive innovation. 

Livestream registration right this way: http://Zettavp.com/ai-native
------
France has fast food joints, but slow food still reigns.
------
Which country has the best food? A revealed preference approach.
------
Americans always have reason why problems the rest of the world solved 50 or 100 years ago are impossible to solve.
------
Yes because a city with 380k ppl and no residential over 6 floors makes sense to compare to 8mil ppl and housing density over 20 floors pervasive throughout. You’d need a never ending sidewalk of these bins, 6 times as deep, to do Manhattan trash. twitter.com/benedictevans/…
------
Spotted 
@ylecun
 (or rather the literary embodiment thereof) in the 
@EPFL
 store. Looks like a cracking read.
------
There are many discussions recently about AI, technology, and the future of our civilization. Most takes are biased towards dystopias. But they are just that - different takes. It does not have to be that way. There are other visions of the future, not utopian either, but much… Show more
------
I want a laptop with a tensor processor and a unified memory system that runs Linux.

Basically, something that can run large models without weighing a ton, requiring a separate GPU RAM, draining the battery in minutes, costing a fortune, and running a proprietary OS.
------
10 years ago: September 1, 2013 was the official birthday of the NYU Center for Data Science.

Probably the first such center in the US, it has flourished since its inception.
CDS offers a PhD program, a Master's program, an undergraduate major, an undergraduate minor, and  joint… Show more
------
Get to know Copilot a little better 

For mental health providers, the detailed documenters, and anyone with a particularly quotable patient 

 This one’s for you: directly add the patient’s words to your clinical notes to refer back to what they said, exactly how they said… Show more
------
Get ready for the 2023 Open Catalyst Challenge! 

 Test dataset drops in ~3 weeks (Sept. 20) with submissions due in 5 weeks (Oct. 6)

For ideas/low hanging fruit check out the overview video https://youtu.be/KFBFvLk3WVI?si=UIcpcRLUKTgfHhd0… or visit office hours
------
Announcing Belebele, a first-of-its-kind multilingual reading comprehension dataset. This dataset is parallel for 122 language variants, enabling direct comparison of how well models understand different languages.

Dataset  https://bit.ly/47UTSAh
------
Amusing.
------
lolllll

if not for ASML

the whole continent would only produce vapidity
------
Fun with DINOv2
------
Do try out the new depth estimation parallax view, it's trippy
------
What happened in the open-source AI world in August? August is traditionally a slow month...but not for AI it seems! Here is a recap!

Code goes wild
- Just 6 months after LLaMA, 
@MetaAI
 releases Code Llama, a family of LLMs for code https://ai.meta.com/blog/code-llama-large-language-model-coding/…. You can now… Show more
------
My friend and former AT&T colleague John S. Denker designed this game while he was an undergrad at Caltech in the mid 1970s.
It was the first handheld microprocessor-driven game.
Then he left his startup to do a PhD in physics at Caltech and then joined Larry Jackel's group at… Show more
------
I mistyped, John did his PhD at Cornell.
------
Full F16 precision 34B Code Llama at >20 t/s on M2 Ultra
------
DINOv2, the cutting-edge computer vision model trained through self-supervised learning to produce universal features, is now available under the Apache 2.0 license.

Onward with open source AI.
------
Today we’re announcing two new updates in our computer vision work — a new, expanded license for our DINOv2 model and the release of FACET, a comprehensive new benchmark dataset to help evaluate and improve fairness in vision models.

More details  https://bit.ly/3L35E1U


------
Miles Davis performing “Agitations” with Ron Carter on bass, Herbie Hancock on piano, Wayne Shorter on sax and Tonny Williams on drums live in Sweden, 1967.
#Jazz #MilesDavis
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
At some point in the 1980s, Americans started getting screwed.
------
Europeans working fewer hours than Americans is a surprisingly recent phenomenon. In 1950, workers in all the 5 biggest Western European countries worked more than Americans. Now all work less.
------
Oldies but goldies: Hopfield, Neural networks and physical systems with emergent collective computational abilities, 1982. Hopfield networks are recurrent networks minimizing an Ising-type energy parameterized by its weights. https://en.wikipedia.org/wiki/Hopfield_network…
------
Open source AI grants from a16z.
------
[New program] a16z Open Source AI Grants

Hackers & independent devs are massively important to the AI ecosystem.

We're starting a grant funding program so they can continue their work without pressure to generate financial returns.

https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/…
------
Speaking with Jocelyn at the AI Natives event in NYC next Thursday, September 7th.
------
Can’t wait! Next Thu 9/7 @ 1 PM ET I get to chat w/ godfather of AI @ylecun about the future of AI and the way research, industry, and entrepreneurship can collectively drive innovation. 

Livestream registration right this way: http://Zettavp.com/ai-native
------
France has fast food joints, but slow food still reigns.
------
Which country has the best food? A revealed preference approach.
------
Americans always have reason why problems the rest of the world solved 50 or 100 years ago are impossible to solve.
------
Yes because a city with 380k ppl and no residential over 6 floors makes sense to compare to 8mil ppl and housing density over 20 floors pervasive throughout. You’d need a never ending sidewalk of these bins, 6 times as deep, to do Manhattan trash. twitter.com/benedictevans/…
------
Spotted 
@ylecun
 (or rather the literary embodiment thereof) in the 
@EPFL
 store. Looks like a cracking read.
------
There are many discussions recently about AI, technology, and the future of our civilization. Most takes are biased towards dystopias. But they are just that - different takes. It does not have to be that way. There are other visions of the future, not utopian either, but much… Show more
------
I want a laptop with a tensor processor and a unified memory system that runs Linux.

Basically, something that can run large models without weighing a ton, requiring a separate GPU RAM, draining the battery in minutes, costing a fortune, and running a proprietary OS.
------
[#artificalintelligence] 
@MetaAI
 juste released Code Llama, a large language model.
 
Fabian Glöckle, PhD student at #ecoledespontsparistech working with 
@Amaury_Hayat
, is among the 5 main authors of the article 

#WeAreEELISA
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Interesting read.
------
I don't know if AI will kill us all. 

But will AI lead to regime change and / or state collapse?

Oh, almost definitely.

This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it:

https://secondbest.ca/p/ai-and-leviathan-part-ii…
------
Open research and open source is all you need.
------
At AMLD GenAI, @armandjoulin is telling us how the building of custom language models is increasingly going to be within the reach of smaller teams and orgs. Paired with Angela Fan’s and @jefrankle’s talks yesterday, this paints a picture of a future where LLMs proliferate.
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
Amusing.
------
lolllll

if not for ASML

the whole continent would only produce vapidity
------
Fun with DINOv2
------
Do try out the new depth estimation parallax view, it's trippy
------
What happened in the open-source AI world in August? August is traditionally a slow month...but not for AI it seems! Here is a recap!

Code goes wild
- Just 6 months after LLaMA, 
@MetaAI
 releases Code Llama, a family of LLMs for code https://ai.meta.com/blog/code-llama-large-language-model-coding/…. You can now… Show more
------
My friend and former AT&T colleague John S. Denker designed this game while he was an undergrad at Caltech in the mid 1970s.
It was the first handheld microprocessor-driven game.
Then he left his startup to do a PhD in physics at Caltech and then joined Larry Jackel's group at… Show more
------
I mistyped, John did his PhD at Cornell.
------
Full F16 precision 34B Code Llama at >20 t/s on M2 Ultra
------
DINOv2, the cutting-edge computer vision model trained through self-supervised learning to produce universal features, is now available under the Apache 2.0 license.

Onward with open source AI.
------
Today we’re announcing two new updates in our computer vision work — a new, expanded license for our DINOv2 model and the release of FACET, a comprehensive new benchmark dataset to help evaluate and improve fairness in vision models.

More details  https://bit.ly/3L35E1U


------
Miles Davis performing “Agitations” with Ron Carter on bass, Herbie Hancock on piano, Wayne Shorter on sax and Tonny Williams on drums live in Sweden, 1967.
#Jazz #MilesDavis
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
At some point in the 1980s, Americans started getting screwed.
------
Europeans working fewer hours than Americans is a surprisingly recent phenomenon. In 1950, workers in all the 5 biggest Western European countries worked more than Americans. Now all work less.
------
Oldies but goldies: Hopfield, Neural networks and physical systems with emergent collective computational abilities, 1982. Hopfield networks are recurrent networks minimizing an Ising-type energy parameterized by its weights. https://en.wikipedia.org/wiki/Hopfield_network…
------
Open source AI grants from a16z.
------
[New program] a16z Open Source AI Grants

Hackers & independent devs are massively important to the AI ecosystem.

We're starting a grant funding program so they can continue their work without pressure to generate financial returns.

https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/…
------
Speaking with Jocelyn at the AI Natives event in NYC next Thursday, September 7th.
------
Can’t wait! Next Thu 9/7 @ 1 PM ET I get to chat w/ godfather of AI @ylecun about the future of AI and the way research, industry, and entrepreneurship can collectively drive innovation. 

Livestream registration right this way: http://Zettavp.com/ai-native
------
France has fast food joints, but slow food still reigns.
------
Which country has the best food? A revealed preference approach.
------
Americans always have reason why problems the rest of the world solved 50 or 100 years ago are impossible to solve.
------
Yes because a city with 380k ppl and no residential over 6 floors makes sense to compare to 8mil ppl and housing density over 20 floors pervasive throughout. You’d need a never ending sidewalk of these bins, 6 times as deep, to do Manhattan trash. twitter.com/benedictevans/…
------
Spotted 
@ylecun
 (or rather the literary embodiment thereof) in the 
@EPFL
 store. Looks like a cracking read.
------
There are many discussions recently about AI, technology, and the future of our civilization. Most takes are biased towards dystopias. But they are just that - different takes. It does not have to be that way. There are other visions of the future, not utopian either, but much… Show more
------
I want a laptop with a tensor processor and a unified memory system that runs Linux.

Basically, something that can run large models without weighing a ton, requiring a separate GPU RAM, draining the battery in minutes, costing a fortune, and running a proprietary OS.
------
[#artificalintelligence] 
@MetaAI
 juste released Code Llama, a large language model.
 
Fabian Glöckle, PhD student at #ecoledespontsparistech working with 
@Amaury_Hayat
, is among the 5 main authors of the article 

#WeAreEELISA
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Interesting read.
------
I don't know if AI will kill us all. 

But will AI lead to regime change and / or state collapse?

Oh, almost definitely.

This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it:

https://secondbest.ca/p/ai-and-leviathan-part-ii…
------
Open research and open source is all you need.
------
At AMLD GenAI, @armandjoulin is telling us how the building of custom language models is increasingly going to be within the reach of smaller teams and orgs. Paired with Angela Fan’s and @jefrankle’s talks yesterday, this paints a picture of a future where LLMs proliferate.
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
"Frontier model" is pure hype. I encourage reviewers to insist that authors remove the phrase from their papers. What is on the "frontier" today will not be tomorrow, so it is a guarantee that your title will be wrong (probably even before you get the reviews back).
------
In the interest of open science and sharing our research, we've published a paper outlining the work on our recently released SeamlessM4T all-in-one multilingual & multimodal translation model.

Read the full paper  https://bit.ly/44uzanK
------
From physician to administrative assistant to physician again.
------
Code Llama was just released 4 days ago. Since then, we already got 

1) WizardCoder-34B (https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…)
2) Phind's finetuned CodeLLama-34B (https://phind.com/blog/code-llama-beats-gpt4…)

*Both reported to be surpassing GPT-4 on HumanEval.

The open source community is amazing!
------
Full F16 precision 34B Code Llama at >20 t/s on M2 Ultra
------
DINOv2, the cutting-edge computer vision model trained through self-supervised learning to produce universal features, is now available under the Apache 2.0 license.

Onward with open source AI.
------
Today we’re announcing two new updates in our computer vision work — a new, expanded license for our DINOv2 model and the release of FACET, a comprehensive new benchmark dataset to help evaluate and improve fairness in vision models.

More details  https://bit.ly/3L35E1U


------
Miles Davis performing “Agitations” with Ron Carter on bass, Herbie Hancock on piano, Wayne Shorter on sax and Tonny Williams on drums live in Sweden, 1967.
#Jazz #MilesDavis
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
At some point in the 1980s, Americans started getting screwed.
------
Europeans working fewer hours than Americans is a surprisingly recent phenomenon. In 1950, workers in all the 5 biggest Western European countries worked more than Americans. Now all work less.
------
Oldies but goldies: Hopfield, Neural networks and physical systems with emergent collective computational abilities, 1982. Hopfield networks are recurrent networks minimizing an Ising-type energy parameterized by its weights. https://en.wikipedia.org/wiki/Hopfield_network…
------
Open source AI grants from a16z.
------
[New program] a16z Open Source AI Grants

Hackers & independent devs are massively important to the AI ecosystem.

We're starting a grant funding program so they can continue their work without pressure to generate financial returns.

https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/…
------
Speaking with Jocelyn at the AI Natives event in NYC next Thursday, September 7th.
------
Can’t wait! Next Thu 9/7 @ 1 PM ET I get to chat w/ godfather of AI @ylecun about the future of AI and the way research, industry, and entrepreneurship can collectively drive innovation. 

Livestream registration right this way: http://Zettavp.com/ai-native
------
France has fast food joints, but slow food still reigns.
------
Which country has the best food? A revealed preference approach.
------
Americans always have reason why problems the rest of the world solved 50 or 100 years ago are impossible to solve.
------
Yes because a city with 380k ppl and no residential over 6 floors makes sense to compare to 8mil ppl and housing density over 20 floors pervasive throughout. You’d need a never ending sidewalk of these bins, 6 times as deep, to do Manhattan trash. twitter.com/benedictevans/…
------
Spotted 
@ylecun
 (or rather the literary embodiment thereof) in the 
@EPFL
 store. Looks like a cracking read.
------
There are many discussions recently about AI, technology, and the future of our civilization. Most takes are biased towards dystopias. But they are just that - different takes. It does not have to be that way. There are other visions of the future, not utopian either, but much… Show more
------
I want a laptop with a tensor processor and a unified memory system that runs Linux.

Basically, something that can run large models without weighing a ton, requiring a separate GPU RAM, draining the battery in minutes, costing a fortune, and running a proprietary OS.
------
[#artificalintelligence] 
@MetaAI
 juste released Code Llama, a large language model.
 
Fabian Glöckle, PhD student at #ecoledespontsparistech working with 
@Amaury_Hayat
, is among the 5 main authors of the article 

#WeAreEELISA
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Interesting read.
------
I don't know if AI will kill us all. 

But will AI lead to regime change and / or state collapse?

Oh, almost definitely.

This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it:

https://secondbest.ca/p/ai-and-leviathan-part-ii…
------
Open research and open source is all you need.
------
At AMLD GenAI, @armandjoulin is telling us how the building of custom language models is increasingly going to be within the reach of smaller teams and orgs. Paired with Angela Fan’s and @jefrankle’s talks yesterday, this paints a picture of a future where LLMs proliferate.
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
"Frontier model" is pure hype. I encourage reviewers to insist that authors remove the phrase from their papers. What is on the "frontier" today will not be tomorrow, so it is a guarantee that your title will be wrong (probably even before you get the reviews back).
------
In the interest of open science and sharing our research, we've published a paper outlining the work on our recently released SeamlessM4T all-in-one multilingual & multimodal translation model.

Read the full paper  https://bit.ly/44uzanK
------
From physician to administrative assistant to physician again.
------
Code Llama was just released 4 days ago. Since then, we already got 

1) WizardCoder-34B (https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…)
2) Phind's finetuned CodeLLama-34B (https://phind.com/blog/code-llama-beats-gpt4…)

*Both reported to be surpassing GPT-4 on HumanEval.

The open source community is amazing!
------
We are thrilled to announce that CDS Postdoc Researcher 
@micahgoldblum
 was recently named a finalist for the 2023 Blavatnik Regional Awards for Young Scientists! These awards celebrate the brightest early-career researchers minds in the tri-state area.
------
I'd say *optimization* is the only way to obtain complexity from primeval simplicity.
There are many ways to optimize .
Darwinian evolution (mutate and select among a population) is just one particularly simple and *inefficient* way to perform zeroth-order optimization.
But there… Show more
------
Darwinism is the only known way to derive great complexity from primeval simplicity. It is a brilliant – perhaps the only possible – explanation for our existence. The full episode is here:
https://youtube.com/watch?v=dcellKvotyI… #darwinism #science #thepoetryofreality
------
You can now try Code Llama 34B (the instruct version) in Hugging Chat!

This model works as a great programming assistant. Try it out! (make sure to change the model, as it defaults to Llama 70B)

http://hf.co/chat
------
ChatGPT or Code Llama? 
Try out Code Llama for free at http://hf.co/chat
------
open source is catching up 
------
At some point in the 1980s, Americans started getting screwed.
------
Europeans working fewer hours than Americans is a surprisingly recent phenomenon. In 1950, workers in all the 5 biggest Western European countries worked more than Americans. Now all work less.
------
Oldies but goldies: Hopfield, Neural networks and physical systems with emergent collective computational abilities, 1982. Hopfield networks are recurrent networks minimizing an Ising-type energy parameterized by its weights. https://en.wikipedia.org/wiki/Hopfield_network…
------
Open source AI grants from a16z.
------
[New program] a16z Open Source AI Grants

Hackers & independent devs are massively important to the AI ecosystem.

We're starting a grant funding program so they can continue their work without pressure to generate financial returns.

https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/…
------
Speaking with Jocelyn at the AI Natives event in NYC next Thursday, September 7th.
------
Can’t wait! Next Thu 9/7 @ 1 PM ET I get to chat w/ godfather of AI @ylecun about the future of AI and the way research, industry, and entrepreneurship can collectively drive innovation. 

Livestream registration right this way: http://Zettavp.com/ai-native
------
France has fast food joints, but slow food still reigns.
------
Which country has the best food? A revealed preference approach.
------
Americans always have reason why problems the rest of the world solved 50 or 100 years ago are impossible to solve.
------
Yes because a city with 380k ppl and no residential over 6 floors makes sense to compare to 8mil ppl and housing density over 20 floors pervasive throughout. You’d need a never ending sidewalk of these bins, 6 times as deep, to do Manhattan trash. twitter.com/benedictevans/…
------
Spotted 
@ylecun
 (or rather the literary embodiment thereof) in the 
@EPFL
 store. Looks like a cracking read.
------
There are many discussions recently about AI, technology, and the future of our civilization. Most takes are biased towards dystopias. But they are just that - different takes. It does not have to be that way. There are other visions of the future, not utopian either, but much… Show more
------
I want a laptop with a tensor processor and a unified memory system that runs Linux.

Basically, something that can run large models without weighing a ton, requiring a separate GPU RAM, draining the battery in minutes, costing a fortune, and running a proprietary OS.
------
[#artificalintelligence] 
@MetaAI
 juste released Code Llama, a large language model.
 
Fabian Glöckle, PhD student at #ecoledespontsparistech working with 
@Amaury_Hayat
, is among the 5 main authors of the article 

#WeAreEELISA
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Interesting read.
------
I don't know if AI will kill us all. 

But will AI lead to regime change and / or state collapse?

Oh, almost definitely.

This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it:

https://secondbest.ca/p/ai-and-leviathan-part-ii…
------
Open research and open source is all you need.
------
At AMLD GenAI, @armandjoulin is telling us how the building of custom language models is increasingly going to be within the reach of smaller teams and orgs. Paired with Angela Fan’s and @jefrankle’s talks yesterday, this paints a picture of a future where LLMs proliferate.
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
"Frontier model" is pure hype. I encourage reviewers to insist that authors remove the phrase from their papers. What is on the "frontier" today will not be tomorrow, so it is a guarantee that your title will be wrong (probably even before you get the reviews back).
------
In the interest of open science and sharing our research, we've published a paper outlining the work on our recently released SeamlessM4T all-in-one multilingual & multimodal translation model.

Read the full paper  https://bit.ly/44uzanK
------
From physician to administrative assistant to physician again.
------
Code Llama was just released 4 days ago. Since then, we already got 

1) WizardCoder-34B (https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…)
2) Phind's finetuned CodeLLama-34B (https://phind.com/blog/code-llama-beats-gpt4…)

*Both reported to be surpassing GPT-4 on HumanEval.

The open source community is amazing!
------
We are thrilled to announce that CDS Postdoc Researcher 
@micahgoldblum
 was recently named a finalist for the 2023 Blavatnik Regional Awards for Young Scientists! These awards celebrate the brightest early-career researchers minds in the tri-state area.
------
I'd say *optimization* is the only way to obtain complexity from primeval simplicity.
There are many ways to optimize .
Darwinian evolution (mutate and select among a population) is just one particularly simple and *inefficient* way to perform zeroth-order optimization.
But there… Show more
------
Darwinism is the only known way to derive great complexity from primeval simplicity. It is a brilliant – perhaps the only possible – explanation for our existence. The full episode is here:
https://youtube.com/watch?v=dcellKvotyI… #darwinism #science #thepoetryofreality
------
You can now try Code Llama 34B (the instruct version) in Hugging Chat!

This model works as a great programming assistant. Try it out! (make sure to change the model, as it defaults to Llama 70B)

http://hf.co/chat
------
This is not wrong.
------
Some of the best startup ideas live in a grey area of legality. Airbnb, Uber, Lyft, YouTube, Coinbase were all somewhere between questionable and flat-out illegal in their early days.

One reason for this is that incumbents cannot take any legal risk on a new initiative.  Even if… Show more
------
France has fast food joints, but slow food still reigns.
------
Which country has the best food? A revealed preference approach.
------
Americans always have reason why problems the rest of the world solved 50 or 100 years ago are impossible to solve.
------
Yes because a city with 380k ppl and no residential over 6 floors makes sense to compare to 8mil ppl and housing density over 20 floors pervasive throughout. You’d need a never ending sidewalk of these bins, 6 times as deep, to do Manhattan trash. twitter.com/benedictevans/…
------
Spotted 
@ylecun
 (or rather the literary embodiment thereof) in the 
@EPFL
 store. Looks like a cracking read.
------
There are many discussions recently about AI, technology, and the future of our civilization. Most takes are biased towards dystopias. But they are just that - different takes. It does not have to be that way. There are other visions of the future, not utopian either, but much… Show more
------
I want a laptop with a tensor processor and a unified memory system that runs Linux.

Basically, something that can run large models without weighing a ton, requiring a separate GPU RAM, draining the battery in minutes, costing a fortune, and running a proprietary OS.
------
[#artificalintelligence] 
@MetaAI
 juste released Code Llama, a large language model.
 
Fabian Glöckle, PhD student at #ecoledespontsparistech working with 
@Amaury_Hayat
, is among the 5 main authors of the article 

#WeAreEELISA
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Interesting read.
------
I don't know if AI will kill us all. 

But will AI lead to regime change and / or state collapse?

Oh, almost definitely.

This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it:

https://secondbest.ca/p/ai-and-leviathan-part-ii…
------
Open research and open source is all you need.
------
At AMLD GenAI, @armandjoulin is telling us how the building of custom language models is increasingly going to be within the reach of smaller teams and orgs. Paired with Angela Fan’s and @jefrankle’s talks yesterday, this paints a picture of a future where LLMs proliferate.
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
"Frontier model" is pure hype. I encourage reviewers to insist that authors remove the phrase from their papers. What is on the "frontier" today will not be tomorrow, so it is a guarantee that your title will be wrong (probably even before you get the reviews back).
------
In the interest of open science and sharing our research, we've published a paper outlining the work on our recently released SeamlessM4T all-in-one multilingual & multimodal translation model.

Read the full paper  https://bit.ly/44uzanK
------
From physician to administrative assistant to physician again.
------
Code Llama was just released 4 days ago. Since then, we already got 

1) WizardCoder-34B (https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…)
2) Phind's finetuned CodeLLama-34B (https://phind.com/blog/code-llama-beats-gpt4…)

*Both reported to be surpassing GPT-4 on HumanEval.

The open source community is amazing!
------
We are thrilled to announce that CDS Postdoc Researcher 
@micahgoldblum
 was recently named a finalist for the 2023 Blavatnik Regional Awards for Young Scientists! These awards celebrate the brightest early-career researchers minds in the tri-state area.
------
I'd say *optimization* is the only way to obtain complexity from primeval simplicity.
There are many ways to optimize .
Darwinian evolution (mutate and select among a population) is just one particularly simple and *inefficient* way to perform zeroth-order optimization.
But there… Show more
------
Darwinism is the only known way to derive great complexity from primeval simplicity. It is a brilliant – perhaps the only possible – explanation for our existence. The full episode is here:
https://youtube.com/watch?v=dcellKvotyI… #darwinism #science #thepoetryofreality
------
You can now try Code Llama 34B (the instruct version) in Hugging Chat!

This model works as a great programming assistant. Try it out! (make sure to change the model, as it defaults to Llama 70B)

http://hf.co/chat
------
This is not wrong.
------
Some of the best startup ideas live in a grey area of legality. Airbnb, Uber, Lyft, YouTube, Coinbase were all somewhere between questionable and flat-out illegal in their early days.

One reason for this is that incumbents cannot take any legal risk on a new initiative.  Even if… Show more
------
Well, technically, LLaMa was *born* in Paris.
Llama-2's origins are more complicated.
------
I just made this with https://hf.co/spaces/jbilcke-hf/comic-factory… in a minute

"A group of llamas visiting Paris for the first time"
------
OMG, we're all gonna die because of...
...telegraph wires.
------
2023: The New York Times cites seriously academics who say AI might end the world 

1881: The New York Times cites seriously academics who say telegraphy might end the world https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
Telegraph doomers !
Encircling the earth with telegraph wires was going to cause the end of the world. Apparently.
------
https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
How the world has changed over the last century.

A compilation of some of our greatest accomplishments as a species.

Credit: 
@toddrjones
 https://toddrjones.com/dataviz/
------
Obviously.
------
France is undoubtedly the greatest country on earth and it’s not even close. If you disagree you’ve never spent 5 hours at the table drinking and eating.
------
An excellent essay on how generative AI may change the way we view creation, art, copyright, intellectual property, and revenues derived from that.
Current laws are probably inadequate.
------
If you put all the world’s knowledge into an AI model and use it to make something new, who owns that and who gets paid? This is a completely new problem that we’ve been arguing about for 500 years. A new essay.
https://ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property…
------
None that I know of.
------
Are there any real AI researchers who actually believe in "FOOM"? The concept seems to have a ton of traction in AI doomer Twitter, but I've never heard anyone in academia or industry mention it except as a lark.
------
I'm proud of the progress that 
@DemRedistrict
 has made in the fight for fair maps. Their work is protecting our democracy, and ensuring that maps are drawn in a way that allows voters to select their representatives, not the other way around.
------
Iterating filters with small supports is equivalent to using a filter with an increasing size. https://en.wikipedia.org/wiki/Convolution…
------
[#artificalintelligence] 
@MetaAI
 juste released Code Llama, a large language model.
 
Fabian Glöckle, PhD student at #ecoledespontsparistech working with 
@Amaury_Hayat
, is among the 5 main authors of the article 

#WeAreEELISA
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Interesting read.
------
I don't know if AI will kill us all. 

But will AI lead to regime change and / or state collapse?

Oh, almost definitely.

This less-than- existential but far more certain risk is strangely neglected in the safety debate. So I wrote about it:

https://secondbest.ca/p/ai-and-leviathan-part-ii…
------
Open research and open source is all you need.
------
At AMLD GenAI, @armandjoulin is telling us how the building of custom language models is increasingly going to be within the reach of smaller teams and orgs. Paired with Angela Fan’s and @jefrankle’s talks yesterday, this paints a picture of a future where LLMs proliferate.
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
"Frontier model" is pure hype. I encourage reviewers to insist that authors remove the phrase from their papers. What is on the "frontier" today will not be tomorrow, so it is a guarantee that your title will be wrong (probably even before you get the reviews back).
------
In the interest of open science and sharing our research, we've published a paper outlining the work on our recently released SeamlessM4T all-in-one multilingual & multimodal translation model.

Read the full paper  https://bit.ly/44uzanK
------
From physician to administrative assistant to physician again.
------
Code Llama was just released 4 days ago. Since then, we already got 

1) WizardCoder-34B (https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…)
2) Phind's finetuned CodeLLama-34B (https://phind.com/blog/code-llama-beats-gpt4…)

*Both reported to be surpassing GPT-4 on HumanEval.

The open source community is amazing!
------
We are thrilled to announce that CDS Postdoc Researcher 
@micahgoldblum
 was recently named a finalist for the 2023 Blavatnik Regional Awards for Young Scientists! These awards celebrate the brightest early-career researchers minds in the tri-state area.
------
I'd say *optimization* is the only way to obtain complexity from primeval simplicity.
There are many ways to optimize .
Darwinian evolution (mutate and select among a population) is just one particularly simple and *inefficient* way to perform zeroth-order optimization.
But there… Show more
------
Darwinism is the only known way to derive great complexity from primeval simplicity. It is a brilliant – perhaps the only possible – explanation for our existence. The full episode is here:
https://youtube.com/watch?v=dcellKvotyI… #darwinism #science #thepoetryofreality
------
You can now try Code Llama 34B (the instruct version) in Hugging Chat!

This model works as a great programming assistant. Try it out! (make sure to change the model, as it defaults to Llama 70B)

http://hf.co/chat
------
This is not wrong.
------
Some of the best startup ideas live in a grey area of legality. Airbnb, Uber, Lyft, YouTube, Coinbase were all somewhere between questionable and flat-out illegal in their early days.

One reason for this is that incumbents cannot take any legal risk on a new initiative.  Even if… Show more
------
Well, technically, LLaMa was *born* in Paris.
Llama-2's origins are more complicated.
------
I just made this with https://hf.co/spaces/jbilcke-hf/comic-factory… in a minute

"A group of llamas visiting Paris for the first time"
------
OMG, we're all gonna die because of...
...telegraph wires.
------
2023: The New York Times cites seriously academics who say AI might end the world 

1881: The New York Times cites seriously academics who say telegraphy might end the world https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
Telegraph doomers !
Encircling the earth with telegraph wires was going to cause the end of the world. Apparently.
------
https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
How the world has changed over the last century.

A compilation of some of our greatest accomplishments as a species.

Credit: 
@toddrjones
 https://toddrjones.com/dataviz/
------
Obviously.
------
France is undoubtedly the greatest country on earth and it’s not even close. If you disagree you’ve never spent 5 hours at the table drinking and eating.
------
An excellent essay on how generative AI may change the way we view creation, art, copyright, intellectual property, and revenues derived from that.
Current laws are probably inadequate.
------
If you put all the world’s knowledge into an AI model and use it to make something new, who owns that and who gets paid? This is a completely new problem that we’ve been arguing about for 500 years. A new essay.
https://ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property…
------
None that I know of.
------
Are there any real AI researchers who actually believe in "FOOM"? The concept seems to have a ton of traction in AI doomer Twitter, but I've never heard anyone in academia or industry mention it except as a lark.
------
I'm proud of the progress that 
@DemRedistrict
 has made in the fight for fair maps. Their work is protecting our democracy, and ensuring that maps are drawn in a way that allows voters to select their representatives, not the other way around.
------
Iterating filters with small supports is equivalent to using a filter with an increasing size. https://en.wikipedia.org/wiki/Convolution…
------
This 
------
the best conversations i've had about "ai risk" have been with integrity people from social media companies, they have the most experience with having complex systems behave in unintended ways and also deal with internal pressures eg. incentives of other teams to get metrics up
------
Llama 2, CodeLlama, and leaked GPT-4 details. 

Here's my new write-up on the noteworthy developments around LLMs of this summer so far:
------
It didn't take 48 hours for the open source community to fine-tune Code Llama to beat GPT-4 (March) version on Humal Eval! 

https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0… 

Model comes from the awesome 
@WizardLM_AI
 group! 
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
Einstein was incredibly smart and loved sailing.
Yet his sailing skills were so bad that his family was terrified every time he went sailing.

Can we finally abandon the whole idea that intelligence is a one-dimensional quantity?
------
"Frontier model" is pure hype. I encourage reviewers to insist that authors remove the phrase from their papers. What is on the "frontier" today will not be tomorrow, so it is a guarantee that your title will be wrong (probably even before you get the reviews back).
------
In the interest of open science and sharing our research, we've published a paper outlining the work on our recently released SeamlessM4T all-in-one multilingual & multimodal translation model.

Read the full paper  https://bit.ly/44uzanK
------
From physician to administrative assistant to physician again.
------
Code Llama was just released 4 days ago. Since then, we already got 

1) WizardCoder-34B (https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…)
2) Phind's finetuned CodeLLama-34B (https://phind.com/blog/code-llama-beats-gpt4…)

*Both reported to be surpassing GPT-4 on HumanEval.

The open source community is amazing!
------
We are thrilled to announce that CDS Postdoc Researcher 
@micahgoldblum
 was recently named a finalist for the 2023 Blavatnik Regional Awards for Young Scientists! These awards celebrate the brightest early-career researchers minds in the tri-state area.
------
I'd say *optimization* is the only way to obtain complexity from primeval simplicity.
There are many ways to optimize .
Darwinian evolution (mutate and select among a population) is just one particularly simple and *inefficient* way to perform zeroth-order optimization.
But there… Show more
------
Darwinism is the only known way to derive great complexity from primeval simplicity. It is a brilliant – perhaps the only possible – explanation for our existence. The full episode is here:
https://youtube.com/watch?v=dcellKvotyI… #darwinism #science #thepoetryofreality
------
You can now try Code Llama 34B (the instruct version) in Hugging Chat!

This model works as a great programming assistant. Try it out! (make sure to change the model, as it defaults to Llama 70B)

http://hf.co/chat
------
This is not wrong.
------
Some of the best startup ideas live in a grey area of legality. Airbnb, Uber, Lyft, YouTube, Coinbase were all somewhere between questionable and flat-out illegal in their early days.

One reason for this is that incumbents cannot take any legal risk on a new initiative.  Even if… Show more
------
Well, technically, LLaMa was *born* in Paris.
Llama-2's origins are more complicated.
------
I just made this with https://hf.co/spaces/jbilcke-hf/comic-factory… in a minute

"A group of llamas visiting Paris for the first time"
------
OMG, we're all gonna die because of...
...telegraph wires.
------
2023: The New York Times cites seriously academics who say AI might end the world 

1881: The New York Times cites seriously academics who say telegraphy might end the world https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
Telegraph doomers !
Encircling the earth with telegraph wires was going to cause the end of the world. Apparently.
------
https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
How the world has changed over the last century.

A compilation of some of our greatest accomplishments as a species.

Credit: 
@toddrjones
 https://toddrjones.com/dataviz/
------
Obviously.
------
France is undoubtedly the greatest country on earth and it’s not even close. If you disagree you’ve never spent 5 hours at the table drinking and eating.
------
An excellent essay on how generative AI may change the way we view creation, art, copyright, intellectual property, and revenues derived from that.
Current laws are probably inadequate.
------
If you put all the world’s knowledge into an AI model and use it to make something new, who owns that and who gets paid? This is a completely new problem that we’ve been arguing about for 500 years. A new essay.
https://ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property…
------
None that I know of.
------
Are there any real AI researchers who actually believe in "FOOM"? The concept seems to have a ton of traction in AI doomer Twitter, but I've never heard anyone in academia or industry mention it except as a lark.
------
I'm proud of the progress that 
@DemRedistrict
 has made in the fight for fair maps. Their work is protecting our democracy, and ensuring that maps are drawn in a way that allows voters to select their representatives, not the other way around.
------
Iterating filters with small supports is equivalent to using a filter with an increasing size. https://en.wikipedia.org/wiki/Convolution…
------
This 
------
the best conversations i've had about "ai risk" have been with integrity people from social media companies, they have the most experience with having complex systems behave in unintended ways and also deal with internal pressures eg. incentives of other teams to get metrics up
------
Llama 2, CodeLlama, and leaked GPT-4 details. 

Here's my new write-up on the noteworthy developments around LLMs of this summer so far:
------
It didn't take 48 hours for the open source community to fine-tune Code Llama to beat GPT-4 (March) version on Humal Eval! 

https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0… 

Model comes from the awesome 
@WizardLM_AI
 group! 
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
It's nice to see how quickly the open-source community was able to build on CodeLlama to surpass GPT4 on HumanEval!
------

Introduce the newest WizardCoder 34B based on Code Llama.

WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1

Demo: http://47.103.63.15:50085/
Model Weights: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0…
Github: https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…

The 13B/7B… Show more
------
We evaluated Code Llama against existing solutions on both HumanEval & MBPP.
- It performed better than open-source, code-specific LLMs & Llama 2.
- Code Llama 34B scored the highest vs other SOTA open solutions on MBPP — on par w/ ChatGPT.

More info  https://bit.ly/45JiPwJ
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
We are thrilled to announce that CDS Postdoc Researcher 
@micahgoldblum
 was recently named a finalist for the 2023 Blavatnik Regional Awards for Young Scientists! These awards celebrate the brightest early-career researchers minds in the tri-state area.
------
I'd say *optimization* is the only way to obtain complexity from primeval simplicity.
There are many ways to optimize .
Darwinian evolution (mutate and select among a population) is just one particularly simple and *inefficient* way to perform zeroth-order optimization.
But there… Show more
------
Darwinism is the only known way to derive great complexity from primeval simplicity. It is a brilliant – perhaps the only possible – explanation for our existence. The full episode is here:
https://youtube.com/watch?v=dcellKvotyI… #darwinism #science #thepoetryofreality
------
You can now try Code Llama 34B (the instruct version) in Hugging Chat!

This model works as a great programming assistant. Try it out! (make sure to change the model, as it defaults to Llama 70B)

http://hf.co/chat
------
This is not wrong.
------
Some of the best startup ideas live in a grey area of legality. Airbnb, Uber, Lyft, YouTube, Coinbase were all somewhere between questionable and flat-out illegal in their early days.

One reason for this is that incumbents cannot take any legal risk on a new initiative.  Even if… Show more
------
Well, technically, LLaMa was *born* in Paris.
Llama-2's origins are more complicated.
------
I just made this with https://hf.co/spaces/jbilcke-hf/comic-factory… in a minute

"A group of llamas visiting Paris for the first time"
------
OMG, we're all gonna die because of...
...telegraph wires.
------
2023: The New York Times cites seriously academics who say AI might end the world 

1881: The New York Times cites seriously academics who say telegraphy might end the world https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
Telegraph doomers !
Encircling the earth with telegraph wires was going to cause the end of the world. Apparently.
------
https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
How the world has changed over the last century.

A compilation of some of our greatest accomplishments as a species.

Credit: 
@toddrjones
 https://toddrjones.com/dataviz/
------
Obviously.
------
France is undoubtedly the greatest country on earth and it’s not even close. If you disagree you’ve never spent 5 hours at the table drinking and eating.
------
An excellent essay on how generative AI may change the way we view creation, art, copyright, intellectual property, and revenues derived from that.
Current laws are probably inadequate.
------
If you put all the world’s knowledge into an AI model and use it to make something new, who owns that and who gets paid? This is a completely new problem that we’ve been arguing about for 500 years. A new essay.
https://ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property…
------
None that I know of.
------
Are there any real AI researchers who actually believe in "FOOM"? The concept seems to have a ton of traction in AI doomer Twitter, but I've never heard anyone in academia or industry mention it except as a lark.
------
I'm proud of the progress that 
@DemRedistrict
 has made in the fight for fair maps. Their work is protecting our democracy, and ensuring that maps are drawn in a way that allows voters to select their representatives, not the other way around.
------
Iterating filters with small supports is equivalent to using a filter with an increasing size. https://en.wikipedia.org/wiki/Convolution…
------
This 
------
the best conversations i've had about "ai risk" have been with integrity people from social media companies, they have the most experience with having complex systems behave in unintended ways and also deal with internal pressures eg. incentives of other teams to get metrics up
------
Llama 2, CodeLlama, and leaked GPT-4 details. 

Here's my new write-up on the noteworthy developments around LLMs of this summer so far:
------
It didn't take 48 hours for the open source community to fine-tune Code Llama to beat GPT-4 (March) version on Humal Eval! 

https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0… 

Model comes from the awesome 
@WizardLM_AI
 group! 
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
It's nice to see how quickly the open-source community was able to build on CodeLlama to surpass GPT4 on HumanEval!
------

Introduce the newest WizardCoder 34B based on Code Llama.

WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1

Demo: http://47.103.63.15:50085/
Model Weights: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0…
Github: https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…

The 13B/7B… Show more
------
We evaluated Code Llama against existing solutions on both HumanEval & MBPP.
- It performed better than open-source, code-specific LLMs & Llama 2.
- Code Llama 34B scored the highest vs other SOTA open solutions on MBPP — on par w/ ChatGPT.

More info  https://bit.ly/45JiPwJ
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
Welcome Code LLama to 
@huggingface
! 

Blog post: https://hf.co/blog/codellama
Models: https://hf.co/codellama
Code playground: https://hf.co/spaces/codellama/codellama-playground…
Chat playground: https://hf.co/spaces/codellama/codellama-13b-chat…
------
Added a paragraph on the impact of the Manhattan project's secrecy on the nuclear arms race to my blog post https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/…
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
This is not wrong.
------
Some of the best startup ideas live in a grey area of legality. Airbnb, Uber, Lyft, YouTube, Coinbase were all somewhere between questionable and flat-out illegal in their early days.

One reason for this is that incumbents cannot take any legal risk on a new initiative.  Even if… Show more
------
Well, technically, LLaMa was *born* in Paris.
Llama-2's origins are more complicated.
------
I just made this with https://hf.co/spaces/jbilcke-hf/comic-factory… in a minute

"A group of llamas visiting Paris for the first time"
------
OMG, we're all gonna die because of...
...telegraph wires.
------
2023: The New York Times cites seriously academics who say AI might end the world 

1881: The New York Times cites seriously academics who say telegraphy might end the world https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
Telegraph doomers !
Encircling the earth with telegraph wires was going to cause the end of the world. Apparently.
------
https://newsletter.pessimistsarchive.org/p/telegraph-doomers-of-the-19th-century…
------
How the world has changed over the last century.

A compilation of some of our greatest accomplishments as a species.

Credit: 
@toddrjones
 https://toddrjones.com/dataviz/
------
Obviously.
------
France is undoubtedly the greatest country on earth and it’s not even close. If you disagree you’ve never spent 5 hours at the table drinking and eating.
------
An excellent essay on how generative AI may change the way we view creation, art, copyright, intellectual property, and revenues derived from that.
Current laws are probably inadequate.
------
If you put all the world’s knowledge into an AI model and use it to make something new, who owns that and who gets paid? This is a completely new problem that we’ve been arguing about for 500 years. A new essay.
https://ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property…
------
None that I know of.
------
Are there any real AI researchers who actually believe in "FOOM"? The concept seems to have a ton of traction in AI doomer Twitter, but I've never heard anyone in academia or industry mention it except as a lark.
------
I'm proud of the progress that 
@DemRedistrict
 has made in the fight for fair maps. Their work is protecting our democracy, and ensuring that maps are drawn in a way that allows voters to select their representatives, not the other way around.
------
Iterating filters with small supports is equivalent to using a filter with an increasing size. https://en.wikipedia.org/wiki/Convolution…
------
This 
------
the best conversations i've had about "ai risk" have been with integrity people from social media companies, they have the most experience with having complex systems behave in unintended ways and also deal with internal pressures eg. incentives of other teams to get metrics up
------
Llama 2, CodeLlama, and leaked GPT-4 details. 

Here's my new write-up on the noteworthy developments around LLMs of this summer so far:
------
It didn't take 48 hours for the open source community to fine-tune Code Llama to beat GPT-4 (March) version on Humal Eval! 

https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0… 

Model comes from the awesome 
@WizardLM_AI
 group! 
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
It's nice to see how quickly the open-source community was able to build on CodeLlama to surpass GPT4 on HumanEval!
------

Introduce the newest WizardCoder 34B based on Code Llama.

WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1

Demo: http://47.103.63.15:50085/
Model Weights: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0…
Github: https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…

The 13B/7B… Show more
------
We evaluated Code Llama against existing solutions on both HumanEval & MBPP.
- It performed better than open-source, code-specific LLMs & Llama 2.
- Code Llama 34B scored the highest vs other SOTA open solutions on MBPP — on par w/ ChatGPT.

More info  https://bit.ly/45JiPwJ
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
Welcome Code LLama to 
@huggingface
! 

Blog post: https://hf.co/blog/codellama
Models: https://hf.co/codellama
Code playground: https://hf.co/spaces/codellama/codellama-playground…
Chat playground: https://hf.co/spaces/codellama/codellama-13b-chat…
------
Added a paragraph on the impact of the Manhattan project's secrecy on the nuclear arms race to my blog post https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/…
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
Code Llama with 
@huggingface
 Yesterday, 
@MetaAI
 released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
Obviously.
------
France is undoubtedly the greatest country on earth and it’s not even close. If you disagree you’ve never spent 5 hours at the table drinking and eating.
------
An excellent essay on how generative AI may change the way we view creation, art, copyright, intellectual property, and revenues derived from that.
Current laws are probably inadequate.
------
If you put all the world’s knowledge into an AI model and use it to make something new, who owns that and who gets paid? This is a completely new problem that we’ve been arguing about for 500 years. A new essay.
https://ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property…
------
None that I know of.
------
Are there any real AI researchers who actually believe in "FOOM"? The concept seems to have a ton of traction in AI doomer Twitter, but I've never heard anyone in academia or industry mention it except as a lark.
------
I'm proud of the progress that 
@DemRedistrict
 has made in the fight for fair maps. Their work is protecting our democracy, and ensuring that maps are drawn in a way that allows voters to select their representatives, not the other way around.
------
Iterating filters with small supports is equivalent to using a filter with an increasing size. https://en.wikipedia.org/wiki/Convolution…
------
This 
------
the best conversations i've had about "ai risk" have been with integrity people from social media companies, they have the most experience with having complex systems behave in unintended ways and also deal with internal pressures eg. incentives of other teams to get metrics up
------
Llama 2, CodeLlama, and leaked GPT-4 details. 

Here's my new write-up on the noteworthy developments around LLMs of this summer so far:
------
It didn't take 48 hours for the open source community to fine-tune Code Llama to beat GPT-4 (March) version on Humal Eval! 

https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0… 

Model comes from the awesome 
@WizardLM_AI
 group! 
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
It's nice to see how quickly the open-source community was able to build on CodeLlama to surpass GPT4 on HumanEval!
------

Introduce the newest WizardCoder 34B based on Code Llama.

WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1

Demo: http://47.103.63.15:50085/
Model Weights: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0…
Github: https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…

The 13B/7B… Show more
------
We evaluated Code Llama against existing solutions on both HumanEval & MBPP.
- It performed better than open-source, code-specific LLMs & Llama 2.
- Code Llama 34B scored the highest vs other SOTA open solutions on MBPP — on par w/ ChatGPT.

More info  https://bit.ly/45JiPwJ
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
Welcome Code LLama to 
@huggingface
! 

Blog post: https://hf.co/blog/codellama
Models: https://hf.co/codellama
Code playground: https://hf.co/spaces/codellama/codellama-playground…
Chat playground: https://hf.co/spaces/codellama/codellama-13b-chat…
------
Added a paragraph on the impact of the Manhattan project's secrecy on the nuclear arms race to my blog post https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/…
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
Code Llama with 
@huggingface
 Yesterday, 
@MetaAI
 released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
You can try Code Llama now in the Code Llama playground 
@huggingface
 space — it's also available in the Hugging Face ecosystem, starting with transformers version 4.33.
------
Code Llama with @huggingface Yesterday, @MetaAI released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
Deep Learning textbook: making progress chapter by chapter.
------
«Chapter 6»
In this chapter, we'll introduce several geometric structures, over which functions are defined, and whose properties can be exploited to reduce computations and ease learning, giving rise to several architecture families we'll cover in this part of the book.
------
Turned 22 times at 22:22 
#aianimation
------
On the top of being a bold step forward in GenAI, this is a great example of comprehensive red teaming and robustness analysis on LLMs. Proud of the Responsible AI teams that were part of this achievement!
------
Today we’re releasing Code Llama, a large language model built on top of Llama 2, fine-tuned for coding & state-of-the-art for publicly available coding tools.

Keeping with our open approach, Code Llama is publicly-available now for both research & commercial use.

More 
------
Code LLaMA has good results and good eval. It's cool to see PPL decrease all the way  up to 100K tokens (after finetuning on 100K token-long inputs). 

Facebook is close to replicating GPT-4 performance on HumanEval. Great news for the open source/science communities!
------
Thanks, 
@sapinker
------
Agree with this... twitter.com/ylecun/status/…
------
This 
------
the best conversations i've had about "ai risk" have been with integrity people from social media companies, they have the most experience with having complex systems behave in unintended ways and also deal with internal pressures eg. incentives of other teams to get metrics up
------
Llama 2, CodeLlama, and leaked GPT-4 details. 

Here's my new write-up on the noteworthy developments around LLMs of this summer so far:
------
It didn't take 48 hours for the open source community to fine-tune Code Llama to beat GPT-4 (March) version on Humal Eval! 

https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0… 

Model comes from the awesome 
@WizardLM_AI
 group! 
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
It's nice to see how quickly the open-source community was able to build on CodeLlama to surpass GPT4 on HumanEval!
------

Introduce the newest WizardCoder 34B based on Code Llama.

WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1

Demo: http://47.103.63.15:50085/
Model Weights: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0…
Github: https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…

The 13B/7B… Show more
------
We evaluated Code Llama against existing solutions on both HumanEval & MBPP.
- It performed better than open-source, code-specific LLMs & Llama 2.
- Code Llama 34B scored the highest vs other SOTA open solutions on MBPP — on par w/ ChatGPT.

More info  https://bit.ly/45JiPwJ
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
Welcome Code LLama to 
@huggingface
! 

Blog post: https://hf.co/blog/codellama
Models: https://hf.co/codellama
Code playground: https://hf.co/spaces/codellama/codellama-playground…
Chat playground: https://hf.co/spaces/codellama/codellama-13b-chat…
------
Added a paragraph on the impact of the Manhattan project's secrecy on the nuclear arms race to my blog post https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/…
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
Code Llama with 
@huggingface
 Yesterday, 
@MetaAI
 released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
You can try Code Llama now in the Code Llama playground 
@huggingface
 space — it's also available in the Hugging Face ecosystem, starting with transformers version 4.33.
------
Code Llama with @huggingface Yesterday, @MetaAI released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
Deep Learning textbook: making progress chapter by chapter.
------
«Chapter 6»
In this chapter, we'll introduce several geometric structures, over which functions are defined, and whose properties can be exploited to reduce computations and ease learning, giving rise to several architecture families we'll cover in this part of the book.
------
Turned 22 times at 22:22 
#aianimation
------
On the top of being a bold step forward in GenAI, this is a great example of comprehensive red teaming and robustness analysis on LLMs. Proud of the Responsible AI teams that were part of this achievement!
------
Today we’re releasing Code Llama, a large language model built on top of Llama 2, fine-tuned for coding & state-of-the-art for publicly available coding tools.

Keeping with our open approach, Code Llama is publicly-available now for both research & commercial use.

More 
------
Code LLaMA has good results and good eval. It's cool to see PPL decrease all the way  up to 100K tokens (after finetuning on 100K token-long inputs). 

Facebook is close to replicating GPT-4 performance on HumanEval. Great news for the open source/science communities!
------
Thanks, 
@sapinker
------
Agree with this... twitter.com/ylecun/status/…
------
Once AI systems become more intelligent than humans, humans we will *still* be the "apex species."

Equating intelligence with dominance is the main fallacy of the whole debate about AI existential risk.
It's just wrong.
Even *within* the human species It's wrong: it's *not* the… Show more
------
Technically, it's 
@syhw
 et al.
------
I cannot believe zuck et al just beat gpt 3.5 at humaneval pass@1 and is approaching gpt4 with only 34b params

(47 pages, therefore reaction thread - code llama)
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try 
@MetaAI
’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Added CodeLLaMa-34B-instruct to http://labs.pplx.ai, give it a spin!

Thanks for the great work 
@MetaAI
 , 
@ylecun
 , 
@jnsgehring
 et al.
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try @MetaAI’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Just me and my brother sailing.
------
Scientists of Twitter! The world needs more reminders that we're living, breathing human beings. 

Quote tweet this with a picture of you doing not-science  twitter.com/vivosaur/statu…
------
It's nice to see how quickly the open-source community was able to build on CodeLlama to surpass GPT4 on HumanEval!
------

Introduce the newest WizardCoder 34B based on Code Llama.

WizardCoder-34B surpasses GPT-4, ChatGPT-3.5 and Claude-2 on HumanEval with 73.2% pass@1

Demo: http://47.103.63.15:50085/
Model Weights: https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0…
Github: https://github.com/nlpxucan/WizardLM/tree/main/WizardCoder…

The 13B/7B… Show more
------
We evaluated Code Llama against existing solutions on both HumanEval & MBPP.
- It performed better than open-source, code-specific LLMs & Llama 2.
- Code Llama 34B scored the highest vs other SOTA open solutions on MBPP — on par w/ ChatGPT.

More info  https://bit.ly/45JiPwJ
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
Welcome Code LLama to 
@huggingface
! 

Blog post: https://hf.co/blog/codellama
Models: https://hf.co/codellama
Code playground: https://hf.co/spaces/codellama/codellama-playground…
Chat playground: https://hf.co/spaces/codellama/codellama-13b-chat…
------
Added a paragraph on the impact of the Manhattan project's secrecy on the nuclear arms race to my blog post https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/…
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
Code Llama with 
@huggingface
 Yesterday, 
@MetaAI
 released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
You can try Code Llama now in the Code Llama playground 
@huggingface
 space — it's also available in the Hugging Face ecosystem, starting with transformers version 4.33.
------
Code Llama with @huggingface Yesterday, @MetaAI released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
Deep Learning textbook: making progress chapter by chapter.
------
«Chapter 6»
In this chapter, we'll introduce several geometric structures, over which functions are defined, and whose properties can be exploited to reduce computations and ease learning, giving rise to several architecture families we'll cover in this part of the book.
------
Turned 22 times at 22:22 
#aianimation
------
On the top of being a bold step forward in GenAI, this is a great example of comprehensive red teaming and robustness analysis on LLMs. Proud of the Responsible AI teams that were part of this achievement!
------
Today we’re releasing Code Llama, a large language model built on top of Llama 2, fine-tuned for coding & state-of-the-art for publicly available coding tools.

Keeping with our open approach, Code Llama is publicly-available now for both research & commercial use.

More 
------
Code LLaMA has good results and good eval. It's cool to see PPL decrease all the way  up to 100K tokens (after finetuning on 100K token-long inputs). 

Facebook is close to replicating GPT-4 performance on HumanEval. Great news for the open source/science communities!
------
Thanks, 
@sapinker
------
Agree with this... twitter.com/ylecun/status/…
------
Once AI systems become more intelligent than humans, humans we will *still* be the "apex species."

Equating intelligence with dominance is the main fallacy of the whole debate about AI existential risk.
It's just wrong.
Even *within* the human species It's wrong: it's *not* the… Show more
------
Technically, it's 
@syhw
 et al.
------
I cannot believe zuck et al just beat gpt 3.5 at humaneval pass@1 and is approaching gpt4 with only 34b params

(47 pages, therefore reaction thread - code llama)
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try 
@MetaAI
’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Added CodeLLaMa-34B-instruct to http://labs.pplx.ai, give it a spin!

Thanks for the great work 
@MetaAI
 , 
@ylecun
 , 
@jnsgehring
 et al.
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try @MetaAI’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
New Blog Post   Llama2-70B-Chat is now available on MosaicML Inference and 
@databricks
 MLflow AI Gateway. Learn more: https://mosaicml.com/blog/llama2-inference…
------
NYU's MaD research group 
@NYUDataScience
 and 
@NYU_Courant
 is bridging the gap between pure #math and #machinelearning, working on some of the world's most pressing problems — from the #mathematics behind neural nets, to harnessing #AI for #climatemodeling

https://nyudatascience.medium.com/blending-theory-and-utility-the-vision-and-impact-of-cdss-mad-group-b531bbc9afeb…
------
This is basically how I think the "AI debate" is playing out.  Most of my mutuals are bottom right (I am too)
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
A great article that summarizes our information perspective on multiple modalities for training, as discussed in our paper (with 
@ylecun
 ): https://arxiv.org/abs/2304.09355. Bottom line: Many questions still require further research.
------
AI’s multi-view wave is coming, and it will be powerful

The rise of multiple modalities of data will be united in a multi-sided view of the world.

https://zdnet.com/article/ais-multi-view-wave-is-coming-and-it-will-be-powerful/…

@ylecun @ziv_ravid 

#AI #deeplearning #generativeAI
------
Welcome Code LLama to 
@huggingface
! 

Blog post: https://hf.co/blog/codellama
Models: https://hf.co/codellama
Code playground: https://hf.co/spaces/codellama/codellama-playground…
Chat playground: https://hf.co/spaces/codellama/codellama-13b-chat…
------
Added a paragraph on the impact of the Manhattan project's secrecy on the nuclear arms race to my blog post https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/…
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
Code Llama with 
@huggingface
 Yesterday, 
@MetaAI
 released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
You can try Code Llama now in the Code Llama playground 
@huggingface
 space — it's also available in the Hugging Face ecosystem, starting with transformers version 4.33.
------
Code Llama with @huggingface Yesterday, @MetaAI released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
Deep Learning textbook: making progress chapter by chapter.
------
«Chapter 6»
In this chapter, we'll introduce several geometric structures, over which functions are defined, and whose properties can be exploited to reduce computations and ease learning, giving rise to several architecture families we'll cover in this part of the book.
------
Turned 22 times at 22:22 
#aianimation
------
On the top of being a bold step forward in GenAI, this is a great example of comprehensive red teaming and robustness analysis on LLMs. Proud of the Responsible AI teams that were part of this achievement!
------
Today we’re releasing Code Llama, a large language model built on top of Llama 2, fine-tuned for coding & state-of-the-art for publicly available coding tools.

Keeping with our open approach, Code Llama is publicly-available now for both research & commercial use.

More 
------
Code LLaMA has good results and good eval. It's cool to see PPL decrease all the way  up to 100K tokens (after finetuning on 100K token-long inputs). 

Facebook is close to replicating GPT-4 performance on HumanEval. Great news for the open source/science communities!
------
Thanks, 
@sapinker
------
Agree with this... twitter.com/ylecun/status/…
------
Once AI systems become more intelligent than humans, humans we will *still* be the "apex species."

Equating intelligence with dominance is the main fallacy of the whole debate about AI existential risk.
It's just wrong.
Even *within* the human species It's wrong: it's *not* the… Show more
------
Technically, it's 
@syhw
 et al.
------
I cannot believe zuck et al just beat gpt 3.5 at humaneval pass@1 and is approaching gpt4 with only 34b params

(47 pages, therefore reaction thread - code llama)
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try 
@MetaAI
’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Added CodeLLaMa-34B-instruct to http://labs.pplx.ai, give it a spin!

Thanks for the great work 
@MetaAI
 , 
@ylecun
 , 
@jnsgehring
 et al.
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try @MetaAI’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
New Blog Post   Llama2-70B-Chat is now available on MosaicML Inference and 
@databricks
 MLflow AI Gateway. Learn more: https://mosaicml.com/blog/llama2-inference…
------
NYU's MaD research group 
@NYUDataScience
 and 
@NYU_Courant
 is bridging the gap between pure #math and #machinelearning, working on some of the world's most pressing problems — from the #mathematics behind neural nets, to harnessing #AI for #climatemodeling

https://nyudatascience.medium.com/blending-theory-and-utility-the-vision-and-impact-of-cdss-mad-group-b531bbc9afeb…
------
This is basically how I think the "AI debate" is playing out.  Most of my mutuals are bottom right (I am too)
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
More exciting Meta AI news this week: Code LLama is a set of LLMs tuned specifically for programming and built on top of Llama 2. Available in three models—Code Llama, Code Llama - Python, and Code Llama - Instruct, fine-tuned for understanding natural language instructions.… Show more
------
Open-Assistant Llama2 70B fine-tuning is out: https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10… with a total score very close to WizardLM.
------
Code Llama performance numbers.
------
CodeLlama -- a version of Llama2 that was fine-tuned for code tasks is live now. Available in 7B, 13B and 34B.
https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
Code Llama 7B is competitive with Llama 2 70B & CodeLlama 34B is SOTA among open LLM models.

Get the model here: https://ai.meta.com/resources/models-and-libraries/llama-downloads/…
------
Code Llama with 
@huggingface
 Yesterday, 
@MetaAI
 released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
You can try Code Llama now in the Code Llama playground 
@huggingface
 space — it's also available in the Hugging Face ecosystem, starting with transformers version 4.33.
------
Code Llama with @huggingface Yesterday, @MetaAI released Code Llama, a family of open-access code LLMs!
Today, we release the integration in the Hugging Face ecosystem

Models:
 https://huggingface.co/codellama

blog post:
 http://hf.co/blog/codellama

Blog post covers how to use it!
------
Deep Learning textbook: making progress chapter by chapter.
------
«Chapter 6»
In this chapter, we'll introduce several geometric structures, over which functions are defined, and whose properties can be exploited to reduce computations and ease learning, giving rise to several architecture families we'll cover in this part of the book.
------
Turned 22 times at 22:22 
#aianimation
------
On the top of being a bold step forward in GenAI, this is a great example of comprehensive red teaming and robustness analysis on LLMs. Proud of the Responsible AI teams that were part of this achievement!
------
Today we’re releasing Code Llama, a large language model built on top of Llama 2, fine-tuned for coding & state-of-the-art for publicly available coding tools.

Keeping with our open approach, Code Llama is publicly-available now for both research & commercial use.

More 
------
Code LLaMA has good results and good eval. It's cool to see PPL decrease all the way  up to 100K tokens (after finetuning on 100K token-long inputs). 

Facebook is close to replicating GPT-4 performance on HumanEval. Great news for the open source/science communities!
------
Thanks, 
@sapinker
------
Agree with this... twitter.com/ylecun/status/…
------
Once AI systems become more intelligent than humans, humans we will *still* be the "apex species."

Equating intelligence with dominance is the main fallacy of the whole debate about AI existential risk.
It's just wrong.
Even *within* the human species It's wrong: it's *not* the… Show more
------
Technically, it's 
@syhw
 et al.
------
I cannot believe zuck et al just beat gpt 3.5 at humaneval pass@1 and is approaching gpt4 with only 34b params

(47 pages, therefore reaction thread - code llama)
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try 
@MetaAI
’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Added CodeLLaMa-34B-instruct to http://labs.pplx.ai, give it a spin!

Thanks for the great work 
@MetaAI
 , 
@ylecun
 , 
@jnsgehring
 et al.
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try @MetaAI’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
New Blog Post   Llama2-70B-Chat is now available on MosaicML Inference and 
@databricks
 MLflow AI Gateway. Learn more: https://mosaicml.com/blog/llama2-inference…
------
NYU's MaD research group 
@NYUDataScience
 and 
@NYU_Courant
 is bridging the gap between pure #math and #machinelearning, working on some of the world's most pressing problems — from the #mathematics behind neural nets, to harnessing #AI for #climatemodeling

https://nyudatascience.medium.com/blending-theory-and-utility-the-vision-and-impact-of-cdss-mad-group-b531bbc9afeb…
------
This is basically how I think the "AI debate" is playing out.  Most of my mutuals are bottom right (I am too)
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
More exciting Meta AI news this week: Code LLama is a set of LLMs tuned specifically for programming and built on top of Llama 2. Available in three models—Code Llama, Code Llama - Python, and Code Llama - Instruct, fine-tuned for understanding natural language instructions.… Show more
------
Open-Assistant Llama2 70B fine-tuning is out: https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10… with a total score very close to WizardLM.
------
Code Llama performance numbers.
------
CodeLlama -- a version of Llama2 that was fine-tuned for code tasks is live now. Available in 7B, 13B and 34B.
https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
A fun example of using Code Llama.
------
Here are some fun things we did with it: 
> I have a pandas dataframe with the columns "decoding", "Capabilities", "Fine-tuning", "Model size", "HE pass@1", "MBPP pass@1". I want a seaborn figure with two scatterplots side-by-side. [...]
------
Code Llama thread from Baptiste, the paper's first author.
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
Turned 22 times at 22:22 
#aianimation
------
On the top of being a bold step forward in GenAI, this is a great example of comprehensive red teaming and robustness analysis on LLMs. Proud of the Responsible AI teams that were part of this achievement!
------
Today we’re releasing Code Llama, a large language model built on top of Llama 2, fine-tuned for coding & state-of-the-art for publicly available coding tools.

Keeping with our open approach, Code Llama is publicly-available now for both research & commercial use.

More 
------
Code LLaMA has good results and good eval. It's cool to see PPL decrease all the way  up to 100K tokens (after finetuning on 100K token-long inputs). 

Facebook is close to replicating GPT-4 performance on HumanEval. Great news for the open source/science communities!
------
Thanks, 
@sapinker
------
Agree with this... twitter.com/ylecun/status/…
------
Once AI systems become more intelligent than humans, humans we will *still* be the "apex species."

Equating intelligence with dominance is the main fallacy of the whole debate about AI existential risk.
It's just wrong.
Even *within* the human species It's wrong: it's *not* the… Show more
------
Technically, it's 
@syhw
 et al.
------
I cannot believe zuck et al just beat gpt 3.5 at humaneval pass@1 and is approaching gpt4 with only 34b params

(47 pages, therefore reaction thread - code llama)
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try 
@MetaAI
’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Added CodeLLaMa-34B-instruct to http://labs.pplx.ai, give it a spin!

Thanks for the great work 
@MetaAI
 , 
@ylecun
 , 
@jnsgehring
 et al.
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try @MetaAI’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
New Blog Post   Llama2-70B-Chat is now available on MosaicML Inference and 
@databricks
 MLflow AI Gateway. Learn more: https://mosaicml.com/blog/llama2-inference…
------
NYU's MaD research group 
@NYUDataScience
 and 
@NYU_Courant
 is bridging the gap between pure #math and #machinelearning, working on some of the world's most pressing problems — from the #mathematics behind neural nets, to harnessing #AI for #climatemodeling

https://nyudatascience.medium.com/blending-theory-and-utility-the-vision-and-impact-of-cdss-mad-group-b531bbc9afeb…
------
This is basically how I think the "AI debate" is playing out.  Most of my mutuals are bottom right (I am too)
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
More exciting Meta AI news this week: Code LLama is a set of LLMs tuned specifically for programming and built on top of Llama 2. Available in three models—Code Llama, Code Llama - Python, and Code Llama - Instruct, fine-tuned for understanding natural language instructions.… Show more
------
Open-Assistant Llama2 70B fine-tuning is out: https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10… with a total score very close to WizardLM.
------
Code Llama performance numbers.
------
CodeLlama -- a version of Llama2 that was fine-tuned for code tasks is live now. Available in 7B, 13B and 34B.
https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
A fun example of using Code Llama.
------
Here are some fun things we did with it: 
> I have a pandas dataframe with the columns "decoding", "Capabilities", "Fine-tuning", "Model size", "HE pass@1", "MBPP pass@1". I want a seaborn figure with two scatterplots side-by-side. [...]
------
Code Llama thread from Baptiste, the paper's first author.
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
You knew that was coming: Code LLama !!!
- Llama-2 tuned for code generation, debugging, etc
- base models, Python-specific, and instruction-tuned.
- 7B, 13B and 33B params models
- Available with the same license as Llama-2
- Blog: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
- Paper:… Show more
------
We're releasing base models, Python-specialized models, and Instruct(ion following) models, all in sizes 7B, 13B, 34B params.
Get the code and weights: https://github.com/facebookresearch/codellama…
Read the research paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
Read the blog post: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Excited to see this released and even happier to see that Cantonese is among the 100 languages being translated!
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… twitter.com/MetaAI/status/… Show more
------
Covid is a contagious disease spread when people interact with other people.

So why are Covid death rates higher in rural areas than urban areas?
------
SeamlessM4T represents a significant breakthrough in the field of speech-to-speech & speech-to-text by addressing the challenges of limited language coverage & a reliance on separate systems.

More details  https://bit.ly/45g2pMq
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
Technically, it's 
@syhw
 et al.
------
I cannot believe zuck et al just beat gpt 3.5 at humaneval pass@1 and is approaching gpt4 with only 34b params

(47 pages, therefore reaction thread - code llama)
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try 
@MetaAI
’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
Added CodeLLaMa-34B-instruct to http://labs.pplx.ai, give it a spin!

Thanks for the great work 
@MetaAI
 , 
@ylecun
 , 
@jnsgehring
 et al.
------
Code LLaMA is now on Perplexity’s LLaMa Chat!

Try asking it to write a function for you, or explain a code snippet:  https://labs.pplx.ai/code-llama

This is the fastest way to try @MetaAI’s latest code-specialized LLM. With our model deployment expertise, we are able to provide you… Show more
------
New Blog Post   Llama2-70B-Chat is now available on MosaicML Inference and 
@databricks
 MLflow AI Gateway. Learn more: https://mosaicml.com/blog/llama2-inference…
------
NYU's MaD research group 
@NYUDataScience
 and 
@NYU_Courant
 is bridging the gap between pure #math and #machinelearning, working on some of the world's most pressing problems — from the #mathematics behind neural nets, to harnessing #AI for #climatemodeling

https://nyudatascience.medium.com/blending-theory-and-utility-the-vision-and-impact-of-cdss-mad-group-b531bbc9afeb…
------
This is basically how I think the "AI debate" is playing out.  Most of my mutuals are bottom right (I am too)
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
More exciting Meta AI news this week: Code LLama is a set of LLMs tuned specifically for programming and built on top of Llama 2. Available in three models—Code Llama, Code Llama - Python, and Code Llama - Instruct, fine-tuned for understanding natural language instructions.… Show more
------
Open-Assistant Llama2 70B fine-tuning is out: https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10… with a total score very close to WizardLM.
------
Code Llama performance numbers.
------
CodeLlama -- a version of Llama2 that was fine-tuned for code tasks is live now. Available in 7B, 13B and 34B.
https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
A fun example of using Code Llama.
------
Here are some fun things we did with it: 
> I have a pandas dataframe with the columns "decoding", "Capabilities", "Fine-tuning", "Model size", "HE pass@1", "MBPP pass@1". I want a seaborn figure with two scatterplots side-by-side. [...]
------
Code Llama thread from Baptiste, the paper's first author.
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
You knew that was coming: Code LLama !!!
- Llama-2 tuned for code generation, debugging, etc
- base models, Python-specific, and instruction-tuned.
- 7B, 13B and 33B params models
- Available with the same license as Llama-2
- Blog: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
- Paper:… Show more
------
We're releasing base models, Python-specialized models, and Instruct(ion following) models, all in sizes 7B, 13B, 34B params.
Get the code and weights: https://github.com/facebookresearch/codellama…
Read the research paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
Read the blog post: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Excited to see this released and even happier to see that Cantonese is among the 100 languages being translated!
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… twitter.com/MetaAI/status/… Show more
------
Covid is a contagious disease spread when people interact with other people.

So why are Covid death rates higher in rural areas than urban areas?
------
SeamlessM4T represents a significant breakthrough in the field of speech-to-speech & speech-to-text by addressing the challenges of limited language coverage & a reliance on separate systems.

More details  https://bit.ly/45g2pMq
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
 https://noemamag.com/ai-and-the-limits-of-language… via @
------
"Language can become a screen which stands between the thinker and reality. This is the reason why true creativity often starts where language ends."

Or so Arthur Koestler observes.

What does this tell us about LLMs and creativity?
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… Show more
------
Introducing SeamlessM4T, the first all-in-one, multilingual multimodal translation model.

This single model can perform tasks across speech-to-text, speech-to-speech, text-to-text translation & speech recognition for up to 100 languages depending on the task.

Details 
------
This animation represents a truly monumental achievement: the avoidance of unimaginable amounts of human suffering. https://ourworldindata.org/child-mortality#infant-mortality…

Credit: 
@countcarbon
------
New Blog Post   Llama2-70B-Chat is now available on MosaicML Inference and 
@databricks
 MLflow AI Gateway. Learn more: https://mosaicml.com/blog/llama2-inference…
------
NYU's MaD research group 
@NYUDataScience
 and 
@NYU_Courant
 is bridging the gap between pure #math and #machinelearning, working on some of the world's most pressing problems — from the #mathematics behind neural nets, to harnessing #AI for #climatemodeling

https://nyudatascience.medium.com/blending-theory-and-utility-the-vision-and-impact-of-cdss-mad-group-b531bbc9afeb…
------
This is basically how I think the "AI debate" is playing out.  Most of my mutuals are bottom right (I am too)
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
More exciting Meta AI news this week: Code LLama is a set of LLMs tuned specifically for programming and built on top of Llama 2. Available in three models—Code Llama, Code Llama - Python, and Code Llama - Instruct, fine-tuned for understanding natural language instructions.… Show more
------
Open-Assistant Llama2 70B fine-tuning is out: https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10… with a total score very close to WizardLM.
------
Code Llama performance numbers.
------
CodeLlama -- a version of Llama2 that was fine-tuned for code tasks is live now. Available in 7B, 13B and 34B.
https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
A fun example of using Code Llama.
------
Here are some fun things we did with it: 
> I have a pandas dataframe with the columns "decoding", "Capabilities", "Fine-tuning", "Model size", "HE pass@1", "MBPP pass@1". I want a seaborn figure with two scatterplots side-by-side. [...]
------
Code Llama thread from Baptiste, the paper's first author.
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
You knew that was coming: Code LLama !!!
- Llama-2 tuned for code generation, debugging, etc
- base models, Python-specific, and instruction-tuned.
- 7B, 13B and 33B params models
- Available with the same license as Llama-2
- Blog: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
- Paper:… Show more
------
We're releasing base models, Python-specialized models, and Instruct(ion following) models, all in sizes 7B, 13B, 34B params.
Get the code and weights: https://github.com/facebookresearch/codellama…
Read the research paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
Read the blog post: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Excited to see this released and even happier to see that Cantonese is among the 100 languages being translated!
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… twitter.com/MetaAI/status/… Show more
------
Covid is a contagious disease spread when people interact with other people.

So why are Covid death rates higher in rural areas than urban areas?
------
SeamlessM4T represents a significant breakthrough in the field of speech-to-speech & speech-to-text by addressing the challenges of limited language coverage & a reliance on separate systems.

More details  https://bit.ly/45g2pMq
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
 https://noemamag.com/ai-and-the-limits-of-language… via @
------
"Language can become a screen which stands between the thinker and reality. This is the reason why true creativity often starts where language ends."

Or so Arthur Koestler observes.

What does this tell us about LLMs and creativity?
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… Show more
------
Introducing SeamlessM4T, the first all-in-one, multilingual multimodal translation model.

This single model can perform tasks across speech-to-text, speech-to-speech, text-to-text translation & speech recognition for up to 100 languages depending on the task.

Details 
------
This animation represents a truly monumental achievement: the avoidance of unimaginable amounts of human suffering. https://ourworldindata.org/child-mortality#infant-mortality…

Credit: 
@countcarbon
------
PhotoRoom is pure magic 
------
Beautiful and terrifying lightning storm  at the Acatenango Volcano  in Guatemala 
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
S3 Finale of 
@therobotbrains
: Jitendra Malik on building AI from the ground up: sensorimotor *before* language learning

https://youtu.be/k_Wrd1kI1B0?si=F-F97EOABiQ6T1u5…

Thank you for making the time Jitendra! Thank you to 
@IndexVentures
 and 
@weights_biases
 for supporting the podcast production!
------
More exciting Meta AI news this week: Code LLama is a set of LLMs tuned specifically for programming and built on top of Llama 2. Available in three models—Code Llama, Code Llama - Python, and Code Llama - Instruct, fine-tuned for understanding natural language instructions.… Show more
------
Open-Assistant Llama2 70B fine-tuning is out: https://huggingface.co/OpenAssistant/llama2-70b-oasst-sft-v10… with a total score very close to WizardLM.
------
Code Llama performance numbers.
------
CodeLlama -- a version of Llama2 that was fine-tuned for code tasks is live now. Available in 7B, 13B and 34B.
https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
A fun example of using Code Llama.
------
Here are some fun things we did with it: 
> I have a pandas dataframe with the columns "decoding", "Capabilities", "Fine-tuning", "Model size", "HE pass@1", "MBPP pass@1". I want a seaborn figure with two scatterplots side-by-side. [...]
------
Code Llama thread from Baptiste, the paper's first author.
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
You knew that was coming: Code LLama !!!
- Llama-2 tuned for code generation, debugging, etc
- base models, Python-specific, and instruction-tuned.
- 7B, 13B and 33B params models
- Available with the same license as Llama-2
- Blog: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
- Paper:… Show more
------
We're releasing base models, Python-specialized models, and Instruct(ion following) models, all in sizes 7B, 13B, 34B params.
Get the code and weights: https://github.com/facebookresearch/codellama…
Read the research paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
Read the blog post: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Excited to see this released and even happier to see that Cantonese is among the 100 languages being translated!
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… twitter.com/MetaAI/status/… Show more
------
Covid is a contagious disease spread when people interact with other people.

So why are Covid death rates higher in rural areas than urban areas?
------
SeamlessM4T represents a significant breakthrough in the field of speech-to-speech & speech-to-text by addressing the challenges of limited language coverage & a reliance on separate systems.

More details  https://bit.ly/45g2pMq
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
 https://noemamag.com/ai-and-the-limits-of-language… via @
------
"Language can become a screen which stands between the thinker and reality. This is the reason why true creativity often starts where language ends."

Or so Arthur Koestler observes.

What does this tell us about LLMs and creativity?
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… Show more
------
Introducing SeamlessM4T, the first all-in-one, multilingual multimodal translation model.

This single model can perform tasks across speech-to-text, speech-to-speech, text-to-text translation & speech recognition for up to 100 languages depending on the task.

Details 
------
This animation represents a truly monumental achievement: the avoidance of unimaginable amounts of human suffering. https://ourworldindata.org/child-mortality#infant-mortality…

Credit: 
@countcarbon
------
PhotoRoom is pure magic 
------
Beautiful and terrifying lightning storm  at the Acatenango Volcano  in Guatemala 
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
Would it be fair for the US to brain-drain China's top AI scientists and entrepreneurs by encouraging them to come to America?
------
How many of those Chinese founders would be here if the US was as open to skilled immigration as, say, Canada? twitter.com/scienceisstrat…
------
i think my t shirts rock. 

(and no ... i don't have a subscription to BI myself ...)

https://businessinsider.com/30-leaders-under-40-changing-healthcare-2023…
------
Remember the signatories of the 
@FLIxrisk
 open letter, which called for a pause on advanced AI development?

According to a new paper, "Why They're Worried," their motivation to sign had nothing to do with X-risk.

Their concerns were NOT centered on "Human Extinction" at all.

1
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
Using Code Llama to look over your shoulder as a debugging helper
------
And beyond just code completion and code generation, it can help you finding bugs or pair program in general.
------
A fun example of using Code Llama.
------
Here are some fun things we did with it: 
> I have a pandas dataframe with the columns "decoding", "Capabilities", "Fine-tuning", "Model size", "HE pass@1", "MBPP pass@1". I want a seaborn figure with two scatterplots side-by-side. [...]
------
Code Llama thread from Baptiste, the paper's first author.
------
Today, we release CodeLlama, a collection of base and instruct-finetuned models with 7B, 13B and 34B parameters. For coding tasks, CodeLlama 7B is competitive with Llama 2 70B and CodeLlama 34B is state-of-the-art among open models. Paper and weights: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
------
You knew that was coming: Code LLama !!!
- Llama-2 tuned for code generation, debugging, etc
- base models, Python-specific, and instruction-tuned.
- 7B, 13B and 33B params models
- Available with the same license as Llama-2
- Blog: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
- Paper:… Show more
------
We're releasing base models, Python-specialized models, and Instruct(ion following) models, all in sizes 7B, 13B, 34B params.
Get the code and weights: https://github.com/facebookresearch/codellama…
Read the research paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/…
Read the blog post: https://ai.meta.com/blog/code-llama-large-language-model-coding/…
------
Excited to see this released and even happier to see that Cantonese is among the 100 languages being translated!
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… twitter.com/MetaAI/status/… Show more
------
Covid is a contagious disease spread when people interact with other people.

So why are Covid death rates higher in rural areas than urban areas?
------
SeamlessM4T represents a significant breakthrough in the field of speech-to-speech & speech-to-text by addressing the challenges of limited language coverage & a reliance on separate systems.

More details  https://bit.ly/45g2pMq
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
 https://noemamag.com/ai-and-the-limits-of-language… via @
------
"Language can become a screen which stands between the thinker and reality. This is the reason why true creativity often starts where language ends."

Or so Arthur Koestler observes.

What does this tell us about LLMs and creativity?
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… Show more
------
Introducing SeamlessM4T, the first all-in-one, multilingual multimodal translation model.

This single model can perform tasks across speech-to-text, speech-to-speech, text-to-text translation & speech recognition for up to 100 languages depending on the task.

Details 
------
This animation represents a truly monumental achievement: the avoidance of unimaginable amounts of human suffering. https://ourworldindata.org/child-mortality#infant-mortality…

Credit: 
@countcarbon
------
PhotoRoom is pure magic 
------
Beautiful and terrifying lightning storm  at the Acatenango Volcano  in Guatemala 
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
Would it be fair for the US to brain-drain China's top AI scientists and entrepreneurs by encouraging them to come to America?
------
How many of those Chinese founders would be here if the US was as open to skilled immigration as, say, Canada? twitter.com/scienceisstrat…
------
i think my t shirts rock. 

(and no ... i don't have a subscription to BI myself ...)

https://businessinsider.com/30-leaders-under-40-changing-healthcare-2023…
------
Remember the signatories of the 
@FLIxrisk
 open letter, which called for a pause on advanced AI development?

According to a new paper, "Why They're Worried," their motivation to sign had nothing to do with X-risk.

Their concerns were NOT centered on "Human Extinction" at all.

1
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
At the AI Native conference on September 7 in NYC.
------
Anyone want to join me and Yann LeCun @ylecun for a conference next month? I'll be speaking on the Secret to AI Innovation.

It's in NYC on 9/7: @Zettaventures' enterprise AI conference — AI Native

If you'd like to be there virtually, here's the registration link to watch the… Show more
------
Positive semi-definite matrices come in many flavors! https://en.wikipedia.org/wiki/Definite_symmetric_matrix…
------
Most signatories of AI doom letters are not actually AI doomers.
------
Many of the professors who sign those open letters are not worried about X-risk. But they lent their name and credibility to the extreme AI doomers.

Due to this exploitation, the fringe becomes mainstream. That's the real misinformation here.

https://shorturl.at/akvJK
------
Excited to see this released and even happier to see that Cantonese is among the 100 languages being translated!
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… twitter.com/MetaAI/status/… Show more
------
Covid is a contagious disease spread when people interact with other people.

So why are Covid death rates higher in rural areas than urban areas?
------
SeamlessM4T represents a significant breakthrough in the field of speech-to-speech & speech-to-text by addressing the challenges of limited language coverage & a reliance on separate systems.

More details  https://bit.ly/45g2pMq
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
 https://noemamag.com/ai-and-the-limits-of-language… via @
------
"Language can become a screen which stands between the thinker and reality. This is the reason why true creativity often starts where language ends."

Or so Arthur Koestler observes.

What does this tell us about LLMs and creativity?
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… Show more
------
Introducing SeamlessM4T, the first all-in-one, multilingual multimodal translation model.

This single model can perform tasks across speech-to-text, speech-to-speech, text-to-text translation & speech recognition for up to 100 languages depending on the task.

Details 
------
This animation represents a truly monumental achievement: the avoidance of unimaginable amounts of human suffering. https://ourworldindata.org/child-mortality#infant-mortality…

Credit: 
@countcarbon
------
PhotoRoom is pure magic 
------
Beautiful and terrifying lightning storm  at the Acatenango Volcano  in Guatemala 
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
Would it be fair for the US to brain-drain China's top AI scientists and entrepreneurs by encouraging them to come to America?
------
How many of those Chinese founders would be here if the US was as open to skilled immigration as, say, Canada? twitter.com/scienceisstrat…
------
i think my t shirts rock. 

(and no ... i don't have a subscription to BI myself ...)

https://businessinsider.com/30-leaders-under-40-changing-healthcare-2023…
------
Remember the signatories of the 
@FLIxrisk
 open letter, which called for a pause on advanced AI development?

According to a new paper, "Why They're Worried," their motivation to sign had nothing to do with X-risk.

Their concerns were NOT centered on "Human Extinction" at all.

1
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
At the AI Native conference on September 7 in NYC.
------
Anyone want to join me and Yann LeCun @ylecun for a conference next month? I'll be speaking on the Secret to AI Innovation.

It's in NYC on 9/7: @Zettaventures' enterprise AI conference — AI Native

If you'd like to be there virtually, here's the registration link to watch the… Show more
------
Positive semi-definite matrices come in many flavors! https://en.wikipedia.org/wiki/Definite_symmetric_matrix…
------
Most signatories of AI doom letters are not actually AI doomers.
------
Many of the professors who sign those open letters are not worried about X-risk. But they lent their name and credibility to the extreme AI doomers.

Due to this exploitation, the fringe becomes mainstream. That's the real misinformation here.

https://shorturl.at/akvJK
------
An old page on relativistic rockets on John Baez's website that I had missed.
------
You can travel across the galaxy in a single life-time with one gravity of constant acceleration

Usually it seems like space is so impossibly vast, it's unlikely aliens or humans could ever realistically visit other stars let alone other galaxies.

However, if you can build a… Show more
------
I consider this chart to be the clearest indictment of our country’s path over the last several decades: In 1980, the U.S. had a typical life expectancy for an affluent country. Today, the U.S. has the lowest life expectancy of any affluent country:
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
 https://noemamag.com/ai-and-the-limits-of-language… via @
------
"Language can become a screen which stands between the thinker and reality. This is the reason why true creativity often starts where language ends."

Or so Arthur Koestler observes.

What does this tell us about LLMs and creativity?
------
Seamless4MT: Massive Multilingual Multimodal Machine Translation.

Language translation + speech recognition + speech synthesis in a single model: speech-to-speech, text-to-text, speech-to-text and text-to-speech.

Works for 100 languages.
Code available under CC-BY-NC license.… Show more
------
Introducing SeamlessM4T, the first all-in-one, multilingual multimodal translation model.

This single model can perform tasks across speech-to-text, speech-to-speech, text-to-text translation & speech recognition for up to 100 languages depending on the task.

Details 
------
This animation represents a truly monumental achievement: the avoidance of unimaginable amounts of human suffering. https://ourworldindata.org/child-mortality#infant-mortality…

Credit: 
@countcarbon
------
PhotoRoom is pure magic 
------
Beautiful and terrifying lightning storm  at the Acatenango Volcano  in Guatemala 
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
Would it be fair for the US to brain-drain China's top AI scientists and entrepreneurs by encouraging them to come to America?
------
How many of those Chinese founders would be here if the US was as open to skilled immigration as, say, Canada? twitter.com/scienceisstrat…
------
i think my t shirts rock. 

(and no ... i don't have a subscription to BI myself ...)

https://businessinsider.com/30-leaders-under-40-changing-healthcare-2023…
------
Remember the signatories of the 
@FLIxrisk
 open letter, which called for a pause on advanced AI development?

According to a new paper, "Why They're Worried," their motivation to sign had nothing to do with X-risk.

Their concerns were NOT centered on "Human Extinction" at all.

1
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
At the AI Native conference on September 7 in NYC.
------
Anyone want to join me and Yann LeCun @ylecun for a conference next month? I'll be speaking on the Secret to AI Innovation.

It's in NYC on 9/7: @Zettaventures' enterprise AI conference — AI Native

If you'd like to be there virtually, here's the registration link to watch the… Show more
------
Positive semi-definite matrices come in many flavors! https://en.wikipedia.org/wiki/Definite_symmetric_matrix…
------
Most signatories of AI doom letters are not actually AI doomers.
------
Many of the professors who sign those open letters are not worried about X-risk. But they lent their name and credibility to the extreme AI doomers.

Due to this exploitation, the fringe becomes mainstream. That's the real misinformation here.

https://shorturl.at/akvJK
------
An old page on relativistic rockets on John Baez's website that I had missed.
------
You can travel across the galaxy in a single life-time with one gravity of constant acceleration

Usually it seems like space is so impossibly vast, it's unlikely aliens or humans could ever realistically visit other stars let alone other galaxies.

However, if you can build a… Show more
------
Help African students travel to Ghana for the Deep Learning Indaba.
------
Last year, 8 of us from our local student AI community got accepted into Indaba, which we attended thanks to MLC's fundraiser.

In 2023, 21 people from this same unit were accepted to Indaba. They are taking a bus to Accra to save money but still need help.https://donorbox.org/support-our-travel-to-deep-learning-indaba-2023…
------
New paper on SSL theory with 
@ziv_ravid
 !
------
@ylecun and I have a paper on compressing information in self-supervised learning:! https://arxiv.org/abs/2304.09355
------
(1/6) The FAIR Embodied AI team at 
@MetaAI
 has multiple full-time openings! If you’re interested in cutting-edge research in AI for robotics, AR and VR, and sharing it with the world, read on. 
------
 Exciting news I'm thrilled to share that my team and I at 
@MetaAI
 have created a deme to showcase our cutting-edge audio-visual speech models in action! 

You can try out our demo yourself using our GitHub repo :
https://github.com/facebookresearch/muavic/tree/main/demo… 
------
Fun.
------
Enter thermodynamic computing. In this preprint, Thermodynamic Linear Algebra (https://arxiv.org/abs/2308.05660), we show that a system of coupled oscillators in contact with a heat reservoir can be used to solve linear systems in an amount of time proportional to the number of variables.
------
Machines have always needed humans to tell them what to do
 
But the artificial intelligence revolution is changing that

Beyond Human: Artificial Intelligence and Us is on BBC iPlayer now and BBC One at 8pm
------
Very cool work on how the retina encodes visual inputs to squeeze it down the optic nerve.
------
1/Our paper @NeuroCellPress "Interpreting the retinal code for natural scenes" develops explainable AI (#XAI) to derive a SOTA deep network model of the retina and *understand* how this net captures natural scenes plus 8 seminal experiments over >2 decades https://sciencedirect.com/science/article/pii/S0896627323004671…
------
Llama2-chat-70B available on IBM http://Watsonx.ai Studio.
------
Today IBM announced it will host @MetaAI's Llama 2-chat 70 billion parameter model in the watsonx․ai studio, furthering their collaboration on open innovation for #AI. Learn more: https://ibm.co/3DPvouA
------
PhotoRoom is pure magic 
------
Beautiful and terrifying lightning storm  at the Acatenango Volcano  in Guatemala 
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
Would it be fair for the US to brain-drain China's top AI scientists and entrepreneurs by encouraging them to come to America?
------
How many of those Chinese founders would be here if the US was as open to skilled immigration as, say, Canada? twitter.com/scienceisstrat…
------
i think my t shirts rock. 

(and no ... i don't have a subscription to BI myself ...)

https://businessinsider.com/30-leaders-under-40-changing-healthcare-2023…
------
Remember the signatories of the 
@FLIxrisk
 open letter, which called for a pause on advanced AI development?

According to a new paper, "Why They're Worried," their motivation to sign had nothing to do with X-risk.

Their concerns were NOT centered on "Human Extinction" at all.

1
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
At the AI Native conference on September 7 in NYC.
------
Anyone want to join me and Yann LeCun @ylecun for a conference next month? I'll be speaking on the Secret to AI Innovation.

It's in NYC on 9/7: @Zettaventures' enterprise AI conference — AI Native

If you'd like to be there virtually, here's the registration link to watch the… Show more
------
Positive semi-definite matrices come in many flavors! https://en.wikipedia.org/wiki/Definite_symmetric_matrix…
------
Most signatories of AI doom letters are not actually AI doomers.
------
Many of the professors who sign those open letters are not worried about X-risk. But they lent their name and credibility to the extreme AI doomers.

Due to this exploitation, the fringe becomes mainstream. That's the real misinformation here.

https://shorturl.at/akvJK
------
An old page on relativistic rockets on John Baez's website that I had missed.
------
You can travel across the galaxy in a single life-time with one gravity of constant acceleration

Usually it seems like space is so impossibly vast, it's unlikely aliens or humans could ever realistically visit other stars let alone other galaxies.

However, if you can build a… Show more
------
Help African students travel to Ghana for the Deep Learning Indaba.
------
Last year, 8 of us from our local student AI community got accepted into Indaba, which we attended thanks to MLC's fundraiser.

In 2023, 21 people from this same unit were accepted to Indaba. They are taking a bus to Accra to save money but still need help.https://donorbox.org/support-our-travel-to-deep-learning-indaba-2023…
------
New paper on SSL theory with 
@ziv_ravid
 !
------
@ylecun and I have a paper on compressing information in self-supervised learning:! https://arxiv.org/abs/2304.09355
------
(1/6) The FAIR Embodied AI team at 
@MetaAI
 has multiple full-time openings! If you’re interested in cutting-edge research in AI for robotics, AR and VR, and sharing it with the world, read on. 
------
 Exciting news I'm thrilled to share that my team and I at 
@MetaAI
 have created a deme to showcase our cutting-edge audio-visual speech models in action! 

You can try out our demo yourself using our GitHub repo :
https://github.com/facebookresearch/muavic/tree/main/demo… 
------
Fun.
------
Enter thermodynamic computing. In this preprint, Thermodynamic Linear Algebra (https://arxiv.org/abs/2308.05660), we show that a system of coupled oscillators in contact with a heat reservoir can be used to solve linear systems in an amount of time proportional to the number of variables.
------
Machines have always needed humans to tell them what to do
 
But the artificial intelligence revolution is changing that

Beyond Human: Artificial Intelligence and Us is on BBC iPlayer now and BBC One at 8pm
------
Very cool work on how the retina encodes visual inputs to squeeze it down the optic nerve.
------
1/Our paper @NeuroCellPress "Interpreting the retinal code for natural scenes" develops explainable AI (#XAI) to derive a SOTA deep network model of the retina and *understand* how this net captures natural scenes plus 8 seminal experiments over >2 decades https://sciencedirect.com/science/article/pii/S0896627323004671…
------
Llama2-chat-70B available on IBM http://Watsonx.ai Studio.
------
Today IBM announced it will host @MetaAI's Llama 2-chat 70 billion parameter model in the watsonx․ai studio, furthering their collaboration on open innovation for #AI. Learn more: https://ibm.co/3DPvouA
------
Humpback! making a splash with self-alignment:
1. Self-augment: generate good "instructions" for a set of existing "answers" using Llama.
2. Self-curate: rate the generated data using Llama.
3. Self-tune: fine-tune Llama with the data.
4. Iterate.
5. Beat other LLMs.
------
New Paper 
Self-Alignment with Instruction Backtranslation

- New method auto-labels web text with instructions & curates high quality ones for FTing

- Our model Humpback  outperforms LIMA, Claude, Guanaco, davinci-003 & Falcon-Inst

https://arxiv.org/abs/2308.06259
(1/4)
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via 
@PessimistsArc
) suggesting a horse outperforms a car.
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
Europe  significantly lags the US  and China  as a tech power. 

Data-rich  below on the economic consequences of tech stagnation for Europe’s prosperity and beyond  (1/25)

Cc: 
@GerardAraud
 
@Noahpinion
 
@erikbryn
 
@paulg
------
Would it be fair for the US to brain-drain China's top AI scientists and entrepreneurs by encouraging them to come to America?
------
How many of those Chinese founders would be here if the US was as open to skilled immigration as, say, Canada? twitter.com/scienceisstrat…
------
i think my t shirts rock. 

(and no ... i don't have a subscription to BI myself ...)

https://businessinsider.com/30-leaders-under-40-changing-healthcare-2023…
------
Remember the signatories of the 
@FLIxrisk
 open letter, which called for a pause on advanced AI development?

According to a new paper, "Why They're Worried," their motivation to sign had nothing to do with X-risk.

Their concerns were NOT centered on "Human Extinction" at all.

1
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
At the AI Native conference on September 7 in NYC.
------
Anyone want to join me and Yann LeCun @ylecun for a conference next month? I'll be speaking on the Secret to AI Innovation.

It's in NYC on 9/7: @Zettaventures' enterprise AI conference — AI Native

If you'd like to be there virtually, here's the registration link to watch the… Show more
------
Positive semi-definite matrices come in many flavors! https://en.wikipedia.org/wiki/Definite_symmetric_matrix…
------
Most signatories of AI doom letters are not actually AI doomers.
------
Many of the professors who sign those open letters are not worried about X-risk. But they lent their name and credibility to the extreme AI doomers.

Due to this exploitation, the fringe becomes mainstream. That's the real misinformation here.

https://shorturl.at/akvJK
------
An old page on relativistic rockets on John Baez's website that I had missed.
------
You can travel across the galaxy in a single life-time with one gravity of constant acceleration

Usually it seems like space is so impossibly vast, it's unlikely aliens or humans could ever realistically visit other stars let alone other galaxies.

However, if you can build a… Show more
------
Help African students travel to Ghana for the Deep Learning Indaba.
------
Last year, 8 of us from our local student AI community got accepted into Indaba, which we attended thanks to MLC's fundraiser.

In 2023, 21 people from this same unit were accepted to Indaba. They are taking a bus to Accra to save money but still need help.https://donorbox.org/support-our-travel-to-deep-learning-indaba-2023…
------
New paper on SSL theory with 
@ziv_ravid
 !
------
@ylecun and I have a paper on compressing information in self-supervised learning:! https://arxiv.org/abs/2304.09355
------
(1/6) The FAIR Embodied AI team at 
@MetaAI
 has multiple full-time openings! If you’re interested in cutting-edge research in AI for robotics, AR and VR, and sharing it with the world, read on. 
------
 Exciting news I'm thrilled to share that my team and I at 
@MetaAI
 have created a deme to showcase our cutting-edge audio-visual speech models in action! 

You can try out our demo yourself using our GitHub repo :
https://github.com/facebookresearch/muavic/tree/main/demo… 
------
Fun.
------
Enter thermodynamic computing. In this preprint, Thermodynamic Linear Algebra (https://arxiv.org/abs/2308.05660), we show that a system of coupled oscillators in contact with a heat reservoir can be used to solve linear systems in an amount of time proportional to the number of variables.
------
Machines have always needed humans to tell them what to do
 
But the artificial intelligence revolution is changing that

Beyond Human: Artificial Intelligence and Us is on BBC iPlayer now and BBC One at 8pm
------
Very cool work on how the retina encodes visual inputs to squeeze it down the optic nerve.
------
1/Our paper @NeuroCellPress "Interpreting the retinal code for natural scenes" develops explainable AI (#XAI) to derive a SOTA deep network model of the retina and *understand* how this net captures natural scenes plus 8 seminal experiments over >2 decades https://sciencedirect.com/science/article/pii/S0896627323004671…
------
Llama2-chat-70B available on IBM http://Watsonx.ai Studio.
------
Today IBM announced it will host @MetaAI's Llama 2-chat 70 billion parameter model in the watsonx․ai studio, furthering their collaboration on open innovation for #AI. Learn more: https://ibm.co/3DPvouA
------
Humpback! making a splash with self-alignment:
1. Self-augment: generate good "instructions" for a set of existing "answers" using Llama.
2. Self-curate: rate the generated data using Llama.
3. Self-tune: fine-tune Llama with the data.
4. Iterate.
5. Beat other LLMs.
------
New Paper 
Self-Alignment with Instruction Backtranslation

- New method auto-labels web text with instructions & curates high quality ones for FTing

- Our model Humpback  outperforms LIMA, Claude, Guanaco, davinci-003 & Falcon-Inst

https://arxiv.org/abs/2308.06259
(1/4)
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via 
@PessimistsArc
) suggesting a horse outperforms a car.
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
When Einstein Failed Edison's Aptitude Test

In 1921, Albert Einstein visited Boston, where reporters handed him a test of knowledge designed by Thomas Edison based on memorized scientific facts

Not recalling the speed of sound, Einstein flunked the exam

https://medium.com/starts-with-a-bang/einstein-edison-and-an-aptitude-for-genius-31a41a1947f1…
------
Michael I. Jordan on ChatGPT and AI: "We're fearful in 10 years it can get out of control and all that. That's just not true. ChatGPT is predicting the next word in a sentence, just remember that's what it does".
https://youtu.be/mszj94hEKH4
1/3
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Assuming à 2% annual growth, humanity's entire power consumption will surpass: 
- the entire power sent by the sun to earth in 360 years.
- the entire supply of fissile material in about 900 years.
- the entire supply of deuterium in the oceans in about 1000 years.
------
The oceans contain enough fusion fuel to power our current civilization for 65 billion years.

If we assume compounding growth of 2%, how long will it last?

Fusion: 1060 years 
Solar:    460 years 

Let's dig into the physics of our energy economy. 
(warning: math ahead).… Show more
------
At the AI Native conference on September 7 in NYC.
------
Anyone want to join me and Yann LeCun @ylecun for a conference next month? I'll be speaking on the Secret to AI Innovation.

It's in NYC on 9/7: @Zettaventures' enterprise AI conference — AI Native

If you'd like to be there virtually, here's the registration link to watch the… Show more
------
Positive semi-definite matrices come in many flavors! https://en.wikipedia.org/wiki/Definite_symmetric_matrix…
------
Most signatories of AI doom letters are not actually AI doomers.
------
Many of the professors who sign those open letters are not worried about X-risk. But they lent their name and credibility to the extreme AI doomers.

Due to this exploitation, the fringe becomes mainstream. That's the real misinformation here.

https://shorturl.at/akvJK
------
An old page on relativistic rockets on John Baez's website that I had missed.
------
You can travel across the galaxy in a single life-time with one gravity of constant acceleration

Usually it seems like space is so impossibly vast, it's unlikely aliens or humans could ever realistically visit other stars let alone other galaxies.

However, if you can build a… Show more
------
Help African students travel to Ghana for the Deep Learning Indaba.
------
Last year, 8 of us from our local student AI community got accepted into Indaba, which we attended thanks to MLC's fundraiser.

In 2023, 21 people from this same unit were accepted to Indaba. They are taking a bus to Accra to save money but still need help.https://donorbox.org/support-our-travel-to-deep-learning-indaba-2023…
------
New paper on SSL theory with 
@ziv_ravid
 !
------
@ylecun and I have a paper on compressing information in self-supervised learning:! https://arxiv.org/abs/2304.09355
------
(1/6) The FAIR Embodied AI team at 
@MetaAI
 has multiple full-time openings! If you’re interested in cutting-edge research in AI for robotics, AR and VR, and sharing it with the world, read on. 
------
 Exciting news I'm thrilled to share that my team and I at 
@MetaAI
 have created a deme to showcase our cutting-edge audio-visual speech models in action! 

You can try out our demo yourself using our GitHub repo :
https://github.com/facebookresearch/muavic/tree/main/demo… 
------
Fun.
------
Enter thermodynamic computing. In this preprint, Thermodynamic Linear Algebra (https://arxiv.org/abs/2308.05660), we show that a system of coupled oscillators in contact with a heat reservoir can be used to solve linear systems in an amount of time proportional to the number of variables.
------
Machines have always needed humans to tell them what to do
 
But the artificial intelligence revolution is changing that

Beyond Human: Artificial Intelligence and Us is on BBC iPlayer now and BBC One at 8pm
------
Very cool work on how the retina encodes visual inputs to squeeze it down the optic nerve.
------
1/Our paper @NeuroCellPress "Interpreting the retinal code for natural scenes" develops explainable AI (#XAI) to derive a SOTA deep network model of the retina and *understand* how this net captures natural scenes plus 8 seminal experiments over >2 decades https://sciencedirect.com/science/article/pii/S0896627323004671…
------
Llama2-chat-70B available on IBM http://Watsonx.ai Studio.
------
Today IBM announced it will host @MetaAI's Llama 2-chat 70 billion parameter model in the watsonx․ai studio, furthering their collaboration on open innovation for #AI. Learn more: https://ibm.co/3DPvouA
------
Humpback! making a splash with self-alignment:
1. Self-augment: generate good "instructions" for a set of existing "answers" using Llama.
2. Self-curate: rate the generated data using Llama.
3. Self-tune: fine-tune Llama with the data.
4. Iterate.
5. Beat other LLMs.
------
New Paper 
Self-Alignment with Instruction Backtranslation

- New method auto-labels web text with instructions & curates high quality ones for FTing

- Our model Humpback  outperforms LIMA, Claude, Guanaco, davinci-003 & Falcon-Inst

https://arxiv.org/abs/2308.06259
(1/4)
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via 
@PessimistsArc
) suggesting a horse outperforms a car.
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
When Einstein Failed Edison's Aptitude Test

In 1921, Albert Einstein visited Boston, where reporters handed him a test of knowledge designed by Thomas Edison based on memorized scientific facts

Not recalling the speed of sound, Einstein flunked the exam

https://medium.com/starts-with-a-bang/einstein-edison-and-an-aptitude-for-genius-31a41a1947f1…
------
Michael I. Jordan on ChatGPT and AI: "We're fearful in 10 years it can get out of control and all that. That's just not true. ChatGPT is predicting the next word in a sentence, just remember that's what it does".
https://youtu.be/mszj94hEKH4
1/3
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Inflation is basically GONE when you exclude the lagged shelter (i.e. rent) data in CPI. Remember: Rent is the biggest variable in the CPI's biggest category (shelter), and there's a known 12-month lag between asking rents and CPI rents. 

I'm surprised how little buzz there is… Show more
------
Reminder: capability and reliability are orthogonal aspects of LLMs. You can show the presence of a capability using examples/screenshots, but not absence. LLMs' remarkable capabilities make them exciting for research, but their unreliability limits their usefulness at present.
------
Nice talk by 
@ylecun
, makes me think about all the resources, people and money that are put into LLMs... if they are a complete detour towards the path of actual intelligent systems

https://youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg&t=2600s&ab_channel=MITDepartmentofPhysics…
------
Dr. Goldblum is a postdoctoral research fellow at NYU—working with Yann LeCun (
@ylecun
) and Andrew Gordon Wilson (
@andrewgwils
)—he is recognized today for his substantial contributions to various aspects of deep learning.
------
An old page on relativistic rockets on John Baez's website that I had missed.
------
You can travel across the galaxy in a single life-time with one gravity of constant acceleration

Usually it seems like space is so impossibly vast, it's unlikely aliens or humans could ever realistically visit other stars let alone other galaxies.

However, if you can build a… Show more
------
Help African students travel to Ghana for the Deep Learning Indaba.
------
Last year, 8 of us from our local student AI community got accepted into Indaba, which we attended thanks to MLC's fundraiser.

In 2023, 21 people from this same unit were accepted to Indaba. They are taking a bus to Accra to save money but still need help.https://donorbox.org/support-our-travel-to-deep-learning-indaba-2023…
------
New paper on SSL theory with 
@ziv_ravid
 !
------
@ylecun and I have a paper on compressing information in self-supervised learning:! https://arxiv.org/abs/2304.09355
------
(1/6) The FAIR Embodied AI team at 
@MetaAI
 has multiple full-time openings! If you’re interested in cutting-edge research in AI for robotics, AR and VR, and sharing it with the world, read on. 
------
 Exciting news I'm thrilled to share that my team and I at 
@MetaAI
 have created a deme to showcase our cutting-edge audio-visual speech models in action! 

You can try out our demo yourself using our GitHub repo :
https://github.com/facebookresearch/muavic/tree/main/demo… 
------
Fun.
------
Enter thermodynamic computing. In this preprint, Thermodynamic Linear Algebra (https://arxiv.org/abs/2308.05660), we show that a system of coupled oscillators in contact with a heat reservoir can be used to solve linear systems in an amount of time proportional to the number of variables.
------
Machines have always needed humans to tell them what to do
 
But the artificial intelligence revolution is changing that

Beyond Human: Artificial Intelligence and Us is on BBC iPlayer now and BBC One at 8pm
------
Very cool work on how the retina encodes visual inputs to squeeze it down the optic nerve.
------
1/Our paper @NeuroCellPress "Interpreting the retinal code for natural scenes" develops explainable AI (#XAI) to derive a SOTA deep network model of the retina and *understand* how this net captures natural scenes plus 8 seminal experiments over >2 decades https://sciencedirect.com/science/article/pii/S0896627323004671…
------
Llama2-chat-70B available on IBM http://Watsonx.ai Studio.
------
Today IBM announced it will host @MetaAI's Llama 2-chat 70 billion parameter model in the watsonx․ai studio, furthering their collaboration on open innovation for #AI. Learn more: https://ibm.co/3DPvouA
------
Humpback! making a splash with self-alignment:
1. Self-augment: generate good "instructions" for a set of existing "answers" using Llama.
2. Self-curate: rate the generated data using Llama.
3. Self-tune: fine-tune Llama with the data.
4. Iterate.
5. Beat other LLMs.
------
New Paper 
Self-Alignment with Instruction Backtranslation

- New method auto-labels web text with instructions & curates high quality ones for FTing

- Our model Humpback  outperforms LIMA, Claude, Guanaco, davinci-003 & Falcon-Inst

https://arxiv.org/abs/2308.06259
(1/4)
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via 
@PessimistsArc
) suggesting a horse outperforms a car.
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
When Einstein Failed Edison's Aptitude Test

In 1921, Albert Einstein visited Boston, where reporters handed him a test of knowledge designed by Thomas Edison based on memorized scientific facts

Not recalling the speed of sound, Einstein flunked the exam

https://medium.com/starts-with-a-bang/einstein-edison-and-an-aptitude-for-genius-31a41a1947f1…
------
Michael I. Jordan on ChatGPT and AI: "We're fearful in 10 years it can get out of control and all that. That's just not true. ChatGPT is predicting the next word in a sentence, just remember that's what it does".
https://youtu.be/mszj94hEKH4
1/3
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Inflation is basically GONE when you exclude the lagged shelter (i.e. rent) data in CPI. Remember: Rent is the biggest variable in the CPI's biggest category (shelter), and there's a known 12-month lag between asking rents and CPI rents. 

I'm surprised how little buzz there is… Show more
------
Reminder: capability and reliability are orthogonal aspects of LLMs. You can show the presence of a capability using examples/screenshots, but not absence. LLMs' remarkable capabilities make them exciting for research, but their unreliability limits their usefulness at present.
------
Nice talk by 
@ylecun
, makes me think about all the resources, people and money that are put into LLMs... if they are a complete detour towards the path of actual intelligent systems

https://youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg&t=2600s&ab_channel=MITDepartmentofPhysics…
------
Dr. Goldblum is a postdoctoral research fellow at NYU—working with Yann LeCun (
@ylecun
) and Andrew Gordon Wilson (
@andrewgwils
)—he is recognized today for his substantial contributions to various aspects of deep learning.
------
Want even more updates on our latest research papers, datasets and more? Subscribe to the Meta AI newsletter to get a regular digest of AI news and updates.

Subscribe 
------
A civilian casualty of the anti-AI crusade.
------
I took down the prosecraft website. I'm sorry, everyone. https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121…
------
Fun.
------
Enter thermodynamic computing. In this preprint, Thermodynamic Linear Algebra (https://arxiv.org/abs/2308.05660), we show that a system of coupled oscillators in contact with a heat reservoir can be used to solve linear systems in an amount of time proportional to the number of variables.
------
Machines have always needed humans to tell them what to do
 
But the artificial intelligence revolution is changing that

Beyond Human: Artificial Intelligence and Us is on BBC iPlayer now and BBC One at 8pm
------
Very cool work on how the retina encodes visual inputs to squeeze it down the optic nerve.
------
1/Our paper @NeuroCellPress "Interpreting the retinal code for natural scenes" develops explainable AI (#XAI) to derive a SOTA deep network model of the retina and *understand* how this net captures natural scenes plus 8 seminal experiments over >2 decades https://sciencedirect.com/science/article/pii/S0896627323004671…
------
Llama2-chat-70B available on IBM http://Watsonx.ai Studio.
------
Today IBM announced it will host @MetaAI's Llama 2-chat 70 billion parameter model in the watsonx․ai studio, furthering their collaboration on open innovation for #AI. Learn more: https://ibm.co/3DPvouA
------
Humpback! making a splash with self-alignment:
1. Self-augment: generate good "instructions" for a set of existing "answers" using Llama.
2. Self-curate: rate the generated data using Llama.
3. Self-tune: fine-tune Llama with the data.
4. Iterate.
5. Beat other LLMs.
------
New Paper 
Self-Alignment with Instruction Backtranslation

- New method auto-labels web text with instructions & curates high quality ones for FTing

- Our model Humpback  outperforms LIMA, Claude, Guanaco, davinci-003 & Falcon-Inst

https://arxiv.org/abs/2308.06259
(1/4)
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via 
@PessimistsArc
) suggesting a horse outperforms a car.
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
When Einstein Failed Edison's Aptitude Test

In 1921, Albert Einstein visited Boston, where reporters handed him a test of knowledge designed by Thomas Edison based on memorized scientific facts

Not recalling the speed of sound, Einstein flunked the exam

https://medium.com/starts-with-a-bang/einstein-edison-and-an-aptitude-for-genius-31a41a1947f1…
------
Michael I. Jordan on ChatGPT and AI: "We're fearful in 10 years it can get out of control and all that. That's just not true. ChatGPT is predicting the next word in a sentence, just remember that's what it does".
https://youtu.be/mszj94hEKH4
1/3
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Inflation is basically GONE when you exclude the lagged shelter (i.e. rent) data in CPI. Remember: Rent is the biggest variable in the CPI's biggest category (shelter), and there's a known 12-month lag between asking rents and CPI rents. 

I'm surprised how little buzz there is… Show more
------
Reminder: capability and reliability are orthogonal aspects of LLMs. You can show the presence of a capability using examples/screenshots, but not absence. LLMs' remarkable capabilities make them exciting for research, but their unreliability limits their usefulness at present.
------
Nice talk by 
@ylecun
, makes me think about all the resources, people and money that are put into LLMs... if they are a complete detour towards the path of actual intelligent systems

https://youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg&t=2600s&ab_channel=MITDepartmentofPhysics…
------
Dr. Goldblum is a postdoctoral research fellow at NYU—working with Yann LeCun (
@ylecun
) and Andrew Gordon Wilson (
@andrewgwils
)—he is recognized today for his substantial contributions to various aspects of deep learning.
------
Want even more updates on our latest research papers, datasets and more? Subscribe to the Meta AI newsletter to get a regular digest of AI news and updates.

Subscribe 
------
A civilian casualty of the anti-AI crusade.
------
I took down the prosecraft website. I'm sorry, everyone. https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121…
------
tldr; from my #kdd2023 talk:   LLM's have enough amazing approximate retrieval abilities that we can gainfully leverage, and we don't need to ascribe  fake reasoning/planning capabilities to them. 

(No illusions that the lesson would survive the llm hype day, but gotta try..)
------
Yes. Both sides fall victim to purity spirals that make them despise the "impure"
https://en.wikipedia.org/wiki/Purity_spiral…
------
Just wondering, if one chooses the "centrist" aka "middle path" stance in any ongoing argument (be it about AI, culture, politics etc), would that actually imply more attacks from both sides? 
------
Back-propagation for feed-forward architectures is a special case of reverse-mode automatic differentiation. It computes the gradient of a loss function with a cost comparable to the computation of the loss function itself. https://en.wikipedia.org/wiki/Backpropagation…
------
AI, RPG, FPS, gangsta rap, Scandinavian monster heavy metal, internet erotica: all causes of unwarranted moral panics.
------
Some cultural expressions I enjoy, such as role-playing games and gangsta rap, were the targets of moral panics in the 80s and 90s. Now Artificial Intelligence is the target of a moral panic with the moral entrepreneurs of  "AI safety" playing the role of the Christian Right.
------
Raise your hand if you’re funding European Open-source startups and let’s change this!
------
A talk I gave at MIT recently.
"Objective-Driven AI: towards AI systems that can learn, remember, plan, reason, have common sense, yet are steerable and safe"

Slides: https://drive.google.com/file/d/1wzHohvoSgKGZvzOWqZybjm4M4veKR6t3/view?usp=drivesdk…

Video:
------
As I have pointed out before, AI doomerism is a kind of apocalyptic cult.

Why would its most vocal advocates come from ultra-religious families (that they broke away from because of science)?
------
July 7: The @BostonGlobe published this profile:

"Dan Hendrycks wants to save us from an AI catastrophe. He's not sure he'll succeed."

Apparently, his evangelical beliefs have been replaced by a new religion:
AI Doomerism.

https://archive.vn/Sn1v0
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Humpback! making a splash with self-alignment:
1. Self-augment: generate good "instructions" for a set of existing "answers" using Llama.
2. Self-curate: rate the generated data using Llama.
3. Self-tune: fine-tune Llama with the data.
4. Iterate.
5. Beat other LLMs.
------
New Paper 
Self-Alignment with Instruction Backtranslation

- New method auto-labels web text with instructions & curates high quality ones for FTing

- Our model Humpback  outperforms LIMA, Claude, Guanaco, davinci-003 & Falcon-Inst

https://arxiv.org/abs/2308.06259
(1/4)
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via 
@PessimistsArc
) suggesting a horse outperforms a car.
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
When Einstein Failed Edison's Aptitude Test

In 1921, Albert Einstein visited Boston, where reporters handed him a test of knowledge designed by Thomas Edison based on memorized scientific facts

Not recalling the speed of sound, Einstein flunked the exam

https://medium.com/starts-with-a-bang/einstein-edison-and-an-aptitude-for-genius-31a41a1947f1…
------
Michael I. Jordan on ChatGPT and AI: "We're fearful in 10 years it can get out of control and all that. That's just not true. ChatGPT is predicting the next word in a sentence, just remember that's what it does".
https://youtu.be/mszj94hEKH4
1/3
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Inflation is basically GONE when you exclude the lagged shelter (i.e. rent) data in CPI. Remember: Rent is the biggest variable in the CPI's biggest category (shelter), and there's a known 12-month lag between asking rents and CPI rents. 

I'm surprised how little buzz there is… Show more
------
Reminder: capability and reliability are orthogonal aspects of LLMs. You can show the presence of a capability using examples/screenshots, but not absence. LLMs' remarkable capabilities make them exciting for research, but their unreliability limits their usefulness at present.
------
Nice talk by 
@ylecun
, makes me think about all the resources, people and money that are put into LLMs... if they are a complete detour towards the path of actual intelligent systems

https://youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg&t=2600s&ab_channel=MITDepartmentofPhysics…
------
Dr. Goldblum is a postdoctoral research fellow at NYU—working with Yann LeCun (
@ylecun
) and Andrew Gordon Wilson (
@andrewgwils
)—he is recognized today for his substantial contributions to various aspects of deep learning.
------
Want even more updates on our latest research papers, datasets and more? Subscribe to the Meta AI newsletter to get a regular digest of AI news and updates.

Subscribe 
------
A civilian casualty of the anti-AI crusade.
------
I took down the prosecraft website. I'm sorry, everyone. https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121…
------
tldr; from my #kdd2023 talk:   LLM's have enough amazing approximate retrieval abilities that we can gainfully leverage, and we don't need to ascribe  fake reasoning/planning capabilities to them. 

(No illusions that the lesson would survive the llm hype day, but gotta try..)
------
Yes. Both sides fall victim to purity spirals that make them despise the "impure"
https://en.wikipedia.org/wiki/Purity_spiral…
------
Just wondering, if one chooses the "centrist" aka "middle path" stance in any ongoing argument (be it about AI, culture, politics etc), would that actually imply more attacks from both sides? 
------
Back-propagation for feed-forward architectures is a special case of reverse-mode automatic differentiation. It computes the gradient of a loss function with a cost comparable to the computation of the loss function itself. https://en.wikipedia.org/wiki/Backpropagation…
------
AI, RPG, FPS, gangsta rap, Scandinavian monster heavy metal, internet erotica: all causes of unwarranted moral panics.
------
Some cultural expressions I enjoy, such as role-playing games and gangsta rap, were the targets of moral panics in the 80s and 90s. Now Artificial Intelligence is the target of a moral panic with the moral entrepreneurs of  "AI safety" playing the role of the Christian Right.
------
Raise your hand if you’re funding European Open-source startups and let’s change this!
------
A talk I gave at MIT recently.
"Objective-Driven AI: towards AI systems that can learn, remember, plan, reason, have common sense, yet are steerable and safe"

Slides: https://drive.google.com/file/d/1wzHohvoSgKGZvzOWqZybjm4M4veKR6t3/view?usp=drivesdk…

Video:
------
As I have pointed out before, AI doomerism is a kind of apocalyptic cult.

Why would its most vocal advocates come from ultra-religious families (that they broke away from because of science)?
------
July 7: The @BostonGlobe published this profile:

"Dan Hendrycks wants to save us from an AI catastrophe. He's not sure he'll succeed."

Apparently, his evangelical beliefs have been replaced by a new religion:
AI Doomerism.

https://archive.vn/Sn1v0
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Anisotropic diffusion is fun! It can also cause SGD in deep learning to get attracted to *higher* training error saddle points that nevertheless have *lower* test error than local minima with lower training error.  Details here: https://arxiv.org/abs/2306.04251
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Crouching revolt, hidden success.

"one of the abiding mysteries of France today is this: a country with an aversion to change, a talent for revolt & an excessive taste for taxes still manages to get so much right. Recently France has even outperformed its big European peers.… Show more
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
"I discovered, to my amazement, that all through history there had been resistance…vand bitter, exaggerated, last-stitch resistance…vto every significant technological change that had taken place on earth" - Isaac Asimov
------
People resist new technology, new ideas. As Dostoevsky opens Crime & Punishment with: "Taking a new step, uttering a new word, is what people fear most." I think fear points the way toward progress. Here's an ad from 1915 (via @PessimistsArc) suggesting a horse outperforms a car.
------
When Einstein Failed Edison's Aptitude Test

In 1921, Albert Einstein visited Boston, where reporters handed him a test of knowledge designed by Thomas Edison based on memorized scientific facts

Not recalling the speed of sound, Einstein flunked the exam

https://medium.com/starts-with-a-bang/einstein-edison-and-an-aptitude-for-genius-31a41a1947f1…
------
Michael I. Jordan on ChatGPT and AI: "We're fearful in 10 years it can get out of control and all that. That's just not true. ChatGPT is predicting the next word in a sentence, just remember that's what it does".
https://youtu.be/mszj94hEKH4
1/3
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Inflation is basically GONE when you exclude the lagged shelter (i.e. rent) data in CPI. Remember: Rent is the biggest variable in the CPI's biggest category (shelter), and there's a known 12-month lag between asking rents and CPI rents. 

I'm surprised how little buzz there is… Show more
------
Reminder: capability and reliability are orthogonal aspects of LLMs. You can show the presence of a capability using examples/screenshots, but not absence. LLMs' remarkable capabilities make them exciting for research, but their unreliability limits their usefulness at present.
------
Nice talk by 
@ylecun
, makes me think about all the resources, people and money that are put into LLMs... if they are a complete detour towards the path of actual intelligent systems

https://youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg&t=2600s&ab_channel=MITDepartmentofPhysics…
------
Dr. Goldblum is a postdoctoral research fellow at NYU—working with Yann LeCun (
@ylecun
) and Andrew Gordon Wilson (
@andrewgwils
)—he is recognized today for his substantial contributions to various aspects of deep learning.
------
Want even more updates on our latest research papers, datasets and more? Subscribe to the Meta AI newsletter to get a regular digest of AI news and updates.

Subscribe 
------
A civilian casualty of the anti-AI crusade.
------
I took down the prosecraft website. I'm sorry, everyone. https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121…
------
tldr; from my #kdd2023 talk:   LLM's have enough amazing approximate retrieval abilities that we can gainfully leverage, and we don't need to ascribe  fake reasoning/planning capabilities to them. 

(No illusions that the lesson would survive the llm hype day, but gotta try..)
------
Yes. Both sides fall victim to purity spirals that make them despise the "impure"
https://en.wikipedia.org/wiki/Purity_spiral…
------
Just wondering, if one chooses the "centrist" aka "middle path" stance in any ongoing argument (be it about AI, culture, politics etc), would that actually imply more attacks from both sides? 
------
Back-propagation for feed-forward architectures is a special case of reverse-mode automatic differentiation. It computes the gradient of a loss function with a cost comparable to the computation of the loss function itself. https://en.wikipedia.org/wiki/Backpropagation…
------
AI, RPG, FPS, gangsta rap, Scandinavian monster heavy metal, internet erotica: all causes of unwarranted moral panics.
------
Some cultural expressions I enjoy, such as role-playing games and gangsta rap, were the targets of moral panics in the 80s and 90s. Now Artificial Intelligence is the target of a moral panic with the moral entrepreneurs of  "AI safety" playing the role of the Christian Right.
------
Raise your hand if you’re funding European Open-source startups and let’s change this!
------
A talk I gave at MIT recently.
"Objective-Driven AI: towards AI systems that can learn, remember, plan, reason, have common sense, yet are steerable and safe"

Slides: https://drive.google.com/file/d/1wzHohvoSgKGZvzOWqZybjm4M4veKR6t3/view?usp=drivesdk…

Video:
------
As I have pointed out before, AI doomerism is a kind of apocalyptic cult.

Why would its most vocal advocates come from ultra-religious families (that they broke away from because of science)?
------
July 7: The @BostonGlobe published this profile:

"Dan Hendrycks wants to save us from an AI catastrophe. He's not sure he'll succeed."

Apparently, his evangelical beliefs have been replaced by a new religion:
AI Doomerism.

https://archive.vn/Sn1v0
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Anisotropic diffusion is fun! It can also cause SGD in deep learning to get attracted to *higher* training error saddle points that nevertheless have *lower* test error than local minima with lower training error.  Details here: https://arxiv.org/abs/2306.04251
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Crouching revolt, hidden success.

"one of the abiding mysteries of France today is this: a country with an aversion to change, a talent for revolt & an excessive taste for taxes still manages to get so much right. Recently France has even outperformed its big European peers.… Show more
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
Capabilities of AI systems do not just "emerge".
Lots of people come up with lots of ideas, try many of them, and fine-tune like mad to bring those new capabilities.
Then, a considerable amount of effort is devoted to detecting and evaluating capabilities *and* flaws.
------
i keep hearing people say "we are discovering new capabilities" of LLMs, or "new capabilities emerge". 

that's the wrong metaphor. we are guiding, shaping, and aligning these models. 

by showing positive examples of desired outputs we aim to increase the likelihood that an LLM… Show more
------
@sanchitgandhi99
 is letting me know that we are about to cross the 1 million downloads for MusicGen! And AudioCraft has just crossed 10k Really excited and touched to see such a fast adoption by the community 

@jadecopet
 
@FelixKreuk
 
@adiyossLC
 
@syhw
 
------
It's great to see US productivity increase at a 3.7% rate in Q2.

Here's a new piece in 
@barronsonline
 by Martin Baily, 
@akorinek
  and me making the case that long-term productivity growth will be much higher as well, due to generative AI and more.
------
Introducing http://detectron.app from 
@OlorenAI
. Upload images, draw bounding boxes, and get a trained model in seconds. Export to ONNX or a prebuilt inference endpoint.

100x better than Google Cloud or wrestling 18 python versions to train a model myself. (2/3)
------
Inflation is basically GONE when you exclude the lagged shelter (i.e. rent) data in CPI. Remember: Rent is the biggest variable in the CPI's biggest category (shelter), and there's a known 12-month lag between asking rents and CPI rents. 

I'm surprised how little buzz there is… Show more
------
Reminder: capability and reliability are orthogonal aspects of LLMs. You can show the presence of a capability using examples/screenshots, but not absence. LLMs' remarkable capabilities make them exciting for research, but their unreliability limits their usefulness at present.
------
Nice talk by 
@ylecun
, makes me think about all the resources, people and money that are put into LLMs... if they are a complete detour towards the path of actual intelligent systems

https://youtube.com/watch?v=vyqXLJsmsrk&list=PLKemzYMx2_Ot1MZ_er2vFiINdJEgDO8Hg&t=2600s&ab_channel=MITDepartmentofPhysics…
------
Dr. Goldblum is a postdoctoral research fellow at NYU—working with Yann LeCun (
@ylecun
) and Andrew Gordon Wilson (
@andrewgwils
)—he is recognized today for his substantial contributions to various aspects of deep learning.
------
Want even more updates on our latest research papers, datasets and more? Subscribe to the Meta AI newsletter to get a regular digest of AI news and updates.

Subscribe 
------
A civilian casualty of the anti-AI crusade.
------
I took down the prosecraft website. I'm sorry, everyone. https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121…
------
tldr; from my #kdd2023 talk:   LLM's have enough amazing approximate retrieval abilities that we can gainfully leverage, and we don't need to ascribe  fake reasoning/planning capabilities to them. 

(No illusions that the lesson would survive the llm hype day, but gotta try..)
------
Yes. Both sides fall victim to purity spirals that make them despise the "impure"
https://en.wikipedia.org/wiki/Purity_spiral…
------
Just wondering, if one chooses the "centrist" aka "middle path" stance in any ongoing argument (be it about AI, culture, politics etc), would that actually imply more attacks from both sides? 
------
Back-propagation for feed-forward architectures is a special case of reverse-mode automatic differentiation. It computes the gradient of a loss function with a cost comparable to the computation of the loss function itself. https://en.wikipedia.org/wiki/Backpropagation…
------
AI, RPG, FPS, gangsta rap, Scandinavian monster heavy metal, internet erotica: all causes of unwarranted moral panics.
------
Some cultural expressions I enjoy, such as role-playing games and gangsta rap, were the targets of moral panics in the 80s and 90s. Now Artificial Intelligence is the target of a moral panic with the moral entrepreneurs of  "AI safety" playing the role of the Christian Right.
------
Raise your hand if you’re funding European Open-source startups and let’s change this!
------
A talk I gave at MIT recently.
"Objective-Driven AI: towards AI systems that can learn, remember, plan, reason, have common sense, yet are steerable and safe"

Slides: https://drive.google.com/file/d/1wzHohvoSgKGZvzOWqZybjm4M4veKR6t3/view?usp=drivesdk…

Video:
------
As I have pointed out before, AI doomerism is a kind of apocalyptic cult.

Why would its most vocal advocates come from ultra-religious families (that they broke away from because of science)?
------
July 7: The @BostonGlobe published this profile:

"Dan Hendrycks wants to save us from an AI catastrophe. He's not sure he'll succeed."

Apparently, his evangelical beliefs have been replaced by a new religion:
AI Doomerism.

https://archive.vn/Sn1v0
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Anisotropic diffusion is fun! It can also cause SGD in deep learning to get attracted to *higher* training error saddle points that nevertheless have *lower* test error than local minima with lower training error.  Details here: https://arxiv.org/abs/2306.04251
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Crouching revolt, hidden success.

"one of the abiding mysteries of France today is this: a country with an aversion to change, a talent for revolt & an excessive taste for taxes still manages to get so much right. Recently France has even outperformed its big European peers.… Show more
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
Capabilities of AI systems do not just "emerge".
Lots of people come up with lots of ideas, try many of them, and fine-tune like mad to bring those new capabilities.
Then, a considerable amount of effort is devoted to detecting and evaluating capabilities *and* flaws.
------
i keep hearing people say "we are discovering new capabilities" of LLMs, or "new capabilities emerge". 

that's the wrong metaphor. we are guiding, shaping, and aligning these models. 

by showing positive examples of desired outputs we aim to increase the likelihood that an LLM… Show more
------
@sanchitgandhi99
 is letting me know that we are about to cross the 1 million downloads for MusicGen! And AudioCraft has just crossed 10k Really excited and touched to see such a fast adoption by the community 

@jadecopet
 
@FelixKreuk
 
@adiyossLC
 
@syhw
 
------
It's great to see US productivity increase at a 3.7% rate in Q2.

Here's a new piece in 
@barronsonline
 by Martin Baily, 
@akorinek
  and me making the case that long-term productivity growth will be much higher as well, due to generative AI and more.
------
AudioGen v2 Colab  Thanks to 
@FelixKreuk
  
@syhw
  Adam Polyak  
@urielsinger
  
@honualx
  
@jadecopet
  
@deviparikh
  
@taigman
  
@adiyossLC
 

paper: https://arxiv.org/abs/2209.15352
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/audiogen-colab…
------
A new version of Vicuna, now based on LLaMA-2.
------
Commercial-friendly Vicuna models!  Th @lmsysorg   just released a new version of their Vicuna model family.  Vicuna is an open LLM alternative to ChatGPT and GPT-4. 

 1/3
------
Faster LlaMa Chat now on http://labs.pplx.ai ! 
We’ve added more capacity and improved the inference efficiency with cool streaming and time to first token metrics! The 70b should feel fast and is largely as capable as gpt-3.5-turbo, so this should give you the same… Show more
------
We've made updates to LlaMa Chat!
Try it for free: https://labs.pplx.ai

 Performance Enhancements
We've boosted overall system efficiency for a smoother experience.

Extended Input Field
After hearing your feedback, we've adjusted the UI to accommodate longer queries,… Show more
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Want even more updates on our latest research papers, datasets and more? Subscribe to the Meta AI newsletter to get a regular digest of AI news and updates.

Subscribe 
------
A civilian casualty of the anti-AI crusade.
------
I took down the prosecraft website. I'm sorry, everyone. https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121…
------
tldr; from my #kdd2023 talk:   LLM's have enough amazing approximate retrieval abilities that we can gainfully leverage, and we don't need to ascribe  fake reasoning/planning capabilities to them. 

(No illusions that the lesson would survive the llm hype day, but gotta try..)
------
Yes. Both sides fall victim to purity spirals that make them despise the "impure"
https://en.wikipedia.org/wiki/Purity_spiral…
------
Just wondering, if one chooses the "centrist" aka "middle path" stance in any ongoing argument (be it about AI, culture, politics etc), would that actually imply more attacks from both sides? 
------
Back-propagation for feed-forward architectures is a special case of reverse-mode automatic differentiation. It computes the gradient of a loss function with a cost comparable to the computation of the loss function itself. https://en.wikipedia.org/wiki/Backpropagation…
------
AI, RPG, FPS, gangsta rap, Scandinavian monster heavy metal, internet erotica: all causes of unwarranted moral panics.
------
Some cultural expressions I enjoy, such as role-playing games and gangsta rap, were the targets of moral panics in the 80s and 90s. Now Artificial Intelligence is the target of a moral panic with the moral entrepreneurs of  "AI safety" playing the role of the Christian Right.
------
Raise your hand if you’re funding European Open-source startups and let’s change this!
------
A talk I gave at MIT recently.
"Objective-Driven AI: towards AI systems that can learn, remember, plan, reason, have common sense, yet are steerable and safe"

Slides: https://drive.google.com/file/d/1wzHohvoSgKGZvzOWqZybjm4M4veKR6t3/view?usp=drivesdk…

Video:
------
As I have pointed out before, AI doomerism is a kind of apocalyptic cult.

Why would its most vocal advocates come from ultra-religious families (that they broke away from because of science)?
------
July 7: The @BostonGlobe published this profile:

"Dan Hendrycks wants to save us from an AI catastrophe. He's not sure he'll succeed."

Apparently, his evangelical beliefs have been replaced by a new religion:
AI Doomerism.

https://archive.vn/Sn1v0
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Anisotropic diffusion is fun! It can also cause SGD in deep learning to get attracted to *higher* training error saddle points that nevertheless have *lower* test error than local minima with lower training error.  Details here: https://arxiv.org/abs/2306.04251
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Crouching revolt, hidden success.

"one of the abiding mysteries of France today is this: a country with an aversion to change, a talent for revolt & an excessive taste for taxes still manages to get so much right. Recently France has even outperformed its big European peers.… Show more
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
Capabilities of AI systems do not just "emerge".
Lots of people come up with lots of ideas, try many of them, and fine-tune like mad to bring those new capabilities.
Then, a considerable amount of effort is devoted to detecting and evaluating capabilities *and* flaws.
------
i keep hearing people say "we are discovering new capabilities" of LLMs, or "new capabilities emerge". 

that's the wrong metaphor. we are guiding, shaping, and aligning these models. 

by showing positive examples of desired outputs we aim to increase the likelihood that an LLM… Show more
------
@sanchitgandhi99
 is letting me know that we are about to cross the 1 million downloads for MusicGen! And AudioCraft has just crossed 10k Really excited and touched to see such a fast adoption by the community 

@jadecopet
 
@FelixKreuk
 
@adiyossLC
 
@syhw
 
------
It's great to see US productivity increase at a 3.7% rate in Q2.

Here's a new piece in 
@barronsonline
 by Martin Baily, 
@akorinek
  and me making the case that long-term productivity growth will be much higher as well, due to generative AI and more.
------
AudioGen v2 Colab  Thanks to 
@FelixKreuk
  
@syhw
  Adam Polyak  
@urielsinger
  
@honualx
  
@jadecopet
  
@deviparikh
  
@taigman
  
@adiyossLC
 

paper: https://arxiv.org/abs/2209.15352
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/audiogen-colab…
------
A new version of Vicuna, now based on LLaMA-2.
------
Commercial-friendly Vicuna models!  Th @lmsysorg   just released a new version of their Vicuna model family.  Vicuna is an open LLM alternative to ChatGPT and GPT-4. 

 1/3
------
Faster LlaMa Chat now on http://labs.pplx.ai ! 
We’ve added more capacity and improved the inference efficiency with cool streaming and time to first token metrics! The 70b should feel fast and is largely as capable as gpt-3.5-turbo, so this should give you the same… Show more
------
We've made updates to LlaMa Chat!
Try it for free: https://labs.pplx.ai

 Performance Enhancements
We've boosted overall system efficiency for a smoother experience.

Extended Input Field
After hearing your feedback, we've adjusted the UI to accommodate longer queries,… Show more
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Really excited about this release! We provide all the tools you need to start training your own audio models or just play with the ones we provideAnd amazing work by 
@jadecopet
 for the final sprint 
https://github.com/facebookresearch/audiocraft…
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models! twitter.com/MetaAI/status/…
------
Raise your hand if you’re funding European Open-source startups and let’s change this!
------
A talk I gave at MIT recently.
"Objective-Driven AI: towards AI systems that can learn, remember, plan, reason, have common sense, yet are steerable and safe"

Slides: https://drive.google.com/file/d/1wzHohvoSgKGZvzOWqZybjm4M4veKR6t3/view?usp=drivesdk…

Video:
------
As I have pointed out before, AI doomerism is a kind of apocalyptic cult.

Why would its most vocal advocates come from ultra-religious families (that they broke away from because of science)?
------
July 7: The @BostonGlobe published this profile:

"Dan Hendrycks wants to save us from an AI catastrophe. He's not sure he'll succeed."

Apparently, his evangelical beliefs have been replaced by a new religion:
AI Doomerism.

https://archive.vn/Sn1v0
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Anisotropic diffusion is fun! It can also cause SGD in deep learning to get attracted to *higher* training error saddle points that nevertheless have *lower* test error than local minima with lower training error.  Details here: https://arxiv.org/abs/2306.04251
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Crouching revolt, hidden success.

"one of the abiding mysteries of France today is this: a country with an aversion to change, a talent for revolt & an excessive taste for taxes still manages to get so much right. Recently France has even outperformed its big European peers.… Show more
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
Capabilities of AI systems do not just "emerge".
Lots of people come up with lots of ideas, try many of them, and fine-tune like mad to bring those new capabilities.
Then, a considerable amount of effort is devoted to detecting and evaluating capabilities *and* flaws.
------
i keep hearing people say "we are discovering new capabilities" of LLMs, or "new capabilities emerge". 

that's the wrong metaphor. we are guiding, shaping, and aligning these models. 

by showing positive examples of desired outputs we aim to increase the likelihood that an LLM… Show more
------
@sanchitgandhi99
 is letting me know that we are about to cross the 1 million downloads for MusicGen! And AudioCraft has just crossed 10k Really excited and touched to see such a fast adoption by the community 

@jadecopet
 
@FelixKreuk
 
@adiyossLC
 
@syhw
 
------
It's great to see US productivity increase at a 3.7% rate in Q2.

Here's a new piece in 
@barronsonline
 by Martin Baily, 
@akorinek
  and me making the case that long-term productivity growth will be much higher as well, due to generative AI and more.
------
AudioGen v2 Colab  Thanks to 
@FelixKreuk
  
@syhw
  Adam Polyak  
@urielsinger
  
@honualx
  
@jadecopet
  
@deviparikh
  
@taigman
  
@adiyossLC
 

paper: https://arxiv.org/abs/2209.15352
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/audiogen-colab…
------
A new version of Vicuna, now based on LLaMA-2.
------
Commercial-friendly Vicuna models!  Th @lmsysorg   just released a new version of their Vicuna model family.  Vicuna is an open LLM alternative to ChatGPT and GPT-4. 

 1/3
------
Faster LlaMa Chat now on http://labs.pplx.ai ! 
We’ve added more capacity and improved the inference efficiency with cool streaming and time to first token metrics! The 70b should feel fast and is largely as capable as gpt-3.5-turbo, so this should give you the same… Show more
------
We've made updates to LlaMa Chat!
Try it for free: https://labs.pplx.ai

 Performance Enhancements
We've boosted overall system efficiency for a smoother experience.

Extended Input Field
After hearing your feedback, we've adjusted the UI to accommodate longer queries,… Show more
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Really excited about this release! We provide all the tools you need to start training your own audio models or just play with the ones we provideAnd amazing work by 
@jadecopet
 for the final sprint 
https://github.com/facebookresearch/audiocraft…
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models! twitter.com/MetaAI/status/…
------
Remember MusicGen? Today we open sourced the training code, as well as for AudioGen, and for EnCodec, and a bunch of goodies (models you can go play with and extend). Big congrats to 
@jadecopet
, 
@honualx
, 
@adiyossLC
 and everybody else for this last push!
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models!
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
Access to healthcare, life expectancy, retirement age, parental leave, infant mortality, infrastructure, incarceration rate, income inequalities, poverty level,...
The US has all the characteristics of an underdeveloped country except for one: GDP/capita.
------
The US is not a typical affluent western democracy - we do worse in most measures of human flourishing. Guns, cars, drugs are major causes.  https://economist.com/united-states/2023/07/31/horrifying-numbers-of-americans-will-not-make-it-to-old-age…
------
Good news alert 

After decades of radical declines in cost, unsubsidized solar & wind are now the cheapest forms of available power 
------
The government is being heavily pressured to ban open source. How can we prevent this? By campaigning in favor of open source and electing officials who understand the fundamental importance of it.
------
Yet another open-source generative AI from Meta: 
AudioCraft = AudioGen + MusicGen + EnCodec
Produces realistic audio and music from text descriptions.
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
“The thinking machine… friend of foe” (1962)
------
CM3leon is a first-of-its-kind multimodal model that achieves state-of-the-art performance for text-to-image generation despite being trained with five times less compute than previous transformer-based methods.

More details and examples  https://bit.ly/44I6t7E
------
Why oh why would we want to have strict caps limiting us from recruiting exactly the people we need for this critical industry?
------
Such an own goal:

“America is limiting its access to one obvious source of talent. Immigrants account for about 40% of highly skilled workers in America’s semiconductor industry. They are funnelled through a couple of visa programmes, with strict caps. But those caps are fixed”
------
Anisotropic diffusion is fun! It can also cause SGD in deep learning to get attracted to *higher* training error saddle points that nevertheless have *lower* test error than local minima with lower training error.  Details here: https://arxiv.org/abs/2306.04251
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Anisotropic diffusion uses space-varying conductivity to slow down diffusion near edges, resulting in non-isotropic diffusion behavior. https://en.wikipedia.org/wiki/Anisotropic_diffusion…
------
Crouching revolt, hidden success.

"one of the abiding mysteries of France today is this: a country with an aversion to change, a talent for revolt & an excessive taste for taxes still manages to get so much right. Recently France has even outperformed its big European peers.… Show more
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
Capabilities of AI systems do not just "emerge".
Lots of people come up with lots of ideas, try many of them, and fine-tune like mad to bring those new capabilities.
Then, a considerable amount of effort is devoted to detecting and evaluating capabilities *and* flaws.
------
i keep hearing people say "we are discovering new capabilities" of LLMs, or "new capabilities emerge". 

that's the wrong metaphor. we are guiding, shaping, and aligning these models. 

by showing positive examples of desired outputs we aim to increase the likelihood that an LLM… Show more
------
@sanchitgandhi99
 is letting me know that we are about to cross the 1 million downloads for MusicGen! And AudioCraft has just crossed 10k Really excited and touched to see such a fast adoption by the community 

@jadecopet
 
@FelixKreuk
 
@adiyossLC
 
@syhw
 
------
It's great to see US productivity increase at a 3.7% rate in Q2.

Here's a new piece in 
@barronsonline
 by Martin Baily, 
@akorinek
  and me making the case that long-term productivity growth will be much higher as well, due to generative AI and more.
------
AudioGen v2 Colab  Thanks to 
@FelixKreuk
  
@syhw
  Adam Polyak  
@urielsinger
  
@honualx
  
@jadecopet
  
@deviparikh
  
@taigman
  
@adiyossLC
 

paper: https://arxiv.org/abs/2209.15352
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/audiogen-colab…
------
A new version of Vicuna, now based on LLaMA-2.
------
Commercial-friendly Vicuna models!  Th @lmsysorg   just released a new version of their Vicuna model family.  Vicuna is an open LLM alternative to ChatGPT and GPT-4. 

 1/3
------
Faster LlaMa Chat now on http://labs.pplx.ai ! 
We’ve added more capacity and improved the inference efficiency with cool streaming and time to first token metrics! The 70b should feel fast and is largely as capable as gpt-3.5-turbo, so this should give you the same… Show more
------
We've made updates to LlaMa Chat!
Try it for free: https://labs.pplx.ai

 Performance Enhancements
We've boosted overall system efficiency for a smoother experience.

Extended Input Field
After hearing your feedback, we've adjusted the UI to accommodate longer queries,… Show more
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Really excited about this release! We provide all the tools you need to start training your own audio models or just play with the ones we provideAnd amazing work by 
@jadecopet
 for the final sprint 
https://github.com/facebookresearch/audiocraft…
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models! twitter.com/MetaAI/status/…
------
Remember MusicGen? Today we open sourced the training code, as well as for AudioGen, and for EnCodec, and a bunch of goodies (models you can go play with and extend). Big congrats to 
@jadecopet
, 
@honualx
, 
@adiyossLC
 and everybody else for this last push!
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models!
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
Access to healthcare, life expectancy, retirement age, parental leave, infant mortality, infrastructure, incarceration rate, income inequalities, poverty level,...
The US has all the characteristics of an underdeveloped country except for one: GDP/capita.
------
The US is not a typical affluent western democracy - we do worse in most measures of human flourishing. Guns, cars, drugs are major causes.  https://economist.com/united-states/2023/07/31/horrifying-numbers-of-americans-will-not-make-it-to-old-age…
------
Good news alert 

After decades of radical declines in cost, unsubsidized solar & wind are now the cheapest forms of available power 
------
The government is being heavily pressured to ban open source. How can we prevent this? By campaigning in favor of open source and electing officials who understand the fundamental importance of it.
------
Yet another open-source generative AI from Meta: 
AudioCraft = AudioGen + MusicGen + EnCodec
Produces realistic audio and music from text descriptions.
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
“The thinking machine… friend of foe” (1962)
------
CM3leon is a first-of-its-kind multimodal model that achieves state-of-the-art performance for text-to-image generation despite being trained with five times less compute than previous transformer-based methods.

More details and examples  https://bit.ly/44I6t7E
------
At the #ICML2023 KLR workshop (Knowledge & Logical Reasoning in the era of Data Driven Learning),  I spoke about how LLM's are ushering in a new era of (approximate) knowledge-based AI systems, and what it means for Planning. Video & Slides 
------
Here are policies that the Hoover Institution recommends to improve the U.S.' long-term competitiveness in the semiconductor industry.

Folks, Reaganomics is over. Industrial policy has won. All that's left is to hash out the details of what the new world looks like.
------
American exceptionalism.
------
Horrifying numbers of Americans will not make it to old age 
------
The proximal map projects on a level set. For l^p norms, it is a thresholding operator shrinking toward 0. It induces sparsity for p smaller than 1. https://en.wikipedia.org/wiki/Proximal_operator…
------
The French economy is doing well, but many French people (mostly opposed to Macron on the left and the right) think it's not.

Similarly, the US economy is doing well, but many Americans (mostly opposed to Biden on the right) think it's not.
------
On many counts France  is quietly doing better than other European countries (1/2)

Cc: @ylecun @GerardAraud @Noahpinion @mattyglesias
------
Capabilities of AI systems do not just "emerge".
Lots of people come up with lots of ideas, try many of them, and fine-tune like mad to bring those new capabilities.
Then, a considerable amount of effort is devoted to detecting and evaluating capabilities *and* flaws.
------
i keep hearing people say "we are discovering new capabilities" of LLMs, or "new capabilities emerge". 

that's the wrong metaphor. we are guiding, shaping, and aligning these models. 

by showing positive examples of desired outputs we aim to increase the likelihood that an LLM… Show more
------
@sanchitgandhi99
 is letting me know that we are about to cross the 1 million downloads for MusicGen! And AudioCraft has just crossed 10k Really excited and touched to see such a fast adoption by the community 

@jadecopet
 
@FelixKreuk
 
@adiyossLC
 
@syhw
 
------
It's great to see US productivity increase at a 3.7% rate in Q2.

Here's a new piece in 
@barronsonline
 by Martin Baily, 
@akorinek
  and me making the case that long-term productivity growth will be much higher as well, due to generative AI and more.
------
AudioGen v2 Colab  Thanks to 
@FelixKreuk
  
@syhw
  Adam Polyak  
@urielsinger
  
@honualx
  
@jadecopet
  
@deviparikh
  
@taigman
  
@adiyossLC
 

paper: https://arxiv.org/abs/2209.15352
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/audiogen-colab…
------
A new version of Vicuna, now based on LLaMA-2.
------
Commercial-friendly Vicuna models!  Th @lmsysorg   just released a new version of their Vicuna model family.  Vicuna is an open LLM alternative to ChatGPT and GPT-4. 

 1/3
------
Faster LlaMa Chat now on http://labs.pplx.ai ! 
We’ve added more capacity and improved the inference efficiency with cool streaming and time to first token metrics! The 70b should feel fast and is largely as capable as gpt-3.5-turbo, so this should give you the same… Show more
------
We've made updates to LlaMa Chat!
Try it for free: https://labs.pplx.ai

 Performance Enhancements
We've boosted overall system efficiency for a smoother experience.

Extended Input Field
After hearing your feedback, we've adjusted the UI to accommodate longer queries,… Show more
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Really excited about this release! We provide all the tools you need to start training your own audio models or just play with the ones we provideAnd amazing work by 
@jadecopet
 for the final sprint 
https://github.com/facebookresearch/audiocraft…
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models! twitter.com/MetaAI/status/…
------
Remember MusicGen? Today we open sourced the training code, as well as for AudioGen, and for EnCodec, and a bunch of goodies (models you can go play with and extend). Big congrats to 
@jadecopet
, 
@honualx
, 
@adiyossLC
 and everybody else for this last push!
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models!
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
Access to healthcare, life expectancy, retirement age, parental leave, infant mortality, infrastructure, incarceration rate, income inequalities, poverty level,...
The US has all the characteristics of an underdeveloped country except for one: GDP/capita.
------
The US is not a typical affluent western democracy - we do worse in most measures of human flourishing. Guns, cars, drugs are major causes.  https://economist.com/united-states/2023/07/31/horrifying-numbers-of-americans-will-not-make-it-to-old-age…
------
Good news alert 

After decades of radical declines in cost, unsubsidized solar & wind are now the cheapest forms of available power 
------
The government is being heavily pressured to ban open source. How can we prevent this? By campaigning in favor of open source and electing officials who understand the fundamental importance of it.
------
Yet another open-source generative AI from Meta: 
AudioCraft = AudioGen + MusicGen + EnCodec
Produces realistic audio and music from text descriptions.
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
“The thinking machine… friend of foe” (1962)
------
CM3leon is a first-of-its-kind multimodal model that achieves state-of-the-art performance for text-to-image generation despite being trained with five times less compute than previous transformer-based methods.

More details and examples  https://bit.ly/44I6t7E
------
At the #ICML2023 KLR workshop (Knowledge & Logical Reasoning in the era of Data Driven Learning),  I spoke about how LLM's are ushering in a new era of (approximate) knowledge-based AI systems, and what it means for Planning. Video & Slides 
------
Here are policies that the Hoover Institution recommends to improve the U.S.' long-term competitiveness in the semiconductor industry.

Folks, Reaganomics is over. Industrial policy has won. All that's left is to hash out the details of what the new world looks like.
------
American exceptionalism.
------
Horrifying numbers of Americans will not make it to old age 
------
The proximal map projects on a level set. For l^p norms, it is a thresholding operator shrinking toward 0. It induces sparsity for p smaller than 1. https://en.wikipedia.org/wiki/Proximal_operator…
------
I remember reading Section 8.4 of the Feynman Lectures on Physics when I was an undergrad, and it was a revelation.
Very few assumptions are required to arrive at what is basically Shrödinger's equation.
Basically just 3 things:
1. the state of a system is a complex vector C
2.… Show more
------
ICML papers with authors affiliated with the NYU Center for Data Science.

https://cds.nyu.edu/icml-2023-papers/…
------
We’re thankful for the incredible response to Llama 2 and early uses + development already emerging in the community. With 150K+ download requests in just the first week, we can't wait to see how you build with these models.

More in this note 
------
LLaMA-2 in Rust, by Sasha 
@srush_nlp
 .
------
http://Llama2.rs (https://github.com/srush/llama2.rs)  - A one-file Rust Llama2.c.

Pretty safe, and fast.
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
AudioGen v2 Colab  Thanks to 
@FelixKreuk
  
@syhw
  Adam Polyak  
@urielsinger
  
@honualx
  
@jadecopet
  
@deviparikh
  
@taigman
  
@adiyossLC
 

paper: https://arxiv.org/abs/2209.15352
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/audiogen-colab…
------
A new version of Vicuna, now based on LLaMA-2.
------
Commercial-friendly Vicuna models!  Th @lmsysorg   just released a new version of their Vicuna model family.  Vicuna is an open LLM alternative to ChatGPT and GPT-4. 

 1/3
------
Faster LlaMa Chat now on http://labs.pplx.ai ! 
We’ve added more capacity and improved the inference efficiency with cool streaming and time to first token metrics! The 70b should feel fast and is largely as capable as gpt-3.5-turbo, so this should give you the same… Show more
------
We've made updates to LlaMa Chat!
Try it for free: https://labs.pplx.ai

 Performance Enhancements
We've boosted overall system efficiency for a smoother experience.

Extended Input Field
After hearing your feedback, we've adjusted the UI to accommodate longer queries,… Show more
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Really excited about this release! We provide all the tools you need to start training your own audio models or just play with the ones we provideAnd amazing work by 
@jadecopet
 for the final sprint 
https://github.com/facebookresearch/audiocraft…
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models! twitter.com/MetaAI/status/…
------
Remember MusicGen? Today we open sourced the training code, as well as for AudioGen, and for EnCodec, and a bunch of goodies (models you can go play with and extend). Big congrats to 
@jadecopet
, 
@honualx
, 
@adiyossLC
 and everybody else for this last push!
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models!
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
Access to healthcare, life expectancy, retirement age, parental leave, infant mortality, infrastructure, incarceration rate, income inequalities, poverty level,...
The US has all the characteristics of an underdeveloped country except for one: GDP/capita.
------
The US is not a typical affluent western democracy - we do worse in most measures of human flourishing. Guns, cars, drugs are major causes.  https://economist.com/united-states/2023/07/31/horrifying-numbers-of-americans-will-not-make-it-to-old-age…
------
Good news alert 

After decades of radical declines in cost, unsubsidized solar & wind are now the cheapest forms of available power 
------
The government is being heavily pressured to ban open source. How can we prevent this? By campaigning in favor of open source and electing officials who understand the fundamental importance of it.
------
Yet another open-source generative AI from Meta: 
AudioCraft = AudioGen + MusicGen + EnCodec
Produces realistic audio and music from text descriptions.
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
“The thinking machine… friend of foe” (1962)
------
CM3leon is a first-of-its-kind multimodal model that achieves state-of-the-art performance for text-to-image generation despite being trained with five times less compute than previous transformer-based methods.

More details and examples  https://bit.ly/44I6t7E
------
At the #ICML2023 KLR workshop (Knowledge & Logical Reasoning in the era of Data Driven Learning),  I spoke about how LLM's are ushering in a new era of (approximate) knowledge-based AI systems, and what it means for Planning. Video & Slides 
------
Here are policies that the Hoover Institution recommends to improve the U.S.' long-term competitiveness in the semiconductor industry.

Folks, Reaganomics is over. Industrial policy has won. All that's left is to hash out the details of what the new world looks like.
------
American exceptionalism.
------
Horrifying numbers of Americans will not make it to old age 
------
The proximal map projects on a level set. For l^p norms, it is a thresholding operator shrinking toward 0. It induces sparsity for p smaller than 1. https://en.wikipedia.org/wiki/Proximal_operator…
------
I remember reading Section 8.4 of the Feynman Lectures on Physics when I was an undergrad, and it was a revelation.
Very few assumptions are required to arrive at what is basically Shrödinger's equation.
Basically just 3 things:
1. the state of a system is a complex vector C
2.… Show more
------
ICML papers with authors affiliated with the NYU Center for Data Science.

https://cds.nyu.edu/icml-2023-papers/…
------
We’re thankful for the incredible response to Llama 2 and early uses + development already emerging in the community. With 150K+ download requests in just the first week, we can't wait to see how you build with these models.

More in this note 
------
LLaMA-2 in Rust, by Sasha 
@srush_nlp
 .
------
http://Llama2.rs (https://github.com/srush/llama2.rs)  - A one-file Rust Llama2.c.

Pretty safe, and fast.
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
You can now test Llama 2 in less than 10 minutes.

Llama 2 is one of the most consequential developments of 2023. It's an open-source alternative to proprietary Large Language Models with a commercial license.

Llama 2 has every ingredient to become successful: it’s open-source,… Show more
------
AI is not nuclear.

The way to make nuclear safe was to make sure only a small number of actors can do it.

The way to make AI safe and robust is to make it open source.
------
An explanation of why eliminating the Global Interpreter Lock in Python enables more efficient multithreading.
The GIL elimination was made possible by a multiyear heroic effort led by Sam Gross at Meta.
------
GIL in Python will be no more. Huge win for AI ecosystem. Congrats to @colesbury - it took 4+ years of amazing engineering and advocacy.

Many parts of @PyTorch could become simpler: DataLoader, Multi-gpu support (DDP), Python deployment (torch::deploy), …

Here’s why.  twitter.com/soumithchintal…
------
Numerical inverse kinematics solves an ill-posed inverse problem (non-unique solution) by gradient descent, thereby leveraging an "implicit bias" (favoring minimal displacements). It is at the heart of robotics and CG animation. https://en.wikipedia.org/wiki/Inverse_kinematics…
------
Really excited about this release! We provide all the tools you need to start training your own audio models or just play with the ones we provideAnd amazing work by 
@jadecopet
 for the final sprint 
https://github.com/facebookresearch/audiocraft…
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models! twitter.com/MetaAI/status/…
------
Remember MusicGen? Today we open sourced the training code, as well as for AudioGen, and for EnCodec, and a bunch of goodies (models you can go play with and extend). Big congrats to 
@jadecopet
, 
@honualx
, 
@adiyossLC
 and everybody else for this last push!
------
Today we open source the training code for our audio generation and compression research in AudioCraft and share new models.

With this release, we aim at giving people the full recipe to play with our models and develop their own models!
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
Access to healthcare, life expectancy, retirement age, parental leave, infant mortality, infrastructure, incarceration rate, income inequalities, poverty level,...
The US has all the characteristics of an underdeveloped country except for one: GDP/capita.
------
The US is not a typical affluent western democracy - we do worse in most measures of human flourishing. Guns, cars, drugs are major causes.  https://economist.com/united-states/2023/07/31/horrifying-numbers-of-americans-will-not-make-it-to-old-age…
------
Good news alert 

After decades of radical declines in cost, unsubsidized solar & wind are now the cheapest forms of available power 
------
The government is being heavily pressured to ban open source. How can we prevent this? By campaigning in favor of open source and electing officials who understand the fundamental importance of it.
------
Yet another open-source generative AI from Meta: 
AudioCraft = AudioGen + MusicGen + EnCodec
Produces realistic audio and music from text descriptions.
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
“The thinking machine… friend of foe” (1962)
------
CM3leon is a first-of-its-kind multimodal model that achieves state-of-the-art performance for text-to-image generation despite being trained with five times less compute than previous transformer-based methods.

More details and examples  https://bit.ly/44I6t7E
------
At the #ICML2023 KLR workshop (Knowledge & Logical Reasoning in the era of Data Driven Learning),  I spoke about how LLM's are ushering in a new era of (approximate) knowledge-based AI systems, and what it means for Planning. Video & Slides 
------
Here are policies that the Hoover Institution recommends to improve the U.S.' long-term competitiveness in the semiconductor industry.

Folks, Reaganomics is over. Industrial policy has won. All that's left is to hash out the details of what the new world looks like.
------
American exceptionalism.
------
Horrifying numbers of Americans will not make it to old age 
------
The proximal map projects on a level set. For l^p norms, it is a thresholding operator shrinking toward 0. It induces sparsity for p smaller than 1. https://en.wikipedia.org/wiki/Proximal_operator…
------
I remember reading Section 8.4 of the Feynman Lectures on Physics when I was an undergrad, and it was a revelation.
Very few assumptions are required to arrive at what is basically Shrödinger's equation.
Basically just 3 things:
1. the state of a system is a complex vector C
2.… Show more
------
ICML papers with authors affiliated with the NYU Center for Data Science.

https://cds.nyu.edu/icml-2023-papers/…
------
We’re thankful for the incredible response to Llama 2 and early uses + development already emerging in the community. With 150K+ download requests in just the first week, we can't wait to see how you build with these models.

More in this note 
------
LLaMA-2 in Rust, by Sasha 
@srush_nlp
 .
------
http://Llama2.rs (https://github.com/srush/llama2.rs)  - A one-file Rust Llama2.c.

Pretty safe, and fast.
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
You can now test Llama 2 in less than 10 minutes.

Llama 2 is one of the most consequential developments of 2023. It's an open-source alternative to proprietary Large Language Models with a commercial license.

Llama 2 has every ingredient to become successful: it’s open-source,… Show more
------
AI is not nuclear.

The way to make nuclear safe was to make sure only a small number of actors can do it.

The way to make AI safe and robust is to make it open source.
------
An explanation of why eliminating the Global Interpreter Lock in Python enables more efficient multithreading.
The GIL elimination was made possible by a multiyear heroic effort led by Sam Gross at Meta.
------
GIL in Python will be no more. Huge win for AI ecosystem. Congrats to @colesbury - it took 4+ years of amazing engineering and advocacy.

Many parts of @PyTorch could become simpler: DataLoader, Multi-gpu support (DDP), Python deployment (torch::deploy), …

Here’s why.  twitter.com/soumithchintal…
------
Looks like my account has been hacked.
Stay tuned....
------
Account integrity restored.
Sorry for the now-deleted spam tweets.
------
Thank you 
@elonmusk
 and team for locking the account quickly and helping with the recovery.
Apologies to those at X and Meta whose Saturday evening was partially ruined.
------
The open source models arena

I try not to post too much about open models until we reach a point where there will no longer be any debate about if they are at the level of closed models.

So let's make it brief. 

----
LLaMA 2

The open models arena heated up last week with the… Show more
------
The number of tourists spending time in France every year is almost twice the population of France.

In August, the number of actual Parisians in Paris is vanishingly small.
------
International tourism (number of annual arrivals):

 France: 117m
 Poland: 88.5m
 Mexico: 51m
 USA: 45m
 Thailand: 39.9m
 Italy: 38.4m 
 Czechia: 37.2m
 Spain: 36.4m
 Canada: 32.4m
 Hungary: 31.6m
 China: 30.4m
 Croatia: 21.6m
 India: 17.9m
 Turkey:… Show more
------
A balanced view of the issues of open vs closed LLMs.

Quote: <<Princeton computer science professor Arvind Narayanan told Vox that “the bottleneck for bad actors isn’t generating misinformation — it’s distributing it and persuading people.” He added, “AI, whether open source or… Show more
------
That's one thing we agree on.
I suggest a gentle ramp up:
- Surely you are joking Mr Feynman 
- QED
- The Feynman Lectures on Physics
- Quantum Mechanics and Path Integrals (Feynman & Hibbs)
------
People should read Feynman’s books
------
Good news alert 

After decades of radical declines in cost, unsubsidized solar & wind are now the cheapest forms of available power 
------
The government is being heavily pressured to ban open source. How can we prevent this? By campaigning in favor of open source and electing officials who understand the fundamental importance of it.
------
Yet another open-source generative AI from Meta: 
AudioCraft = AudioGen + MusicGen + EnCodec
Produces realistic audio and music from text descriptions.
------
Today we're sharing details on AudioCraft, a new family of generative AI models built for generating high-quality, realistic audio & music from text. AudioCraft is a single code base that works for music, sound, compression & generation — all in the same place.

More details 
------
“The thinking machine… friend of foe” (1962)
------
CM3leon is a first-of-its-kind multimodal model that achieves state-of-the-art performance for text-to-image generation despite being trained with five times less compute than previous transformer-based methods.

More details and examples  https://bit.ly/44I6t7E
------
At the #ICML2023 KLR workshop (Knowledge & Logical Reasoning in the era of Data Driven Learning),  I spoke about how LLM's are ushering in a new era of (approximate) knowledge-based AI systems, and what it means for Planning. Video & Slides 
------
Here are policies that the Hoover Institution recommends to improve the U.S.' long-term competitiveness in the semiconductor industry.

Folks, Reaganomics is over. Industrial policy has won. All that's left is to hash out the details of what the new world looks like.
------
American exceptionalism.
------
Horrifying numbers of Americans will not make it to old age 
------
The proximal map projects on a level set. For l^p norms, it is a thresholding operator shrinking toward 0. It induces sparsity for p smaller than 1. https://en.wikipedia.org/wiki/Proximal_operator…
------
I remember reading Section 8.4 of the Feynman Lectures on Physics when I was an undergrad, and it was a revelation.
Very few assumptions are required to arrive at what is basically Shrödinger's equation.
Basically just 3 things:
1. the state of a system is a complex vector C
2.… Show more
------
ICML papers with authors affiliated with the NYU Center for Data Science.

https://cds.nyu.edu/icml-2023-papers/…
------
We’re thankful for the incredible response to Llama 2 and early uses + development already emerging in the community. With 150K+ download requests in just the first week, we can't wait to see how you build with these models.

More in this note 
------
LLaMA-2 in Rust, by Sasha 
@srush_nlp
 .
------
http://Llama2.rs (https://github.com/srush/llama2.rs)  - A one-file Rust Llama2.c.

Pretty safe, and fast.
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
You can now test Llama 2 in less than 10 minutes.

Llama 2 is one of the most consequential developments of 2023. It's an open-source alternative to proprietary Large Language Models with a commercial license.

Llama 2 has every ingredient to become successful: it’s open-source,… Show more
------
AI is not nuclear.

The way to make nuclear safe was to make sure only a small number of actors can do it.

The way to make AI safe and robust is to make it open source.
------
An explanation of why eliminating the Global Interpreter Lock in Python enables more efficient multithreading.
The GIL elimination was made possible by a multiyear heroic effort led by Sam Gross at Meta.
------
GIL in Python will be no more. Huge win for AI ecosystem. Congrats to @colesbury - it took 4+ years of amazing engineering and advocacy.

Many parts of @PyTorch could become simpler: DataLoader, Multi-gpu support (DDP), Python deployment (torch::deploy), …

Here’s why.  twitter.com/soumithchintal…
------
Looks like my account has been hacked.
Stay tuned....
------
Account integrity restored.
Sorry for the now-deleted spam tweets.
------
Thank you 
@elonmusk
 and team for locking the account quickly and helping with the recovery.
Apologies to those at X and Meta whose Saturday evening was partially ruined.
------
The open source models arena

I try not to post too much about open models until we reach a point where there will no longer be any debate about if they are at the level of closed models.

So let's make it brief. 

----
LLaMA 2

The open models arena heated up last week with the… Show more
------
The number of tourists spending time in France every year is almost twice the population of France.

In August, the number of actual Parisians in Paris is vanishingly small.
------
International tourism (number of annual arrivals):

 France: 117m
 Poland: 88.5m
 Mexico: 51m
 USA: 45m
 Thailand: 39.9m
 Italy: 38.4m 
 Czechia: 37.2m
 Spain: 36.4m
 Canada: 32.4m
 Hungary: 31.6m
 China: 30.4m
 Croatia: 21.6m
 India: 17.9m
 Turkey:… Show more
------
A balanced view of the issues of open vs closed LLMs.

Quote: <<Princeton computer science professor Arvind Narayanan told Vox that “the bottleneck for bad actors isn’t generating misinformation — it’s distributing it and persuading people.” He added, “AI, whether open source or… Show more
------
That's one thing we agree on.
I suggest a gentle ramp up:
- Surely you are joking Mr Feynman 
- QED
- The Feynman Lectures on Physics
- Quantum Mechanics and Path Integrals (Feynman & Hibbs)
------
People should read Feynman’s books
------
No more GIL!
Python code can now breathe multiple gulps of fresh air simultaneously.
------
No More GIL!
the Python team has officially accepted the proposal.

Congrats @colesbury on his multi-year brilliant effort to remove the GIL, and a heartfelt thanks to the Python Steering Council and Core team for a thoughtful plan to make this a reality.

https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474…
------
To better enable the community to build on our work — and contribute to the responsible development of LLMs — we've published further details about the architecture, training compute, approach to fine-tuning & more for Llama 2 in a new paper.

Full paper https://bit.ly/44JAELQ
------
This went viral, thanks Jurgen! The requests have hit a high and we’re adding more capacity to make the LLaMa  70b chat faster and more reliable. It’s fun and usable for most open ended things like cooking ideas, ideas for coding interview questions, hiking ideas for weekend,… Show more
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
At the #ICML2023 KLR workshop (Knowledge & Logical Reasoning in the era of Data Driven Learning),  I spoke about how LLM's are ushering in a new era of (approximate) knowledge-based AI systems, and what it means for Planning. Video & Slides 
------
Here are policies that the Hoover Institution recommends to improve the U.S.' long-term competitiveness in the semiconductor industry.

Folks, Reaganomics is over. Industrial policy has won. All that's left is to hash out the details of what the new world looks like.
------
American exceptionalism.
------
Horrifying numbers of Americans will not make it to old age 
------
The proximal map projects on a level set. For l^p norms, it is a thresholding operator shrinking toward 0. It induces sparsity for p smaller than 1. https://en.wikipedia.org/wiki/Proximal_operator…
------
I remember reading Section 8.4 of the Feynman Lectures on Physics when I was an undergrad, and it was a revelation.
Very few assumptions are required to arrive at what is basically Shrödinger's equation.
Basically just 3 things:
1. the state of a system is a complex vector C
2.… Show more
------
ICML papers with authors affiliated with the NYU Center for Data Science.

https://cds.nyu.edu/icml-2023-papers/…
------
We’re thankful for the incredible response to Llama 2 and early uses + development already emerging in the community. With 150K+ download requests in just the first week, we can't wait to see how you build with these models.

More in this note 
------
LLaMA-2 in Rust, by Sasha 
@srush_nlp
 .
------
http://Llama2.rs (https://github.com/srush/llama2.rs)  - A one-file Rust Llama2.c.

Pretty safe, and fast.
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
You can now test Llama 2 in less than 10 minutes.

Llama 2 is one of the most consequential developments of 2023. It's an open-source alternative to proprietary Large Language Models with a commercial license.

Llama 2 has every ingredient to become successful: it’s open-source,… Show more
------
AI is not nuclear.

The way to make nuclear safe was to make sure only a small number of actors can do it.

The way to make AI safe and robust is to make it open source.
------
An explanation of why eliminating the Global Interpreter Lock in Python enables more efficient multithreading.
The GIL elimination was made possible by a multiyear heroic effort led by Sam Gross at Meta.
------
GIL in Python will be no more. Huge win for AI ecosystem. Congrats to @colesbury - it took 4+ years of amazing engineering and advocacy.

Many parts of @PyTorch could become simpler: DataLoader, Multi-gpu support (DDP), Python deployment (torch::deploy), …

Here’s why.  twitter.com/soumithchintal…
------
Looks like my account has been hacked.
Stay tuned....
------
Account integrity restored.
Sorry for the now-deleted spam tweets.
------
Thank you 
@elonmusk
 and team for locking the account quickly and helping with the recovery.
Apologies to those at X and Meta whose Saturday evening was partially ruined.
------
The open source models arena

I try not to post too much about open models until we reach a point where there will no longer be any debate about if they are at the level of closed models.

So let's make it brief. 

----
LLaMA 2

The open models arena heated up last week with the… Show more
------
The number of tourists spending time in France every year is almost twice the population of France.

In August, the number of actual Parisians in Paris is vanishingly small.
------
International tourism (number of annual arrivals):

 France: 117m
 Poland: 88.5m
 Mexico: 51m
 USA: 45m
 Thailand: 39.9m
 Italy: 38.4m 
 Czechia: 37.2m
 Spain: 36.4m
 Canada: 32.4m
 Hungary: 31.6m
 China: 30.4m
 Croatia: 21.6m
 India: 17.9m
 Turkey:… Show more
------
A balanced view of the issues of open vs closed LLMs.

Quote: <<Princeton computer science professor Arvind Narayanan told Vox that “the bottleneck for bad actors isn’t generating misinformation — it’s distributing it and persuading people.” He added, “AI, whether open source or… Show more
------
That's one thing we agree on.
I suggest a gentle ramp up:
- Surely you are joking Mr Feynman 
- QED
- The Feynman Lectures on Physics
- Quantum Mechanics and Path Integrals (Feynman & Hibbs)
------
People should read Feynman’s books
------
No more GIL!
Python code can now breathe multiple gulps of fresh air simultaneously.
------
No More GIL!
the Python team has officially accepted the proposal.

Congrats @colesbury on his multi-year brilliant effort to remove the GIL, and a heartfelt thanks to the Python Steering Council and Core team for a thoughtful plan to make this a reality.

https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474…
------
To better enable the community to build on our work — and contribute to the responsible development of LLMs — we've published further details about the architecture, training compute, approach to fine-tuning & more for Llama 2 in a new paper.

Full paper https://bit.ly/44JAELQ
------
This went viral, thanks Jurgen! The requests have hit a high and we’re adding more capacity to make the LLaMa  70b chat faster and more reliable. It’s fun and usable for most open ended things like cooking ideas, ideas for coding interview questions, hiking ideas for weekend,… Show more
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
«Masked Trajectory Models for Prediction, Representation, and Control»
Good job, 
@philippswu
, both for the work and the great explanation!
https://arxiv.org/abs/2305.02968
------
In case you didn't know, the increase of polarization in the US House of Representatives started long before social networks or the internet existed.
------
Mitosis of Congress
------
Link to paper:
------
So exciting to _finally_ get to talk about the US 2020 FB and IG Election Project!

A few notes from my perspective as a methodological collaborator kind of on the border between the academic and the Meta teams. 
------
“Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations" won the Best Student Paper Award at the 19th “Robotics: Science and Systems” (RSS) Conference in Korea earlier this month.
------
I remember reading Section 8.4 of the Feynman Lectures on Physics when I was an undergrad, and it was a revelation.
Very few assumptions are required to arrive at what is basically Shrödinger's equation.
Basically just 3 things:
1. the state of a system is a complex vector C
2.… Show more
------
ICML papers with authors affiliated with the NYU Center for Data Science.

https://cds.nyu.edu/icml-2023-papers/…
------
We’re thankful for the incredible response to Llama 2 and early uses + development already emerging in the community. With 150K+ download requests in just the first week, we can't wait to see how you build with these models.

More in this note 
------
LLaMA-2 in Rust, by Sasha 
@srush_nlp
 .
------
http://Llama2.rs (https://github.com/srush/llama2.rs)  - A one-file Rust Llama2.c.

Pretty safe, and fast.
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
You can now test Llama 2 in less than 10 minutes.

Llama 2 is one of the most consequential developments of 2023. It's an open-source alternative to proprietary Large Language Models with a commercial license.

Llama 2 has every ingredient to become successful: it’s open-source,… Show more
------
AI is not nuclear.

The way to make nuclear safe was to make sure only a small number of actors can do it.

The way to make AI safe and robust is to make it open source.
------
An explanation of why eliminating the Global Interpreter Lock in Python enables more efficient multithreading.
The GIL elimination was made possible by a multiyear heroic effort led by Sam Gross at Meta.
------
GIL in Python will be no more. Huge win for AI ecosystem. Congrats to @colesbury - it took 4+ years of amazing engineering and advocacy.

Many parts of @PyTorch could become simpler: DataLoader, Multi-gpu support (DDP), Python deployment (torch::deploy), …

Here’s why.  twitter.com/soumithchintal…
------
Looks like my account has been hacked.
Stay tuned....
------
Account integrity restored.
Sorry for the now-deleted spam tweets.
------
Thank you 
@elonmusk
 and team for locking the account quickly and helping with the recovery.
Apologies to those at X and Meta whose Saturday evening was partially ruined.
------
The open source models arena

I try not to post too much about open models until we reach a point where there will no longer be any debate about if they are at the level of closed models.

So let's make it brief. 

----
LLaMA 2

The open models arena heated up last week with the… Show more
------
The number of tourists spending time in France every year is almost twice the population of France.

In August, the number of actual Parisians in Paris is vanishingly small.
------
International tourism (number of annual arrivals):

 France: 117m
 Poland: 88.5m
 Mexico: 51m
 USA: 45m
 Thailand: 39.9m
 Italy: 38.4m 
 Czechia: 37.2m
 Spain: 36.4m
 Canada: 32.4m
 Hungary: 31.6m
 China: 30.4m
 Croatia: 21.6m
 India: 17.9m
 Turkey:… Show more
------
A balanced view of the issues of open vs closed LLMs.

Quote: <<Princeton computer science professor Arvind Narayanan told Vox that “the bottleneck for bad actors isn’t generating misinformation — it’s distributing it and persuading people.” He added, “AI, whether open source or… Show more
------
That's one thing we agree on.
I suggest a gentle ramp up:
- Surely you are joking Mr Feynman 
- QED
- The Feynman Lectures on Physics
- Quantum Mechanics and Path Integrals (Feynman & Hibbs)
------
People should read Feynman’s books
------
No more GIL!
Python code can now breathe multiple gulps of fresh air simultaneously.
------
No More GIL!
the Python team has officially accepted the proposal.

Congrats @colesbury on his multi-year brilliant effort to remove the GIL, and a heartfelt thanks to the Python Steering Council and Core team for a thoughtful plan to make this a reality.

https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474…
------
To better enable the community to build on our work — and contribute to the responsible development of LLMs — we've published further details about the architecture, training compute, approach to fine-tuning & more for Llama 2 in a new paper.

Full paper https://bit.ly/44JAELQ
------
This went viral, thanks Jurgen! The requests have hit a high and we’re adding more capacity to make the LLaMa  70b chat faster and more reliable. It’s fun and usable for most open ended things like cooking ideas, ideas for coding interview questions, hiking ideas for weekend,… Show more
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
«Masked Trajectory Models for Prediction, Representation, and Control»
Good job, 
@philippswu
, both for the work and the great explanation!
https://arxiv.org/abs/2305.02968
------
In case you didn't know, the increase of polarization in the US House of Representatives started long before social networks or the internet existed.
------
Mitosis of Congress
------
Link to paper:
------
So exciting to _finally_ get to talk about the US 2020 FB and IG Election Project!

A few notes from my perspective as a methodological collaborator kind of on the border between the academic and the Meta teams. 
------
“Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations" won the Best Student Paper Award at the 19th “Robotics: Science and Systems” (RSS) Conference in Korea earlier this month.
------
«Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization»
Ideas can and should be communicated without unnecessary obfuscation.
Very often, less is more. Especially at conferences where you are inundated by loads of input.
https://arxiv.org/abs/2212.10445
------
After three years of hard work, today we publish on 
@ScienceMagazine
 and 
@Nature
 the first four studies of an unprecedented research collaboration to examine #SocialMediaAndElections_1/8
------
New 
@nature
: Like-minded sources on Facebook are prevalent but not polarizing
https://nature.com/articles/s41586-023-06297-w… (open access!)

Our key findings:
-Median FB user gets 50.4% of content from like-minded sources
-But reducing exposure by ~1/3 for 3 months had no measurable effect on attitudes
------
Finally, please read the other incredible papers in both 
@ScienceMagazine
 and 
@Nature
:

Asymmetric Ideological Segregation in Exposure to Political News on Facebook
https://science.org/doi/10.1126/science.ade7138…
 
Like-minded sources on Facebook are prevalent but not polarizing
------
The Legendre-Fenchel transform extends the Legendre transform to arbitrary dimensions. |x|^2/2 is the only fixed point of the transform. https://en.wikipedia.org/wiki/Legendre_transformation…
------
You can now test Llama 2 in less than 10 minutes.

Llama 2 is one of the most consequential developments of 2023. It's an open-source alternative to proprietary Large Language Models with a commercial license.

Llama 2 has every ingredient to become successful: it’s open-source,… Show more
------
AI is not nuclear.

The way to make nuclear safe was to make sure only a small number of actors can do it.

The way to make AI safe and robust is to make it open source.
------
An explanation of why eliminating the Global Interpreter Lock in Python enables more efficient multithreading.
The GIL elimination was made possible by a multiyear heroic effort led by Sam Gross at Meta.
------
GIL in Python will be no more. Huge win for AI ecosystem. Congrats to @colesbury - it took 4+ years of amazing engineering and advocacy.

Many parts of @PyTorch could become simpler: DataLoader, Multi-gpu support (DDP), Python deployment (torch::deploy), …

Here’s why.  twitter.com/soumithchintal…
------
Looks like my account has been hacked.
Stay tuned....
------
Account integrity restored.
Sorry for the now-deleted spam tweets.
------
Thank you 
@elonmusk
 and team for locking the account quickly and helping with the recovery.
Apologies to those at X and Meta whose Saturday evening was partially ruined.
------
The open source models arena

I try not to post too much about open models until we reach a point where there will no longer be any debate about if they are at the level of closed models.

So let's make it brief. 

----
LLaMA 2

The open models arena heated up last week with the… Show more
------
The number of tourists spending time in France every year is almost twice the population of France.

In August, the number of actual Parisians in Paris is vanishingly small.
------
International tourism (number of annual arrivals):

 France: 117m
 Poland: 88.5m
 Mexico: 51m
 USA: 45m
 Thailand: 39.9m
 Italy: 38.4m 
 Czechia: 37.2m
 Spain: 36.4m
 Canada: 32.4m
 Hungary: 31.6m
 China: 30.4m
 Croatia: 21.6m
 India: 17.9m
 Turkey:… Show more
------
A balanced view of the issues of open vs closed LLMs.

Quote: <<Princeton computer science professor Arvind Narayanan told Vox that “the bottleneck for bad actors isn’t generating misinformation — it’s distributing it and persuading people.” He added, “AI, whether open source or… Show more
------
That's one thing we agree on.
I suggest a gentle ramp up:
- Surely you are joking Mr Feynman 
- QED
- The Feynman Lectures on Physics
- Quantum Mechanics and Path Integrals (Feynman & Hibbs)
------
People should read Feynman’s books
------
No more GIL!
Python code can now breathe multiple gulps of fresh air simultaneously.
------
No More GIL!
the Python team has officially accepted the proposal.

Congrats @colesbury on his multi-year brilliant effort to remove the GIL, and a heartfelt thanks to the Python Steering Council and Core team for a thoughtful plan to make this a reality.

https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474…
------
To better enable the community to build on our work — and contribute to the responsible development of LLMs — we've published further details about the architecture, training compute, approach to fine-tuning & more for Llama 2 in a new paper.

Full paper https://bit.ly/44JAELQ
------
This went viral, thanks Jurgen! The requests have hit a high and we’re adding more capacity to make the LLaMa  70b chat faster and more reliable. It’s fun and usable for most open ended things like cooking ideas, ideas for coding interview questions, hiking ideas for weekend,… Show more
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
«Masked Trajectory Models for Prediction, Representation, and Control»
Good job, 
@philippswu
, both for the work and the great explanation!
https://arxiv.org/abs/2305.02968
------
In case you didn't know, the increase of polarization in the US House of Representatives started long before social networks or the internet existed.
------
Mitosis of Congress
------
Link to paper:
------
So exciting to _finally_ get to talk about the US 2020 FB and IG Election Project!

A few notes from my perspective as a methodological collaborator kind of on the border between the academic and the Meta teams. 
------
“Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations" won the Best Student Paper Award at the 19th “Robotics: Science and Systems” (RSS) Conference in Korea earlier this month.
------
«Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization»
Ideas can and should be communicated without unnecessary obfuscation.
Very often, less is more. Especially at conferences where you are inundated by loads of input.
https://arxiv.org/abs/2212.10445
------
After three years of hard work, today we publish on 
@ScienceMagazine
 and 
@Nature
 the first four studies of an unprecedented research collaboration to examine #SocialMediaAndElections_1/8
------
New 
@nature
: Like-minded sources on Facebook are prevalent but not polarizing
https://nature.com/articles/s41586-023-06297-w… (open access!)

Our key findings:
-Median FB user gets 50.4% of content from like-minded sources
-But reducing exposure by ~1/3 for 3 months had no measurable effect on attitudes
------
Finally, please read the other incredible papers in both 
@ScienceMagazine
 and 
@Nature
:

Asymmetric Ideological Segregation in Exposure to Political News on Facebook
https://science.org/doi/10.1126/science.ade7138…
 
Like-minded sources on Facebook are prevalent but not polarizing
------
If you're a researcher interested in potentially accessing de-identified study data to explore related questions, ICPSR will host a full replication archive: https://socialmediaarchive.org

11/
------
Removing reshared content (which includes viral political content) from Facebook feed does not significantly affect political polarization or other political attitudes.
------
3. ATTITUDES: As with the chrono-feed experiment, removing reshares did not significantly affect political polarization or other individual-level political attitudes.

Much more to dig into in these two papers and the others in this research package.

8/
------
During the 2020 elections, FB users who used a reverse-chronological feed instead of the regular algorithmic feed did not exhibit "altered levels of affective polarization, political knowledge, political behavior, or other key attitudes."
------
3. SURVEY-MEASURED POLITICAL OUTCOMES: Despite these changes in users' on-platform experience, the chronological feed did not significantly alter levels of issue or affective polarization, political knowledge, political behavior or other key attitudes during the study. 13/
------
A thread on the main findings of the studies of the effect of FB & Instagram on political opinion during the 2020 elections.
------
Today is publication day for the first 4 papers resulting from a unique collaboration between Meta researchers and outside academics to study the political effects of Facebook and Instagram in the 2020 U.S. election!  1/N
------
The open source models arena

I try not to post too much about open models until we reach a point where there will no longer be any debate about if they are at the level of closed models.

So let's make it brief. 

----
LLaMA 2

The open models arena heated up last week with the… Show more
------
The number of tourists spending time in France every year is almost twice the population of France.

In August, the number of actual Parisians in Paris is vanishingly small.
------
International tourism (number of annual arrivals):

 France: 117m
 Poland: 88.5m
 Mexico: 51m
 USA: 45m
 Thailand: 39.9m
 Italy: 38.4m 
 Czechia: 37.2m
 Spain: 36.4m
 Canada: 32.4m
 Hungary: 31.6m
 China: 30.4m
 Croatia: 21.6m
 India: 17.9m
 Turkey:… Show more
------
A balanced view of the issues of open vs closed LLMs.

Quote: <<Princeton computer science professor Arvind Narayanan told Vox that “the bottleneck for bad actors isn’t generating misinformation — it’s distributing it and persuading people.” He added, “AI, whether open source or… Show more
------
That's one thing we agree on.
I suggest a gentle ramp up:
- Surely you are joking Mr Feynman 
- QED
- The Feynman Lectures on Physics
- Quantum Mechanics and Path Integrals (Feynman & Hibbs)
------
People should read Feynman’s books
------
No more GIL!
Python code can now breathe multiple gulps of fresh air simultaneously.
------
No More GIL!
the Python team has officially accepted the proposal.

Congrats @colesbury on his multi-year brilliant effort to remove the GIL, and a heartfelt thanks to the Python Steering Council and Core team for a thoughtful plan to make this a reality.

https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474…
------
To better enable the community to build on our work — and contribute to the responsible development of LLMs — we've published further details about the architecture, training compute, approach to fine-tuning & more for Llama 2 in a new paper.

Full paper https://bit.ly/44JAELQ
------
This went viral, thanks Jurgen! The requests have hit a high and we’re adding more capacity to make the LLaMa  70b chat faster and more reliable. It’s fun and usable for most open ended things like cooking ideas, ideas for coding interview questions, hiking ideas for weekend,… Show more
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
«Masked Trajectory Models for Prediction, Representation, and Control»
Good job, 
@philippswu
, both for the work and the great explanation!
https://arxiv.org/abs/2305.02968
------
In case you didn't know, the increase of polarization in the US House of Representatives started long before social networks or the internet existed.
------
Mitosis of Congress
------
Link to paper:
------
So exciting to _finally_ get to talk about the US 2020 FB and IG Election Project!

A few notes from my perspective as a methodological collaborator kind of on the border between the academic and the Meta teams. 
------
“Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations" won the Best Student Paper Award at the 19th “Robotics: Science and Systems” (RSS) Conference in Korea earlier this month.
------
«Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization»
Ideas can and should be communicated without unnecessary obfuscation.
Very often, less is more. Especially at conferences where you are inundated by loads of input.
https://arxiv.org/abs/2212.10445
------
After three years of hard work, today we publish on 
@ScienceMagazine
 and 
@Nature
 the first four studies of an unprecedented research collaboration to examine #SocialMediaAndElections_1/8
------
New 
@nature
: Like-minded sources on Facebook are prevalent but not polarizing
https://nature.com/articles/s41586-023-06297-w… (open access!)

Our key findings:
-Median FB user gets 50.4% of content from like-minded sources
-But reducing exposure by ~1/3 for 3 months had no measurable effect on attitudes
------
Finally, please read the other incredible papers in both 
@ScienceMagazine
 and 
@Nature
:

Asymmetric Ideological Segregation in Exposure to Political News on Facebook
https://science.org/doi/10.1126/science.ade7138…
 
Like-minded sources on Facebook are prevalent but not polarizing
------
If you're a researcher interested in potentially accessing de-identified study data to explore related questions, ICPSR will host a full replication archive: https://socialmediaarchive.org

11/
------
Removing reshared content (which includes viral political content) from Facebook feed does not significantly affect political polarization or other political attitudes.
------
3. ATTITUDES: As with the chrono-feed experiment, removing reshares did not significantly affect political polarization or other individual-level political attitudes.

Much more to dig into in these two papers and the others in this research package.

8/
------
During the 2020 elections, FB users who used a reverse-chronological feed instead of the regular algorithmic feed did not exhibit "altered levels of affective polarization, political knowledge, political behavior, or other key attitudes."
------
3. SURVEY-MEASURED POLITICAL OUTCOMES: Despite these changes in users' on-platform experience, the chronological feed did not significantly alter levels of issue or affective polarization, political knowledge, political behavior or other key attitudes during the study. 13/
------
A thread on the main findings of the studies of the effect of FB & Instagram on political opinion during the 2020 elections.
------
Today is publication day for the first 4 papers resulting from a unique collaboration between Meta researchers and outside academics to study the political effects of Facebook and Instagram in the 2020 U.S. election!  1/N
------
Four papers in Sciences & Nature on the impact of Facebook and Instagram on political opinions during the 2020 elections.

Always good to actually collect and study the data, rather than use gut feelings.
------
New in Science and Nature: The first four papers from the U.S. 2020 Facebook and Instagram Election Study!
------
Pretty funny how financial types don't understand the concept of long-term R&D investment.
To them, R&D investment is "lost money".
It only becomes "lost" if/when you give up on the whole product concept.
But that has not happened.
------
Mark Zuckerberg's Metaverse has lost over $21.3 billion since 2022.
------
Those threats:
- have existed for years without AI.
- social network co's have been on the frontline fighting them.
- Meta has large orgs entirely devoted to fighting them.
- they make *massive* use of the latest AI tech, including transformers/LLMs.
- the claim by some AI… Show more
------
With a comprehensive understanding of the range of risks associated with #GeneralPurposeAI models, policymakers can proactively mitigate these hazards -
with @pegahbyte we provide a risk map for this! 

3 risk categories incl. current examples & scenarios: https://stiftung-nv.de/de/publikation/governing-general-purpose-ai-comprehensive-map-unreliability-misuse-and-systemic-risks…
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
No more GIL!
Python code can now breathe multiple gulps of fresh air simultaneously.
------
No More GIL!
the Python team has officially accepted the proposal.

Congrats @colesbury on his multi-year brilliant effort to remove the GIL, and a heartfelt thanks to the Python Steering Council and Core team for a thoughtful plan to make this a reality.

https://discuss.python.org/t/a-steering-council-notice-about-pep-703-making-the-global-interpreter-lock-optional-in-cpython/30474…
------
To better enable the community to build on our work — and contribute to the responsible development of LLMs — we've published further details about the architecture, training compute, approach to fine-tuning & more for Llama 2 in a new paper.

Full paper https://bit.ly/44JAELQ
------
This went viral, thanks Jurgen! The requests have hit a high and we’re adding more capacity to make the LLaMa  70b chat faster and more reliable. It’s fun and usable for most open ended things like cooking ideas, ideas for coding interview questions, hiking ideas for weekend,… Show more
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
«Masked Trajectory Models for Prediction, Representation, and Control»
Good job, 
@philippswu
, both for the work and the great explanation!
https://arxiv.org/abs/2305.02968
------
In case you didn't know, the increase of polarization in the US House of Representatives started long before social networks or the internet existed.
------
Mitosis of Congress
------
Link to paper:
------
So exciting to _finally_ get to talk about the US 2020 FB and IG Election Project!

A few notes from my perspective as a methodological collaborator kind of on the border between the academic and the Meta teams. 
------
“Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations" won the Best Student Paper Award at the 19th “Robotics: Science and Systems” (RSS) Conference in Korea earlier this month.
------
«Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization»
Ideas can and should be communicated without unnecessary obfuscation.
Very often, less is more. Especially at conferences where you are inundated by loads of input.
https://arxiv.org/abs/2212.10445
------
After three years of hard work, today we publish on 
@ScienceMagazine
 and 
@Nature
 the first four studies of an unprecedented research collaboration to examine #SocialMediaAndElections_1/8
------
New 
@nature
: Like-minded sources on Facebook are prevalent but not polarizing
https://nature.com/articles/s41586-023-06297-w… (open access!)

Our key findings:
-Median FB user gets 50.4% of content from like-minded sources
-But reducing exposure by ~1/3 for 3 months had no measurable effect on attitudes
------
Finally, please read the other incredible papers in both 
@ScienceMagazine
 and 
@Nature
:

Asymmetric Ideological Segregation in Exposure to Political News on Facebook
https://science.org/doi/10.1126/science.ade7138…
 
Like-minded sources on Facebook are prevalent but not polarizing
------
If you're a researcher interested in potentially accessing de-identified study data to explore related questions, ICPSR will host a full replication archive: https://socialmediaarchive.org

11/
------
Removing reshared content (which includes viral political content) from Facebook feed does not significantly affect political polarization or other political attitudes.
------
3. ATTITUDES: As with the chrono-feed experiment, removing reshares did not significantly affect political polarization or other individual-level political attitudes.

Much more to dig into in these two papers and the others in this research package.

8/
------
During the 2020 elections, FB users who used a reverse-chronological feed instead of the regular algorithmic feed did not exhibit "altered levels of affective polarization, political knowledge, political behavior, or other key attitudes."
------
3. SURVEY-MEASURED POLITICAL OUTCOMES: Despite these changes in users' on-platform experience, the chronological feed did not significantly alter levels of issue or affective polarization, political knowledge, political behavior or other key attitudes during the study. 13/
------
A thread on the main findings of the studies of the effect of FB & Instagram on political opinion during the 2020 elections.
------
Today is publication day for the first 4 papers resulting from a unique collaboration between Meta researchers and outside academics to study the political effects of Facebook and Instagram in the 2020 U.S. election!  1/N
------
Four papers in Sciences & Nature on the impact of Facebook and Instagram on political opinions during the 2020 elections.

Always good to actually collect and study the data, rather than use gut feelings.
------
New in Science and Nature: The first four papers from the U.S. 2020 Facebook and Instagram Election Study!
------
Pretty funny how financial types don't understand the concept of long-term R&D investment.
To them, R&D investment is "lost money".
It only becomes "lost" if/when you give up on the whole product concept.
But that has not happened.
------
Mark Zuckerberg's Metaverse has lost over $21.3 billion since 2022.
------
Those threats:
- have existed for years without AI.
- social network co's have been on the frontline fighting them.
- Meta has large orgs entirely devoted to fighting them.
- they make *massive* use of the latest AI tech, including transformers/LLMs.
- the claim by some AI… Show more
------
With a comprehensive understanding of the range of risks associated with #GeneralPurposeAI models, policymakers can proactively mitigate these hazards -
with @pegahbyte we provide a risk map for this! 

3 risk categories incl. current examples & scenarios: https://stiftung-nv.de/de/publikation/governing-general-purpose-ai-comprehensive-map-unreliability-misuse-and-systemic-risks…
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
Major Regretxit
------
Huge regret over Brexit in Britain 

Cc: @Noahpinion @williamnhutton @DalrympleWill @GerardAraud
------
L'IA aide le médecin 
@NablaTech
------
 "Deux minutes au lieu de deux heures"

Certaines disciplines utilisent déjà l’IA comme assistant, tandis que la recherche médicale s’en empare. Pour progresser, les données seront la clef.  Thread 1/7  
https://lexpress.fr/sciences-sante/sante/deux-minutes-au-lieu-de-deux-heures-quand-lia-se-met-au-service-de-la-sante-NVXYW7ZP2JH5FA63M6KDBKWY64/…
------
We're looking for a research engineer to work with us on exciting topics around neural compression on the FAIR team in New York! If you're interested, please apply! I'm also at ICML if you'd like to chat.

Position:
------
Open Catalyst Demo: using AI to accelerate the simulation of molecules interacting with catalysts.
This may help the discovery of new catalysts.
------
Today we're releasing the Open Catalyst Demo to the public — this new service will allow researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials ~1000x faster than existing computational methods using AI.

Demo 
------
«Masked Trajectory Models for Prediction, Representation, and Control»
Good job, 
@philippswu
, both for the work and the great explanation!
https://arxiv.org/abs/2305.02968
------
In case you didn't know, the increase of polarization in the US House of Representatives started long before social networks or the internet existed.
------
Mitosis of Congress
------
Link to paper:
------
So exciting to _finally_ get to talk about the US 2020 FB and IG Election Project!

A few notes from my perspective as a methodological collaborator kind of on the border between the academic and the Meta teams. 
------
“Teach a Robot to FISH: Versatile Imitation from One Minute of Demonstrations" won the Best Student Paper Award at the 19th “Robotics: Science and Systems” (RSS) Conference in Korea earlier this month.
------
«Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization»
Ideas can and should be communicated without unnecessary obfuscation.
Very often, less is more. Especially at conferences where you are inundated by loads of input.
https://arxiv.org/abs/2212.10445
------
After three years of hard work, today we publish on 
@ScienceMagazine
 and 
@Nature
 the first four studies of an unprecedented research collaboration to examine #SocialMediaAndElections_1/8
------
New 
@nature
: Like-minded sources on Facebook are prevalent but not polarizing
https://nature.com/articles/s41586-023-06297-w… (open access!)

Our key findings:
-Median FB user gets 50.4% of content from like-minded sources
-But reducing exposure by ~1/3 for 3 months had no measurable effect on attitudes
------
Finally, please read the other incredible papers in both 
@ScienceMagazine
 and 
@Nature
:

Asymmetric Ideological Segregation in Exposure to Political News on Facebook
https://science.org/doi/10.1126/science.ade7138…
 
Like-minded sources on Facebook are prevalent but not polarizing
------
If you're a researcher interested in potentially accessing de-identified study data to explore related questions, ICPSR will host a full replication archive: https://socialmediaarchive.org

11/
------
Removing reshared content (which includes viral political content) from Facebook feed does not significantly affect political polarization or other political attitudes.
------
3. ATTITUDES: As with the chrono-feed experiment, removing reshares did not significantly affect political polarization or other individual-level political attitudes.

Much more to dig into in these two papers and the others in this research package.

8/
------
During the 2020 elections, FB users who used a reverse-chronological feed instead of the regular algorithmic feed did not exhibit "altered levels of affective polarization, political knowledge, political behavior, or other key attitudes."
------
3. SURVEY-MEASURED POLITICAL OUTCOMES: Despite these changes in users' on-platform experience, the chronological feed did not significantly alter levels of issue or affective polarization, political knowledge, political behavior or other key attitudes during the study. 13/
------
A thread on the main findings of the studies of the effect of FB & Instagram on political opinion during the 2020 elections.
------
Today is publication day for the first 4 papers resulting from a unique collaboration between Meta researchers and outside academics to study the political effects of Facebook and Instagram in the 2020 U.S. election!  1/N
------
Four papers in Sciences & Nature on the impact of Facebook and Instagram on political opinions during the 2020 elections.

Always good to actually collect and study the data, rather than use gut feelings.
------
New in Science and Nature: The first four papers from the U.S. 2020 Facebook and Instagram Election Study!
------
Pretty funny how financial types don't understand the concept of long-term R&D investment.
To them, R&D investment is "lost money".
It only becomes "lost" if/when you give up on the whole product concept.
But that has not happened.
------
Mark Zuckerberg's Metaverse has lost over $21.3 billion since 2022.
------
Those threats:
- have existed for years without AI.
- social network co's have been on the frontline fighting them.
- Meta has large orgs entirely devoted to fighting them.
- they make *massive* use of the latest AI tech, including transformers/LLMs.
- the claim by some AI… Show more
------
With a comprehensive understanding of the range of risks associated with #GeneralPurposeAI models, policymakers can proactively mitigate these hazards -
with @pegahbyte we provide a risk map for this! 

3 risk categories incl. current examples & scenarios: https://stiftung-nv.de/de/publikation/governing-general-purpose-ai-comprehensive-map-unreliability-misuse-and-systemic-risks…
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
Major Regretxit
------
Huge regret over Brexit in Britain 

Cc: @Noahpinion @williamnhutton @DalrympleWill @GerardAraud
------
L'IA aide le médecin 
@NablaTech
------
 "Deux minutes au lieu de deux heures"

Certaines disciplines utilisent déjà l’IA comme assistant, tandis que la recherche médicale s’en empare. Pour progresser, les données seront la clef.  Thread 1/7  
https://lexpress.fr/sciences-sante/sante/deux-minutes-au-lieu-de-deux-heures-quand-lia-se-met-au-service-de-la-sante-NVXYW7ZP2JH5FA63M6KDBKWY64/…
------
We're looking for a research engineer to work with us on exciting topics around neural compression on the FAIR team in New York! If you're interested, please apply! I'm also at ICML if you'd like to chat.

Position:
------
Open Catalyst Demo: using AI to accelerate the simulation of molecules interacting with catalysts.
This may help the discovery of new catalysts.
------
Today we're releasing the Open Catalyst Demo to the public — this new service will allow researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials ~1000x faster than existing computational methods using AI.

Demo 
------
Key Takesaways from 
@pmarca
 and 
@joerogan
 

Full notes here ---> https://podcastnotes.org/joe-rogan-experience/2010-marc-andreessen-joe-rogan-ai/…

Think of AI as a sophisticated autocomplete that probabilistically uses all the text ever written to accurately predict the next word. 

The next step for AI is to correlate seemingly… Show more
------
https://time.com/6297403/india-ai-karya-startup/…

This is an amazing story, and follows along the lines of other work on data localization that for eg 
@_KarenHao
 has reported on, such as the work by 
@mahelona
. 1/2
------
 New paper 
Leveraging Implicit Feedback from Deployment Data in Dialogue

Optimizing for implicit feedback signals using BlenderBot conversations gives improved social  agents, e.g. using length or sentiment of future human responses.

Findings:
- Several methods give gains;… Show more
------
«Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization»
Ideas can and should be communicated without unnecessary obfuscation.
Very often, less is more. Especially at conferences where you are inundated by loads of input.
https://arxiv.org/abs/2212.10445
------
After three years of hard work, today we publish on 
@ScienceMagazine
 and 
@Nature
 the first four studies of an unprecedented research collaboration to examine #SocialMediaAndElections_1/8
------
New 
@nature
: Like-minded sources on Facebook are prevalent but not polarizing
https://nature.com/articles/s41586-023-06297-w… (open access!)

Our key findings:
-Median FB user gets 50.4% of content from like-minded sources
-But reducing exposure by ~1/3 for 3 months had no measurable effect on attitudes
------
Finally, please read the other incredible papers in both 
@ScienceMagazine
 and 
@Nature
:

Asymmetric Ideological Segregation in Exposure to Political News on Facebook
https://science.org/doi/10.1126/science.ade7138…
 
Like-minded sources on Facebook are prevalent but not polarizing
------
If you're a researcher interested in potentially accessing de-identified study data to explore related questions, ICPSR will host a full replication archive: https://socialmediaarchive.org

11/
------
Removing reshared content (which includes viral political content) from Facebook feed does not significantly affect political polarization or other political attitudes.
------
3. ATTITUDES: As with the chrono-feed experiment, removing reshares did not significantly affect political polarization or other individual-level political attitudes.

Much more to dig into in these two papers and the others in this research package.

8/
------
During the 2020 elections, FB users who used a reverse-chronological feed instead of the regular algorithmic feed did not exhibit "altered levels of affective polarization, political knowledge, political behavior, or other key attitudes."
------
3. SURVEY-MEASURED POLITICAL OUTCOMES: Despite these changes in users' on-platform experience, the chronological feed did not significantly alter levels of issue or affective polarization, political knowledge, political behavior or other key attitudes during the study. 13/
------
A thread on the main findings of the studies of the effect of FB & Instagram on political opinion during the 2020 elections.
------
Today is publication day for the first 4 papers resulting from a unique collaboration between Meta researchers and outside academics to study the political effects of Facebook and Instagram in the 2020 U.S. election!  1/N
------
Four papers in Sciences & Nature on the impact of Facebook and Instagram on political opinions during the 2020 elections.

Always good to actually collect and study the data, rather than use gut feelings.
------
New in Science and Nature: The first four papers from the U.S. 2020 Facebook and Instagram Election Study!
------
Pretty funny how financial types don't understand the concept of long-term R&D investment.
To them, R&D investment is "lost money".
It only becomes "lost" if/when you give up on the whole product concept.
But that has not happened.
------
Mark Zuckerberg's Metaverse has lost over $21.3 billion since 2022.
------
Those threats:
- have existed for years without AI.
- social network co's have been on the frontline fighting them.
- Meta has large orgs entirely devoted to fighting them.
- they make *massive* use of the latest AI tech, including transformers/LLMs.
- the claim by some AI… Show more
------
With a comprehensive understanding of the range of risks associated with #GeneralPurposeAI models, policymakers can proactively mitigate these hazards -
with @pegahbyte we provide a risk map for this! 

3 risk categories incl. current examples & scenarios: https://stiftung-nv.de/de/publikation/governing-general-purpose-ai-comprehensive-map-unreliability-misuse-and-systemic-risks…
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
Major Regretxit
------
Huge regret over Brexit in Britain 

Cc: @Noahpinion @williamnhutton @DalrympleWill @GerardAraud
------
L'IA aide le médecin 
@NablaTech
------
 "Deux minutes au lieu de deux heures"

Certaines disciplines utilisent déjà l’IA comme assistant, tandis que la recherche médicale s’en empare. Pour progresser, les données seront la clef.  Thread 1/7  
https://lexpress.fr/sciences-sante/sante/deux-minutes-au-lieu-de-deux-heures-quand-lia-se-met-au-service-de-la-sante-NVXYW7ZP2JH5FA63M6KDBKWY64/…
------
We're looking for a research engineer to work with us on exciting topics around neural compression on the FAIR team in New York! If you're interested, please apply! I'm also at ICML if you'd like to chat.

Position:
------
Open Catalyst Demo: using AI to accelerate the simulation of molecules interacting with catalysts.
This may help the discovery of new catalysts.
------
Today we're releasing the Open Catalyst Demo to the public — this new service will allow researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials ~1000x faster than existing computational methods using AI.

Demo 
------
Key Takesaways from 
@pmarca
 and 
@joerogan
 

Full notes here ---> https://podcastnotes.org/joe-rogan-experience/2010-marc-andreessen-joe-rogan-ai/…

Think of AI as a sophisticated autocomplete that probabilistically uses all the text ever written to accurately predict the next word. 

The next step for AI is to correlate seemingly… Show more
------
https://time.com/6297403/india-ai-karya-startup/…

This is an amazing story, and follows along the lines of other work on data localization that for eg 
@_KarenHao
 has reported on, such as the work by 
@mahelona
. 1/2
------
 New paper 
Leveraging Implicit Feedback from Deployment Data in Dialogue

Optimizing for implicit feedback signals using BlenderBot conversations gives improved social  agents, e.g. using length or sentiment of future human responses.

Findings:
- Several methods give gains;… Show more
------
We now evaluated also the 
@MetaAI
's LLaMA 2 70B model!  Exciting times ahead!

We also updated ChatGPT which seems to have improved over the last months

Thanks for providing the compute/API end point 
@a16z
  
@replicatehq
 
@appenz
 
@rajko_rad
 
@Mascobot
------
We evaluated LLaMA-2 Chat! 

It seems to be similar quality as the latest Vicuna's. Excited to see how much the community will be able to improve it using LLaMA-2 base and their fine-tuning pipelines!

@WizardLM_AI @lmsysorg @huggingface 

https://github.com/tatsu-lab/alpaca_eval…
------
Motion-Content JEPA (MC-JEPA):
A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features.

A Hierarchical JEPA-style architecture that is trained with a VICReg criterion to simultaneously extract high-level "content" features from pairs… Show more
------
If you're a researcher interested in potentially accessing de-identified study data to explore related questions, ICPSR will host a full replication archive: https://socialmediaarchive.org

11/
------
Removing reshared content (which includes viral political content) from Facebook feed does not significantly affect political polarization or other political attitudes.
------
3. ATTITUDES: As with the chrono-feed experiment, removing reshares did not significantly affect political polarization or other individual-level political attitudes.

Much more to dig into in these two papers and the others in this research package.

8/
------
During the 2020 elections, FB users who used a reverse-chronological feed instead of the regular algorithmic feed did not exhibit "altered levels of affective polarization, political knowledge, political behavior, or other key attitudes."
------
3. SURVEY-MEASURED POLITICAL OUTCOMES: Despite these changes in users' on-platform experience, the chronological feed did not significantly alter levels of issue or affective polarization, political knowledge, political behavior or other key attitudes during the study. 13/
------
A thread on the main findings of the studies of the effect of FB & Instagram on political opinion during the 2020 elections.
------
Today is publication day for the first 4 papers resulting from a unique collaboration between Meta researchers and outside academics to study the political effects of Facebook and Instagram in the 2020 U.S. election!  1/N
------
Four papers in Sciences & Nature on the impact of Facebook and Instagram on political opinions during the 2020 elections.

Always good to actually collect and study the data, rather than use gut feelings.
------
New in Science and Nature: The first four papers from the U.S. 2020 Facebook and Instagram Election Study!
------
Pretty funny how financial types don't understand the concept of long-term R&D investment.
To them, R&D investment is "lost money".
It only becomes "lost" if/when you give up on the whole product concept.
But that has not happened.
------
Mark Zuckerberg's Metaverse has lost over $21.3 billion since 2022.
------
Those threats:
- have existed for years without AI.
- social network co's have been on the frontline fighting them.
- Meta has large orgs entirely devoted to fighting them.
- they make *massive* use of the latest AI tech, including transformers/LLMs.
- the claim by some AI… Show more
------
With a comprehensive understanding of the range of risks associated with #GeneralPurposeAI models, policymakers can proactively mitigate these hazards -
with @pegahbyte we provide a risk map for this! 

3 risk categories incl. current examples & scenarios: https://stiftung-nv.de/de/publikation/governing-general-purpose-ai-comprehensive-map-unreliability-misuse-and-systemic-risks…
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
Major Regretxit
------
Huge regret over Brexit in Britain 

Cc: @Noahpinion @williamnhutton @DalrympleWill @GerardAraud
------
L'IA aide le médecin 
@NablaTech
------
 "Deux minutes au lieu de deux heures"

Certaines disciplines utilisent déjà l’IA comme assistant, tandis que la recherche médicale s’en empare. Pour progresser, les données seront la clef.  Thread 1/7  
https://lexpress.fr/sciences-sante/sante/deux-minutes-au-lieu-de-deux-heures-quand-lia-se-met-au-service-de-la-sante-NVXYW7ZP2JH5FA63M6KDBKWY64/…
------
We're looking for a research engineer to work with us on exciting topics around neural compression on the FAIR team in New York! If you're interested, please apply! I'm also at ICML if you'd like to chat.

Position:
------
Open Catalyst Demo: using AI to accelerate the simulation of molecules interacting with catalysts.
This may help the discovery of new catalysts.
------
Today we're releasing the Open Catalyst Demo to the public — this new service will allow researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials ~1000x faster than existing computational methods using AI.

Demo 
------
Key Takesaways from 
@pmarca
 and 
@joerogan
 

Full notes here ---> https://podcastnotes.org/joe-rogan-experience/2010-marc-andreessen-joe-rogan-ai/…

Think of AI as a sophisticated autocomplete that probabilistically uses all the text ever written to accurately predict the next word. 

The next step for AI is to correlate seemingly… Show more
------
https://time.com/6297403/india-ai-karya-startup/…

This is an amazing story, and follows along the lines of other work on data localization that for eg 
@_KarenHao
 has reported on, such as the work by 
@mahelona
. 1/2
------
 New paper 
Leveraging Implicit Feedback from Deployment Data in Dialogue

Optimizing for implicit feedback signals using BlenderBot conversations gives improved social  agents, e.g. using length or sentiment of future human responses.

Findings:
- Several methods give gains;… Show more
------
We now evaluated also the 
@MetaAI
's LLaMA 2 70B model!  Exciting times ahead!

We also updated ChatGPT which seems to have improved over the last months

Thanks for providing the compute/API end point 
@a16z
  
@replicatehq
 
@appenz
 
@rajko_rad
 
@Mascobot
------
We evaluated LLaMA-2 Chat! 

It seems to be similar quality as the latest Vicuna's. Excited to see how much the community will be able to improve it using LLaMA-2 base and their fine-tuning pipelines!

@WizardLM_AI @lmsysorg @huggingface 

https://github.com/tatsu-lab/alpaca_eval…
------
Motion-Content JEPA (MC-JEPA):
A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features.

A Hierarchical JEPA-style architecture that is trained with a VICReg criterion to simultaneously extract high-level "content" features from pairs… Show more
------
Building conspiracy theories out of the inaccuracies of smaller models is dumb. The 70b-llama-chat gets it right. 
@ylecun
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
Want to make self-supervised learning (SSL) converge in one training epoch rather than hundreds?! Check out our new paper: https://arxiv.org/abs/2304.03977, joint-work with @PeterTo16278553  
@YiMaTweets
 
@ylecun
------
Regulations should not forbid nor hamper open source AI.
------
Very important! https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/…
------
There’s no economic, health, or social policy reason for this. In fact, it’s counterproductive on all three dimensions.

However, there are entrenched companies making billions of dollars this way plus others getting big tax breaks and politicians who count on them for support.
------
Does anyone in the world have an actual positive case to make for continuing to attach health insurance to employment in the US? Is there any good reason at all to keep doing this?
------
#ACL2023NLP — Here are  interesting new papers you should know about from Meta AI — and where you can find more details if you’re not at the conference.


------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
Four papers in Sciences & Nature on the impact of Facebook and Instagram on political opinions during the 2020 elections.

Always good to actually collect and study the data, rather than use gut feelings.
------
New in Science and Nature: The first four papers from the U.S. 2020 Facebook and Instagram Election Study!
------
Pretty funny how financial types don't understand the concept of long-term R&D investment.
To them, R&D investment is "lost money".
It only becomes "lost" if/when you give up on the whole product concept.
But that has not happened.
------
Mark Zuckerberg's Metaverse has lost over $21.3 billion since 2022.
------
Those threats:
- have existed for years without AI.
- social network co's have been on the frontline fighting them.
- Meta has large orgs entirely devoted to fighting them.
- they make *massive* use of the latest AI tech, including transformers/LLMs.
- the claim by some AI… Show more
------
With a comprehensive understanding of the range of risks associated with #GeneralPurposeAI models, policymakers can proactively mitigate these hazards -
with @pegahbyte we provide a risk map for this! 

3 risk categories incl. current examples & scenarios: https://stiftung-nv.de/de/publikation/governing-general-purpose-ai-comprehensive-map-unreliability-misuse-and-systemic-risks…
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
Major Regretxit
------
Huge regret over Brexit in Britain 

Cc: @Noahpinion @williamnhutton @DalrympleWill @GerardAraud
------
L'IA aide le médecin 
@NablaTech
------
 "Deux minutes au lieu de deux heures"

Certaines disciplines utilisent déjà l’IA comme assistant, tandis que la recherche médicale s’en empare. Pour progresser, les données seront la clef.  Thread 1/7  
https://lexpress.fr/sciences-sante/sante/deux-minutes-au-lieu-de-deux-heures-quand-lia-se-met-au-service-de-la-sante-NVXYW7ZP2JH5FA63M6KDBKWY64/…
------
We're looking for a research engineer to work with us on exciting topics around neural compression on the FAIR team in New York! If you're interested, please apply! I'm also at ICML if you'd like to chat.

Position:
------
Open Catalyst Demo: using AI to accelerate the simulation of molecules interacting with catalysts.
This may help the discovery of new catalysts.
------
Today we're releasing the Open Catalyst Demo to the public — this new service will allow researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials ~1000x faster than existing computational methods using AI.

Demo 
------
Key Takesaways from 
@pmarca
 and 
@joerogan
 

Full notes here ---> https://podcastnotes.org/joe-rogan-experience/2010-marc-andreessen-joe-rogan-ai/…

Think of AI as a sophisticated autocomplete that probabilistically uses all the text ever written to accurately predict the next word. 

The next step for AI is to correlate seemingly… Show more
------
https://time.com/6297403/india-ai-karya-startup/…

This is an amazing story, and follows along the lines of other work on data localization that for eg 
@_KarenHao
 has reported on, such as the work by 
@mahelona
. 1/2
------
 New paper 
Leveraging Implicit Feedback from Deployment Data in Dialogue

Optimizing for implicit feedback signals using BlenderBot conversations gives improved social  agents, e.g. using length or sentiment of future human responses.

Findings:
- Several methods give gains;… Show more
------
We now evaluated also the 
@MetaAI
's LLaMA 2 70B model!  Exciting times ahead!

We also updated ChatGPT which seems to have improved over the last months

Thanks for providing the compute/API end point 
@a16z
  
@replicatehq
 
@appenz
 
@rajko_rad
 
@Mascobot
------
We evaluated LLaMA-2 Chat! 

It seems to be similar quality as the latest Vicuna's. Excited to see how much the community will be able to improve it using LLaMA-2 base and their fine-tuning pipelines!

@WizardLM_AI @lmsysorg @huggingface 

https://github.com/tatsu-lab/alpaca_eval…
------
Motion-Content JEPA (MC-JEPA):
A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features.

A Hierarchical JEPA-style architecture that is trained with a VICReg criterion to simultaneously extract high-level "content" features from pairs… Show more
------
Building conspiracy theories out of the inaccuracies of smaller models is dumb. The 70b-llama-chat gets it right. 
@ylecun
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
Want to make self-supervised learning (SSL) converge in one training epoch rather than hundreds?! Check out our new paper: https://arxiv.org/abs/2304.03977, joint-work with @PeterTo16278553  
@YiMaTweets
 
@ylecun
------
Regulations should not forbid nor hamper open source AI.
------
Very important! https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/…
------
There’s no economic, health, or social policy reason for this. In fact, it’s counterproductive on all three dimensions.

However, there are entrenched companies making billions of dollars this way plus others getting big tax breaks and politicians who count on them for support.
------
Does anyone in the world have an actual positive case to make for continuing to attach health insurance to employment in the US? Is there any good reason at all to keep doing this?
------
#ACL2023NLP — Here are  interesting new papers you should know about from Meta AI — and where you can find more details if you’re not at the conference.


------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
The US is notorious for it's mass shootings, but its immigration policies (or lack thereof) set a new standard for the art of shooting yourself in the foot with a bazooka.

Advice to graduate students from countries the US doesn't like: just go to Europe.
------
I’m quite used to the cruelty students can face when they apply for a US visa but this one broke me. We offered admission to a stellar, talented & hardworking student. After months of work and hundreds of dollars, an embassy officer saw him for 5 mins & said no. why? …
------
(and I hate overzealous spelling correctors that turn "its" into "it's" behind your back)
------
C'est étonnant, à chaque fois que je poste des photos du système solaire, je reçois plein de messages de gens qui font leurs propres recherches. 
"Où sont les étoiles?"
"La NASA ou Stanley Kubrick font de fausses images".
Thread rapide
------
Intelligence is the commodity we are in most dire need to improve human condition.
------
There are a lot of things wrong with this world…

but too much intelligence is not one of them.
------
The most powerful open source model is out!!

 Nous-Hermes-LLaMA2 

- https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b…

- GGML: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML…
- GPTQ: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ…

war.
------
"Our study found evidence of higher excess mortality for Republican voters compared with Democratic voters in Florida and Ohio after, but not before,  #COVID-19 vaccines were available to all adults in the US." 
https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2807617…
------
Major Regretxit
------
Huge regret over Brexit in Britain 

Cc: @Noahpinion @williamnhutton @DalrympleWill @GerardAraud
------
L'IA aide le médecin 
@NablaTech
------
 "Deux minutes au lieu de deux heures"

Certaines disciplines utilisent déjà l’IA comme assistant, tandis que la recherche médicale s’en empare. Pour progresser, les données seront la clef.  Thread 1/7  
https://lexpress.fr/sciences-sante/sante/deux-minutes-au-lieu-de-deux-heures-quand-lia-se-met-au-service-de-la-sante-NVXYW7ZP2JH5FA63M6KDBKWY64/…
------
We're looking for a research engineer to work with us on exciting topics around neural compression on the FAIR team in New York! If you're interested, please apply! I'm also at ICML if you'd like to chat.

Position:
------
Open Catalyst Demo: using AI to accelerate the simulation of molecules interacting with catalysts.
This may help the discovery of new catalysts.
------
Today we're releasing the Open Catalyst Demo to the public — this new service will allow researchers to accelerate work in material sciences by enabling them to simulate the reactivity of catalyst materials ~1000x faster than existing computational methods using AI.

Demo 
------
Key Takesaways from 
@pmarca
 and 
@joerogan
 

Full notes here ---> https://podcastnotes.org/joe-rogan-experience/2010-marc-andreessen-joe-rogan-ai/…

Think of AI as a sophisticated autocomplete that probabilistically uses all the text ever written to accurately predict the next word. 

The next step for AI is to correlate seemingly… Show more
------
https://time.com/6297403/india-ai-karya-startup/…

This is an amazing story, and follows along the lines of other work on data localization that for eg 
@_KarenHao
 has reported on, such as the work by 
@mahelona
. 1/2
------
 New paper 
Leveraging Implicit Feedback from Deployment Data in Dialogue

Optimizing for implicit feedback signals using BlenderBot conversations gives improved social  agents, e.g. using length or sentiment of future human responses.

Findings:
- Several methods give gains;… Show more
------
We now evaluated also the 
@MetaAI
's LLaMA 2 70B model!  Exciting times ahead!

We also updated ChatGPT which seems to have improved over the last months

Thanks for providing the compute/API end point 
@a16z
  
@replicatehq
 
@appenz
 
@rajko_rad
 
@Mascobot
------
We evaluated LLaMA-2 Chat! 

It seems to be similar quality as the latest Vicuna's. Excited to see how much the community will be able to improve it using LLaMA-2 base and their fine-tuning pipelines!

@WizardLM_AI @lmsysorg @huggingface 

https://github.com/tatsu-lab/alpaca_eval…
------
Motion-Content JEPA (MC-JEPA):
A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features.

A Hierarchical JEPA-style architecture that is trained with a VICReg criterion to simultaneously extract high-level "content" features from pairs… Show more
------
Building conspiracy theories out of the inaccuracies of smaller models is dumb. The 70b-llama-chat gets it right. 
@ylecun
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
Want to make self-supervised learning (SSL) converge in one training epoch rather than hundreds?! Check out our new paper: https://arxiv.org/abs/2304.03977, joint-work with @PeterTo16278553  
@YiMaTweets
 
@ylecun
------
Regulations should not forbid nor hamper open source AI.
------
Very important! https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/…
------
There’s no economic, health, or social policy reason for this. In fact, it’s counterproductive on all three dimensions.

However, there are entrenched companies making billions of dollars this way plus others getting big tax breaks and politicians who count on them for support.
------
Does anyone in the world have an actual positive case to make for continuing to attach health insurance to employment in the US? Is there any good reason at all to keep doing this?
------
#ACL2023NLP — Here are  interesting new papers you should know about from Meta AI — and where you can find more details if you’re not at the conference.


------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
The US is notorious for it's mass shootings, but its immigration policies (or lack thereof) set a new standard for the art of shooting yourself in the foot with a bazooka.

Advice to graduate students from countries the US doesn't like: just go to Europe.
------
I’m quite used to the cruelty students can face when they apply for a US visa but this one broke me. We offered admission to a stellar, talented & hardworking student. After months of work and hundreds of dollars, an embassy officer saw him for 5 mins & said no. why? …
------
(and I hate overzealous spelling correctors that turn "its" into "it's" behind your back)
------
C'est étonnant, à chaque fois que je poste des photos du système solaire, je reçois plein de messages de gens qui font leurs propres recherches. 
"Où sont les étoiles?"
"La NASA ou Stanley Kubrick font de fausses images".
Thread rapide
------
Intelligence is the commodity we are in most dire need to improve human condition.
------
There are a lot of things wrong with this world…

but too much intelligence is not one of them.
------
The most powerful open source model is out!!

 Nous-Hermes-LLaMA2 

- https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b…

- GGML: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML…
- GPTQ: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ…

war.
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from 
@MetaAI
, running on fast optimized inference on 
@huggingface
 infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Qualcomm working with Meta to run Llama-2 on mobile devices.
------
Llama-2 is coming to your phone: https://qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi…
------
AI is nothing like nuclear bombs. It’s either like the printing press (which is why journalists are afraid) or it’s like photosynthesis.
------
 LLaMa-2-70B-Chat is available now!

Try it here: http://labs.pplx.ai

 What will you ask first?
------
Llama v2 7b chat and Llama v2 13b chat Colab  Thanks to 
@ylecun
  and 
@MetaAI
 Llama Team  

page: https://ai.meta.com/llama/
paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…

@gradio
 ui: https://github.com/oobabooga/text-generation-webui…
colab: please try it  https://github.com/camenduru/text-generation-webui-colab…
------
Key Takesaways from 
@pmarca
 and 
@joerogan
 

Full notes here ---> https://podcastnotes.org/joe-rogan-experience/2010-marc-andreessen-joe-rogan-ai/…

Think of AI as a sophisticated autocomplete that probabilistically uses all the text ever written to accurately predict the next word. 

The next step for AI is to correlate seemingly… Show more
------
https://time.com/6297403/india-ai-karya-startup/…

This is an amazing story, and follows along the lines of other work on data localization that for eg 
@_KarenHao
 has reported on, such as the work by 
@mahelona
. 1/2
------
 New paper 
Leveraging Implicit Feedback from Deployment Data in Dialogue

Optimizing for implicit feedback signals using BlenderBot conversations gives improved social  agents, e.g. using length or sentiment of future human responses.

Findings:
- Several methods give gains;… Show more
------
We now evaluated also the 
@MetaAI
's LLaMA 2 70B model!  Exciting times ahead!

We also updated ChatGPT which seems to have improved over the last months

Thanks for providing the compute/API end point 
@a16z
  
@replicatehq
 
@appenz
 
@rajko_rad
 
@Mascobot
------
We evaluated LLaMA-2 Chat! 

It seems to be similar quality as the latest Vicuna's. Excited to see how much the community will be able to improve it using LLaMA-2 base and their fine-tuning pipelines!

@WizardLM_AI @lmsysorg @huggingface 

https://github.com/tatsu-lab/alpaca_eval…
------
Motion-Content JEPA (MC-JEPA):
A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features.

A Hierarchical JEPA-style architecture that is trained with a VICReg criterion to simultaneously extract high-level "content" features from pairs… Show more
------
Building conspiracy theories out of the inaccuracies of smaller models is dumb. The 70b-llama-chat gets it right. 
@ylecun
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
Want to make self-supervised learning (SSL) converge in one training epoch rather than hundreds?! Check out our new paper: https://arxiv.org/abs/2304.03977, joint-work with @PeterTo16278553  
@YiMaTweets
 
@ylecun
------
Regulations should not forbid nor hamper open source AI.
------
Very important! https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/…
------
There’s no economic, health, or social policy reason for this. In fact, it’s counterproductive on all three dimensions.

However, there are entrenched companies making billions of dollars this way plus others getting big tax breaks and politicians who count on them for support.
------
Does anyone in the world have an actual positive case to make for continuing to attach health insurance to employment in the US? Is there any good reason at all to keep doing this?
------
#ACL2023NLP — Here are  interesting new papers you should know about from Meta AI — and where you can find more details if you’re not at the conference.


------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
The US is notorious for it's mass shootings, but its immigration policies (or lack thereof) set a new standard for the art of shooting yourself in the foot with a bazooka.

Advice to graduate students from countries the US doesn't like: just go to Europe.
------
I’m quite used to the cruelty students can face when they apply for a US visa but this one broke me. We offered admission to a stellar, talented & hardworking student. After months of work and hundreds of dollars, an embassy officer saw him for 5 mins & said no. why? …
------
(and I hate overzealous spelling correctors that turn "its" into "it's" behind your back)
------
C'est étonnant, à chaque fois que je poste des photos du système solaire, je reçois plein de messages de gens qui font leurs propres recherches. 
"Où sont les étoiles?"
"La NASA ou Stanley Kubrick font de fausses images".
Thread rapide
------
Intelligence is the commodity we are in most dire need to improve human condition.
------
There are a lot of things wrong with this world…

but too much intelligence is not one of them.
------
The most powerful open source model is out!!

 Nous-Hermes-LLaMA2 

- https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b…

- GGML: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML…
- GPTQ: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ…

war.
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from 
@MetaAI
, running on fast optimized inference on 
@huggingface
 infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Qualcomm working with Meta to run Llama-2 on mobile devices.
------
Llama-2 is coming to your phone: https://qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi…
------
AI is nothing like nuclear bombs. It’s either like the printing press (which is why journalists are afraid) or it’s like photosynthesis.
------
 LLaMa-2-70B-Chat is available now!

Try it here: http://labs.pplx.ai

 What will you ask first?
------
Llama v2 7b chat and Llama v2 13b chat Colab  Thanks to 
@ylecun
  and 
@MetaAI
 Llama Team  

page: https://ai.meta.com/llama/
paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…

@gradio
 ui: https://github.com/oobabooga/text-generation-webui…
colab: please try it  https://github.com/camenduru/text-generation-webui-colab…
------
We hope you have found all the answers you needed in our cookbook around SOTA representation learning with SSL! But wait, we will be giving away even more tips and tricks at our #ICML2023 tutorial!
Monday/1:30pm local/exhibit hall2
speakers include 
@imisra_
 
@mcaron31
 
@endernewton
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
We now evaluated also the 
@MetaAI
's LLaMA 2 70B model!  Exciting times ahead!

We also updated ChatGPT which seems to have improved over the last months

Thanks for providing the compute/API end point 
@a16z
  
@replicatehq
 
@appenz
 
@rajko_rad
 
@Mascobot
------
We evaluated LLaMA-2 Chat! 

It seems to be similar quality as the latest Vicuna's. Excited to see how much the community will be able to improve it using LLaMA-2 base and their fine-tuning pipelines!

@WizardLM_AI @lmsysorg @huggingface 

https://github.com/tatsu-lab/alpaca_eval…
------
Motion-Content JEPA (MC-JEPA):
A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features.

A Hierarchical JEPA-style architecture that is trained with a VICReg criterion to simultaneously extract high-level "content" features from pairs… Show more
------
Building conspiracy theories out of the inaccuracies of smaller models is dumb. The 70b-llama-chat gets it right. 
@ylecun
------
Meta used my 1991 ideas to train LLaMA 2, but made it insinuate that I “have been involved in harmful activities” and have not made “positive contributions to society, such as pioneers in their field.” @Meta & LLaMA promoter @ylecun should correct this ASAP. See… Show more
------
Want to make self-supervised learning (SSL) converge in one training epoch rather than hundreds?! Check out our new paper: https://arxiv.org/abs/2304.03977, joint-work with @PeterTo16278553  
@YiMaTweets
 
@ylecun
------
Regulations should not forbid nor hamper open source AI.
------
Very important! https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/…
------
There’s no economic, health, or social policy reason for this. In fact, it’s counterproductive on all three dimensions.

However, there are entrenched companies making billions of dollars this way plus others getting big tax breaks and politicians who count on them for support.
------
Does anyone in the world have an actual positive case to make for continuing to attach health insurance to employment in the US? Is there any good reason at all to keep doing this?
------
#ACL2023NLP — Here are  interesting new papers you should know about from Meta AI — and where you can find more details if you’re not at the conference.


------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
The US is notorious for it's mass shootings, but its immigration policies (or lack thereof) set a new standard for the art of shooting yourself in the foot with a bazooka.

Advice to graduate students from countries the US doesn't like: just go to Europe.
------
I’m quite used to the cruelty students can face when they apply for a US visa but this one broke me. We offered admission to a stellar, talented & hardworking student. After months of work and hundreds of dollars, an embassy officer saw him for 5 mins & said no. why? …
------
(and I hate overzealous spelling correctors that turn "its" into "it's" behind your back)
------
C'est étonnant, à chaque fois que je poste des photos du système solaire, je reçois plein de messages de gens qui font leurs propres recherches. 
"Où sont les étoiles?"
"La NASA ou Stanley Kubrick font de fausses images".
Thread rapide
------
Intelligence is the commodity we are in most dire need to improve human condition.
------
There are a lot of things wrong with this world…

but too much intelligence is not one of them.
------
The most powerful open source model is out!!

 Nous-Hermes-LLaMA2 

- https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b…

- GGML: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML…
- GPTQ: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ…

war.
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from 
@MetaAI
, running on fast optimized inference on 
@huggingface
 infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Qualcomm working with Meta to run Llama-2 on mobile devices.
------
Llama-2 is coming to your phone: https://qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi…
------
AI is nothing like nuclear bombs. It’s either like the printing press (which is why journalists are afraid) or it’s like photosynthesis.
------
 LLaMa-2-70B-Chat is available now!

Try it here: http://labs.pplx.ai

 What will you ask first?
------
Llama v2 7b chat and Llama v2 13b chat Colab  Thanks to 
@ylecun
  and 
@MetaAI
 Llama Team  

page: https://ai.meta.com/llama/
paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…

@gradio
 ui: https://github.com/oobabooga/text-generation-webui…
colab: please try it  https://github.com/camenduru/text-generation-webui-colab…
------
We hope you have found all the answers you needed in our cookbook around SOTA representation learning with SSL! But wait, we will be giving away even more tips and tricks at our #ICML2023 tutorial!
Monday/1:30pm local/exhibit hall2
speakers include 
@imisra_
 
@mcaron31
 
@endernewton
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
RankMe: cheap/fast label-free hparam selection for DNNs will be at ICML
- oral: ballroom B 4pm (local) Wed.
- poster: exhibit hall 1 #609 1:30pm Thur.
Also includes insights around representations' ranks, their surprising consistency across datasets, ...
https://arxiv.org/abs/2210.02885
------
A couple papers presented by Quentin at ICML next week.
The Split Invariant-Equivariant work is a JEPA architecture that learns representations in which invariant content and equivariant pose are factorized in a Self-Supervised manner.
------
I will be at #ICML next week, presenting two papers:
- RankMe https://arxiv.org/abs/2210.02885 (Wed. + Thur.)
- SIE  https://arxiv.org/abs/2302.10283 (Wed.)

I would love to meet new people and talk about anything representation learning related, so reach out if you want to chat !
------
Intelligence is a collection of skills, and an ability to solve new problems and acquire new skills.
The set of skills current AI systems possess or can acquire is very different from the set of skills humans possess or can acquire.
Both are specialized.
Humans less so.
------
1/5 Short thread on my post https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1… on how Artificial General Intelligence (AGI) and it's impact on human jobs. 

Basic case for AGI fits on back of envelope: Moore's law means compute grows exponentially and experience shows capabilities scale with log compute.
------
AI researchers seek to understand intelligence well enough to create beings of greater intelligence than current humans. 

Reaching this profound intellectual milestone will enrich our economies and challenge our societal institutions. It will be unprecedented and… Show more
------
The release of Llama-2 is about the creation of an collaborative ecosystem to facilitate access and accelerate progress.
------
Excited to announce open source release of the 7B, 13B, and 70B Llama 2 pre-trained and fine-tuned models. These models are awesome- pre-trained on 2T tokens and fine-tuned with over 1MM human annotations.

https://about.fb.com/news/2023/07/llama-2/…
------
Run Llama2 on your MacBook with GPU support! 

http://gist.github.com/adrienbrault/b…

Getting 20-25 token/s with https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin…… on M2 Max
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Want to make self-supervised learning (SSL) converge in one training epoch rather than hundreds?! Check out our new paper: https://arxiv.org/abs/2304.03977, joint-work with @PeterTo16278553  
@YiMaTweets
 
@ylecun
------
Regulations should not forbid nor hamper open source AI.
------
Very important! https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/…
------
There’s no economic, health, or social policy reason for this. In fact, it’s counterproductive on all three dimensions.

However, there are entrenched companies making billions of dollars this way plus others getting big tax breaks and politicians who count on them for support.
------
Does anyone in the world have an actual positive case to make for continuing to attach health insurance to employment in the US? Is there any good reason at all to keep doing this?
------
#ACL2023NLP — Here are  interesting new papers you should know about from Meta AI — and where you can find more details if you’re not at the conference.


------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
The US is notorious for it's mass shootings, but its immigration policies (or lack thereof) set a new standard for the art of shooting yourself in the foot with a bazooka.

Advice to graduate students from countries the US doesn't like: just go to Europe.
------
I’m quite used to the cruelty students can face when they apply for a US visa but this one broke me. We offered admission to a stellar, talented & hardworking student. After months of work and hundreds of dollars, an embassy officer saw him for 5 mins & said no. why? …
------
(and I hate overzealous spelling correctors that turn "its" into "it's" behind your back)
------
C'est étonnant, à chaque fois que je poste des photos du système solaire, je reçois plein de messages de gens qui font leurs propres recherches. 
"Où sont les étoiles?"
"La NASA ou Stanley Kubrick font de fausses images".
Thread rapide
------
Intelligence is the commodity we are in most dire need to improve human condition.
------
There are a lot of things wrong with this world…

but too much intelligence is not one of them.
------
The most powerful open source model is out!!

 Nous-Hermes-LLaMA2 

- https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b…

- GGML: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML…
- GPTQ: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ…

war.
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from 
@MetaAI
, running on fast optimized inference on 
@huggingface
 infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Qualcomm working with Meta to run Llama-2 on mobile devices.
------
Llama-2 is coming to your phone: https://qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi…
------
AI is nothing like nuclear bombs. It’s either like the printing press (which is why journalists are afraid) or it’s like photosynthesis.
------
 LLaMa-2-70B-Chat is available now!

Try it here: http://labs.pplx.ai

 What will you ask first?
------
Llama v2 7b chat and Llama v2 13b chat Colab  Thanks to 
@ylecun
  and 
@MetaAI
 Llama Team  

page: https://ai.meta.com/llama/
paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…

@gradio
 ui: https://github.com/oobabooga/text-generation-webui…
colab: please try it  https://github.com/camenduru/text-generation-webui-colab…
------
We hope you have found all the answers you needed in our cookbook around SOTA representation learning with SSL! But wait, we will be giving away even more tips and tricks at our #ICML2023 tutorial!
Monday/1:30pm local/exhibit hall2
speakers include 
@imisra_
 
@mcaron31
 
@endernewton
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
RankMe: cheap/fast label-free hparam selection for DNNs will be at ICML
- oral: ballroom B 4pm (local) Wed.
- poster: exhibit hall 1 #609 1:30pm Thur.
Also includes insights around representations' ranks, their surprising consistency across datasets, ...
https://arxiv.org/abs/2210.02885
------
A couple papers presented by Quentin at ICML next week.
The Split Invariant-Equivariant work is a JEPA architecture that learns representations in which invariant content and equivariant pose are factorized in a Self-Supervised manner.
------
I will be at #ICML next week, presenting two papers:
- RankMe https://arxiv.org/abs/2210.02885 (Wed. + Thur.)
- SIE  https://arxiv.org/abs/2302.10283 (Wed.)

I would love to meet new people and talk about anything representation learning related, so reach out if you want to chat !
------
Intelligence is a collection of skills, and an ability to solve new problems and acquire new skills.
The set of skills current AI systems possess or can acquire is very different from the set of skills humans possess or can acquire.
Both are specialized.
Humans less so.
------
1/5 Short thread on my post https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1… on how Artificial General Intelligence (AGI) and it's impact on human jobs. 

Basic case for AGI fits on back of envelope: Moore's law means compute grows exponentially and experience shows capabilities scale with log compute.
------
AI researchers seek to understand intelligence well enough to create beings of greater intelligence than current humans. 

Reaching this profound intellectual milestone will enrich our economies and challenge our societal institutions. It will be unprecedented and… Show more
------
The release of Llama-2 is about the creation of an collaborative ecosystem to facilitate access and accelerate progress.
------
Excited to announce open source release of the 7B, 13B, and 70B Llama 2 pre-trained and fine-tuned models. These models are awesome- pre-trained on 2T tokens and fine-tuned with over 1MM human annotations.

https://about.fb.com/news/2023/07/llama-2/…
------
Run Llama2 on your MacBook with GPU support! 

http://gist.github.com/adrienbrault/b…

Getting 20-25 token/s with https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin…… on M2 Max
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Thrilled to share a new blog post on how to fine-tune LLaMa 2 with QLoRA and Hugging Face on Amazon SageMaker
The blog post includes instructions for 7B, 13B, and 70B versions of the Model alongside Hardware requirements. 

  https://philschmid.de/sagemaker-llama2-qlora…
------
Did you know that you can train all Llama-2 models on your own data in just a few lines?

The script even works with the 70B model on a single A100 GPU thanks to the magic of 4bit and and PEFT!

Learn more: https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model…
Full script: https://github.com/lvwerra/trl/blob/main/examples/scripts/sft_trainer.py…
------
the 70B llama model now live on HuggingChat. Try it out now.

**amazed by the pace of adoption**
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from @MetaAI, running on fast optimized inference on @huggingface infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Heat, Wave and Schrodinger equations are fundamental linear partial differential equations of physics. https://en.wikipedia.org/wiki/Heat_equation… https://en.wikipedia.org/wiki/Wave_equation… https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation…
------
The US is notorious for it's mass shootings, but its immigration policies (or lack thereof) set a new standard for the art of shooting yourself in the foot with a bazooka.

Advice to graduate students from countries the US doesn't like: just go to Europe.
------
I’m quite used to the cruelty students can face when they apply for a US visa but this one broke me. We offered admission to a stellar, talented & hardworking student. After months of work and hundreds of dollars, an embassy officer saw him for 5 mins & said no. why? …
------
(and I hate overzealous spelling correctors that turn "its" into "it's" behind your back)
------
C'est étonnant, à chaque fois que je poste des photos du système solaire, je reçois plein de messages de gens qui font leurs propres recherches. 
"Où sont les étoiles?"
"La NASA ou Stanley Kubrick font de fausses images".
Thread rapide
------
Intelligence is the commodity we are in most dire need to improve human condition.
------
There are a lot of things wrong with this world…

but too much intelligence is not one of them.
------
The most powerful open source model is out!!

 Nous-Hermes-LLaMA2 

- https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b…

- GGML: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GGML…
- GPTQ: https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b-GPTQ…

war.
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from 
@MetaAI
, running on fast optimized inference on 
@huggingface
 infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Qualcomm working with Meta to run Llama-2 on mobile devices.
------
Llama-2 is coming to your phone: https://qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi…
------
AI is nothing like nuclear bombs. It’s either like the printing press (which is why journalists are afraid) or it’s like photosynthesis.
------
 LLaMa-2-70B-Chat is available now!

Try it here: http://labs.pplx.ai

 What will you ask first?
------
Llama v2 7b chat and Llama v2 13b chat Colab  Thanks to 
@ylecun
  and 
@MetaAI
 Llama Team  

page: https://ai.meta.com/llama/
paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…

@gradio
 ui: https://github.com/oobabooga/text-generation-webui…
colab: please try it  https://github.com/camenduru/text-generation-webui-colab…
------
We hope you have found all the answers you needed in our cookbook around SOTA representation learning with SSL! But wait, we will be giving away even more tips and tricks at our #ICML2023 tutorial!
Monday/1:30pm local/exhibit hall2
speakers include 
@imisra_
 
@mcaron31
 
@endernewton
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
RankMe: cheap/fast label-free hparam selection for DNNs will be at ICML
- oral: ballroom B 4pm (local) Wed.
- poster: exhibit hall 1 #609 1:30pm Thur.
Also includes insights around representations' ranks, their surprising consistency across datasets, ...
https://arxiv.org/abs/2210.02885
------
A couple papers presented by Quentin at ICML next week.
The Split Invariant-Equivariant work is a JEPA architecture that learns representations in which invariant content and equivariant pose are factorized in a Self-Supervised manner.
------
I will be at #ICML next week, presenting two papers:
- RankMe https://arxiv.org/abs/2210.02885 (Wed. + Thur.)
- SIE  https://arxiv.org/abs/2302.10283 (Wed.)

I would love to meet new people and talk about anything representation learning related, so reach out if you want to chat !
------
Intelligence is a collection of skills, and an ability to solve new problems and acquire new skills.
The set of skills current AI systems possess or can acquire is very different from the set of skills humans possess or can acquire.
Both are specialized.
Humans less so.
------
1/5 Short thread on my post https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1… on how Artificial General Intelligence (AGI) and it's impact on human jobs. 

Basic case for AGI fits on back of envelope: Moore's law means compute grows exponentially and experience shows capabilities scale with log compute.
------
AI researchers seek to understand intelligence well enough to create beings of greater intelligence than current humans. 

Reaching this profound intellectual milestone will enrich our economies and challenge our societal institutions. It will be unprecedented and… Show more
------
The release of Llama-2 is about the creation of an collaborative ecosystem to facilitate access and accelerate progress.
------
Excited to announce open source release of the 7B, 13B, and 70B Llama 2 pre-trained and fine-tuned models. These models are awesome- pre-trained on 2T tokens and fine-tuned with over 1MM human annotations.

https://about.fb.com/news/2023/07/llama-2/…
------
Run Llama2 on your MacBook with GPU support! 

http://gist.github.com/adrienbrault/b…

Getting 20-25 token/s with https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin…… on M2 Max
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Thrilled to share a new blog post on how to fine-tune LLaMa 2 with QLoRA and Hugging Face on Amazon SageMaker
The blog post includes instructions for 7B, 13B, and 70B versions of the Model alongside Hardware requirements. 

  https://philschmid.de/sagemaker-llama2-qlora…
------
Did you know that you can train all Llama-2 models on your own data in just a few lines?

The script even works with the 70B model on a single A100 GPU thanks to the magic of 4bit and and PEFT!

Learn more: https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model…
Full script: https://github.com/lvwerra/trl/blob/main/examples/scripts/sft_trainer.py…
------
the 70B llama model now live on HuggingChat. Try it out now.

**amazed by the pace of adoption**
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from @MetaAI, running on fast optimized inference on @huggingface infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
LLaMa 2 has taken the world by storm. But not everyone wants to download the checkpoint, and talk to it on terminal. Talk to LLaMa 2 on Perplexity's LLaMa Chat: http://llama.perplexity.ai, fastest right now. This is fully hosted and powered by our in-house LLM inference… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 by 
@Meta
 is already integrated with 
@huggingface
 transformers, TGI, inference endpoints, PEFT and much more. Time for builders to build! https://huggingface.co/blog/llama2#inference…
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from 
@MetaAI
, running on fast optimized inference on 
@huggingface
 infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
Qualcomm working with Meta to run Llama-2 on mobile devices.
------
Llama-2 is coming to your phone: https://qualcomm.com/news/releases/2023/07/qualcomm-works-with-meta-to-enable-on-device-ai-applications-usi…
------
AI is nothing like nuclear bombs. It’s either like the printing press (which is why journalists are afraid) or it’s like photosynthesis.
------
 LLaMa-2-70B-Chat is available now!

Try it here: http://labs.pplx.ai

 What will you ask first?
------
Llama v2 7b chat and Llama v2 13b chat Colab  Thanks to 
@ylecun
  and 
@MetaAI
 Llama Team  

page: https://ai.meta.com/llama/
paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…

@gradio
 ui: https://github.com/oobabooga/text-generation-webui…
colab: please try it  https://github.com/camenduru/text-generation-webui-colab…
------
We hope you have found all the answers you needed in our cookbook around SOTA representation learning with SSL! But wait, we will be giving away even more tips and tricks at our #ICML2023 tutorial!
Monday/1:30pm local/exhibit hall2
speakers include 
@imisra_
 
@mcaron31
 
@endernewton
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
RankMe: cheap/fast label-free hparam selection for DNNs will be at ICML
- oral: ballroom B 4pm (local) Wed.
- poster: exhibit hall 1 #609 1:30pm Thur.
Also includes insights around representations' ranks, their surprising consistency across datasets, ...
https://arxiv.org/abs/2210.02885
------
A couple papers presented by Quentin at ICML next week.
The Split Invariant-Equivariant work is a JEPA architecture that learns representations in which invariant content and equivariant pose are factorized in a Self-Supervised manner.
------
I will be at #ICML next week, presenting two papers:
- RankMe https://arxiv.org/abs/2210.02885 (Wed. + Thur.)
- SIE  https://arxiv.org/abs/2302.10283 (Wed.)

I would love to meet new people and talk about anything representation learning related, so reach out if you want to chat !
------
Intelligence is a collection of skills, and an ability to solve new problems and acquire new skills.
The set of skills current AI systems possess or can acquire is very different from the set of skills humans possess or can acquire.
Both are specialized.
Humans less so.
------
1/5 Short thread on my post https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1… on how Artificial General Intelligence (AGI) and it's impact on human jobs. 

Basic case for AGI fits on back of envelope: Moore's law means compute grows exponentially and experience shows capabilities scale with log compute.
------
AI researchers seek to understand intelligence well enough to create beings of greater intelligence than current humans. 

Reaching this profound intellectual milestone will enrich our economies and challenge our societal institutions. It will be unprecedented and… Show more
------
The release of Llama-2 is about the creation of an collaborative ecosystem to facilitate access and accelerate progress.
------
Excited to announce open source release of the 7B, 13B, and 70B Llama 2 pre-trained and fine-tuned models. These models are awesome- pre-trained on 2T tokens and fine-tuned with over 1MM human annotations.

https://about.fb.com/news/2023/07/llama-2/…
------
Run Llama2 on your MacBook with GPU support! 

http://gist.github.com/adrienbrault/b…

Getting 20-25 token/s with https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin…… on M2 Max
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Thrilled to share a new blog post on how to fine-tune LLaMa 2 with QLoRA and Hugging Face on Amazon SageMaker
The blog post includes instructions for 7B, 13B, and 70B versions of the Model alongside Hardware requirements. 

  https://philschmid.de/sagemaker-llama2-qlora…
------
Did you know that you can train all Llama-2 models on your own data in just a few lines?

The script even works with the 70B model on a single A100 GPU thanks to the magic of 4bit and and PEFT!

Learn more: https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model…
Full script: https://github.com/lvwerra/trl/blob/main/examples/scripts/sft_trainer.py…
------
the 70B llama model now live on HuggingChat. Try it out now.

**amazed by the pace of adoption**
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from @MetaAI, running on fast optimized inference on @huggingface infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
LLaMa 2 has taken the world by storm. But not everyone wants to download the checkpoint, and talk to it on terminal. Talk to LLaMa 2 on Perplexity's LLaMa Chat: http://llama.perplexity.ai, fastest right now. This is fully hosted and powered by our in-house LLM inference… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 by 
@Meta
 is already integrated with 
@huggingface
 transformers, TGI, inference endpoints, PEFT and much more. Time for builders to build! https://huggingface.co/blog/llama2#inference…
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama-2 is available on AWS through Amazon SageMaker JumpStart.
------
Bel article dans Le Monde sur la sortie de Llama-2 en accès libre par Meta.
------
Excited to share my analysis of the LLAMA2 model.

In short, this model and paper are incredibly well done. Meta has stepped up the level for open-source and signaled another path for the future of LLMs.

Influencers are now right with "equals chatgpt".
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
We hope you have found all the answers you needed in our cookbook around SOTA representation learning with SSL! But wait, we will be giving away even more tips and tricks at our #ICML2023 tutorial!
Monday/1:30pm local/exhibit hall2
speakers include 
@imisra_
 
@mcaron31
 
@endernewton
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
RankMe: cheap/fast label-free hparam selection for DNNs will be at ICML
- oral: ballroom B 4pm (local) Wed.
- poster: exhibit hall 1 #609 1:30pm Thur.
Also includes insights around representations' ranks, their surprising consistency across datasets, ...
https://arxiv.org/abs/2210.02885
------
A couple papers presented by Quentin at ICML next week.
The Split Invariant-Equivariant work is a JEPA architecture that learns representations in which invariant content and equivariant pose are factorized in a Self-Supervised manner.
------
I will be at #ICML next week, presenting two papers:
- RankMe https://arxiv.org/abs/2210.02885 (Wed. + Thur.)
- SIE  https://arxiv.org/abs/2302.10283 (Wed.)

I would love to meet new people and talk about anything representation learning related, so reach out if you want to chat !
------
Intelligence is a collection of skills, and an ability to solve new problems and acquire new skills.
The set of skills current AI systems possess or can acquire is very different from the set of skills humans possess or can acquire.
Both are specialized.
Humans less so.
------
1/5 Short thread on my post https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1… on how Artificial General Intelligence (AGI) and it's impact on human jobs. 

Basic case for AGI fits on back of envelope: Moore's law means compute grows exponentially and experience shows capabilities scale with log compute.
------
AI researchers seek to understand intelligence well enough to create beings of greater intelligence than current humans. 

Reaching this profound intellectual milestone will enrich our economies and challenge our societal institutions. It will be unprecedented and… Show more
------
The release of Llama-2 is about the creation of an collaborative ecosystem to facilitate access and accelerate progress.
------
Excited to announce open source release of the 7B, 13B, and 70B Llama 2 pre-trained and fine-tuned models. These models are awesome- pre-trained on 2T tokens and fine-tuned with over 1MM human annotations.

https://about.fb.com/news/2023/07/llama-2/…
------
Run Llama2 on your MacBook with GPU support! 

http://gist.github.com/adrienbrault/b…

Getting 20-25 token/s with https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin…… on M2 Max
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Thrilled to share a new blog post on how to fine-tune LLaMa 2 with QLoRA and Hugging Face on Amazon SageMaker
The blog post includes instructions for 7B, 13B, and 70B versions of the Model alongside Hardware requirements. 

  https://philschmid.de/sagemaker-llama2-qlora…
------
Did you know that you can train all Llama-2 models on your own data in just a few lines?

The script even works with the 70B model on a single A100 GPU thanks to the magic of 4bit and and PEFT!

Learn more: https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model…
Full script: https://github.com/lvwerra/trl/blob/main/examples/scripts/sft_trainer.py…
------
the 70B llama model now live on HuggingChat. Try it out now.

**amazed by the pace of adoption**
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from @MetaAI, running on fast optimized inference on @huggingface infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
LLaMa 2 has taken the world by storm. But not everyone wants to download the checkpoint, and talk to it on terminal. Talk to LLaMa 2 on Perplexity's LLaMa Chat: http://llama.perplexity.ai, fastest right now. This is fully hosted and powered by our in-house LLM inference… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 by 
@Meta
 is already integrated with 
@huggingface
 transformers, TGI, inference endpoints, PEFT and much more. Time for builders to build! https://huggingface.co/blog/llama2#inference…
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama-2 is available on AWS through Amazon SageMaker JumpStart.
------
Bel article dans Le Monde sur la sortie de Llama-2 en accès libre par Meta.
------
Excited to share my analysis of the LLAMA2 model.

In short, this model and paper are incredibly well done. Meta has stepped up the level for open-source and signaled another path for the future of LLMs.

Influencers are now right with "equals chatgpt".
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
Llama 2 was just announced, so I built an app for everyone to test it out, for free! 

Built with 
@replit
 and 
@replicatehq
 . 

I really like this model so far, especially for reasoning.

Thanks 
@ylecun
------
Llama 2 is a step forward for commercially available language models and open innovation in AI. These new models were pretrained on 2T tokens, and have double the context length when compared to the original release of Llama.

Download Llama 2  https://bit.ly/3Q45cDS
------
I also recommend reading 
@natolambert
's excellent blog post that summarizes the key points, if you don't have time for 36 pages of whitepaper:
------
Intelligence is a collection of skills, and an ability to solve new problems and acquire new skills.
The set of skills current AI systems possess or can acquire is very different from the set of skills humans possess or can acquire.
Both are specialized.
Humans less so.
------
1/5 Short thread on my post https://windowsontheory.org/2023/07/17/the-shape-of-agi-cartoons-and-back-of-envelope/?1… on how Artificial General Intelligence (AGI) and it's impact on human jobs. 

Basic case for AGI fits on back of envelope: Moore's law means compute grows exponentially and experience shows capabilities scale with log compute.
------
AI researchers seek to understand intelligence well enough to create beings of greater intelligence than current humans. 

Reaching this profound intellectual milestone will enrich our economies and challenge our societal institutions. It will be unprecedented and… Show more
------
The release of Llama-2 is about the creation of an collaborative ecosystem to facilitate access and accelerate progress.
------
Excited to announce open source release of the 7B, 13B, and 70B Llama 2 pre-trained and fine-tuned models. These models are awesome- pre-trained on 2T tokens and fine-tuned with over 1MM human annotations.

https://about.fb.com/news/2023/07/llama-2/…
------
Run Llama2 on your MacBook with GPU support! 

http://gist.github.com/adrienbrault/b…

Getting 20-25 token/s with https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/blob/main/llama-2-13b-chat.ggmlv3.q4_0.bin…… on M2 Max
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Thrilled to share a new blog post on how to fine-tune LLaMa 2 with QLoRA and Hugging Face on Amazon SageMaker
The blog post includes instructions for 7B, 13B, and 70B versions of the Model alongside Hardware requirements. 

  https://philschmid.de/sagemaker-llama2-qlora…
------
Did you know that you can train all Llama-2 models on your own data in just a few lines?

The script even works with the 70B model on a single A100 GPU thanks to the magic of 4bit and and PEFT!

Learn more: https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model…
Full script: https://github.com/lvwerra/trl/blob/main/examples/scripts/sft_trainer.py…
------
the 70B llama model now live on HuggingChat. Try it out now.

**amazed by the pace of adoption**
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from @MetaAI, running on fast optimized inference on @huggingface infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
LLaMa 2 has taken the world by storm. But not everyone wants to download the checkpoint, and talk to it on terminal. Talk to LLaMa 2 on Perplexity's LLaMa Chat: http://llama.perplexity.ai, fastest right now. This is fully hosted and powered by our in-house LLM inference… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 by 
@Meta
 is already integrated with 
@huggingface
 transformers, TGI, inference endpoints, PEFT and much more. Time for builders to build! https://huggingface.co/blog/llama2#inference…
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama-2 is available on AWS through Amazon SageMaker JumpStart.
------
Bel article dans Le Monde sur la sortie de Llama-2 en accès libre par Meta.
------
Excited to share my analysis of the LLAMA2 model.

In short, this model and paper are incredibly well done. Meta has stepped up the level for open-source and signaled another path for the future of LLMs.

Influencers are now right with "equals chatgpt".
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
Llama 2 was just announced, so I built an app for everyone to test it out, for free! 

Built with 
@replit
 and 
@replicatehq
 . 

I really like this model so far, especially for reasoning.

Thanks 
@ylecun
------
Llama 2 is a step forward for commercially available language models and open innovation in AI. These new models were pretrained on 2T tokens, and have double the context length when compared to the original release of Llama.

Download Llama 2  https://bit.ly/3Q45cDS
------
I also recommend reading 
@natolambert
's excellent blog post that summarizes the key points, if you don't have time for 36 pages of whitepaper:
------
The long-awaited sequel, Llama-2 is announced today! It's the best OSS model we have now.

▸ Tiers: 7B, 13B, 70B. Context: 4K
▸ 70B is close to GPT-3.5 on reasoning tasks, but there is a significant gap on coding benchmarks. It's on par or better than PaLM-540B on most… Show more
------
We believe an open approach is the right one for the development of today's Al models.

Today, we’re releasing Llama 2, the next generation of Meta’s open source Large Language Model, available for free for research & commercial use.

Details  https://bit.ly/3Dh9hNp
------
LLaMa-2 from 
@MetaAI
 is here!
Open weights, free for research and commercial use. Pre-trained on 2T tokens.
Fine-tuned too (unlike v1).

Lets gooo....
https://ai.meta.com/llama/
The paper lists the amazing authors who worked to make this happen night and day. Be sure to thank… Show more
------
This is indeed huge news in the world of AI!  So excited to see this out in the world!
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
At 
@perplexity_ai
, we've been working diligently on our in-house fast LLMs inference infrastructure and gearing up for the training and serving of our own LLMs.

Now, with 
@MetaAI
 paving the way by open sourcing LLaMA-2, many exciting opportunities have suddenly become available.… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Thrilled to share a new blog post on how to fine-tune LLaMa 2 with QLoRA and Hugging Face on Amazon SageMaker
The blog post includes instructions for 7B, 13B, and 70B versions of the Model alongside Hardware requirements. 

  https://philschmid.de/sagemaker-llama2-qlora…
------
Did you know that you can train all Llama-2 models on your own data in just a few lines?

The script even works with the 70B model on a single A100 GPU thanks to the magic of 4bit and and PEFT!

Learn more: https://huggingface.co/docs/trl/main/en/lora_tuning_peft#finetuning-llama2-model…
Full script: https://github.com/lvwerra/trl/blob/main/examples/scripts/sft_trainer.py…
------
the 70B llama model now live on HuggingChat. Try it out now.

**amazed by the pace of adoption**
------
Llama 2 (70B) just landed in HuggingChat

This is the largest running version of the model from @MetaAI, running on fast optimized inference on @huggingface infra.

Unleash the llamas! 

Try it out now

http://hf.co/chat
------
LLaMa 2 has taken the world by storm. But not everyone wants to download the checkpoint, and talk to it on terminal. Talk to LLaMa 2 on Perplexity's LLaMa Chat: http://llama.perplexity.ai, fastest right now. This is fully hosted and powered by our in-house LLM inference… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 by 
@Meta
 is already integrated with 
@huggingface
 transformers, TGI, inference endpoints, PEFT and much more. Time for builders to build! https://huggingface.co/blog/llama2#inference…
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama-2 is available on AWS through Amazon SageMaker JumpStart.
------
Bel article dans Le Monde sur la sortie de Llama-2 en accès libre par Meta.
------
Excited to share my analysis of the LLAMA2 model.

In short, this model and paper are incredibly well done. Meta has stepped up the level for open-source and signaled another path for the future of LLMs.

Influencers are now right with "equals chatgpt".
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
Llama 2 was just announced, so I built an app for everyone to test it out, for free! 

Built with 
@replit
 and 
@replicatehq
 . 

I really like this model so far, especially for reasoning.

Thanks 
@ylecun
------
Llama 2 is a step forward for commercially available language models and open innovation in AI. These new models were pretrained on 2T tokens, and have double the context length when compared to the original release of Llama.

Download Llama 2  https://bit.ly/3Q45cDS
------
I also recommend reading 
@natolambert
's excellent blog post that summarizes the key points, if you don't have time for 36 pages of whitepaper:
------
The long-awaited sequel, Llama-2 is announced today! It's the best OSS model we have now.

▸ Tiers: 7B, 13B, 70B. Context: 4K
▸ 70B is close to GPT-3.5 on reasoning tasks, but there is a significant gap on coding benchmarks. It's on par or better than PaLM-540B on most… Show more
------
We believe an open approach is the right one for the development of today's Al models.

Today, we’re releasing Llama 2, the next generation of Meta’s open source Large Language Model, available for free for research & commercial use.

Details  https://bit.ly/3Dh9hNp
------
LLaMa-2 from 
@MetaAI
 is here!
Open weights, free for research and commercial use. Pre-trained on 2T tokens.
Fine-tuned too (unlike v1).

Lets gooo....
https://ai.meta.com/llama/
The paper lists the amazing authors who worked to make this happen night and day. Be sure to thank… Show more
------
This is indeed huge news in the world of AI!  So excited to see this out in the world!
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Buckle up for a deep dive! We're about to unpack the intriguing interplay between generalization, information bottleneck (IB), and deep networks. Let's (try) break this down!  A thread about one time I was wrong
 
------
Llama 2 is out!  http://ai.meta.com/llama
This new version has better language generation, more layers of safety, a broad set of partners – and a license that authorizes commercial use.  
I continue to believe that an open approach is the right path to build better models!
------
Meta releases Llama 2: Open Foundation and Fine-Tuned Chat Models

paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…
blog: https://ai.meta.com/llama/

develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion… Show more
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Numbers of public models on 
@huggingface
:
- 
@Meta
: 689 including MusicGen, Galactica, Wav2Vec, RoBERTa,... - https://huggingface.co/facebook
- 
@Google
: 591 including BERT, Flan, T5, mobilnet,...  - https://huggingface.co/google
- 
@Microsoft
 : 252 including DialoGPT, BioGPT, layoutLM, uniML,… Show more
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
LLaMa 2 has taken the world by storm. But not everyone wants to download the checkpoint, and talk to it on terminal. Talk to LLaMa 2 on Perplexity's LLaMa Chat: http://llama.perplexity.ai, fastest right now. This is fully hosted and powered by our in-house LLM inference… Show more
------
Introducing LLaMa Chat: The fastest way to chat with @MetaAI/@meta's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama 2 by 
@Meta
 is already integrated with 
@huggingface
 transformers, TGI, inference endpoints, PEFT and much more. Time for builders to build! https://huggingface.co/blog/llama2#inference…
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama-2 is available on AWS through Amazon SageMaker JumpStart.
------
Bel article dans Le Monde sur la sortie de Llama-2 en accès libre par Meta.
------
Excited to share my analysis of the LLAMA2 model.

In short, this model and paper are incredibly well done. Meta has stepped up the level for open-source and signaled another path for the future of LLMs.

Influencers are now right with "equals chatgpt".
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
Llama 2 was just announced, so I built an app for everyone to test it out, for free! 

Built with 
@replit
 and 
@replicatehq
 . 

I really like this model so far, especially for reasoning.

Thanks 
@ylecun
------
Llama 2 is a step forward for commercially available language models and open innovation in AI. These new models were pretrained on 2T tokens, and have double the context length when compared to the original release of Llama.

Download Llama 2  https://bit.ly/3Q45cDS
------
I also recommend reading 
@natolambert
's excellent blog post that summarizes the key points, if you don't have time for 36 pages of whitepaper:
------
The long-awaited sequel, Llama-2 is announced today! It's the best OSS model we have now.

▸ Tiers: 7B, 13B, 70B. Context: 4K
▸ 70B is close to GPT-3.5 on reasoning tasks, but there is a significant gap on coding benchmarks. It's on par or better than PaLM-540B on most… Show more
------
We believe an open approach is the right one for the development of today's Al models.

Today, we’re releasing Llama 2, the next generation of Meta’s open source Large Language Model, available for free for research & commercial use.

Details  https://bit.ly/3Dh9hNp
------
LLaMa-2 from 
@MetaAI
 is here!
Open weights, free for research and commercial use. Pre-trained on 2T tokens.
Fine-tuned too (unlike v1).

Lets gooo....
https://ai.meta.com/llama/
The paper lists the amazing authors who worked to make this happen night and day. Be sure to thank… Show more
------
This is indeed huge news in the world of AI!  So excited to see this out in the world!
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Buckle up for a deep dive! We're about to unpack the intriguing interplay between generalization, information bottleneck (IB), and deep networks. Let's (try) break this down!  A thread about one time I was wrong
 
------
Llama 2 is out!  http://ai.meta.com/llama
This new version has better language generation, more layers of safety, a broad set of partners – and a license that authorizes commercial use.  
I continue to believe that an open approach is the right path to build better models!
------
Meta releases Llama 2: Open Foundation and Fine-Tuned Chat Models

paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…
blog: https://ai.meta.com/llama/

develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion… Show more
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Numbers of public models on 
@huggingface
:
- 
@Meta
: 689 including MusicGen, Galactica, Wav2Vec, RoBERTa,... - https://huggingface.co/facebook
- 
@Google
: 591 including BERT, Flan, T5, mobilnet,...  - https://huggingface.co/google
- 
@Microsoft
 : 252 including DialoGPT, BioGPT, layoutLM, uniML,… Show more
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
Happy that our Active Self-Supervised Learning got accepted at ICCV! We prove that DNNs learn optimal representations only from positive data pairing. Since positive pairs are way cheaper than labels to query we also study that new active learning strategy
https://arxiv.org/abs/2303.15256
------
 Have questions about the 2023 Open Catalyst Challenge? We've got answers!

 Join our weekly office hours starting 7/20:

- Wednesdays, 9-10am PT
- Thursdays, 5-6pm PT

 Tune in on 7/20 and 7/26 for an overview and tips!

 Zoom link available here:
------
Fantastic piece in Sciences on the limitations of LLMs by my Munk Debate teammate 
@MelMitchell1
.

Quote: "The assumptions that we make for humans—that they cannot memorize vast collections of text related to test questions, and when they answer questions correctly, they will be… Show more
------
How do we know how smart AI systems are? | Science https://science.org/doi/10.1126/science.adj5957…
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Introducing LLaMa Chat: The fastest way to chat with 
@MetaAI
/
@meta
's Llama2! 

Try it here: https://llama.perplexity.ai, feedback appreciated!
 
This is our first step towards building a blazing-fast LLM inference completely in-house, for everyone to try. What's next? We'll be… Show more
------
Llama-2 is available on AWS through Amazon SageMaker JumpStart.
------
Bel article dans Le Monde sur la sortie de Llama-2 en accès libre par Meta.
------
Excited to share my analysis of the LLAMA2 model.

In short, this model and paper are incredibly well done. Meta has stepped up the level for open-source and signaled another path for the future of LLMs.

Influencers are now right with "equals chatgpt".
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
Llama 2 was just announced, so I built an app for everyone to test it out, for free! 

Built with 
@replit
 and 
@replicatehq
 . 

I really like this model so far, especially for reasoning.

Thanks 
@ylecun
------
Llama 2 is a step forward for commercially available language models and open innovation in AI. These new models were pretrained on 2T tokens, and have double the context length when compared to the original release of Llama.

Download Llama 2  https://bit.ly/3Q45cDS
------
I also recommend reading 
@natolambert
's excellent blog post that summarizes the key points, if you don't have time for 36 pages of whitepaper:
------
The long-awaited sequel, Llama-2 is announced today! It's the best OSS model we have now.

▸ Tiers: 7B, 13B, 70B. Context: 4K
▸ 70B is close to GPT-3.5 on reasoning tasks, but there is a significant gap on coding benchmarks. It's on par or better than PaLM-540B on most… Show more
------
We believe an open approach is the right one for the development of today's Al models.

Today, we’re releasing Llama 2, the next generation of Meta’s open source Large Language Model, available for free for research & commercial use.

Details  https://bit.ly/3Dh9hNp
------
LLaMa-2 from 
@MetaAI
 is here!
Open weights, free for research and commercial use. Pre-trained on 2T tokens.
Fine-tuned too (unlike v1).

Lets gooo....
https://ai.meta.com/llama/
The paper lists the amazing authors who worked to make this happen night and day. Be sure to thank… Show more
------
This is indeed huge news in the world of AI!  So excited to see this out in the world!
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Buckle up for a deep dive! We're about to unpack the intriguing interplay between generalization, information bottleneck (IB), and deep networks. Let's (try) break this down!  A thread about one time I was wrong
 
------
Llama 2 is out!  http://ai.meta.com/llama
This new version has better language generation, more layers of safety, a broad set of partners – and a license that authorizes commercial use.  
I continue to believe that an open approach is the right path to build better models!
------
Meta releases Llama 2: Open Foundation and Fine-Tuned Chat Models

paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…
blog: https://ai.meta.com/llama/

develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion… Show more
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Numbers of public models on 
@huggingface
:
- 
@Meta
: 689 including MusicGen, Galactica, Wav2Vec, RoBERTa,... - https://huggingface.co/facebook
- 
@Google
: 591 including BERT, Flan, T5, mobilnet,...  - https://huggingface.co/google
- 
@Microsoft
 : 252 including DialoGPT, BioGPT, layoutLM, uniML,… Show more
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
Happy that our Active Self-Supervised Learning got accepted at ICCV! We prove that DNNs learn optimal representations only from positive data pairing. Since positive pairs are way cheaper than labels to query we also study that new active learning strategy
https://arxiv.org/abs/2303.15256
------
 Have questions about the 2023 Open Catalyst Challenge? We've got answers!

 Join our weekly office hours starting 7/20:

- Wednesdays, 9-10am PT
- Thursdays, 5-6pm PT

 Tune in on 7/20 and 7/26 for an overview and tips!

 Zoom link available here:
------
Fantastic piece in Sciences on the limitations of LLMs by my Munk Debate teammate 
@MelMitchell1
.

Quote: "The assumptions that we make for humans—that they cannot memorize vast collections of text related to test questions, and when they answer questions correctly, they will be… Show more
------
How do we know how smart AI systems are? | Science https://science.org/doi/10.1126/science.adj5957…
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Pretty cool new work of ours on using VICReg-based Self-Supervised Learning to estimate the parameters of a partial differential equation from data.
With 
@mialon_gregoire
, 
@garridoq_
, Hanna Lawrence, Manual Rehman, myself and 
@bobak_kiani
.
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Super happy to finally share this project at the intersection of self-supervised learning and AI for Science! 

In collaboration with 
@garridoq_
 , 
@HLawrenceCS
, 
@danyalrehman17
, 
@ylecun
, and 
@bobak_kiani
 

1/8
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
I'm very happy to be able to share this article publicly!

It articulates a "centrist" view on AI risks, adding some sobriety to a discussion that gets a bit out of hand sometimes.

Thanks to my amazing co-authors and the folks at 
@NoemaMag
 for all their work on this.
------
Focusing on the prospect of human extinction by AI in the distant future may prevent us from addressing AI’s disruptive dangers to society today | @tyrell_turing, @blaiseaguera, ​​@g_lajoie_ & @dhanya_sridhar in @NoemaMag 

https://noemamag.com/the-illusion-of-ais-existential-risk…
------
Llama 2 was just announced, so I built an app for everyone to test it out, for free! 

Built with 
@replit
 and 
@replicatehq
 . 

I really like this model so far, especially for reasoning.

Thanks 
@ylecun
------
Llama 2 is a step forward for commercially available language models and open innovation in AI. These new models were pretrained on 2T tokens, and have double the context length when compared to the original release of Llama.

Download Llama 2  https://bit.ly/3Q45cDS
------
I also recommend reading 
@natolambert
's excellent blog post that summarizes the key points, if you don't have time for 36 pages of whitepaper:
------
The long-awaited sequel, Llama-2 is announced today! It's the best OSS model we have now.

▸ Tiers: 7B, 13B, 70B. Context: 4K
▸ 70B is close to GPT-3.5 on reasoning tasks, but there is a significant gap on coding benchmarks. It's on par or better than PaLM-540B on most… Show more
------
We believe an open approach is the right one for the development of today's Al models.

Today, we’re releasing Llama 2, the next generation of Meta’s open source Large Language Model, available for free for research & commercial use.

Details  https://bit.ly/3Dh9hNp
------
LLaMa-2 from 
@MetaAI
 is here!
Open weights, free for research and commercial use. Pre-trained on 2T tokens.
Fine-tuned too (unlike v1).

Lets gooo....
https://ai.meta.com/llama/
The paper lists the amazing authors who worked to make this happen night and day. Be sure to thank… Show more
------
This is indeed huge news in the world of AI!  So excited to see this out in the world!
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Buckle up for a deep dive! We're about to unpack the intriguing interplay between generalization, information bottleneck (IB), and deep networks. Let's (try) break this down!  A thread about one time I was wrong
 
------
Llama 2 is out!  http://ai.meta.com/llama
This new version has better language generation, more layers of safety, a broad set of partners – and a license that authorizes commercial use.  
I continue to believe that an open approach is the right path to build better models!
------
Meta releases Llama 2: Open Foundation and Fine-Tuned Chat Models

paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…
blog: https://ai.meta.com/llama/

develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion… Show more
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Numbers of public models on 
@huggingface
:
- 
@Meta
: 689 including MusicGen, Galactica, Wav2Vec, RoBERTa,... - https://huggingface.co/facebook
- 
@Google
: 591 including BERT, Flan, T5, mobilnet,...  - https://huggingface.co/google
- 
@Microsoft
 : 252 including DialoGPT, BioGPT, layoutLM, uniML,… Show more
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
Happy that our Active Self-Supervised Learning got accepted at ICCV! We prove that DNNs learn optimal representations only from positive data pairing. Since positive pairs are way cheaper than labels to query we also study that new active learning strategy
https://arxiv.org/abs/2303.15256
------
 Have questions about the 2023 Open Catalyst Challenge? We've got answers!

 Join our weekly office hours starting 7/20:

- Wednesdays, 9-10am PT
- Thursdays, 5-6pm PT

 Tune in on 7/20 and 7/26 for an overview and tips!

 Zoom link available here:
------
Fantastic piece in Sciences on the limitations of LLMs by my Munk Debate teammate 
@MelMitchell1
.

Quote: "The assumptions that we make for humans—that they cannot memorize vast collections of text related to test questions, and when they answer questions correctly, they will be… Show more
------
How do we know how smart AI systems are? | Science https://science.org/doi/10.1126/science.adj5957…
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Pretty cool new work of ours on using VICReg-based Self-Supervised Learning to estimate the parameters of a partial differential equation from data.
With 
@mialon_gregoire
, 
@garridoq_
, Hanna Lawrence, Manual Rehman, myself and 
@bobak_kiani
.
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Super happy to finally share this project at the intersection of self-supervised learning and AI for Science! 

In collaboration with 
@garridoq_
 , 
@HLawrenceCS
, 
@danyalrehman17
, 
@ylecun
, and 
@bobak_kiani
 

1/8
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Aujourd'hui à 18h15 en direct sur France Culture:
Un débat sur l'IA avec Anne Alombert, Patrick Perez, et Yoshua Bengio .
------
Et on continue les #RencontresdePetrarque demain sur l’IA avec les deux prix Turing 
@ylecun
 et Yoshua Bengio, puis 
@AnneAlombert
 et le chercheur Patrick Perez 
@Valeo_Group
------
Complete bullshit.
Pardon my french.
------
Nine humanoid robots gathered at the United Nations’ 'AI for Good' conference in Geneva for the world’s first human-robot press conference https://reut.rs/3PNvNor
------
Intelligence is certainly not a one-dimensional thing.

@togelius
 is right.
------
Are AI doomers platonists? It seems that most of the doomer arguments rest on the idea that there is such a thing as Intelligence, which has certain properties and quantity. The nominalist position is that the word intelligence is just a convenient way of clustering phenomena.
------
The long-awaited sequel, Llama-2 is announced today! It's the best OSS model we have now.

▸ Tiers: 7B, 13B, 70B. Context: 4K
▸ 70B is close to GPT-3.5 on reasoning tasks, but there is a significant gap on coding benchmarks. It's on par or better than PaLM-540B on most… Show more
------
We believe an open approach is the right one for the development of today's Al models.

Today, we’re releasing Llama 2, the next generation of Meta’s open source Large Language Model, available for free for research & commercial use.

Details  https://bit.ly/3Dh9hNp
------
LLaMa-2 from 
@MetaAI
 is here!
Open weights, free for research and commercial use. Pre-trained on 2T tokens.
Fine-tuned too (unlike v1).

Lets gooo....
https://ai.meta.com/llama/
The paper lists the amazing authors who worked to make this happen night and day. Be sure to thank… Show more
------
This is indeed huge news in the world of AI!  So excited to see this out in the world!
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Buckle up for a deep dive! We're about to unpack the intriguing interplay between generalization, information bottleneck (IB), and deep networks. Let's (try) break this down!  A thread about one time I was wrong
 
------
Llama 2 is out!  http://ai.meta.com/llama
This new version has better language generation, more layers of safety, a broad set of partners – and a license that authorizes commercial use.  
I continue to believe that an open approach is the right path to build better models!
------
Meta releases Llama 2: Open Foundation and Fine-Tuned Chat Models

paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…
blog: https://ai.meta.com/llama/

develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion… Show more
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Numbers of public models on 
@huggingface
:
- 
@Meta
: 689 including MusicGen, Galactica, Wav2Vec, RoBERTa,... - https://huggingface.co/facebook
- 
@Google
: 591 including BERT, Flan, T5, mobilnet,...  - https://huggingface.co/google
- 
@Microsoft
 : 252 including DialoGPT, BioGPT, layoutLM, uniML,… Show more
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
Happy that our Active Self-Supervised Learning got accepted at ICCV! We prove that DNNs learn optimal representations only from positive data pairing. Since positive pairs are way cheaper than labels to query we also study that new active learning strategy
https://arxiv.org/abs/2303.15256
------
 Have questions about the 2023 Open Catalyst Challenge? We've got answers!

 Join our weekly office hours starting 7/20:

- Wednesdays, 9-10am PT
- Thursdays, 5-6pm PT

 Tune in on 7/20 and 7/26 for an overview and tips!

 Zoom link available here:
------
Fantastic piece in Sciences on the limitations of LLMs by my Munk Debate teammate 
@MelMitchell1
.

Quote: "The assumptions that we make for humans—that they cannot memorize vast collections of text related to test questions, and when they answer questions correctly, they will be… Show more
------
How do we know how smart AI systems are? | Science https://science.org/doi/10.1126/science.adj5957…
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Pretty cool new work of ours on using VICReg-based Self-Supervised Learning to estimate the parameters of a partial differential equation from data.
With 
@mialon_gregoire
, 
@garridoq_
, Hanna Lawrence, Manual Rehman, myself and 
@bobak_kiani
.
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Super happy to finally share this project at the intersection of self-supervised learning and AI for Science! 

In collaboration with 
@garridoq_
 , 
@HLawrenceCS
, 
@danyalrehman17
, 
@ylecun
, and 
@bobak_kiani
 

1/8
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Aujourd'hui à 18h15 en direct sur France Culture:
Un débat sur l'IA avec Anne Alombert, Patrick Perez, et Yoshua Bengio .
------
Et on continue les #RencontresdePetrarque demain sur l’IA avec les deux prix Turing 
@ylecun
 et Yoshua Bengio, puis 
@AnneAlombert
 et le chercheur Patrick Perez 
@Valeo_Group
------
Complete bullshit.
Pardon my french.
------
Nine humanoid robots gathered at the United Nations’ 'AI for Good' conference in Geneva for the world’s first human-robot press conference https://reut.rs/3PNvNor
------
Intelligence is certainly not a one-dimensional thing.

@togelius
 is right.
------
Are AI doomers platonists? It seems that most of the doomer arguments rest on the idea that there is such a thing as Intelligence, which has certain properties and quantity. The nominalist position is that the word intelligence is just a convenient way of clustering phenomena.
------
People believe that if they could somehow walk into a research lab, they could then 'steal the knowledge'.

It does not work like that.  Innovation is illegible.

You can go, right now, on many campuses all over the world, just walk in and talk to the professors, the students,… Show more
------
Yes, we do believe that more knowledge is better than less.
In fact, that's one excellent reason to work on AI.
------
Herbert Simon said "In the long run and on average, more knowledge is better than less." I guess we could view this as the credo of science. It is fundamentally a belief about humanity's ability to choose good over evil. As AI improves, do we still believe this?
------
 #Threads de 
@Meta
 est lancé

Pour l'utiliser depuis la France / l'Europe, ce n'est pas possible... probablement pour des raisons de RGPD. Il faut donc ruser pour se connecter mais ça fonctionne en quelques minutes (petit guide à la fin ) ! 

Bilan ?
------
I am surya_ganguli on the th***ds app - you know the one EM is suing :)  I am hoping to resurrect there the intellectual paradise of ML/AI, neuro, physics, math, stats, economics, philosophy & more that my twitter feed once was. If working on these topics reply w/your profile!
------
The government are ramming through this Online Safety Bill even though it is a travesty of justice which will make the UK Internet obviously less safe. 1/
------
 Major Updates on the LLM Survey 

* 34+ new pages, 200+ new references
* New figures (e.g. LLaMA family)
* New chapters (e.g. complex task planning w/ LLMs)
* 26 useful prompting tips
* Empirical evaluation of 8 abilities of LLMs with specially selected tasks

1/n 
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
Llama 2 is out!  http://ai.meta.com/llama
This new version has better language generation, more layers of safety, a broad set of partners – and a license that authorizes commercial use.  
I continue to believe that an open approach is the right path to build better models!
------
Meta releases Llama 2: Open Foundation and Fine-Tuned Chat Models

paper: https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/…
blog: https://ai.meta.com/llama/

develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion… Show more
------
This is huge: Llama-v2 is open source, with a license that authorizes commercial use!

This is going to change the landscape of the LLM market.
Llama-v2 is available on Microsoft Azure and will be available on AWS, Hugging Face and other providers

Pretrained and fine-tuned… Show more
------
Numbers of public models on 
@huggingface
:
- 
@Meta
: 689 including MusicGen, Galactica, Wav2Vec, RoBERTa,... - https://huggingface.co/facebook
- 
@Google
: 591 including BERT, Flan, T5, mobilnet,...  - https://huggingface.co/google
- 
@Microsoft
 : 252 including DialoGPT, BioGPT, layoutLM, uniML,… Show more
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
Happy that our Active Self-Supervised Learning got accepted at ICCV! We prove that DNNs learn optimal representations only from positive data pairing. Since positive pairs are way cheaper than labels to query we also study that new active learning strategy
https://arxiv.org/abs/2303.15256
------
 Have questions about the 2023 Open Catalyst Challenge? We've got answers!

 Join our weekly office hours starting 7/20:

- Wednesdays, 9-10am PT
- Thursdays, 5-6pm PT

 Tune in on 7/20 and 7/26 for an overview and tips!

 Zoom link available here:
------
Fantastic piece in Sciences on the limitations of LLMs by my Munk Debate teammate 
@MelMitchell1
.

Quote: "The assumptions that we make for humans—that they cannot memorize vast collections of text related to test questions, and when they answer questions correctly, they will be… Show more
------
How do we know how smart AI systems are? | Science https://science.org/doi/10.1126/science.adj5957…
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Pretty cool new work of ours on using VICReg-based Self-Supervised Learning to estimate the parameters of a partial differential equation from data.
With 
@mialon_gregoire
, 
@garridoq_
, Hanna Lawrence, Manual Rehman, myself and 
@bobak_kiani
.
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Super happy to finally share this project at the intersection of self-supervised learning and AI for Science! 

In collaboration with 
@garridoq_
 , 
@HLawrenceCS
, 
@danyalrehman17
, 
@ylecun
, and 
@bobak_kiani
 

1/8
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Aujourd'hui à 18h15 en direct sur France Culture:
Un débat sur l'IA avec Anne Alombert, Patrick Perez, et Yoshua Bengio .
------
Et on continue les #RencontresdePetrarque demain sur l’IA avec les deux prix Turing 
@ylecun
 et Yoshua Bengio, puis 
@AnneAlombert
 et le chercheur Patrick Perez 
@Valeo_Group
------
Complete bullshit.
Pardon my french.
------
Nine humanoid robots gathered at the United Nations’ 'AI for Good' conference in Geneva for the world’s first human-robot press conference https://reut.rs/3PNvNor
------
Intelligence is certainly not a one-dimensional thing.

@togelius
 is right.
------
Are AI doomers platonists? It seems that most of the doomer arguments rest on the idea that there is such a thing as Intelligence, which has certain properties and quantity. The nominalist position is that the word intelligence is just a convenient way of clustering phenomena.
------
People believe that if they could somehow walk into a research lab, they could then 'steal the knowledge'.

It does not work like that.  Innovation is illegible.

You can go, right now, on many campuses all over the world, just walk in and talk to the professors, the students,… Show more
------
Yes, we do believe that more knowledge is better than less.
In fact, that's one excellent reason to work on AI.
------
Herbert Simon said "In the long run and on average, more knowledge is better than less." I guess we could view this as the credo of science. It is fundamentally a belief about humanity's ability to choose good over evil. As AI improves, do we still believe this?
------
 #Threads de 
@Meta
 est lancé

Pour l'utiliser depuis la France / l'Europe, ce n'est pas possible... probablement pour des raisons de RGPD. Il faut donc ruser pour se connecter mais ça fonctionne en quelques minutes (petit guide à la fin ) ! 

Bilan ?
------
I am surya_ganguli on the th***ds app - you know the one EM is suing :)  I am hoping to resurrect there the intellectual paradise of ML/AI, neuro, physics, math, stats, economics, philosophy & more that my twitter feed once was. If working on these topics reply w/your profile!
------
The government are ramming through this Online Safety Bill even though it is a travesty of justice which will make the UK Internet obviously less safe. 1/
------
 Major Updates on the LLM Survey 

* 34+ new pages, 200+ new references
* New figures (e.g. LLaMA family)
* New chapters (e.g. complex task planning w/ LLMs)
* 26 useful prompting tips
* Empirical evaluation of 8 abilities of LLMs with specially selected tasks

1/n 
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
The hairy ball theorem states that in odd dimension d, vector fields on the tangent plane of a (d-1)-sphere necessarily contain a singular point (where it vanishes). https://en.wikipedia.org/wiki/Hairy_ball_theorem…
------
One cannot just "solve the AI alignment problem."
Let alone do it in 4 years.

One doesn't just "solve" the safety problem for turbojets, cars, rockets, or human societies, either.

Engineering-for-reliability is always a process of continuous & iterative refinement.
------
There is a hierarchy of training paradigms: 
- Architectural: uses general properties of the data to direct the architecture of the learning system.
- Self-Supervised: can use lots of (raw) data to pre-train a large system to represent the data in a task-independent way.
-… Show more
------
How does declaring something to be innate help us do AI science? It still seems to me, as an ML researcher, as a universal excuse for “stuff we don’t understand “. The whole idea of pre-training is exactly to create a network with good innate representations
------
I'm on Threads, not surprisingly.
------
A big challenge for #AI research over the next decade is whether AI will be allowed to form consciousness and wisdom like human, Yann LeCun, chief AI scientist at 
@Meta
 and Turing Award winner, said at the #WAIC2023 today. 
@ylecun
------
Merci à 
@ylecun
 pour cet excellent ouvrage pédagogique pour mieux comprendre la « boîte noire » de l’#IA et du #deeplearning. À lire sans modération pendant l’été 
------
Happy that our Active Self-Supervised Learning got accepted at ICCV! We prove that DNNs learn optimal representations only from positive data pairing. Since positive pairs are way cheaper than labels to query we also study that new active learning strategy
https://arxiv.org/abs/2303.15256
------
 Have questions about the 2023 Open Catalyst Challenge? We've got answers!

 Join our weekly office hours starting 7/20:

- Wednesdays, 9-10am PT
- Thursdays, 5-6pm PT

 Tune in on 7/20 and 7/26 for an overview and tips!

 Zoom link available here:
------
Fantastic piece in Sciences on the limitations of LLMs by my Munk Debate teammate 
@MelMitchell1
.

Quote: "The assumptions that we make for humans—that they cannot memorize vast collections of text related to test questions, and when they answer questions correctly, they will be… Show more
------
How do we know how smart AI systems are? | Science https://science.org/doi/10.1126/science.adj5957…
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Pretty cool new work of ours on using VICReg-based Self-Supervised Learning to estimate the parameters of a partial differential equation from data.
With 
@mialon_gregoire
, 
@garridoq_
, Hanna Lawrence, Manual Rehman, myself and 
@bobak_kiani
.
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Super happy to finally share this project at the intersection of self-supervised learning and AI for Science! 

In collaboration with 
@garridoq_
 , 
@HLawrenceCS
, 
@danyalrehman17
, 
@ylecun
, and 
@bobak_kiani
 

1/8
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Aujourd'hui à 18h15 en direct sur France Culture:
Un débat sur l'IA avec Anne Alombert, Patrick Perez, et Yoshua Bengio .
------
Et on continue les #RencontresdePetrarque demain sur l’IA avec les deux prix Turing 
@ylecun
 et Yoshua Bengio, puis 
@AnneAlombert
 et le chercheur Patrick Perez 
@Valeo_Group
------
Complete bullshit.
Pardon my french.
------
Nine humanoid robots gathered at the United Nations’ 'AI for Good' conference in Geneva for the world’s first human-robot press conference https://reut.rs/3PNvNor
------
Intelligence is certainly not a one-dimensional thing.

@togelius
 is right.
------
Are AI doomers platonists? It seems that most of the doomer arguments rest on the idea that there is such a thing as Intelligence, which has certain properties and quantity. The nominalist position is that the word intelligence is just a convenient way of clustering phenomena.
------
People believe that if they could somehow walk into a research lab, they could then 'steal the knowledge'.

It does not work like that.  Innovation is illegible.

You can go, right now, on many campuses all over the world, just walk in and talk to the professors, the students,… Show more
------
Yes, we do believe that more knowledge is better than less.
In fact, that's one excellent reason to work on AI.
------
Herbert Simon said "In the long run and on average, more knowledge is better than less." I guess we could view this as the credo of science. It is fundamentally a belief about humanity's ability to choose good over evil. As AI improves, do we still believe this?
------
 #Threads de 
@Meta
 est lancé

Pour l'utiliser depuis la France / l'Europe, ce n'est pas possible... probablement pour des raisons de RGPD. Il faut donc ruser pour se connecter mais ça fonctionne en quelques minutes (petit guide à la fin ) ! 

Bilan ?
------
I am surya_ganguli on the th***ds app - you know the one EM is suing :)  I am hoping to resurrect there the intellectual paradise of ML/AI, neuro, physics, math, stats, economics, philosophy & more that my twitter feed once was. If working on these topics reply w/your profile!
------
The government are ramming through this Online Safety Bill even though it is a travesty of justice which will make the UK Internet obviously less safe. 1/
------
 Major Updates on the LLM Survey 

* 34+ new pages, 200+ new references
* New figures (e.g. LLaMA family)
* New chapters (e.g. complex task planning w/ LLMs)
* 26 useful prompting tips
* Empirical evaluation of 8 abilities of LLMs with specially selected tasks

1/n 
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
The hairy ball theorem states that in odd dimension d, vector fields on the tangent plane of a (d-1)-sphere necessarily contain a singular point (where it vanishes). https://en.wikipedia.org/wiki/Hairy_ball_theorem…
------
One cannot just "solve the AI alignment problem."
Let alone do it in 4 years.

One doesn't just "solve" the safety problem for turbojets, cars, rockets, or human societies, either.

Engineering-for-reliability is always a process of continuous & iterative refinement.
------
There is a hierarchy of training paradigms: 
- Architectural: uses general properties of the data to direct the architecture of the learning system.
- Self-Supervised: can use lots of (raw) data to pre-train a large system to represent the data in a task-independent way.
-… Show more
------
How does declaring something to be innate help us do AI science? It still seems to me, as an ML researcher, as a universal excuse for “stuff we don’t understand “. The whole idea of pre-training is exactly to create a network with good innate representations
------
I'm on Threads, not surprisingly.
------
A big challenge for #AI research over the next decade is whether AI will be allowed to form consciousness and wisdom like human, Yann LeCun, chief AI scientist at 
@Meta
 and Turing Award winner, said at the #WAIC2023 today. 
@ylecun
------
La France s'impose déjà comme une grande nation de l'#intelligenceartificielle, grâce à 
@ylecun
 ! La rock star de 
@VivaTech
 propose un algorithme open source qui met l'éthique avant tout, sans sacrifier la performance. 
@LesEchos
------
What happens if super intelligent machines fall into the wrong hands?


@MIT
's 
@tegmark
: "If Hitler were more intelligent the world would have been worse"


@Meta
's 
@ylecun
: "how do you know you don't have Hitler in your class right now?"

Watch the full debate here:… Show more
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
What is ignored or neglected by the media -- but will be studied by historians?

Here's the full list of 25 examples:
------
Pretty cool new work of ours on using VICReg-based Self-Supervised Learning to estimate the parameters of a partial differential equation from data.
With 
@mialon_gregoire
, 
@garridoq_
, Hanna Lawrence, Manual Rehman, myself and 
@bobak_kiani
.
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Super happy to finally share this project at the intersection of self-supervised learning and AI for Science! 

In collaboration with 
@garridoq_
 , 
@HLawrenceCS
, 
@danyalrehman17
, 
@ylecun
, and 
@bobak_kiani
 

1/8
------
Self-Supervised Learning with Lie Symmetries for Partial Differential Equations

paper page: https://huggingface.co/papers/2307.05432…

Machine learning for differential equations paves the way for computationally efficient alternatives to numerical solvers, with potentially broad impacts in… Show more
------
Aujourd'hui à 18h15 en direct sur France Culture:
Un débat sur l'IA avec Anne Alombert, Patrick Perez, et Yoshua Bengio .
------
Et on continue les #RencontresdePetrarque demain sur l’IA avec les deux prix Turing 
@ylecun
 et Yoshua Bengio, puis 
@AnneAlombert
 et le chercheur Patrick Perez 
@Valeo_Group
------
Complete bullshit.
Pardon my french.
------
Nine humanoid robots gathered at the United Nations’ 'AI for Good' conference in Geneva for the world’s first human-robot press conference https://reut.rs/3PNvNor
------
Intelligence is certainly not a one-dimensional thing.

@togelius
 is right.
------
Are AI doomers platonists? It seems that most of the doomer arguments rest on the idea that there is such a thing as Intelligence, which has certain properties and quantity. The nominalist position is that the word intelligence is just a convenient way of clustering phenomena.
------
People believe that if they could somehow walk into a research lab, they could then 'steal the knowledge'.

It does not work like that.  Innovation is illegible.

You can go, right now, on many campuses all over the world, just walk in and talk to the professors, the students,… Show more
------
Yes, we do believe that more knowledge is better than less.
In fact, that's one excellent reason to work on AI.
------
Herbert Simon said "In the long run and on average, more knowledge is better than less." I guess we could view this as the credo of science. It is fundamentally a belief about humanity's ability to choose good over evil. As AI improves, do we still believe this?
------
 #Threads de 
@Meta
 est lancé

Pour l'utiliser depuis la France / l'Europe, ce n'est pas possible... probablement pour des raisons de RGPD. Il faut donc ruser pour se connecter mais ça fonctionne en quelques minutes (petit guide à la fin ) ! 

Bilan ?
------
I am surya_ganguli on the th***ds app - you know the one EM is suing :)  I am hoping to resurrect there the intellectual paradise of ML/AI, neuro, physics, math, stats, economics, philosophy & more that my twitter feed once was. If working on these topics reply w/your profile!
------
The government are ramming through this Online Safety Bill even though it is a travesty of justice which will make the UK Internet obviously less safe. 1/
------
 Major Updates on the LLM Survey 

* 34+ new pages, 200+ new references
* New figures (e.g. LLaMA family)
* New chapters (e.g. complex task planning w/ LLMs)
* 26 useful prompting tips
* Empirical evaluation of 8 abilities of LLMs with specially selected tasks

1/n 
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
The hairy ball theorem states that in odd dimension d, vector fields on the tangent plane of a (d-1)-sphere necessarily contain a singular point (where it vanishes). https://en.wikipedia.org/wiki/Hairy_ball_theorem…
------
One cannot just "solve the AI alignment problem."
Let alone do it in 4 years.

One doesn't just "solve" the safety problem for turbojets, cars, rockets, or human societies, either.

Engineering-for-reliability is always a process of continuous & iterative refinement.
------
There is a hierarchy of training paradigms: 
- Architectural: uses general properties of the data to direct the architecture of the learning system.
- Self-Supervised: can use lots of (raw) data to pre-train a large system to represent the data in a task-independent way.
-… Show more
------
How does declaring something to be innate help us do AI science? It still seems to me, as an ML researcher, as a universal excuse for “stuff we don’t understand “. The whole idea of pre-training is exactly to create a network with good innate representations
------
I'm on Threads, not surprisingly.
------
A big challenge for #AI research over the next decade is whether AI will be allowed to form consciousness and wisdom like human, Yann LeCun, chief AI scientist at 
@Meta
 and Turing Award winner, said at the #WAIC2023 today. 
@ylecun
------
La France s'impose déjà comme une grande nation de l'#intelligenceartificielle, grâce à 
@ylecun
 ! La rock star de 
@VivaTech
 propose un algorithme open source qui met l'éthique avant tout, sans sacrifier la performance. 
@LesEchos
------
What happens if super intelligent machines fall into the wrong hands?


@MIT
's 
@tegmark
: "If Hitler were more intelligent the world would have been worse"


@Meta
's 
@ylecun
: "how do you know you don't have Hitler in your class right now?"

Watch the full debate here:… Show more
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
I-JEPA is the first model based on a component of 
@ylecun
's vision to make AI systems learn and reason like animals and humans. It uses self-supervised computer vision that learns to understand the world by predicting it.

Details  https://bit.ly/3rkx6Rn
------
Grazie mille Università di Siena 
------
A #YannLeCun la laurea ad honorem dall'#Università di #Siena.
Il conferimento si è tenuto il 3/7 alla Certosa di Pontignano alla presenza del Rettore #RobertoDiPietra, dei Direttori dei Dipartimenti universitari e dei Delegati.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#LaureaUnisiLeCun
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
Aujourd'hui à 18h15 en direct sur France Culture:
Un débat sur l'IA avec Anne Alombert, Patrick Perez, et Yoshua Bengio .
------
Et on continue les #RencontresdePetrarque demain sur l’IA avec les deux prix Turing 
@ylecun
 et Yoshua Bengio, puis 
@AnneAlombert
 et le chercheur Patrick Perez 
@Valeo_Group
------
Complete bullshit.
Pardon my french.
------
Nine humanoid robots gathered at the United Nations’ 'AI for Good' conference in Geneva for the world’s first human-robot press conference https://reut.rs/3PNvNor
------
Intelligence is certainly not a one-dimensional thing.

@togelius
 is right.
------
Are AI doomers platonists? It seems that most of the doomer arguments rest on the idea that there is such a thing as Intelligence, which has certain properties and quantity. The nominalist position is that the word intelligence is just a convenient way of clustering phenomena.
------
People believe that if they could somehow walk into a research lab, they could then 'steal the knowledge'.

It does not work like that.  Innovation is illegible.

You can go, right now, on many campuses all over the world, just walk in and talk to the professors, the students,… Show more
------
Yes, we do believe that more knowledge is better than less.
In fact, that's one excellent reason to work on AI.
------
Herbert Simon said "In the long run and on average, more knowledge is better than less." I guess we could view this as the credo of science. It is fundamentally a belief about humanity's ability to choose good over evil. As AI improves, do we still believe this?
------
 #Threads de 
@Meta
 est lancé

Pour l'utiliser depuis la France / l'Europe, ce n'est pas possible... probablement pour des raisons de RGPD. Il faut donc ruser pour se connecter mais ça fonctionne en quelques minutes (petit guide à la fin ) ! 

Bilan ?
------
I am surya_ganguli on the th***ds app - you know the one EM is suing :)  I am hoping to resurrect there the intellectual paradise of ML/AI, neuro, physics, math, stats, economics, philosophy & more that my twitter feed once was. If working on these topics reply w/your profile!
------
The government are ramming through this Online Safety Bill even though it is a travesty of justice which will make the UK Internet obviously less safe. 1/
------
 Major Updates on the LLM Survey 

* 34+ new pages, 200+ new references
* New figures (e.g. LLaMA family)
* New chapters (e.g. complex task planning w/ LLMs)
* 26 useful prompting tips
* Empirical evaluation of 8 abilities of LLMs with specially selected tasks

1/n 
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
The hairy ball theorem states that in odd dimension d, vector fields on the tangent plane of a (d-1)-sphere necessarily contain a singular point (where it vanishes). https://en.wikipedia.org/wiki/Hairy_ball_theorem…
------
One cannot just "solve the AI alignment problem."
Let alone do it in 4 years.

One doesn't just "solve" the safety problem for turbojets, cars, rockets, or human societies, either.

Engineering-for-reliability is always a process of continuous & iterative refinement.
------
There is a hierarchy of training paradigms: 
- Architectural: uses general properties of the data to direct the architecture of the learning system.
- Self-Supervised: can use lots of (raw) data to pre-train a large system to represent the data in a task-independent way.
-… Show more
------
How does declaring something to be innate help us do AI science? It still seems to me, as an ML researcher, as a universal excuse for “stuff we don’t understand “. The whole idea of pre-training is exactly to create a network with good innate representations
------
I'm on Threads, not surprisingly.
------
A big challenge for #AI research over the next decade is whether AI will be allowed to form consciousness and wisdom like human, Yann LeCun, chief AI scientist at 
@Meta
 and Turing Award winner, said at the #WAIC2023 today. 
@ylecun
------
La France s'impose déjà comme une grande nation de l'#intelligenceartificielle, grâce à 
@ylecun
 ! La rock star de 
@VivaTech
 propose un algorithme open source qui met l'éthique avant tout, sans sacrifier la performance. 
@LesEchos
------
What happens if super intelligent machines fall into the wrong hands?


@MIT
's 
@tegmark
: "If Hitler were more intelligent the world would have been worse"


@Meta
's 
@ylecun
: "how do you know you don't have Hitler in your class right now?"

Watch the full debate here:… Show more
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
I-JEPA is the first model based on a component of 
@ylecun
's vision to make AI systems learn and reason like animals and humans. It uses self-supervised computer vision that learns to understand the world by predicting it.

Details  https://bit.ly/3rkx6Rn
------
Grazie mille Università di Siena 
------
A #YannLeCun la laurea ad honorem dall'#Università di #Siena.
Il conferimento si è tenuto il 3/7 alla Certosa di Pontignano alla presenza del Rettore #RobertoDiPietra, dei Direttori dei Dipartimenti universitari e dei Delegati.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#LaureaUnisiLeCun
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
I assume others have pointed this out, but the misery index  — unemployment plus inflation — is all the way back to where it was when Biden took office 1/
------
 #Threads de 
@Meta
 est lancé

Pour l'utiliser depuis la France / l'Europe, ce n'est pas possible... probablement pour des raisons de RGPD. Il faut donc ruser pour se connecter mais ça fonctionne en quelques minutes (petit guide à la fin ) ! 

Bilan ?
------
I am surya_ganguli on the th***ds app - you know the one EM is suing :)  I am hoping to resurrect there the intellectual paradise of ML/AI, neuro, physics, math, stats, economics, philosophy & more that my twitter feed once was. If working on these topics reply w/your profile!
------
The government are ramming through this Online Safety Bill even though it is a travesty of justice which will make the UK Internet obviously less safe. 1/
------
 Major Updates on the LLM Survey 

* 34+ new pages, 200+ new references
* New figures (e.g. LLaMA family)
* New chapters (e.g. complex task planning w/ LLMs)
* 26 useful prompting tips
* Empirical evaluation of 8 abilities of LLMs with specially selected tasks

1/n 
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
The hairy ball theorem states that in odd dimension d, vector fields on the tangent plane of a (d-1)-sphere necessarily contain a singular point (where it vanishes). https://en.wikipedia.org/wiki/Hairy_ball_theorem…
------
One cannot just "solve the AI alignment problem."
Let alone do it in 4 years.

One doesn't just "solve" the safety problem for turbojets, cars, rockets, or human societies, either.

Engineering-for-reliability is always a process of continuous & iterative refinement.
------
There is a hierarchy of training paradigms: 
- Architectural: uses general properties of the data to direct the architecture of the learning system.
- Self-Supervised: can use lots of (raw) data to pre-train a large system to represent the data in a task-independent way.
-… Show more
------
How does declaring something to be innate help us do AI science? It still seems to me, as an ML researcher, as a universal excuse for “stuff we don’t understand “. The whole idea of pre-training is exactly to create a network with good innate representations
------
I'm on Threads, not surprisingly.
------
A big challenge for #AI research over the next decade is whether AI will be allowed to form consciousness and wisdom like human, Yann LeCun, chief AI scientist at 
@Meta
 and Turing Award winner, said at the #WAIC2023 today. 
@ylecun
------
La France s'impose déjà comme une grande nation de l'#intelligenceartificielle, grâce à 
@ylecun
 ! La rock star de 
@VivaTech
 propose un algorithme open source qui met l'éthique avant tout, sans sacrifier la performance. 
@LesEchos
------
What happens if super intelligent machines fall into the wrong hands?


@MIT
's 
@tegmark
: "If Hitler were more intelligent the world would have been worse"


@Meta
's 
@ylecun
: "how do you know you don't have Hitler in your class right now?"

Watch the full debate here:… Show more
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
I-JEPA is the first model based on a component of 
@ylecun
's vision to make AI systems learn and reason like animals and humans. It uses self-supervised computer vision that learns to understand the world by predicting it.

Details  https://bit.ly/3rkx6Rn
------
Grazie mille Università di Siena 
------
A #YannLeCun la laurea ad honorem dall'#Università di #Siena.
Il conferimento si è tenuto il 3/7 alla Certosa di Pontignano alla presenza del Rettore #RobertoDiPietra, dei Direttori dei Dipartimenti universitari e dei Delegati.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#LaureaUnisiLeCun
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
I assume others have pointed this out, but the misery index  — unemployment plus inflation — is all the way back to where it was when Biden took office 1/
------
The graph below shows how well the richest Top 1% have done across different countries over the past 200 years. 

Some interesting patterns explored in .
#dataviz
------
Thank you, University of Siena 
@unisiena
 !
------
Laurea ad Honorem @unisiena - Yann LeCun, VP Meta, Chief AI Scientist #Meta, NYU.
Lectio Magistralis:
The Present and Future of #ArtificialIntelligence
July 3 at 11.30, Certosa di Pontignano.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#yannlecun #LaureaUnisiLeCun
------
The geodesic distance extends a local metric into a global one. Geodesic curves define networks of curves that are similar to spanning trees on a graph. https://en.wikipedia.org/wiki/Geodesic https://en.wikipedia.org/wiki/Riemannian_manifold…
------
Thrilled to announce our study on robot visual navigation methods is now published in 
@SciRobotics
!

All credit to my amazing collaborators: 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
, 
@dchaplot
 (1/7)
------
Psychologists have identified a pervasive illusion that has existed for at least 70 years: The illusion of moral decline https://psypost.org/2023/06/psychologists-have-identified-a-pervasive-illusion-that-has-existed-for-at-least-70-years-166017…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
Huge shoutout to the creators of MusicGen 
@MetaAI
 . Had a lot of fun trying it out and ultimately generating a podcast intro . 
@jadecopet
 
@FelixKreuk
 
@itai_gat
 
@adiyossLC
 
@honualx
 
@syhw
 

Also talked about Meta's open source approach and AI infrastructure. 
@ylecun
------
The hairy ball theorem states that in odd dimension d, vector fields on the tangent plane of a (d-1)-sphere necessarily contain a singular point (where it vanishes). https://en.wikipedia.org/wiki/Hairy_ball_theorem…
------
One cannot just "solve the AI alignment problem."
Let alone do it in 4 years.

One doesn't just "solve" the safety problem for turbojets, cars, rockets, or human societies, either.

Engineering-for-reliability is always a process of continuous & iterative refinement.
------
There is a hierarchy of training paradigms: 
- Architectural: uses general properties of the data to direct the architecture of the learning system.
- Self-Supervised: can use lots of (raw) data to pre-train a large system to represent the data in a task-independent way.
-… Show more
------
How does declaring something to be innate help us do AI science? It still seems to me, as an ML researcher, as a universal excuse for “stuff we don’t understand “. The whole idea of pre-training is exactly to create a network with good innate representations
------
I'm on Threads, not surprisingly.
------
A big challenge for #AI research over the next decade is whether AI will be allowed to form consciousness and wisdom like human, Yann LeCun, chief AI scientist at 
@Meta
 and Turing Award winner, said at the #WAIC2023 today. 
@ylecun
------
La France s'impose déjà comme une grande nation de l'#intelligenceartificielle, grâce à 
@ylecun
 ! La rock star de 
@VivaTech
 propose un algorithme open source qui met l'éthique avant tout, sans sacrifier la performance. 
@LesEchos
------
What happens if super intelligent machines fall into the wrong hands?


@MIT
's 
@tegmark
: "If Hitler were more intelligent the world would have been worse"


@Meta
's 
@ylecun
: "how do you know you don't have Hitler in your class right now?"

Watch the full debate here:… Show more
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
I-JEPA is the first model based on a component of 
@ylecun
's vision to make AI systems learn and reason like animals and humans. It uses self-supervised computer vision that learns to understand the world by predicting it.

Details  https://bit.ly/3rkx6Rn
------
Grazie mille Università di Siena 
------
A #YannLeCun la laurea ad honorem dall'#Università di #Siena.
Il conferimento si è tenuto il 3/7 alla Certosa di Pontignano alla presenza del Rettore #RobertoDiPietra, dei Direttori dei Dipartimenti universitari e dei Delegati.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#LaureaUnisiLeCun
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
I assume others have pointed this out, but the misery index  — unemployment plus inflation — is all the way back to where it was when Biden took office 1/
------
The graph below shows how well the richest Top 1% have done across different countries over the past 200 years. 

Some interesting patterns explored in .
#dataviz
------
Thank you, University of Siena 
@unisiena
 !
------
Laurea ad Honorem @unisiena - Yann LeCun, VP Meta, Chief AI Scientist #Meta, NYU.
Lectio Magistralis:
The Present and Future of #ArtificialIntelligence
July 3 at 11.30, Certosa di Pontignano.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#yannlecun #LaureaUnisiLeCun
------
The geodesic distance extends a local metric into a global one. Geodesic curves define networks of curves that are similar to spanning trees on a graph. https://en.wikipedia.org/wiki/Geodesic https://en.wikipedia.org/wiki/Riemannian_manifold…
------
Thrilled to announce our study on robot visual navigation methods is now published in 
@SciRobotics
!

All credit to my amazing collaborators: 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
, 
@dchaplot
 (1/7)
------
Psychologists have identified a pervasive illusion that has existed for at least 70 years: The illusion of moral decline https://psypost.org/2023/06/psychologists-have-identified-a-pervasive-illusion-that-has-existed-for-at-least-70-years-166017…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
The official result of the Munk Debate "Be it resolved, AI research and development poses an existential threat" are out.

The NO side (
@MelMitchell1
 and me) wins by 4% over the YES side (
@tegmark
 and Yoshua Bengio).

The YES/NO split among the audience was 67/33 before the… Show more
------
Excited to announce that our paper on "Navigating to objects in the real world" is published at  Science Robotics!
https://science.org/doi/10.1126/scirobotics.adf6991…

PDF: https://science.org/doi/epdf/10.1126/scirobotics.adf6991…

w. 
@theo_gervet
 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
 


@MetaAI
 
@SCSatCMU


 for more details 
------
Robot visual navigation in unseen homes is hard: end-to-end RL works well in sim but gets only 23% real-world success.

Today, in the first real-world empirical study of visual navigation, we show Modular Learning achieves 90% success in unseen homes!
https://theophilegervet.github.io/projects/real-world-object-navigation/… 
1/N
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
La France s'impose déjà comme une grande nation de l'#intelligenceartificielle, grâce à 
@ylecun
 ! La rock star de 
@VivaTech
 propose un algorithme open source qui met l'éthique avant tout, sans sacrifier la performance. 
@LesEchos
------
What happens if super intelligent machines fall into the wrong hands?


@MIT
's 
@tegmark
: "If Hitler were more intelligent the world would have been worse"


@Meta
's 
@ylecun
: "how do you know you don't have Hitler in your class right now?"

Watch the full debate here:… Show more
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
I-JEPA is the first model based on a component of 
@ylecun
's vision to make AI systems learn and reason like animals and humans. It uses self-supervised computer vision that learns to understand the world by predicting it.

Details  https://bit.ly/3rkx6Rn
------
Grazie mille Università di Siena 
------
A #YannLeCun la laurea ad honorem dall'#Università di #Siena.
Il conferimento si è tenuto il 3/7 alla Certosa di Pontignano alla presenza del Rettore #RobertoDiPietra, dei Direttori dei Dipartimenti universitari e dei Delegati.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#LaureaUnisiLeCun
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
I assume others have pointed this out, but the misery index  — unemployment plus inflation — is all the way back to where it was when Biden took office 1/
------
The graph below shows how well the richest Top 1% have done across different countries over the past 200 years. 

Some interesting patterns explored in .
#dataviz
------
Thank you, University of Siena 
@unisiena
 !
------
Laurea ad Honorem @unisiena - Yann LeCun, VP Meta, Chief AI Scientist #Meta, NYU.
Lectio Magistralis:
The Present and Future of #ArtificialIntelligence
July 3 at 11.30, Certosa di Pontignano.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#yannlecun #LaureaUnisiLeCun
------
The geodesic distance extends a local metric into a global one. Geodesic curves define networks of curves that are similar to spanning trees on a graph. https://en.wikipedia.org/wiki/Geodesic https://en.wikipedia.org/wiki/Riemannian_manifold…
------
Thrilled to announce our study on robot visual navigation methods is now published in 
@SciRobotics
!

All credit to my amazing collaborators: 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
, 
@dchaplot
 (1/7)
------
Psychologists have identified a pervasive illusion that has existed for at least 70 years: The illusion of moral decline https://psypost.org/2023/06/psychologists-have-identified-a-pervasive-illusion-that-has-existed-for-at-least-70-years-166017…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
The official result of the Munk Debate "Be it resolved, AI research and development poses an existential threat" are out.

The NO side (
@MelMitchell1
 and me) wins by 4% over the YES side (
@tegmark
 and Yoshua Bengio).

The YES/NO split among the audience was 67/33 before the… Show more
------
Excited to announce that our paper on "Navigating to objects in the real world" is published at  Science Robotics!
https://science.org/doi/10.1126/scirobotics.adf6991…

PDF: https://science.org/doi/epdf/10.1126/scirobotics.adf6991…

w. 
@theo_gervet
 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
 


@MetaAI
 
@SCSatCMU


 for more details 
------
Robot visual navigation in unseen homes is hard: end-to-end RL works well in sim but gets only 23% real-world success.

Today, in the first real-world empirical study of visual navigation, we show Modular Learning achieves 90% success in unseen homes!
https://theophilegervet.github.io/projects/real-world-object-navigation/… 
1/N
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
Data center power consumption barely changes because it's largely determined by economics: Google and Meta can't spend more than a few bucks per user per year on power.
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Electricity use at data centers did NOT skyrocket.

In fact, despite massive growth in computation and data storage provided, total electricity use barely budged.

#EfficiencyFTW
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Nice MIT Tech Review piece by 
@Melissahei
 about our stance on AI existential risks, with quotes by 
@jpineau1
 and me.

…https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2023/06/20/1075075/metas-ai-leaders-want-you-to-know-fears-over-ai-existential-risk-are-ridiculous/amp/…
------
I used to have even longer hair, but even now,they are still not white.
Also, my ears are not pointy, and my archer skills are feeble.
------
@ylecun 
SDXL 0.9
Stuck legolas in the middle of your name, got this
------
La place de l'IA en France

 "Le meilleur modèle, plus ou moins Open Source aujourd'hui, s'appelle LLaMA et crée par 
@Meta
 et l'équipe de 
@ylecun
. Sur les auteurs du modèle, 11 sur 14 sont Français"

 
@Gorintic
 de 
@avec_alan
------
I-JEPA is the first model based on a component of 
@ylecun
's vision to make AI systems learn and reason like animals and humans. It uses self-supervised computer vision that learns to understand the world by predicting it.

Details  https://bit.ly/3rkx6Rn
------
Grazie mille Università di Siena 
------
A #YannLeCun la laurea ad honorem dall'#Università di #Siena.
Il conferimento si è tenuto il 3/7 alla Certosa di Pontignano alla presenza del Rettore #RobertoDiPietra, dei Direttori dei Dipartimenti universitari e dei Delegati.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#LaureaUnisiLeCun
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
I assume others have pointed this out, but the misery index  — unemployment plus inflation — is all the way back to where it was when Biden took office 1/
------
The graph below shows how well the richest Top 1% have done across different countries over the past 200 years. 

Some interesting patterns explored in .
#dataviz
------
Thank you, University of Siena 
@unisiena
 !
------
Laurea ad Honorem @unisiena - Yann LeCun, VP Meta, Chief AI Scientist #Meta, NYU.
Lectio Magistralis:
The Present and Future of #ArtificialIntelligence
July 3 at 11.30, Certosa di Pontignano.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#yannlecun #LaureaUnisiLeCun
------
The geodesic distance extends a local metric into a global one. Geodesic curves define networks of curves that are similar to spanning trees on a graph. https://en.wikipedia.org/wiki/Geodesic https://en.wikipedia.org/wiki/Riemannian_manifold…
------
Thrilled to announce our study on robot visual navigation methods is now published in 
@SciRobotics
!

All credit to my amazing collaborators: 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
, 
@dchaplot
 (1/7)
------
Psychologists have identified a pervasive illusion that has existed for at least 70 years: The illusion of moral decline https://psypost.org/2023/06/psychologists-have-identified-a-pervasive-illusion-that-has-existed-for-at-least-70-years-166017…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
The official result of the Munk Debate "Be it resolved, AI research and development poses an existential threat" are out.

The NO side (
@MelMitchell1
 and me) wins by 4% over the YES side (
@tegmark
 and Yoshua Bengio).

The YES/NO split among the audience was 67/33 before the… Show more
------
Excited to announce that our paper on "Navigating to objects in the real world" is published at  Science Robotics!
https://science.org/doi/10.1126/scirobotics.adf6991…

PDF: https://science.org/doi/epdf/10.1126/scirobotics.adf6991…

w. 
@theo_gervet
 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
 


@MetaAI
 
@SCSatCMU


 for more details 
------
Robot visual navigation in unseen homes is hard: end-to-end RL works well in sim but gets only 23% real-world success.

Today, in the first real-world empirical study of visual navigation, we show Modular Learning achieves 90% success in unseen homes!
https://theophilegervet.github.io/projects/real-world-object-navigation/… 
1/N
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
Data center power consumption barely changes because it's largely determined by economics: Google and Meta can't spend more than a few bucks per user per year on power.
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Electricity use at data centers did NOT skyrocket.

In fact, despite massive growth in computation and data storage provided, total electricity use barely budged.

#EfficiencyFTW
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Nice MIT Tech Review piece by 
@Melissahei
 about our stance on AI existential risks, with quotes by 
@jpineau1
 and me.

…https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2023/06/20/1075075/metas-ai-leaders-want-you-to-know-fears-over-ai-existential-risk-are-ridiculous/amp/…
------
I used to have even longer hair, but even now,they are still not white.
Also, my ears are not pointy, and my archer skills are feeble.
------
@ylecun 
SDXL 0.9
Stuck legolas in the middle of your name, got this
------
Wow the 
@NablaTech
 team knows how to give a proper demo!  Insane demonstration of their Copilot product for GPs: no set- up nor painful integrations, just a light-weight Chrome plug-in and the note-taking magic happens.
------
We're thrilled to announce the 3rd Open Catalyst Challenge 
@NeurIPSConf
 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
The Open Catalyst Challenge invites participants to help address the pressing challenges faced by the world due to energy scarcity and climate change.

More details on the 2023 challenge in the full thread from 
@OpenCatalyst
 
------
We're thrilled to announce the 3rd Open Catalyst Challenge @NeurIPSConf 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
"A Taxonomy of AI Panic Facilitators"
A visualization of leading AI Doomers (X-risk open letters, media interviews & OpEds).

Some AI experts enable them, while others oppose them.
The gender dynamics are fucked up.
It says a lot about the panic itself.

Your thoughts?
------
I assume others have pointed this out, but the misery index  — unemployment plus inflation — is all the way back to where it was when Biden took office 1/
------
The graph below shows how well the richest Top 1% have done across different countries over the past 200 years. 

Some interesting patterns explored in .
#dataviz
------
Thank you, University of Siena 
@unisiena
 !
------
Laurea ad Honorem @unisiena - Yann LeCun, VP Meta, Chief AI Scientist #Meta, NYU.
Lectio Magistralis:
The Present and Future of #ArtificialIntelligence
July 3 at 11.30, Certosa di Pontignano.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#yannlecun #LaureaUnisiLeCun
------
The geodesic distance extends a local metric into a global one. Geodesic curves define networks of curves that are similar to spanning trees on a graph. https://en.wikipedia.org/wiki/Geodesic https://en.wikipedia.org/wiki/Riemannian_manifold…
------
Thrilled to announce our study on robot visual navigation methods is now published in 
@SciRobotics
!

All credit to my amazing collaborators: 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
, 
@dchaplot
 (1/7)
------
Psychologists have identified a pervasive illusion that has existed for at least 70 years: The illusion of moral decline https://psypost.org/2023/06/psychologists-have-identified-a-pervasive-illusion-that-has-existed-for-at-least-70-years-166017…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
The official result of the Munk Debate "Be it resolved, AI research and development poses an existential threat" are out.

The NO side (
@MelMitchell1
 and me) wins by 4% over the YES side (
@tegmark
 and Yoshua Bengio).

The YES/NO split among the audience was 67/33 before the… Show more
------
Excited to announce that our paper on "Navigating to objects in the real world" is published at  Science Robotics!
https://science.org/doi/10.1126/scirobotics.adf6991…

PDF: https://science.org/doi/epdf/10.1126/scirobotics.adf6991…

w. 
@theo_gervet
 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
 


@MetaAI
 
@SCSatCMU


 for more details 
------
Robot visual navigation in unseen homes is hard: end-to-end RL works well in sim but gets only 23% real-world success.

Today, in the first real-world empirical study of visual navigation, we show Modular Learning achieves 90% success in unseen homes!
https://theophilegervet.github.io/projects/real-world-object-navigation/… 
1/N
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
Data center power consumption barely changes because it's largely determined by economics: Google and Meta can't spend more than a few bucks per user per year on power.
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Electricity use at data centers did NOT skyrocket.

In fact, despite massive growth in computation and data storage provided, total electricity use barely budged.

#EfficiencyFTW
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Nice MIT Tech Review piece by 
@Melissahei
 about our stance on AI existential risks, with quotes by 
@jpineau1
 and me.

…https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2023/06/20/1075075/metas-ai-leaders-want-you-to-know-fears-over-ai-existential-risk-are-ridiculous/amp/…
------
I used to have even longer hair, but even now,they are still not white.
Also, my ears are not pointy, and my archer skills are feeble.
------
@ylecun 
SDXL 0.9
Stuck legolas in the middle of your name, got this
------
Wow the 
@NablaTech
 team knows how to give a proper demo!  Insane demonstration of their Copilot product for GPs: no set- up nor painful integrations, just a light-weight Chrome plug-in and the note-taking magic happens.
------
We're thrilled to announce the 3rd Open Catalyst Challenge 
@NeurIPSConf
 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
The Open Catalyst Challenge invites participants to help address the pressing challenges faced by the world due to energy scarcity and climate change.

More details on the 2023 challenge in the full thread from 
@OpenCatalyst
 
------
We're thrilled to announce the 3rd Open Catalyst Challenge @NeurIPSConf 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
Nice piece. But it should have talked about 
@NablaTech
 one of the first players in that space (which the NYT wrote about a while back).
------
Generative artificial intelligence is coming to health care, but likely in measured steps. At first, more tireless scribe than genius partner. https://nytimes.com/2023/06/26/technology/an-ai-diagnosis-can-wait-just-eliminate-pajama-time.html?smid=tw-share…
------
Nice defense of AI open science and open source by 
@ClementDelangue
 in his congressional testimony.
------
This is my 5-minute testimony before the US Congress!

Open science and open source AI distribute economic gains by enabling hundreds of thousands of small companies and startups to build with AI. It fosters innovation, and fair competition between all.

Thanks to ethical… Show more
------
The Levenberg-Marquardt is a standard method for non-linear least-squares, combining the best of gradient descent and Newton methods by replacing the Hessian by the Jacobian term only. https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm…
------
Thank you, University of Siena 
@unisiena
 !
------
Laurea ad Honorem @unisiena - Yann LeCun, VP Meta, Chief AI Scientist #Meta, NYU.
Lectio Magistralis:
The Present and Future of #ArtificialIntelligence
July 3 at 11.30, Certosa di Pontignano.
 https://unisi.it/unisilife/eventi/laurea-ad-honorem-yann-lecun…
#yannlecun #LaureaUnisiLeCun
------
The geodesic distance extends a local metric into a global one. Geodesic curves define networks of curves that are similar to spanning trees on a graph. https://en.wikipedia.org/wiki/Geodesic https://en.wikipedia.org/wiki/Riemannian_manifold…
------
Thrilled to announce our study on robot visual navigation methods is now published in 
@SciRobotics
!

All credit to my amazing collaborators: 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
, 
@dchaplot
 (1/7)
------
Psychologists have identified a pervasive illusion that has existed for at least 70 years: The illusion of moral decline https://psypost.org/2023/06/psychologists-have-identified-a-pervasive-illusion-that-has-existed-for-at-least-70-years-166017…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
The official result of the Munk Debate "Be it resolved, AI research and development poses an existential threat" are out.

The NO side (
@MelMitchell1
 and me) wins by 4% over the YES side (
@tegmark
 and Yoshua Bengio).

The YES/NO split among the audience was 67/33 before the… Show more
------
Excited to announce that our paper on "Navigating to objects in the real world" is published at  Science Robotics!
https://science.org/doi/10.1126/scirobotics.adf6991…

PDF: https://science.org/doi/epdf/10.1126/scirobotics.adf6991…

w. 
@theo_gervet
 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
 


@MetaAI
 
@SCSatCMU


 for more details 
------
Robot visual navigation in unseen homes is hard: end-to-end RL works well in sim but gets only 23% real-world success.

Today, in the first real-world empirical study of visual navigation, we show Modular Learning achieves 90% success in unseen homes!
https://theophilegervet.github.io/projects/real-world-object-navigation/… 
1/N
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
Data center power consumption barely changes because it's largely determined by economics: Google and Meta can't spend more than a few bucks per user per year on power.
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Electricity use at data centers did NOT skyrocket.

In fact, despite massive growth in computation and data storage provided, total electricity use barely budged.

#EfficiencyFTW
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Nice MIT Tech Review piece by 
@Melissahei
 about our stance on AI existential risks, with quotes by 
@jpineau1
 and me.

…https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2023/06/20/1075075/metas-ai-leaders-want-you-to-know-fears-over-ai-existential-risk-are-ridiculous/amp/…
------
I used to have even longer hair, but even now,they are still not white.
Also, my ears are not pointy, and my archer skills are feeble.
------
@ylecun 
SDXL 0.9
Stuck legolas in the middle of your name, got this
------
Wow the 
@NablaTech
 team knows how to give a proper demo!  Insane demonstration of their Copilot product for GPs: no set- up nor painful integrations, just a light-weight Chrome plug-in and the note-taking magic happens.
------
We're thrilled to announce the 3rd Open Catalyst Challenge 
@NeurIPSConf
 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
The Open Catalyst Challenge invites participants to help address the pressing challenges faced by the world due to energy scarcity and climate change.

More details on the 2023 challenge in the full thread from 
@OpenCatalyst
 
------
We're thrilled to announce the 3rd Open Catalyst Challenge @NeurIPSConf 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
Nice piece. But it should have talked about 
@NablaTech
 one of the first players in that space (which the NYT wrote about a while back).
------
Generative artificial intelligence is coming to health care, but likely in measured steps. At first, more tireless scribe than genius partner. https://nytimes.com/2023/06/26/technology/an-ai-diagnosis-can-wait-just-eliminate-pajama-time.html?smid=tw-share…
------
Nice defense of AI open science and open source by 
@ClementDelangue
 in his congressional testimony.
------
This is my 5-minute testimony before the US Congress!

Open science and open source AI distribute economic gains by enabling hundreds of thousands of small companies and startups to build with AI. It fosters innovation, and fair competition between all.

Thanks to ethical… Show more
------
The Levenberg-Marquardt is a standard method for non-linear least-squares, combining the best of gradient descent and Newton methods by replacing the Hessian by the Jacobian term only. https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm…
------
Most people massively underestimate the costs of particulate pollution.

Thousands are dying as a result.
------
 New working paper alert! 

Negative Externalities of Temporary Reductions in Cognition: Evidence from Particulate Matter Pollution and Fatal Car Crashes

with @troachecon

TL;DR:  fine particulate matter pollution (PM2.5) = bad for brains &   fatal car crashes

1/17
------
Every branch of science has its corresponding pseudoscience. 

Astronomy has astrology. 
Geophysics has flat-earth beliefs. 
Chemistry had (has?) alchemy. 
Evolutionary biology has creationism. 

AI now has AGI existential risk. 

Maybe it’s a sign of maturing as a field.
------
Exactly.
We are missing a number of basic concepts to get human-level AI.
------
People want AGI so when they see meaningful progress in AI they think it might be THE ONE MISSING KEY. Many now try to massage LLMs into "AGI" but it won't work. LLMs are far from AGI () and only 1 piece of the solution. Focus on the unsolved pieces would mean faster progress!
------
New paper from the lab: “Dimensionality and ramping: Signatures of sentence integration in the dynamics of brains and deep language models” (Journal of Neuroscience, 2023)
https://jneurosci.org/content/early/2023/05/11/JNEUROSCI.1163-22.2023…
(1/n)
------
Good thread on AI policy from 
@jackclarkSF
 
I agree that limiting compute or requiring a license above a certain threshold of compute power would be bad policy.
I also agree that many of the AI safety policies that have been floating around are naïve.
------
Will write something longer, but if best ideas for AI policy involve depriving people of the 'means of production' of AI (e.g H100s), then you don't have a hugely viable policy. (I 100% am not criticizing @Simeon_Cps here; his tweet highlights how difficult the situation is). twitter.com/Simeon_Cps/sta…
------
A paperclip maximizer, a stochastic parrot, king Midas, a jpeg of the web,  markets, democracy, an alien, a shoggoth,...

So many metaphors offered for AI.  I discuss these and their limitations.
------
The official result of the Munk Debate "Be it resolved, AI research and development poses an existential threat" are out.

The NO side (
@MelMitchell1
 and me) wins by 4% over the YES side (
@tegmark
 and Yoshua Bengio).

The YES/NO split among the audience was 67/33 before the… Show more
------
Excited to announce that our paper on "Navigating to objects in the real world" is published at  Science Robotics!
https://science.org/doi/10.1126/scirobotics.adf6991…

PDF: https://science.org/doi/epdf/10.1126/scirobotics.adf6991…

w. 
@theo_gervet
 
@soumithchintala
, 
@DhruvBatraDB
, 
@JitendraMalikCV
 


@MetaAI
 
@SCSatCMU


 for more details 
------
Robot visual navigation in unseen homes is hard: end-to-end RL works well in sim but gets only 23% real-world success.

Today, in the first real-world empirical study of visual navigation, we show Modular Learning achieves 90% success in unseen homes!
https://theophilegervet.github.io/projects/real-world-object-navigation/… 
1/N
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
Data center power consumption barely changes because it's largely determined by economics: Google and Meta can't spend more than a few bucks per user per year on power.
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Electricity use at data centers did NOT skyrocket.

In fact, despite massive growth in computation and data storage provided, total electricity use barely budged.

#EfficiencyFTW
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Nice MIT Tech Review piece by 
@Melissahei
 about our stance on AI existential risks, with quotes by 
@jpineau1
 and me.

…https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2023/06/20/1075075/metas-ai-leaders-want-you-to-know-fears-over-ai-existential-risk-are-ridiculous/amp/…
------
I used to have even longer hair, but even now,they are still not white.
Also, my ears are not pointy, and my archer skills are feeble.
------
@ylecun 
SDXL 0.9
Stuck legolas in the middle of your name, got this
------
Wow the 
@NablaTech
 team knows how to give a proper demo!  Insane demonstration of their Copilot product for GPs: no set- up nor painful integrations, just a light-weight Chrome plug-in and the note-taking magic happens.
------
We're thrilled to announce the 3rd Open Catalyst Challenge 
@NeurIPSConf
 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
The Open Catalyst Challenge invites participants to help address the pressing challenges faced by the world due to energy scarcity and climate change.

More details on the 2023 challenge in the full thread from 
@OpenCatalyst
 
------
We're thrilled to announce the 3rd Open Catalyst Challenge @NeurIPSConf 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
Nice piece. But it should have talked about 
@NablaTech
 one of the first players in that space (which the NYT wrote about a while back).
------
Generative artificial intelligence is coming to health care, but likely in measured steps. At first, more tireless scribe than genius partner. https://nytimes.com/2023/06/26/technology/an-ai-diagnosis-can-wait-just-eliminate-pajama-time.html?smid=tw-share…
------
Nice defense of AI open science and open source by 
@ClementDelangue
 in his congressional testimony.
------
This is my 5-minute testimony before the US Congress!

Open science and open source AI distribute economic gains by enabling hundreds of thousands of small companies and startups to build with AI. It fosters innovation, and fair competition between all.

Thanks to ethical… Show more
------
The Levenberg-Marquardt is a standard method for non-linear least-squares, combining the best of gradient descent and Newton methods by replacing the Hessian by the Jacobian term only. https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm…
------
Most people massively underestimate the costs of particulate pollution.

Thousands are dying as a result.
------
 New working paper alert! 

Negative Externalities of Temporary Reductions in Cognition: Evidence from Particulate Matter Pollution and Fatal Car Crashes

with @troachecon

TL;DR:  fine particulate matter pollution (PM2.5) = bad for brains &   fatal car crashes

1/17
------
Every branch of science has its corresponding pseudoscience. 

Astronomy has astrology. 
Geophysics has flat-earth beliefs. 
Chemistry had (has?) alchemy. 
Evolutionary biology has creationism. 

AI now has AGI existential risk. 

Maybe it’s a sign of maturing as a field.
------
Exactly.
We are missing a number of basic concepts to get human-level AI.
------
People want AGI so when they see meaningful progress in AI they think it might be THE ONE MISSING KEY. Many now try to massage LLMs into "AGI" but it won't work. LLMs are far from AGI () and only 1 piece of the solution. Focus on the unsolved pieces would mean faster progress!
------
New paper from the lab: “Dimensionality and ramping: Signatures of sentence integration in the dynamics of brains and deep language models” (Journal of Neuroscience, 2023)
https://jneurosci.org/content/early/2023/05/11/JNEUROSCI.1163-22.2023…
(1/n)
------
Good thread on AI policy from 
@jackclarkSF
 
I agree that limiting compute or requiring a license above a certain threshold of compute power would be bad policy.
I also agree that many of the AI safety policies that have been floating around are naïve.
------
Will write something longer, but if best ideas for AI policy involve depriving people of the 'means of production' of AI (e.g H100s), then you don't have a hugely viable policy. (I 100% am not criticizing @Simeon_Cps here; his tweet highlights how difficult the situation is). twitter.com/Simeon_Cps/sta…
------
Si on parlait de l'impact énergétique du repassage comparé à la vidéo HD ? Ici un fer vapeur ; typiquement ce genre d'appareil en chauffe consomme de 2000 à 2500 W. Heureusement, comme un radiateur, il ne chauffe pas tout le temps (dépend du thermostat = la température voulue).
------
L'Intelligence Artificielle n'est pas un phénomène que l'on subit,  mais un artefact que l'on construit. On le construira pour être bénéfique.
------
Risques de dérives avec l’IA?

« On construit ces machines, donc on va les construire de telle manière à ce qu’elles soient soumises à l’humanité d’une part, et contraintes de ne pouvoir avoir que des comportements sécurisés », dit @ylecun au #TJ18h

#IA
------
Désormais disponible en format poche.
------
Pour écouter l'entretien de @ylecun sur #ICIRDI et dans le #Téléjournalde18h de @RadioCanadaInfo #Montréal avec @PatriceRoyTJ pour son livre 
pour parler de son livre "Quand la machine apprend" : https://bit.ly/3pjiaCB  
 
https://bit.ly/42Bx6cQ
------
The US is a clear outlier among developed countries when it comes to healthcare cost and outcomes.
------
This study is about the UK health system, but there’s one very clear outlier in most of the charts. https://kingsfund.org.uk/sites/default/files/2023-06/How_NHS_compare_2023.pdf…
------
Data center power consumption barely changes because it's largely determined by economics: Google and Meta can't spend more than a few bucks per user per year on power.
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Electricity use at data centers did NOT skyrocket.

In fact, despite massive growth in computation and data storage provided, total electricity use barely budged.

#EfficiencyFTW
------
The most important top line conclusion is that data center electricity use only went up 6% from 2010 to 2018, while compute instances, data transfers, and data storage, all increased massively. Efficiency improvements almost totally offset growth in service demand.
------
Nice MIT Tech Review piece by 
@Melissahei
 about our stance on AI existential risks, with quotes by 
@jpineau1
 and me.

…https://www-technologyreview-com.cdn.ampproject.org/c/s/www.technologyreview.com/2023/06/20/1075075/metas-ai-leaders-want-you-to-know-fears-over-ai-existential-risk-are-ridiculous/amp/…
------
I used to have even longer hair, but even now,they are still not white.
Also, my ears are not pointy, and my archer skills are feeble.
------
@ylecun 
SDXL 0.9
Stuck legolas in the middle of your name, got this
------
Wow the 
@NablaTech
 team knows how to give a proper demo!  Insane demonstration of their Copilot product for GPs: no set- up nor painful integrations, just a light-weight Chrome plug-in and the note-taking magic happens.
------
We're thrilled to announce the 3rd Open Catalyst Challenge 
@NeurIPSConf
 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
The Open Catalyst Challenge invites participants to help address the pressing challenges faced by the world due to energy scarcity and climate change.

More details on the 2023 challenge in the full thread from 
@OpenCatalyst
 
------
We're thrilled to announce the 3rd Open Catalyst Challenge @NeurIPSConf 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
Nice piece. But it should have talked about 
@NablaTech
 one of the first players in that space (which the NYT wrote about a while back).
------
Generative artificial intelligence is coming to health care, but likely in measured steps. At first, more tireless scribe than genius partner. https://nytimes.com/2023/06/26/technology/an-ai-diagnosis-can-wait-just-eliminate-pajama-time.html?smid=tw-share…
------
Nice defense of AI open science and open source by 
@ClementDelangue
 in his congressional testimony.
------
This is my 5-minute testimony before the US Congress!

Open science and open source AI distribute economic gains by enabling hundreds of thousands of small companies and startups to build with AI. It fosters innovation, and fair competition between all.

Thanks to ethical… Show more
------
The Levenberg-Marquardt is a standard method for non-linear least-squares, combining the best of gradient descent and Newton methods by replacing the Hessian by the Jacobian term only. https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm…
------
Most people massively underestimate the costs of particulate pollution.

Thousands are dying as a result.
------
 New working paper alert! 

Negative Externalities of Temporary Reductions in Cognition: Evidence from Particulate Matter Pollution and Fatal Car Crashes

with @troachecon

TL;DR:  fine particulate matter pollution (PM2.5) = bad for brains &   fatal car crashes

1/17
------
Every branch of science has its corresponding pseudoscience. 

Astronomy has astrology. 
Geophysics has flat-earth beliefs. 
Chemistry had (has?) alchemy. 
Evolutionary biology has creationism. 

AI now has AGI existential risk. 

Maybe it’s a sign of maturing as a field.
------
Exactly.
We are missing a number of basic concepts to get human-level AI.
------
People want AGI so when they see meaningful progress in AI they think it might be THE ONE MISSING KEY. Many now try to massage LLMs into "AGI" but it won't work. LLMs are far from AGI () and only 1 piece of the solution. Focus on the unsolved pieces would mean faster progress!
------
New paper from the lab: “Dimensionality and ramping: Signatures of sentence integration in the dynamics of brains and deep language models” (Journal of Neuroscience, 2023)
https://jneurosci.org/content/early/2023/05/11/JNEUROSCI.1163-22.2023…
(1/n)
------
Good thread on AI policy from 
@jackclarkSF
 
I agree that limiting compute or requiring a license above a certain threshold of compute power would be bad policy.
I also agree that many of the AI safety policies that have been floating around are naïve.
------
Will write something longer, but if best ideas for AI policy involve depriving people of the 'means of production' of AI (e.g H100s), then you don't have a hugely viable policy. (I 100% am not criticizing @Simeon_Cps here; his tweet highlights how difficult the situation is). twitter.com/Simeon_Cps/sta…
------
Si on parlait de l'impact énergétique du repassage comparé à la vidéo HD ? Ici un fer vapeur ; typiquement ce genre d'appareil en chauffe consomme de 2000 à 2500 W. Heureusement, comme un radiateur, il ne chauffe pas tout le temps (dépend du thermostat = la température voulue).
------
L'Intelligence Artificielle n'est pas un phénomène que l'on subit,  mais un artefact que l'on construit. On le construira pour être bénéfique.
------
Risques de dérives avec l’IA?

« On construit ces machines, donc on va les construire de telle manière à ce qu’elles soient soumises à l’humanité d’une part, et contraintes de ne pouvoir avoir que des comportements sécurisés », dit @ylecun au #TJ18h

#IA
------
Désormais disponible en format poche.
------
Pour écouter l'entretien de @ylecun sur #ICIRDI et dans le #Téléjournalde18h de @RadioCanadaInfo #Montréal avec @PatriceRoyTJ pour son livre 
pour parler de son livre "Quand la machine apprend" : https://bit.ly/3pjiaCB  
 
https://bit.ly/42Bx6cQ
------
Thanks for clarifying.
------
FINAL UPDATE: On June 24th, Armando Solar-Lezama (Professor in EECS and COO/Associate Director of CSAIL, MIT), Tonio Buonassisi (Professor of Mechanical Engineering, MIT), and Yoon Kim (Assistant Professor in EECS and CSAIL, MIT) released a public statement regarding the paper.  twitter.com/raunakdoesdev/…
------
Merci Yann LeCun (
@ylecun
) pour cette entrevue, https://ici.radio-canada.ca/nouvelle/1990358/yann-cun-intelligence-artificielle-entrevue… #ÉduQc
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Wow the 
@NablaTech
 team knows how to give a proper demo!  Insane demonstration of their Copilot product for GPs: no set- up nor painful integrations, just a light-weight Chrome plug-in and the note-taking magic happens.
------
We're thrilled to announce the 3rd Open Catalyst Challenge 
@NeurIPSConf
 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
The Open Catalyst Challenge invites participants to help address the pressing challenges faced by the world due to energy scarcity and climate change.

More details on the 2023 challenge in the full thread from 
@OpenCatalyst
 
------
We're thrilled to announce the 3rd Open Catalyst Challenge @NeurIPSConf 2023! 

This year's focus: computing adsorption energy — which builds on our past challenges and moves closer to practical applications. Visit our website to learn more! https://opencatalystproject.org/challenge.html

1/8
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
Nice piece. But it should have talked about 
@NablaTech
 one of the first players in that space (which the NYT wrote about a while back).
------
Generative artificial intelligence is coming to health care, but likely in measured steps. At first, more tireless scribe than genius partner. https://nytimes.com/2023/06/26/technology/an-ai-diagnosis-can-wait-just-eliminate-pajama-time.html?smid=tw-share…
------
Nice defense of AI open science and open source by 
@ClementDelangue
 in his congressional testimony.
------
This is my 5-minute testimony before the US Congress!

Open science and open source AI distribute economic gains by enabling hundreds of thousands of small companies and startups to build with AI. It fosters innovation, and fair competition between all.

Thanks to ethical… Show more
------
The Levenberg-Marquardt is a standard method for non-linear least-squares, combining the best of gradient descent and Newton methods by replacing the Hessian by the Jacobian term only. https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm…
------
Most people massively underestimate the costs of particulate pollution.

Thousands are dying as a result.
------
 New working paper alert! 

Negative Externalities of Temporary Reductions in Cognition: Evidence from Particulate Matter Pollution and Fatal Car Crashes

with @troachecon

TL;DR:  fine particulate matter pollution (PM2.5) = bad for brains &   fatal car crashes

1/17
------
Every branch of science has its corresponding pseudoscience. 

Astronomy has astrology. 
Geophysics has flat-earth beliefs. 
Chemistry had (has?) alchemy. 
Evolutionary biology has creationism. 

AI now has AGI existential risk. 

Maybe it’s a sign of maturing as a field.
------
Exactly.
We are missing a number of basic concepts to get human-level AI.
------
People want AGI so when they see meaningful progress in AI they think it might be THE ONE MISSING KEY. Many now try to massage LLMs into "AGI" but it won't work. LLMs are far from AGI () and only 1 piece of the solution. Focus on the unsolved pieces would mean faster progress!
------
New paper from the lab: “Dimensionality and ramping: Signatures of sentence integration in the dynamics of brains and deep language models” (Journal of Neuroscience, 2023)
https://jneurosci.org/content/early/2023/05/11/JNEUROSCI.1163-22.2023…
(1/n)
------
Good thread on AI policy from 
@jackclarkSF
 
I agree that limiting compute or requiring a license above a certain threshold of compute power would be bad policy.
I also agree that many of the AI safety policies that have been floating around are naïve.
------
Will write something longer, but if best ideas for AI policy involve depriving people of the 'means of production' of AI (e.g H100s), then you don't have a hugely viable policy. (I 100% am not criticizing @Simeon_Cps here; his tweet highlights how difficult the situation is). twitter.com/Simeon_Cps/sta…
------
Si on parlait de l'impact énergétique du repassage comparé à la vidéo HD ? Ici un fer vapeur ; typiquement ce genre d'appareil en chauffe consomme de 2000 à 2500 W. Heureusement, comme un radiateur, il ne chauffe pas tout le temps (dépend du thermostat = la température voulue).
------
L'Intelligence Artificielle n'est pas un phénomène que l'on subit,  mais un artefact que l'on construit. On le construira pour être bénéfique.
------
Risques de dérives avec l’IA?

« On construit ces machines, donc on va les construire de telle manière à ce qu’elles soient soumises à l’humanité d’une part, et contraintes de ne pouvoir avoir que des comportements sécurisés », dit @ylecun au #TJ18h

#IA
------
Désormais disponible en format poche.
------
Pour écouter l'entretien de @ylecun sur #ICIRDI et dans le #Téléjournalde18h de @RadioCanadaInfo #Montréal avec @PatriceRoyTJ pour son livre 
pour parler de son livre "Quand la machine apprend" : https://bit.ly/3pjiaCB  
 
https://bit.ly/42Bx6cQ
------
Thanks for clarifying.
------
FINAL UPDATE: On June 24th, Armando Solar-Lezama (Professor in EECS and COO/Associate Director of CSAIL, MIT), Tonio Buonassisi (Professor of Mechanical Engineering, MIT), and Yoon Kim (Assistant Professor in EECS and CSAIL, MIT) released a public statement regarding the paper.  twitter.com/raunakdoesdev/…
------
Merci Yann LeCun (
@ylecun
) pour cette entrevue, https://ici.radio-canada.ca/nouvelle/1990358/yann-cun-intelligence-artificielle-entrevue… #ÉduQc
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Full video of the Munk Debate that took place on 2023-06-22: 
"Be it resolved, AI research and development poses an existential threat."
On the YES side: Yoshua Bengio & 
@tegmark

On the NO side: 
@MelMitchell1
 & me.
------
How long does 
@ylecun
 think it will take to pivot the #ML field from where it is to where he'd like it to be? In celebration of #AlanTuringDay, watch the #AMTuringAward winner & Chief #AI Scientist at 
@MetaAI
 discuss with our Exec. Director, 
@usamaf
------
Entrevue complète de 22 minutes avec 
@PatriceRoyTJ
 sur Radio Canada
------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
You can now watch our Munk Debate on AI for free (below)

Be it Resolved, AI research and development poses an existential threat 

PRO: 
@tegmark
 and Yoshua Bengio
CON: 
@ylecun
 and 
@MelMitchell1
 

To support civil and substantive debates visit our website: http://munkdebates.com
------
Nice piece. But it should have talked about 
@NablaTech
 one of the first players in that space (which the NYT wrote about a while back).
------
Generative artificial intelligence is coming to health care, but likely in measured steps. At first, more tireless scribe than genius partner. https://nytimes.com/2023/06/26/technology/an-ai-diagnosis-can-wait-just-eliminate-pajama-time.html?smid=tw-share…
------
Nice defense of AI open science and open source by 
@ClementDelangue
 in his congressional testimony.
------
This is my 5-minute testimony before the US Congress!

Open science and open source AI distribute economic gains by enabling hundreds of thousands of small companies and startups to build with AI. It fosters innovation, and fair competition between all.

Thanks to ethical… Show more
------
The Levenberg-Marquardt is a standard method for non-linear least-squares, combining the best of gradient descent and Newton methods by replacing the Hessian by the Jacobian term only. https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm…
------
Most people massively underestimate the costs of particulate pollution.

Thousands are dying as a result.
------
 New working paper alert! 

Negative Externalities of Temporary Reductions in Cognition: Evidence from Particulate Matter Pollution and Fatal Car Crashes

with @troachecon

TL;DR:  fine particulate matter pollution (PM2.5) = bad for brains &   fatal car crashes

1/17
------
Every branch of science has its corresponding pseudoscience. 

Astronomy has astrology. 
Geophysics has flat-earth beliefs. 
Chemistry had (has?) alchemy. 
Evolutionary biology has creationism. 

AI now has AGI existential risk. 

Maybe it’s a sign of maturing as a field.
------
Exactly.
We are missing a number of basic concepts to get human-level AI.
------
People want AGI so when they see meaningful progress in AI they think it might be THE ONE MISSING KEY. Many now try to massage LLMs into "AGI" but it won't work. LLMs are far from AGI () and only 1 piece of the solution. Focus on the unsolved pieces would mean faster progress!
------
New paper from the lab: “Dimensionality and ramping: Signatures of sentence integration in the dynamics of brains and deep language models” (Journal of Neuroscience, 2023)
https://jneurosci.org/content/early/2023/05/11/JNEUROSCI.1163-22.2023…
(1/n)
------
Good thread on AI policy from 
@jackclarkSF
 
I agree that limiting compute or requiring a license above a certain threshold of compute power would be bad policy.
I also agree that many of the AI safety policies that have been floating around are naïve.
------
Will write something longer, but if best ideas for AI policy involve depriving people of the 'means of production' of AI (e.g H100s), then you don't have a hugely viable policy. (I 100% am not criticizing @Simeon_Cps here; his tweet highlights how difficult the situation is). twitter.com/Simeon_Cps/sta…
------
Si on parlait de l'impact énergétique du repassage comparé à la vidéo HD ? Ici un fer vapeur ; typiquement ce genre d'appareil en chauffe consomme de 2000 à 2500 W. Heureusement, comme un radiateur, il ne chauffe pas tout le temps (dépend du thermostat = la température voulue).
------
L'Intelligence Artificielle n'est pas un phénomène que l'on subit,  mais un artefact que l'on construit. On le construira pour être bénéfique.
------
Risques de dérives avec l’IA?

« On construit ces machines, donc on va les construire de telle manière à ce qu’elles soient soumises à l’humanité d’une part, et contraintes de ne pouvoir avoir que des comportements sécurisés », dit @ylecun au #TJ18h

#IA
------
Désormais disponible en format poche.
------
Pour écouter l'entretien de @ylecun sur #ICIRDI et dans le #Téléjournalde18h de @RadioCanadaInfo #Montréal avec @PatriceRoyTJ pour son livre 
pour parler de son livre "Quand la machine apprend" : https://bit.ly/3pjiaCB  
 
https://bit.ly/42Bx6cQ
------
Thanks for clarifying.
------
FINAL UPDATE: On June 24th, Armando Solar-Lezama (Professor in EECS and COO/Associate Director of CSAIL, MIT), Tonio Buonassisi (Professor of Mechanical Engineering, MIT), and Yoon Kim (Assistant Professor in EECS and CSAIL, MIT) released a public statement regarding the paper.  twitter.com/raunakdoesdev/…
------
Merci Yann LeCun (
@ylecun
) pour cette entrevue, https://ici.radio-canada.ca/nouvelle/1990358/yann-cun-intelligence-artificielle-entrevue… #ÉduQc
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Full video of the Munk Debate that took place on 2023-06-22: 
"Be it resolved, AI research and development poses an existential threat."
On the YES side: Yoshua Bengio & 
@tegmark

On the NO side: 
@MelMitchell1
 & me.
------
How long does 
@ylecun
 think it will take to pivot the #ML field from where it is to where he'd like it to be? In celebration of #AlanTuringDay, watch the #AMTuringAward winner & Chief #AI Scientist at 
@MetaAI
 discuss with our Exec. Director, 
@usamaf
------
Entrevue complète de 22 minutes avec 
@PatriceRoyTJ
 sur Radio Canada
------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
Bye-bye Toronto
------
Top AI professionals have recently called for a pause in training AI models more powerful than GPT-4.

This has sparked a debate as some experts argue for the benefits of AI models while others express concerns.


@ylecun
, one of the fathers of AI and Chief AI Scientist at 
@Meta
… Show more
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
Most people massively underestimate the costs of particulate pollution.

Thousands are dying as a result.
------
 New working paper alert! 

Negative Externalities of Temporary Reductions in Cognition: Evidence from Particulate Matter Pollution and Fatal Car Crashes

with @troachecon

TL;DR:  fine particulate matter pollution (PM2.5) = bad for brains &   fatal car crashes

1/17
------
Every branch of science has its corresponding pseudoscience. 

Astronomy has astrology. 
Geophysics has flat-earth beliefs. 
Chemistry had (has?) alchemy. 
Evolutionary biology has creationism. 

AI now has AGI existential risk. 

Maybe it’s a sign of maturing as a field.
------
Exactly.
We are missing a number of basic concepts to get human-level AI.
------
People want AGI so when they see meaningful progress in AI they think it might be THE ONE MISSING KEY. Many now try to massage LLMs into "AGI" but it won't work. LLMs are far from AGI () and only 1 piece of the solution. Focus on the unsolved pieces would mean faster progress!
------
New paper from the lab: “Dimensionality and ramping: Signatures of sentence integration in the dynamics of brains and deep language models” (Journal of Neuroscience, 2023)
https://jneurosci.org/content/early/2023/05/11/JNEUROSCI.1163-22.2023…
(1/n)
------
Good thread on AI policy from 
@jackclarkSF
 
I agree that limiting compute or requiring a license above a certain threshold of compute power would be bad policy.
I also agree that many of the AI safety policies that have been floating around are naïve.
------
Will write something longer, but if best ideas for AI policy involve depriving people of the 'means of production' of AI (e.g H100s), then you don't have a hugely viable policy. (I 100% am not criticizing @Simeon_Cps here; his tweet highlights how difficult the situation is). twitter.com/Simeon_Cps/sta…
------
Si on parlait de l'impact énergétique du repassage comparé à la vidéo HD ? Ici un fer vapeur ; typiquement ce genre d'appareil en chauffe consomme de 2000 à 2500 W. Heureusement, comme un radiateur, il ne chauffe pas tout le temps (dépend du thermostat = la température voulue).
------
L'Intelligence Artificielle n'est pas un phénomène que l'on subit,  mais un artefact que l'on construit. On le construira pour être bénéfique.
------
Risques de dérives avec l’IA?

« On construit ces machines, donc on va les construire de telle manière à ce qu’elles soient soumises à l’humanité d’une part, et contraintes de ne pouvoir avoir que des comportements sécurisés », dit @ylecun au #TJ18h

#IA
------
Désormais disponible en format poche.
------
Pour écouter l'entretien de @ylecun sur #ICIRDI et dans le #Téléjournalde18h de @RadioCanadaInfo #Montréal avec @PatriceRoyTJ pour son livre 
pour parler de son livre "Quand la machine apprend" : https://bit.ly/3pjiaCB  
 
https://bit.ly/42Bx6cQ
------
Thanks for clarifying.
------
FINAL UPDATE: On June 24th, Armando Solar-Lezama (Professor in EECS and COO/Associate Director of CSAIL, MIT), Tonio Buonassisi (Professor of Mechanical Engineering, MIT), and Yoon Kim (Assistant Professor in EECS and CSAIL, MIT) released a public statement regarding the paper.  twitter.com/raunakdoesdev/…
------
Merci Yann LeCun (
@ylecun
) pour cette entrevue, https://ici.radio-canada.ca/nouvelle/1990358/yann-cun-intelligence-artificielle-entrevue… #ÉduQc
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Full video of the Munk Debate that took place on 2023-06-22: 
"Be it resolved, AI research and development poses an existential threat."
On the YES side: Yoshua Bengio & 
@tegmark

On the NO side: 
@MelMitchell1
 & me.
------
How long does 
@ylecun
 think it will take to pivot the #ML field from where it is to where he'd like it to be? In celebration of #AlanTuringDay, watch the #AMTuringAward winner & Chief #AI Scientist at 
@MetaAI
 discuss with our Exec. Director, 
@usamaf
------
Entrevue complète de 22 minutes avec 
@PatriceRoyTJ
 sur Radio Canada
------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
Bye-bye Toronto
------
Top AI professionals have recently called for a pause in training AI models more powerful than GPT-4.

This has sparked a debate as some experts argue for the benefits of AI models while others express concerns.


@ylecun
, one of the fathers of AI and Chief AI Scientist at 
@Meta
… Show more
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
That's what economists have kept telling us.
------
ChatGPT is stoking fears of mass layoffs, but a study of several EU countries found the deep-learning boom of the 2010s actually created job opportunities. https://trib.al/v78ZZwW
------
Si on parlait de l'impact énergétique du repassage comparé à la vidéo HD ? Ici un fer vapeur ; typiquement ce genre d'appareil en chauffe consomme de 2000 à 2500 W. Heureusement, comme un radiateur, il ne chauffe pas tout le temps (dépend du thermostat = la température voulue).
------
L'Intelligence Artificielle n'est pas un phénomène que l'on subit,  mais un artefact que l'on construit. On le construira pour être bénéfique.
------
Risques de dérives avec l’IA?

« On construit ces machines, donc on va les construire de telle manière à ce qu’elles soient soumises à l’humanité d’une part, et contraintes de ne pouvoir avoir que des comportements sécurisés », dit @ylecun au #TJ18h

#IA
------
Désormais disponible en format poche.
------
Pour écouter l'entretien de @ylecun sur #ICIRDI et dans le #Téléjournalde18h de @RadioCanadaInfo #Montréal avec @PatriceRoyTJ pour son livre 
pour parler de son livre "Quand la machine apprend" : https://bit.ly/3pjiaCB  
 
https://bit.ly/42Bx6cQ
------
Thanks for clarifying.
------
FINAL UPDATE: On June 24th, Armando Solar-Lezama (Professor in EECS and COO/Associate Director of CSAIL, MIT), Tonio Buonassisi (Professor of Mechanical Engineering, MIT), and Yoon Kim (Assistant Professor in EECS and CSAIL, MIT) released a public statement regarding the paper.  twitter.com/raunakdoesdev/…
------
Merci Yann LeCun (
@ylecun
) pour cette entrevue, https://ici.radio-canada.ca/nouvelle/1990358/yann-cun-intelligence-artificielle-entrevue… #ÉduQc
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Full video of the Munk Debate that took place on 2023-06-22: 
"Be it resolved, AI research and development poses an existential threat."
On the YES side: Yoshua Bengio & 
@tegmark

On the NO side: 
@MelMitchell1
 & me.
------
How long does 
@ylecun
 think it will take to pivot the #ML field from where it is to where he'd like it to be? In celebration of #AlanTuringDay, watch the #AMTuringAward winner & Chief #AI Scientist at 
@MetaAI
 discuss with our Exec. Director, 
@usamaf
------
Entrevue complète de 22 minutes avec 
@PatriceRoyTJ
 sur Radio Canada
------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
Bye-bye Toronto
------
Top AI professionals have recently called for a pause in training AI models more powerful than GPT-4.

This has sparked a debate as some experts argue for the benefits of AI models while others express concerns.


@ylecun
, one of the fathers of AI and Chief AI Scientist at 
@Meta
… Show more
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
That's what economists have kept telling us.
------
ChatGPT is stoking fears of mass layoffs, but a study of several EU countries found the deep-learning boom of the 2010s actually created job opportunities. https://trib.al/v78ZZwW
------
Est-ce que l’intelligence artificielle va dépasser les capacités du cerveau humain?

« Ça ne fait aucun doute. C’est une question de temps », dit 
@ylecun
 au #TJ18h

#IA
------
From the 
@munkdebate
 on AI

https://munkdebates.com/debates/artificial-intelligence…
------
Tonight from the Munk Debate on AI


@MelMitchell1
 and I are debating Max 
@tegmark
 and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
My debate partner 
@MelMitchell1
 arguing that AI does NOT represent an existential threat at the 
@munkdebate
 on AI

Watch live here:
https://munkdebates.com/debates/artificial-intelligence…
------
My opponent Yoshua Bengio's opening statement at the 
@munkdebate
 on AI

Livestream here:
https://munkdebates.com/debates/artificial-intelligence…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Thanks for clarifying.
------
FINAL UPDATE: On June 24th, Armando Solar-Lezama (Professor in EECS and COO/Associate Director of CSAIL, MIT), Tonio Buonassisi (Professor of Mechanical Engineering, MIT), and Yoon Kim (Assistant Professor in EECS and CSAIL, MIT) released a public statement regarding the paper.  twitter.com/raunakdoesdev/…
------
Merci Yann LeCun (
@ylecun
) pour cette entrevue, https://ici.radio-canada.ca/nouvelle/1990358/yann-cun-intelligence-artificielle-entrevue… #ÉduQc
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Full video of the Munk Debate that took place on 2023-06-22: 
"Be it resolved, AI research and development poses an existential threat."
On the YES side: Yoshua Bengio & 
@tegmark

On the NO side: 
@MelMitchell1
 & me.
------
How long does 
@ylecun
 think it will take to pivot the #ML field from where it is to where he'd like it to be? In celebration of #AlanTuringDay, watch the #AMTuringAward winner & Chief #AI Scientist at 
@MetaAI
 discuss with our Exec. Director, 
@usamaf
------
Entrevue complète de 22 minutes avec 
@PatriceRoyTJ
 sur Radio Canada
------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
Bye-bye Toronto
------
Top AI professionals have recently called for a pause in training AI models more powerful than GPT-4.

This has sparked a debate as some experts argue for the benefits of AI models while others express concerns.


@ylecun
, one of the fathers of AI and Chief AI Scientist at 
@Meta
… Show more
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
That's what economists have kept telling us.
------
ChatGPT is stoking fears of mass layoffs, but a study of several EU countries found the deep-learning boom of the 2010s actually created job opportunities. https://trib.al/v78ZZwW
------
Est-ce que l’intelligence artificielle va dépasser les capacités du cerveau humain?

« Ça ne fait aucun doute. C’est une question de temps », dit 
@ylecun
 au #TJ18h

#IA
------
From the 
@munkdebate
 on AI

https://munkdebates.com/debates/artificial-intelligence…
------
Tonight from the Munk Debate on AI


@MelMitchell1
 and I are debating Max 
@tegmark
 and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
My debate partner 
@MelMitchell1
 arguing that AI does NOT represent an existential threat at the 
@munkdebate
 on AI

Watch live here:
https://munkdebates.com/debates/artificial-intelligence…
------
My opponent Yoshua Bengio's opening statement at the 
@munkdebate
 on AI

Livestream here:
https://munkdebates.com/debates/artificial-intelligence…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Pas de moratoire et pas de discours alarmiste sur l'intelligence artificielle : demain, on vous présente une rare entrevue avec 
@ylecun
, directeur scientifique des activités en intelligence artificielle de Facebook. 

#IA
------
Une entrevue au journal télévisé de Radio-Canada dans quelques instants.
------
Dans quelques instants, ne manquez pas la grande entrevue avec @ylecun au #TJ18h

L’intelligence artificielle n’est pas une menace pour l'humanité mais une chance de renaissance : l'un des pères de l’IA refuse les scénarios catastrophes brandis par ses collègues.
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
« Aucun des économistes à qui je parle ne croît à ce scénario. Tous disent qu’à chaque fois qu’il y a une transformation technologique, il n’y a pas de chômage à long terme », assure 
@ylecun
 à propos de la potentielle perte d’emploi causée par l’#IA #Europe1
------
Full video of the Munk Debate that took place on 2023-06-22: 
"Be it resolved, AI research and development poses an existential threat."
On the YES side: Yoshua Bengio & 
@tegmark

On the NO side: 
@MelMitchell1
 & me.
------
How long does 
@ylecun
 think it will take to pivot the #ML field from where it is to where he'd like it to be? In celebration of #AlanTuringDay, watch the #AMTuringAward winner & Chief #AI Scientist at 
@MetaAI
 discuss with our Exec. Director, 
@usamaf
------
Entrevue complète de 22 minutes avec 
@PatriceRoyTJ
 sur Radio Canada
------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
Bye-bye Toronto
------
Top AI professionals have recently called for a pause in training AI models more powerful than GPT-4.

This has sparked a debate as some experts argue for the benefits of AI models while others express concerns.


@ylecun
, one of the fathers of AI and Chief AI Scientist at 
@Meta
… Show more
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
That's what economists have kept telling us.
------
ChatGPT is stoking fears of mass layoffs, but a study of several EU countries found the deep-learning boom of the 2010s actually created job opportunities. https://trib.al/v78ZZwW
------
Est-ce que l’intelligence artificielle va dépasser les capacités du cerveau humain?

« Ça ne fait aucun doute. C’est une question de temps », dit 
@ylecun
 au #TJ18h

#IA
------
From the 
@munkdebate
 on AI

https://munkdebates.com/debates/artificial-intelligence…
------
Tonight from the Munk Debate on AI


@MelMitchell1
 and I are debating Max 
@tegmark
 and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
My debate partner 
@MelMitchell1
 arguing that AI does NOT represent an existential threat at the 
@munkdebate
 on AI

Watch live here:
https://munkdebates.com/debates/artificial-intelligence…
------
My opponent Yoshua Bengio's opening statement at the 
@munkdebate
 on AI

Livestream here:
https://munkdebates.com/debates/artificial-intelligence…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Pas de moratoire et pas de discours alarmiste sur l'intelligence artificielle : demain, on vous présente une rare entrevue avec 
@ylecun
, directeur scientifique des activités en intelligence artificielle de Facebook. 

#IA
------
Une entrevue au journal télévisé de Radio-Canada dans quelques instants.
------
Dans quelques instants, ne manquez pas la grande entrevue avec @ylecun au #TJ18h

L’intelligence artificielle n’est pas une menace pour l'humanité mais une chance de renaissance : l'un des pères de l’IA refuse les scénarios catastrophes brandis par ses collègues.
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
The AI Apocalypse Scorecard, with quotes from tonight's debaters:

@MelMitchell1
, 
@tegmark
, Yoshua Bengio, and me, among several others.
------
"AI is intrinsically good, because the effect of AI is to make people smarter"
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Domestic robot at #CVPR2023
------
Come join us for an instruction-following robot assistant demo at #CVPR2023 Meta Booth by the FAIR Embodied AI team.

Give Spot a free-form natural language instruction for object fetching.

Details: …https://languageguidedskillcoordination.github.io

------
The first 90 seconds of my 6 minute opening statement at the Munk debate yesterday evening.
------
HAPPENING NOW:

@ylecun's opening statement at the Munk Debate on AI.

You can watch the it live (exclusively for Munk donors) here:
https://munkdebates.com/debates/artificial-intelligence…
------
Bye-bye Toronto
------
Top AI professionals have recently called for a pause in training AI models more powerful than GPT-4.

This has sparked a debate as some experts argue for the benefits of AI models while others express concerns.


@ylecun
, one of the fathers of AI and Chief AI Scientist at 
@Meta
… Show more
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
That's what economists have kept telling us.
------
ChatGPT is stoking fears of mass layoffs, but a study of several EU countries found the deep-learning boom of the 2010s actually created job opportunities. https://trib.al/v78ZZwW
------
Est-ce que l’intelligence artificielle va dépasser les capacités du cerveau humain?

« Ça ne fait aucun doute. C’est une question de temps », dit 
@ylecun
 au #TJ18h

#IA
------
From the 
@munkdebate
 on AI

https://munkdebates.com/debates/artificial-intelligence…
------
Tonight from the Munk Debate on AI


@MelMitchell1
 and I are debating Max 
@tegmark
 and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
My debate partner 
@MelMitchell1
 arguing that AI does NOT represent an existential threat at the 
@munkdebate
 on AI

Watch live here:
https://munkdebates.com/debates/artificial-intelligence…
------
My opponent Yoshua Bengio's opening statement at the 
@munkdebate
 on AI

Livestream here:
https://munkdebates.com/debates/artificial-intelligence…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Pas de moratoire et pas de discours alarmiste sur l'intelligence artificielle : demain, on vous présente une rare entrevue avec 
@ylecun
, directeur scientifique des activités en intelligence artificielle de Facebook. 

#IA
------
Une entrevue au journal télévisé de Radio-Canada dans quelques instants.
------
Dans quelques instants, ne manquez pas la grande entrevue avec @ylecun au #TJ18h

L’intelligence artificielle n’est pas une menace pour l'humanité mais une chance de renaissance : l'un des pères de l’IA refuse les scénarios catastrophes brandis par ses collègues.
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
The AI Apocalypse Scorecard, with quotes from tonight's debaters:

@MelMitchell1
, 
@tegmark
, Yoshua Bengio, and me, among several others.
------
"AI is intrinsically good, because the effect of AI is to make people smarter"
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Domestic robot at #CVPR2023
------
Come join us for an instruction-following robot assistant demo at #CVPR2023 Meta Booth by the FAIR Embodied AI team.

Give Spot a free-form natural language instruction for object fetching.

Details: …https://languageguidedskillcoordination.github.io

------
Try out HomeRobot, download the simulation, and implement your best solution. More details on the challenge in the 
------
The future of robot butlers starts with mobile manipulation.
We’re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!
- Full robot stack 
- Parallel sim and real evaluation 
- No robot required 

https://aihabitat.org/challenge/2023_homerobot_ovmm/…
------
Tonight 7:00pm EST
------
Tonight at 7PM ET

It might be our most important debate ever.

Be it Resolved, AI research and development poses and existential threat.

PRO: @tegmark and Yoshua Bengio
CON: @ylecun and @MelMitchell1 

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Maybe RFK Jr. is a sign that America is drowning in misinformation. Or maybe it was always this bad. Either way, it's going to be very hard to clean up our information ecosystem.
------
A disturbingly large number of Americans believe in conspiracy theories.
But contrary to a common belief, the proportion has not increased over time .
In fact, it has decreased in many instances.
[h/t 
@Noahpinion
]
------
In this segment, 
@tegmark
 argues that more intelligence is not always beneficial, saying that the world would have been worse off if Hitler had been smarter.

Max is a professor at MIT. His job, like mine, is to increase the intelligence of students and other humans.

He doesn't… Show more
------
Tonight from the Munk Debate on AI

@MelMitchell1 and I are debating Max @tegmark and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
That's what economists have kept telling us.
------
ChatGPT is stoking fears of mass layoffs, but a study of several EU countries found the deep-learning boom of the 2010s actually created job opportunities. https://trib.al/v78ZZwW
------
Est-ce que l’intelligence artificielle va dépasser les capacités du cerveau humain?

« Ça ne fait aucun doute. C’est une question de temps », dit 
@ylecun
 au #TJ18h

#IA
------
From the 
@munkdebate
 on AI

https://munkdebates.com/debates/artificial-intelligence…
------
Tonight from the Munk Debate on AI


@MelMitchell1
 and I are debating Max 
@tegmark
 and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
My debate partner 
@MelMitchell1
 arguing that AI does NOT represent an existential threat at the 
@munkdebate
 on AI

Watch live here:
https://munkdebates.com/debates/artificial-intelligence…
------
My opponent Yoshua Bengio's opening statement at the 
@munkdebate
 on AI

Livestream here:
https://munkdebates.com/debates/artificial-intelligence…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Pas de moratoire et pas de discours alarmiste sur l'intelligence artificielle : demain, on vous présente une rare entrevue avec 
@ylecun
, directeur scientifique des activités en intelligence artificielle de Facebook. 

#IA
------
Une entrevue au journal télévisé de Radio-Canada dans quelques instants.
------
Dans quelques instants, ne manquez pas la grande entrevue avec @ylecun au #TJ18h

L’intelligence artificielle n’est pas une menace pour l'humanité mais une chance de renaissance : l'un des pères de l’IA refuse les scénarios catastrophes brandis par ses collègues.
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
The AI Apocalypse Scorecard, with quotes from tonight's debaters:

@MelMitchell1
, 
@tegmark
, Yoshua Bengio, and me, among several others.
------
"AI is intrinsically good, because the effect of AI is to make people smarter"
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Domestic robot at #CVPR2023
------
Come join us for an instruction-following robot assistant demo at #CVPR2023 Meta Booth by the FAIR Embodied AI team.

Give Spot a free-form natural language instruction for object fetching.

Details: …https://languageguidedskillcoordination.github.io

------
Try out HomeRobot, download the simulation, and implement your best solution. More details on the challenge in the 
------
The future of robot butlers starts with mobile manipulation.
We’re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!
- Full robot stack 
- Parallel sim and real evaluation 
- No robot required 

https://aihabitat.org/challenge/2023_homerobot_ovmm/…
------
Tonight 7:00pm EST
------
Tonight at 7PM ET

It might be our most important debate ever.

Be it Resolved, AI research and development poses and existential threat.

PRO: @tegmark and Yoshua Bengio
CON: @ylecun and @MelMitchell1 

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Maybe RFK Jr. is a sign that America is drowning in misinformation. Or maybe it was always this bad. Either way, it's going to be very hard to clean up our information ecosystem.
------
A disturbingly large number of Americans believe in conspiracy theories.
But contrary to a common belief, the proportion has not increased over time .
In fact, it has decreased in many instances.
[h/t 
@Noahpinion
]
------
Join us at #CVPR for our exciting  robot demo!

 Find us near the 
@MetaAI
 booth
‍ Trained vision-based robot control models at scale with 
@ai_habitat

 Achieving zero-shot transfer to reality for open vocabulary object rearrangement

 No ticket needed 
------
We’ve only had access to GAIA-1 for a few weeks and are discovering new capabilities every day. The results are phenomenal!

GAIA isn't just a generative video model, it is a world model, ie. controllable by video, text & action prompts

Why is this huge for self driving? Thread:
------
A closer look at the architecture of Meta's first-generation AI inference accelerator. MTIA v1 is a custom-designed ASIC built with next-generation recommendation model requirements in mind.

Read more  https://bit.ly/46hV3sU

We'll be sharing more at #ISCA2023.
------
Tonight from the Munk Debate on AI


@MelMitchell1
 and I are debating Max 
@tegmark
 and Yoshua Bengio

https://munkdebates.com/debates/artificial-intelligence…
------
My debate partner 
@MelMitchell1
 arguing that AI does NOT represent an existential threat at the 
@munkdebate
 on AI

Watch live here:
https://munkdebates.com/debates/artificial-intelligence…
------
My opponent Yoshua Bengio's opening statement at the 
@munkdebate
 on AI

Livestream here:
https://munkdebates.com/debates/artificial-intelligence…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Pas de moratoire et pas de discours alarmiste sur l'intelligence artificielle : demain, on vous présente une rare entrevue avec 
@ylecun
, directeur scientifique des activités en intelligence artificielle de Facebook. 

#IA
------
Une entrevue au journal télévisé de Radio-Canada dans quelques instants.
------
Dans quelques instants, ne manquez pas la grande entrevue avec @ylecun au #TJ18h

L’intelligence artificielle n’est pas une menace pour l'humanité mais une chance de renaissance : l'un des pères de l’IA refuse les scénarios catastrophes brandis par ses collègues.
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
The AI Apocalypse Scorecard, with quotes from tonight's debaters:

@MelMitchell1
, 
@tegmark
, Yoshua Bengio, and me, among several others.
------
"AI is intrinsically good, because the effect of AI is to make people smarter"
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Domestic robot at #CVPR2023
------
Come join us for an instruction-following robot assistant demo at #CVPR2023 Meta Booth by the FAIR Embodied AI team.

Give Spot a free-form natural language instruction for object fetching.

Details: …https://languageguidedskillcoordination.github.io

------
Try out HomeRobot, download the simulation, and implement your best solution. More details on the challenge in the 
------
The future of robot butlers starts with mobile manipulation.
We’re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!
- Full robot stack 
- Parallel sim and real evaluation 
- No robot required 

https://aihabitat.org/challenge/2023_homerobot_ovmm/…
------
Tonight 7:00pm EST
------
Tonight at 7PM ET

It might be our most important debate ever.

Be it Resolved, AI research and development poses and existential threat.

PRO: @tegmark and Yoshua Bengio
CON: @ylecun and @MelMitchell1 

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Maybe RFK Jr. is a sign that America is drowning in misinformation. Or maybe it was always this bad. Either way, it's going to be very hard to clean up our information ecosystem.
------
A disturbingly large number of Americans believe in conspiracy theories.
But contrary to a common belief, the proportion has not increased over time .
In fact, it has decreased in many instances.
[h/t 
@Noahpinion
]
------
Join us at #CVPR for our exciting  robot demo!

 Find us near the 
@MetaAI
 booth
‍ Trained vision-based robot control models at scale with 
@ai_habitat

 Achieving zero-shot transfer to reality for open vocabulary object rearrangement

 No ticket needed 
------
We’ve only had access to GAIA-1 for a few weeks and are discovering new capabilities every day. The results are phenomenal!

GAIA isn't just a generative video model, it is a world model, ie. controllable by video, text & action prompts

Why is this huge for self driving? Thread:
------
A closer look at the architecture of Meta's first-generation AI inference accelerator. MTIA v1 is a custom-designed ASIC built with next-generation recommendation model requirements in mind.

Read more  https://bit.ly/46hV3sU

We'll be sharing more at #ISCA2023.
------
Exactly.
Automated manufacturing makes handcrafted goods more valuable.
------
Within a few years, artisanal "certified human-made" content is going to sell at a big premium to AI-generated content. twitter.com/DigEconLab/sta…
------
Fun CIFAR workshop, as usual.
Picture of CIFAR-18 
------
Just wrapped: The summer meeting of CIFAR's Learning in Machines & Brains program in Quebec City.

Agenda-setting discussions with some of the world's top neuro- and computer scientists collaborating on big questions about AI and human intelligence. https://cifar.ca/research-programs/learning-in-machines-brains/…
------
Tweet: "new paper on Self-Supervised Learning for Objective-Driven AI"

Comment#1: "OMG this is Skynet! We're all gonna die. Has Yann ever heard of the alignment problem?"

Comment#2: "This is a dead end & will never work. Yann is too stupid to understand my AGI design… Show more
------
Overzealous spelling correctors on mobile devices be like:
"neutral nets, such as convents trained with backdrop and stochastic gradient decent."

What better place than a convent to do a cross validation?
But working in a convent will not increase your CV dimension.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by 
@MetaAI
 has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
HAPPENING NOW:  My opening statement at the 
@munkdebate
 on the existential risk of AI.  

You can watch the it live (exclusively for Munk donors) here: https://munkdebates.com/debates/artificial-intelligence…
------
Pas de moratoire et pas de discours alarmiste sur l'intelligence artificielle : demain, on vous présente une rare entrevue avec 
@ylecun
, directeur scientifique des activités en intelligence artificielle de Facebook. 

#IA
------
Une entrevue au journal télévisé de Radio-Canada dans quelques instants.
------
Dans quelques instants, ne manquez pas la grande entrevue avec @ylecun au #TJ18h

L’intelligence artificielle n’est pas une menace pour l'humanité mais une chance de renaissance : l'un des pères de l’IA refuse les scénarios catastrophes brandis par ses collègues.
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
The AI Apocalypse Scorecard, with quotes from tonight's debaters:

@MelMitchell1
, 
@tegmark
, Yoshua Bengio, and me, among several others.
------
"AI is intrinsically good, because the effect of AI is to make people smarter"
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Domestic robot at #CVPR2023
------
Come join us for an instruction-following robot assistant demo at #CVPR2023 Meta Booth by the FAIR Embodied AI team.

Give Spot a free-form natural language instruction for object fetching.

Details: …https://languageguidedskillcoordination.github.io

------
Try out HomeRobot, download the simulation, and implement your best solution. More details on the challenge in the 
------
The future of robot butlers starts with mobile manipulation.
We’re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!
- Full robot stack 
- Parallel sim and real evaluation 
- No robot required 

https://aihabitat.org/challenge/2023_homerobot_ovmm/…
------
Tonight 7:00pm EST
------
Tonight at 7PM ET

It might be our most important debate ever.

Be it Resolved, AI research and development poses and existential threat.

PRO: @tegmark and Yoshua Bengio
CON: @ylecun and @MelMitchell1 

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Maybe RFK Jr. is a sign that America is drowning in misinformation. Or maybe it was always this bad. Either way, it's going to be very hard to clean up our information ecosystem.
------
A disturbingly large number of Americans believe in conspiracy theories.
But contrary to a common belief, the proportion has not increased over time .
In fact, it has decreased in many instances.
[h/t 
@Noahpinion
]
------
Join us at #CVPR for our exciting  robot demo!

 Find us near the 
@MetaAI
 booth
‍ Trained vision-based robot control models at scale with 
@ai_habitat

 Achieving zero-shot transfer to reality for open vocabulary object rearrangement

 No ticket needed 
------
We’ve only had access to GAIA-1 for a few weeks and are discovering new capabilities every day. The results are phenomenal!

GAIA isn't just a generative video model, it is a world model, ie. controllable by video, text & action prompts

Why is this huge for self driving? Thread:
------
A closer look at the architecture of Meta's first-generation AI inference accelerator. MTIA v1 is a custom-designed ASIC built with next-generation recommendation model requirements in mind.

Read more  https://bit.ly/46hV3sU

We'll be sharing more at #ISCA2023.
------
Exactly.
Automated manufacturing makes handcrafted goods more valuable.
------
Within a few years, artisanal "certified human-made" content is going to sell at a big premium to AI-generated content. twitter.com/DigEconLab/sta…
------
Fun CIFAR workshop, as usual.
Picture of CIFAR-18 
------
Just wrapped: The summer meeting of CIFAR's Learning in Machines & Brains program in Quebec City.

Agenda-setting discussions with some of the world's top neuro- and computer scientists collaborating on big questions about AI and human intelligence. https://cifar.ca/research-programs/learning-in-machines-brains/…
------
Tweet: "new paper on Self-Supervised Learning for Objective-Driven AI"

Comment#1: "OMG this is Skynet! We're all gonna die. Has Yann ever heard of the alignment problem?"

Comment#2: "This is a dead end & will never work. Yann is too stupid to understand my AGI design… Show more
------
Overzealous spelling correctors on mobile devices be like:
"neutral nets, such as convents trained with backdrop and stochastic gradient decent."

What better place than a convent to do a cross validation?
But working in a convent will not increase your CV dimension.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by 
@MetaAI
 has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
EnCodec, is now on  Transformers!Think of it as a low level latent space  inversible to audio  It also provides a discrete space for Language Models as used in our MusicGen model.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by @MetaAI has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
#CVPR2023 — Here are  Interesting new papers you should know about from Meta AI — and how you can access them if you’re not at the conference.


------
"A.I. will not lead to human extinction," says Professor Yann LeCun, "because we will find ways to make it safe."

This Thursday at 7:00pm, Professor LeCun is participating in a live debate on the technology's future—livestream details:


@ylecun
 
@munkdebate
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Huge fan of JEPA - kudos to 
@ylecun
 and co for a new AI approach that blows generative AI out of the water
------
Objective-Driven AI architectures are the future.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
Munk debate room, before the storm.

[don't be alarmed if you see posts from me during the debate: the organizers will post for me]
------
The AI Apocalypse Scorecard, with quotes from tonight's debaters:

@MelMitchell1
, 
@tegmark
, Yoshua Bengio, and me, among several others.
------
"AI is intrinsically good, because the effect of AI is to make people smarter"
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Domestic robot at #CVPR2023
------
Come join us for an instruction-following robot assistant demo at #CVPR2023 Meta Booth by the FAIR Embodied AI team.

Give Spot a free-form natural language instruction for object fetching.

Details: …https://languageguidedskillcoordination.github.io

------
Try out HomeRobot, download the simulation, and implement your best solution. More details on the challenge in the 
------
The future of robot butlers starts with mobile manipulation.
We’re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!
- Full robot stack 
- Parallel sim and real evaluation 
- No robot required 

https://aihabitat.org/challenge/2023_homerobot_ovmm/…
------
Tonight 7:00pm EST
------
Tonight at 7PM ET

It might be our most important debate ever.

Be it Resolved, AI research and development poses and existential threat.

PRO: @tegmark and Yoshua Bengio
CON: @ylecun and @MelMitchell1 

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Maybe RFK Jr. is a sign that America is drowning in misinformation. Or maybe it was always this bad. Either way, it's going to be very hard to clean up our information ecosystem.
------
A disturbingly large number of Americans believe in conspiracy theories.
But contrary to a common belief, the proportion has not increased over time .
In fact, it has decreased in many instances.
[h/t 
@Noahpinion
]
------
Join us at #CVPR for our exciting  robot demo!

 Find us near the 
@MetaAI
 booth
‍ Trained vision-based robot control models at scale with 
@ai_habitat

 Achieving zero-shot transfer to reality for open vocabulary object rearrangement

 No ticket needed 
------
We’ve only had access to GAIA-1 for a few weeks and are discovering new capabilities every day. The results are phenomenal!

GAIA isn't just a generative video model, it is a world model, ie. controllable by video, text & action prompts

Why is this huge for self driving? Thread:
------
A closer look at the architecture of Meta's first-generation AI inference accelerator. MTIA v1 is a custom-designed ASIC built with next-generation recommendation model requirements in mind.

Read more  https://bit.ly/46hV3sU

We'll be sharing more at #ISCA2023.
------
Exactly.
Automated manufacturing makes handcrafted goods more valuable.
------
Within a few years, artisanal "certified human-made" content is going to sell at a big premium to AI-generated content. twitter.com/DigEconLab/sta…
------
Fun CIFAR workshop, as usual.
Picture of CIFAR-18 
------
Just wrapped: The summer meeting of CIFAR's Learning in Machines & Brains program in Quebec City.

Agenda-setting discussions with some of the world's top neuro- and computer scientists collaborating on big questions about AI and human intelligence. https://cifar.ca/research-programs/learning-in-machines-brains/…
------
Tweet: "new paper on Self-Supervised Learning for Objective-Driven AI"

Comment#1: "OMG this is Skynet! We're all gonna die. Has Yann ever heard of the alignment problem?"

Comment#2: "This is a dead end & will never work. Yann is too stupid to understand my AGI design… Show more
------
Overzealous spelling correctors on mobile devices be like:
"neutral nets, such as convents trained with backdrop and stochastic gradient decent."

What better place than a convent to do a cross validation?
But working in a convent will not increase your CV dimension.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by 
@MetaAI
 has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
EnCodec, is now on  Transformers!Think of it as a low level latent space  inversible to audio  It also provides a discrete space for Language Models as used in our MusicGen model.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by @MetaAI has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
#CVPR2023 — Here are  Interesting new papers you should know about from Meta AI — and how you can access them if you’re not at the conference.


------
"A.I. will not lead to human extinction," says Professor Yann LeCun, "because we will find ways to make it safe."

This Thursday at 7:00pm, Professor LeCun is participating in a live debate on the technology's future—livestream details:


@ylecun
 
@munkdebate
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Huge fan of JEPA - kudos to 
@ylecun
 and co for a new AI approach that blows generative AI out of the water
------
Objective-Driven AI architectures are the future.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
Live debate this Thursday about the risk of AI-fueled human extinction, together with 
@MelMitchell1
 opposite to 
@tegmark
 and my friend Yoshua Bengio.
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Getting ready for the demo at #CVPR23 
@MetaAI
 booth tomorrow.
------
Great episode of 20VC with Nabla CEO and former FAIRy Alexandre Lebrun :

- Why No Models Today Will Be Used in a Year,
- Why Open Will Always Beat Closed in AI,
- Why Proprietary Data is Less Important Than Ever
- Why EU AI Regulation is a Disaster

I can't disagree!
------
My friends, I am at least as excited as Harry Stebbings sounds excited at the beginning of every 20VC podcast. It was my turn eventually!

A few questions we covered: How to Work with Zuck(erberg), How to Deploy AI in Healthcare, Why No Models Today Will Be Used in a Year...
------
Try out HomeRobot, download the simulation, and implement your best solution. More details on the challenge in the 
------
The future of robot butlers starts with mobile manipulation.
We’re announcing the NeurIPS 2023 Open-Vocabulary Mobile Manipulation Challenge!
- Full robot stack 
- Parallel sim and real evaluation 
- No robot required 

https://aihabitat.org/challenge/2023_homerobot_ovmm/…
------
Tonight 7:00pm EST
------
Tonight at 7PM ET

It might be our most important debate ever.

Be it Resolved, AI research and development poses and existential threat.

PRO: @tegmark and Yoshua Bengio
CON: @ylecun and @MelMitchell1 

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Maybe RFK Jr. is a sign that America is drowning in misinformation. Or maybe it was always this bad. Either way, it's going to be very hard to clean up our information ecosystem.
------
A disturbingly large number of Americans believe in conspiracy theories.
But contrary to a common belief, the proportion has not increased over time .
In fact, it has decreased in many instances.
[h/t 
@Noahpinion
]
------
Join us at #CVPR for our exciting  robot demo!

 Find us near the 
@MetaAI
 booth
‍ Trained vision-based robot control models at scale with 
@ai_habitat

 Achieving zero-shot transfer to reality for open vocabulary object rearrangement

 No ticket needed 
------
We’ve only had access to GAIA-1 for a few weeks and are discovering new capabilities every day. The results are phenomenal!

GAIA isn't just a generative video model, it is a world model, ie. controllable by video, text & action prompts

Why is this huge for self driving? Thread:
------
A closer look at the architecture of Meta's first-generation AI inference accelerator. MTIA v1 is a custom-designed ASIC built with next-generation recommendation model requirements in mind.

Read more  https://bit.ly/46hV3sU

We'll be sharing more at #ISCA2023.
------
Exactly.
Automated manufacturing makes handcrafted goods more valuable.
------
Within a few years, artisanal "certified human-made" content is going to sell at a big premium to AI-generated content. twitter.com/DigEconLab/sta…
------
Fun CIFAR workshop, as usual.
Picture of CIFAR-18 
------
Just wrapped: The summer meeting of CIFAR's Learning in Machines & Brains program in Quebec City.

Agenda-setting discussions with some of the world's top neuro- and computer scientists collaborating on big questions about AI and human intelligence. https://cifar.ca/research-programs/learning-in-machines-brains/…
------
Tweet: "new paper on Self-Supervised Learning for Objective-Driven AI"

Comment#1: "OMG this is Skynet! We're all gonna die. Has Yann ever heard of the alignment problem?"

Comment#2: "This is a dead end & will never work. Yann is too stupid to understand my AGI design… Show more
------
Overzealous spelling correctors on mobile devices be like:
"neutral nets, such as convents trained with backdrop and stochastic gradient decent."

What better place than a convent to do a cross validation?
But working in a convent will not increase your CV dimension.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by 
@MetaAI
 has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
EnCodec, is now on  Transformers!Think of it as a low level latent space  inversible to audio  It also provides a discrete space for Language Models as used in our MusicGen model.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by @MetaAI has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
#CVPR2023 — Here are  Interesting new papers you should know about from Meta AI — and how you can access them if you’re not at the conference.


------
"A.I. will not lead to human extinction," says Professor Yann LeCun, "because we will find ways to make it safe."

This Thursday at 7:00pm, Professor LeCun is participating in a live debate on the technology's future—livestream details:


@ylecun
 
@munkdebate
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Huge fan of JEPA - kudos to 
@ylecun
 and co for a new AI approach that blows generative AI out of the water
------
Objective-Driven AI architectures are the future.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
Live debate this Thursday about the risk of AI-fueled human extinction, together with 
@MelMitchell1
 opposite to 
@tegmark
 and my friend Yoshua Bengio.
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Getting ready for the demo at #CVPR23 
@MetaAI
 booth tomorrow.
------
Great episode of 20VC with Nabla CEO and former FAIRy Alexandre Lebrun :

- Why No Models Today Will Be Used in a Year,
- Why Open Will Always Beat Closed in AI,
- Why Proprietary Data is Less Important Than Ever
- Why EU AI Regulation is a Disaster

I can't disagree!
------
My friends, I am at least as excited as Harry Stebbings sounds excited at the beginning of every 20VC podcast. It was my turn eventually!

A few questions we covered: How to Work with Zuck(erberg), How to Deploy AI in Healthcare, Why No Models Today Will Be Used in a Year...
------
Excellent entretien croisé entre Yoshua Bengio et moi paru dans Les Échos Weekend il y a quelques jours.

Propos recueillis par Benoît Georges et Stefano Lupieri.
------
L'IA était omniprésente au salon 
@VivaTech
 : un danger selon 
@elonmusk
, une chance selon 
@ylecun
 
À écouter ici : https://mondenumerique.info/episode/lhebdo-du-170623-special-vivatech… 
#Podcast #MondeNumerique L'Hebdo
------
I can't make it to #CVPR2023 this year, but 
@MetaAI
 / FAIR has a huge presence, as usual.

More info: https://ai.facebook.com/events/cvpr-2023…
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
Join us at #CVPR for our exciting  robot demo!

 Find us near the 
@MetaAI
 booth
‍ Trained vision-based robot control models at scale with 
@ai_habitat

 Achieving zero-shot transfer to reality for open vocabulary object rearrangement

 No ticket needed 
------
We’ve only had access to GAIA-1 for a few weeks and are discovering new capabilities every day. The results are phenomenal!

GAIA isn't just a generative video model, it is a world model, ie. controllable by video, text & action prompts

Why is this huge for self driving? Thread:
------
A closer look at the architecture of Meta's first-generation AI inference accelerator. MTIA v1 is a custom-designed ASIC built with next-generation recommendation model requirements in mind.

Read more  https://bit.ly/46hV3sU

We'll be sharing more at #ISCA2023.
------
Exactly.
Automated manufacturing makes handcrafted goods more valuable.
------
Within a few years, artisanal "certified human-made" content is going to sell at a big premium to AI-generated content. twitter.com/DigEconLab/sta…
------
Fun CIFAR workshop, as usual.
Picture of CIFAR-18 
------
Just wrapped: The summer meeting of CIFAR's Learning in Machines & Brains program in Quebec City.

Agenda-setting discussions with some of the world's top neuro- and computer scientists collaborating on big questions about AI and human intelligence. https://cifar.ca/research-programs/learning-in-machines-brains/…
------
Tweet: "new paper on Self-Supervised Learning for Objective-Driven AI"

Comment#1: "OMG this is Skynet! We're all gonna die. Has Yann ever heard of the alignment problem?"

Comment#2: "This is a dead end & will never work. Yann is too stupid to understand my AGI design… Show more
------
Overzealous spelling correctors on mobile devices be like:
"neutral nets, such as convents trained with backdrop and stochastic gradient decent."

What better place than a convent to do a cross validation?
But working in a convent will not increase your CV dimension.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by 
@MetaAI
 has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
EnCodec, is now on  Transformers!Think of it as a low level latent space  inversible to audio  It also provides a discrete space for Language Models as used in our MusicGen model.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by @MetaAI has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
#CVPR2023 — Here are  Interesting new papers you should know about from Meta AI — and how you can access them if you’re not at the conference.


------
"A.I. will not lead to human extinction," says Professor Yann LeCun, "because we will find ways to make it safe."

This Thursday at 7:00pm, Professor LeCun is participating in a live debate on the technology's future—livestream details:


@ylecun
 
@munkdebate
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Huge fan of JEPA - kudos to 
@ylecun
 and co for a new AI approach that blows generative AI out of the water
------
Objective-Driven AI architectures are the future.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
Live debate this Thursday about the risk of AI-fueled human extinction, together with 
@MelMitchell1
 opposite to 
@tegmark
 and my friend Yoshua Bengio.
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Getting ready for the demo at #CVPR23 
@MetaAI
 booth tomorrow.
------
Great episode of 20VC with Nabla CEO and former FAIRy Alexandre Lebrun :

- Why No Models Today Will Be Used in a Year,
- Why Open Will Always Beat Closed in AI,
- Why Proprietary Data is Less Important Than Ever
- Why EU AI Regulation is a Disaster

I can't disagree!
------
My friends, I am at least as excited as Harry Stebbings sounds excited at the beginning of every 20VC podcast. It was my turn eventually!

A few questions we covered: How to Work with Zuck(erberg), How to Deploy AI in Healthcare, Why No Models Today Will Be Used in a Year...
------
Excellent entretien croisé entre Yoshua Bengio et moi paru dans Les Échos Weekend il y a quelques jours.

Propos recueillis par Benoît Georges et Stefano Lupieri.
------
L'IA était omniprésente au salon 
@VivaTech
 : un danger selon 
@elonmusk
, une chance selon 
@ylecun
 
À écouter ici : https://mondenumerique.info/episode/lhebdo-du-170623-special-vivatech… 
#Podcast #MondeNumerique L'Hebdo
------
I can't make it to #CVPR2023 this year, but 
@MetaAI
 / FAIR has a huge presence, as usual.

More info: https://ai.facebook.com/events/cvpr-2023…
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
My friend Jean Ponce was at Vivatech to present a new startup called Enhance Lab, spun off from his Inria group Willow.

Enhance Lab has an *amazing* image enhancement tech that does simultaneous demosaicing, denoising, super-resolution and HDR from raw  photo bursts.

[Full… Show more
------
 #InriaVivaTech | Willow présente Enhance Lab, une solution logicielle qui multiplie par 4 la résolution spatiale des photos de smartphone, soit jusqu'à 16 fois + de pixels. Utile pour gérer le bruit et la perte de détails ! 
En savoir + sur Willow : https://inria.fr/fr/willow
------
Co-organizing the Embodied AI Workshop at CVPR! With 6 speakers, 10 challenges, 20+ participating organizations, we will be exploring themes including generalist agents, foundation models, sim2real transfer and much more. Join us at CVPR 2023 in Vancouver! #cvpr2023 #embodiedai
------
2023 sur l'écume de l'Onde #Innovation
Mieux que #ChatGPT ? #Meta présente une #IA qui s’approche de l’intelligence humaine 

@Edu_Num
 
"plus proche que" est différent de "proche de" quand il s'agit d'une imitation/simulation du cerveau.

@ylecun

https://01net.com/actualites/mieux-chatgpt-meta-presente-ia-approche-intelligence-humaine.html… via 
@01net
------
Fun CIFAR workshop, as usual.
Picture of CIFAR-18 
------
Just wrapped: The summer meeting of CIFAR's Learning in Machines & Brains program in Quebec City.

Agenda-setting discussions with some of the world's top neuro- and computer scientists collaborating on big questions about AI and human intelligence. https://cifar.ca/research-programs/learning-in-machines-brains/…
------
Tweet: "new paper on Self-Supervised Learning for Objective-Driven AI"

Comment#1: "OMG this is Skynet! We're all gonna die. Has Yann ever heard of the alignment problem?"

Comment#2: "This is a dead end & will never work. Yann is too stupid to understand my AGI design… Show more
------
Overzealous spelling correctors on mobile devices be like:
"neutral nets, such as convents trained with backdrop and stochastic gradient decent."

What better place than a convent to do a cross validation?
But working in a convent will not increase your CV dimension.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by 
@MetaAI
 has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
EnCodec, is now on  Transformers!Think of it as a low level latent space  inversible to audio  It also provides a discrete space for Language Models as used in our MusicGen model.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by @MetaAI has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
#CVPR2023 — Here are  Interesting new papers you should know about from Meta AI — and how you can access them if you’re not at the conference.


------
"A.I. will not lead to human extinction," says Professor Yann LeCun, "because we will find ways to make it safe."

This Thursday at 7:00pm, Professor LeCun is participating in a live debate on the technology's future—livestream details:


@ylecun
 
@munkdebate
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Huge fan of JEPA - kudos to 
@ylecun
 and co for a new AI approach that blows generative AI out of the water
------
Objective-Driven AI architectures are the future.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
Live debate this Thursday about the risk of AI-fueled human extinction, together with 
@MelMitchell1
 opposite to 
@tegmark
 and my friend Yoshua Bengio.
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Getting ready for the demo at #CVPR23 
@MetaAI
 booth tomorrow.
------
Great episode of 20VC with Nabla CEO and former FAIRy Alexandre Lebrun :

- Why No Models Today Will Be Used in a Year,
- Why Open Will Always Beat Closed in AI,
- Why Proprietary Data is Less Important Than Ever
- Why EU AI Regulation is a Disaster

I can't disagree!
------
My friends, I am at least as excited as Harry Stebbings sounds excited at the beginning of every 20VC podcast. It was my turn eventually!

A few questions we covered: How to Work with Zuck(erberg), How to Deploy AI in Healthcare, Why No Models Today Will Be Used in a Year...
------
Excellent entretien croisé entre Yoshua Bengio et moi paru dans Les Échos Weekend il y a quelques jours.

Propos recueillis par Benoît Georges et Stefano Lupieri.
------
L'IA était omniprésente au salon 
@VivaTech
 : un danger selon 
@elonmusk
, une chance selon 
@ylecun
 
À écouter ici : https://mondenumerique.info/episode/lhebdo-du-170623-special-vivatech… 
#Podcast #MondeNumerique L'Hebdo
------
I can't make it to #CVPR2023 this year, but 
@MetaAI
 / FAIR has a huge presence, as usual.

More info: https://ai.facebook.com/events/cvpr-2023…
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
My friend Jean Ponce was at Vivatech to present a new startup called Enhance Lab, spun off from his Inria group Willow.

Enhance Lab has an *amazing* image enhancement tech that does simultaneous demosaicing, denoising, super-resolution and HDR from raw  photo bursts.

[Full… Show more
------
 #InriaVivaTech | Willow présente Enhance Lab, une solution logicielle qui multiplie par 4 la résolution spatiale des photos de smartphone, soit jusqu'à 16 fois + de pixels. Utile pour gérer le bruit et la perte de détails ! 
En savoir + sur Willow : https://inria.fr/fr/willow
------
Co-organizing the Embodied AI Workshop at CVPR! With 6 speakers, 10 challenges, 20+ participating organizations, we will be exploring themes including generalist agents, foundation models, sim2real transfer and much more. Join us at CVPR 2023 in Vancouver! #cvpr2023 #embodiedai
------
2023 sur l'écume de l'Onde #Innovation
Mieux que #ChatGPT ? #Meta présente une #IA qui s’approche de l’intelligence humaine 

@Edu_Num
 
"plus proche que" est différent de "proche de" quand il s'agit d'une imitation/simulation du cerveau.

@ylecun

https://01net.com/actualites/mieux-chatgpt-meta-presente-ia-approche-intelligence-humaine.html… via 
@01net
------
How to shoot yourself in the foot with a bazooka in the form of insane immigration laws.
------
Nearly 40,000 foreign-born graduates of U.S. universities were recruited to Canada from 2017 to 2021. The USA is forcing some of the smartest people leave. 

The likelihood of getting an H1B went down from 1 in 4 to now 1 in 7 due to completely arbitrary caps set long ago. twitter.com/LettieriDC/sta…
------
After an impressive first salvo by GPT-4, I score this battle as a clear victory for 
@MIT
 seniors. 

John Henry would be proud.
------
For those who (like me) were interested in the "GPT can ace MIT" paper, 

Here's a great short writeup by three MIT EECS seniors explaining the many things wrong with analysis.

https://dub.sh/gptsucksatmit
------
So that paper about how GPT-4 could ace MIT's curriculum turns out to be deeply flawed in multiple ways. A great reminder that preprints are not peer-reviewed, but also that public volunteer review can be excellent (in this case, by a group of undergrads).
------
I’m incredibly excited to share a sneak peak of 
@wayve_ai
’s GAIA-1, a major step forward in action and language-conditioned world models for #AutonomousDriving. Here’s a glimpse of what GAIA-1 can do - more in the . (These are not real videos!)  But what's a world model?
------
EnCodec, is now on  Transformers!Think of it as a low level latent space  inversible to audio  It also provides a discrete space for Language Models as used in our MusicGen model.
------
Want to train your own Bark/MusicGen-like TTS/TTA models? 

The SoTA Encodec model by @MetaAI has now landed in Transformers! 

It supports compression up to 1.5KHz and produces discrete audio representations. 

Model: https://huggingface.co/docs/transformers/main/en/model_doc/encodec#overview…
Colab: https://github.com/Vaibhavs10/notebooks/blob/main/use_encodec_w_transformers.ipynb…
------
#CVPR2023 — Here are  Interesting new papers you should know about from Meta AI — and how you can access them if you’re not at the conference.


------
"A.I. will not lead to human extinction," says Professor Yann LeCun, "because we will find ways to make it safe."

This Thursday at 7:00pm, Professor LeCun is participating in a live debate on the technology's future—livestream details:


@ylecun
 
@munkdebate
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Huge fan of JEPA - kudos to 
@ylecun
 and co for a new AI approach that blows generative AI out of the water
------
Objective-Driven AI architectures are the future.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
Live debate this Thursday about the risk of AI-fueled human extinction, together with 
@MelMitchell1
 opposite to 
@tegmark
 and my friend Yoshua Bengio.
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Getting ready for the demo at #CVPR23 
@MetaAI
 booth tomorrow.
------
Great episode of 20VC with Nabla CEO and former FAIRy Alexandre Lebrun :

- Why No Models Today Will Be Used in a Year,
- Why Open Will Always Beat Closed in AI,
- Why Proprietary Data is Less Important Than Ever
- Why EU AI Regulation is a Disaster

I can't disagree!
------
My friends, I am at least as excited as Harry Stebbings sounds excited at the beginning of every 20VC podcast. It was my turn eventually!

A few questions we covered: How to Work with Zuck(erberg), How to Deploy AI in Healthcare, Why No Models Today Will Be Used in a Year...
------
Excellent entretien croisé entre Yoshua Bengio et moi paru dans Les Échos Weekend il y a quelques jours.

Propos recueillis par Benoît Georges et Stefano Lupieri.
------
L'IA était omniprésente au salon 
@VivaTech
 : un danger selon 
@elonmusk
, une chance selon 
@ylecun
 
À écouter ici : https://mondenumerique.info/episode/lhebdo-du-170623-special-vivatech… 
#Podcast #MondeNumerique L'Hebdo
------
I can't make it to #CVPR2023 this year, but 
@MetaAI
 / FAIR has a huge presence, as usual.

More info: https://ai.facebook.com/events/cvpr-2023…
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
My friend Jean Ponce was at Vivatech to present a new startup called Enhance Lab, spun off from his Inria group Willow.

Enhance Lab has an *amazing* image enhancement tech that does simultaneous demosaicing, denoising, super-resolution and HDR from raw  photo bursts.

[Full… Show more
------
 #InriaVivaTech | Willow présente Enhance Lab, une solution logicielle qui multiplie par 4 la résolution spatiale des photos de smartphone, soit jusqu'à 16 fois + de pixels. Utile pour gérer le bruit et la perte de détails ! 
En savoir + sur Willow : https://inria.fr/fr/willow
------
Co-organizing the Embodied AI Workshop at CVPR! With 6 speakers, 10 challenges, 20+ participating organizations, we will be exploring themes including generalist agents, foundation models, sim2real transfer and much more. Join us at CVPR 2023 in Vancouver! #cvpr2023 #embodiedai
------
2023 sur l'écume de l'Onde #Innovation
Mieux que #ChatGPT ? #Meta présente une #IA qui s’approche de l’intelligence humaine 

@Edu_Num
 
"plus proche que" est différent de "proche de" quand il s'agit d'une imitation/simulation du cerveau.

@ylecun

https://01net.com/actualites/mieux-chatgpt-meta-presente-ia-approche-intelligence-humaine.html… via 
@01net
------
How to shoot yourself in the foot with a bazooka in the form of insane immigration laws.
------
Nearly 40,000 foreign-born graduates of U.S. universities were recruited to Canada from 2017 to 2021. The USA is forcing some of the smartest people leave. 

The likelihood of getting an H1B went down from 1 in 4 to now 1 in 7 due to completely arbitrary caps set long ago. twitter.com/LettieriDC/sta…
------
After an impressive first salvo by GPT-4, I score this battle as a clear victory for 
@MIT
 seniors. 

John Henry would be proud.
------
For those who (like me) were interested in the "GPT can ace MIT" paper, 

Here's a great short writeup by three MIT EECS seniors explaining the many things wrong with analysis.

https://dub.sh/gptsucksatmit
------
So that paper about how GPT-4 could ace MIT's curriculum turns out to be deeply flawed in multiple ways. A great reminder that preprints are not peer-reviewed, but also that public volunteer review can be excellent (in this case, by a group of undergrads).
------
I’m incredibly excited to share a sneak peak of 
@wayve_ai
’s GAIA-1, a major step forward in action and language-conditioned world models for #AutonomousDriving. Here’s a glimpse of what GAIA-1 can do - more in the . (These are not real videos!)  But what's a world model?
------
Getting the insights of those pushing the frontier of technology is a necessity for effective regulation that does not hinder development. I very much enjoyed discussing the future of A.I. and regulation with 
@ylecun
.
------
Enregistrement complet de mon interview avec 
@dimitripavlenko

diffusée sur Europe 1 vendredi matin.
------
Une interview sur Europe 1 diffusée hier matin.
------
« En tant qu’humain, on est toujours troublé quand quelque chose est capable de parler, on lui attribue automatiquement une intelligence, mais c’est une erreur »,  selon @ylecun, vice-président du groupe chargé de l'IA chez @Meta à propos de l’intelligence artificielle #Europe1
------
Interview complète
------
Live debate this Thursday about the risk of AI-fueled human extinction, together with 
@MelMitchell1
 opposite to 
@tegmark
 and my friend Yoshua Bengio.
------
Meta Chief AI Scientist @ylecun thinks fear about AI are overblown and without merit.

He'll debate @tegmark and Yoshua Bengio at our Munk Debate on #AI, this Thursday at 7:00 PM ET.

Livestream details here:
https://munkdebates.com/debates/artificial-intelligence…
------
Getting ready for the demo at #CVPR23 
@MetaAI
 booth tomorrow.
------
Great episode of 20VC with Nabla CEO and former FAIRy Alexandre Lebrun :

- Why No Models Today Will Be Used in a Year,
- Why Open Will Always Beat Closed in AI,
- Why Proprietary Data is Less Important Than Ever
- Why EU AI Regulation is a Disaster

I can't disagree!
------
My friends, I am at least as excited as Harry Stebbings sounds excited at the beginning of every 20VC podcast. It was my turn eventually!

A few questions we covered: How to Work with Zuck(erberg), How to Deploy AI in Healthcare, Why No Models Today Will Be Used in a Year...
------
Excellent entretien croisé entre Yoshua Bengio et moi paru dans Les Échos Weekend il y a quelques jours.

Propos recueillis par Benoît Georges et Stefano Lupieri.
------
L'IA était omniprésente au salon 
@VivaTech
 : un danger selon 
@elonmusk
, une chance selon 
@ylecun
 
À écouter ici : https://mondenumerique.info/episode/lhebdo-du-170623-special-vivatech… 
#Podcast #MondeNumerique L'Hebdo
------
I can't make it to #CVPR2023 this year, but 
@MetaAI
 / FAIR has a huge presence, as usual.

More info: https://ai.facebook.com/events/cvpr-2023…
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
My friend Jean Ponce was at Vivatech to present a new startup called Enhance Lab, spun off from his Inria group Willow.

Enhance Lab has an *amazing* image enhancement tech that does simultaneous demosaicing, denoising, super-resolution and HDR from raw  photo bursts.

[Full… Show more
------
 #InriaVivaTech | Willow présente Enhance Lab, une solution logicielle qui multiplie par 4 la résolution spatiale des photos de smartphone, soit jusqu'à 16 fois + de pixels. Utile pour gérer le bruit et la perte de détails ! 
En savoir + sur Willow : https://inria.fr/fr/willow
------
Co-organizing the Embodied AI Workshop at CVPR! With 6 speakers, 10 challenges, 20+ participating organizations, we will be exploring themes including generalist agents, foundation models, sim2real transfer and much more. Join us at CVPR 2023 in Vancouver! #cvpr2023 #embodiedai
------
2023 sur l'écume de l'Onde #Innovation
Mieux que #ChatGPT ? #Meta présente une #IA qui s’approche de l’intelligence humaine 

@Edu_Num
 
"plus proche que" est différent de "proche de" quand il s'agit d'une imitation/simulation du cerveau.

@ylecun

https://01net.com/actualites/mieux-chatgpt-meta-presente-ia-approche-intelligence-humaine.html… via 
@01net
------
How to shoot yourself in the foot with a bazooka in the form of insane immigration laws.
------
Nearly 40,000 foreign-born graduates of U.S. universities were recruited to Canada from 2017 to 2021. The USA is forcing some of the smartest people leave. 

The likelihood of getting an H1B went down from 1 in 4 to now 1 in 7 due to completely arbitrary caps set long ago. twitter.com/LettieriDC/sta…
------
After an impressive first salvo by GPT-4, I score this battle as a clear victory for 
@MIT
 seniors. 

John Henry would be proud.
------
For those who (like me) were interested in the "GPT can ace MIT" paper, 

Here's a great short writeup by three MIT EECS seniors explaining the many things wrong with analysis.

https://dub.sh/gptsucksatmit
------
So that paper about how GPT-4 could ace MIT's curriculum turns out to be deeply flawed in multiple ways. A great reminder that preprints are not peer-reviewed, but also that public volunteer review can be excellent (in this case, by a group of undergrads).
------
I’m incredibly excited to share a sneak peak of 
@wayve_ai
’s GAIA-1, a major step forward in action and language-conditioned world models for #AutonomousDriving. Here’s a glimpse of what GAIA-1 can do - more in the . (These are not real videos!)  But what's a world model?
------
Getting the insights of those pushing the frontier of technology is a necessity for effective regulation that does not hinder development. I very much enjoyed discussing the future of A.I. and regulation with 
@ylecun
.
------
Enregistrement complet de mon interview avec 
@dimitripavlenko

diffusée sur Europe 1 vendredi matin.
------
Une interview sur Europe 1 diffusée hier matin.
------
« En tant qu’humain, on est toujours troublé quand quelque chose est capable de parler, on lui attribue automatiquement une intelligence, mais c’est une erreur »,  selon @ylecun, vice-président du groupe chargé de l'IA chez @Meta à propos de l’intelligence artificielle #Europe1
------
Interview complète
------
i love the distinction between thought and language 
@ylecun
 makes here.

interacting a lot with LLMs made clear to me that the struggle of finding words, of trying them out to express a thought I feel … is unknown to LLMs.

intelligence is more than language.
It is a series of… Show more
------
Une interview sur Europe 1 diffusée hier matin. twitter.com/Europe1/status…
------
Ce débat risque/opportunité entre 
@ylecun
 et Yoshua Bengio mérite vraiment d'être lu (malheureusement sous paywall)  et me semble être largement en faveur de Le Cun (opportunité) qui met en avant de nombreux exemples concrets de traitement des menaces.
------
The fact that you can employ people to work for you that are smarter than you does not make your job disappear.

Similarly, we will all have AI assistants working with us that are smarter than us but will not make our job disappear.

It will make us smarter & more efficient.
------
Dans le cadre de notre club "Chatham House", nous recevons ce soir 
@ylecun
, VP & Chief AI Scientist 
@Meta
.

Une discussion passionnante et franche sur les perspectives de l'#IA, co-organisée avec l'équipe de 
@MetaFrance
. 

Un grand merci à tous pour la richesse des échanges ! 
------
Excellent entretien croisé entre Yoshua Bengio et moi paru dans Les Échos Weekend il y a quelques jours.

Propos recueillis par Benoît Georges et Stefano Lupieri.
------
L'IA était omniprésente au salon 
@VivaTech
 : un danger selon 
@elonmusk
, une chance selon 
@ylecun
 
À écouter ici : https://mondenumerique.info/episode/lhebdo-du-170623-special-vivatech… 
#Podcast #MondeNumerique L'Hebdo
------
I can't make it to #CVPR2023 this year, but 
@MetaAI
 / FAIR has a huge presence, as usual.

More info: https://ai.facebook.com/events/cvpr-2023…
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
 Hey #CVPR2023! We’re here in Vancouver and excited to share new work, showcase demos and participate in interesting conversations this week.

 Booth #1602

A of things to look out for from the Meta AI team 

1/6
------
My friend Jean Ponce was at Vivatech to present a new startup called Enhance Lab, spun off from his Inria group Willow.

Enhance Lab has an *amazing* image enhancement tech that does simultaneous demosaicing, denoising, super-resolution and HDR from raw  photo bursts.

[Full… Show more
------
 #InriaVivaTech | Willow présente Enhance Lab, une solution logicielle qui multiplie par 4 la résolution spatiale des photos de smartphone, soit jusqu'à 16 fois + de pixels. Utile pour gérer le bruit et la perte de détails ! 
En savoir + sur Willow : https://inria.fr/fr/willow
------
Co-organizing the Embodied AI Workshop at CVPR! With 6 speakers, 10 challenges, 20+ participating organizations, we will be exploring themes including generalist agents, foundation models, sim2real transfer and much more. Join us at CVPR 2023 in Vancouver! #cvpr2023 #embodiedai
------
2023 sur l'écume de l'Onde #Innovation
Mieux que #ChatGPT ? #Meta présente une #IA qui s’approche de l’intelligence humaine 

@Edu_Num
 
"plus proche que" est différent de "proche de" quand il s'agit d'une imitation/simulation du cerveau.

@ylecun

https://01net.com/actualites/mieux-chatgpt-meta-presente-ia-approche-intelligence-humaine.html… via 
@01net
------
How to shoot yourself in the foot with a bazooka in the form of insane immigration laws.
------
Nearly 40,000 foreign-born graduates of U.S. universities were recruited to Canada from 2017 to 2021. The USA is forcing some of the smartest people leave. 

The likelihood of getting an H1B went down from 1 in 4 to now 1 in 7 due to completely arbitrary caps set long ago. twitter.com/LettieriDC/sta…
------
After an impressive first salvo by GPT-4, I score this battle as a clear victory for 
@MIT
 seniors. 

John Henry would be proud.
------
For those who (like me) were interested in the "GPT can ace MIT" paper, 

Here's a great short writeup by three MIT EECS seniors explaining the many things wrong with analysis.

https://dub.sh/gptsucksatmit
------
So that paper about how GPT-4 could ace MIT's curriculum turns out to be deeply flawed in multiple ways. A great reminder that preprints are not peer-reviewed, but also that public volunteer review can be excellent (in this case, by a group of undergrads).
------
I’m incredibly excited to share a sneak peak of 
@wayve_ai
’s GAIA-1, a major step forward in action and language-conditioned world models for #AutonomousDriving. Here’s a glimpse of what GAIA-1 can do - more in the . (These are not real videos!)  But what's a world model?
------
Getting the insights of those pushing the frontier of technology is a necessity for effective regulation that does not hinder development. I very much enjoyed discussing the future of A.I. and regulation with 
@ylecun
.
------
Enregistrement complet de mon interview avec 
@dimitripavlenko

diffusée sur Europe 1 vendredi matin.
------
Une interview sur Europe 1 diffusée hier matin.
------
« En tant qu’humain, on est toujours troublé quand quelque chose est capable de parler, on lui attribue automatiquement une intelligence, mais c’est une erreur »,  selon @ylecun, vice-président du groupe chargé de l'IA chez @Meta à propos de l’intelligence artificielle #Europe1
------
Interview complète
------
i love the distinction between thought and language 
@ylecun
 makes here.

interacting a lot with LLMs made clear to me that the struggle of finding words, of trying them out to express a thought I feel … is unknown to LLMs.

intelligence is more than language.
It is a series of… Show more
------
Une interview sur Europe 1 diffusée hier matin. twitter.com/Europe1/status…
------
Ce débat risque/opportunité entre 
@ylecun
 et Yoshua Bengio mérite vraiment d'être lu (malheureusement sous paywall)  et me semble être largement en faveur de Le Cun (opportunité) qui met en avant de nombreux exemples concrets de traitement des menaces.
------
The fact that you can employ people to work for you that are smarter than you does not make your job disappear.

Similarly, we will all have AI assistants working with us that are smarter than us but will not make our job disappear.

It will make us smarter & more efficient.
------
Dans le cadre de notre club "Chatham House", nous recevons ce soir 
@ylecun
, VP & Chief AI Scientist 
@Meta
.

Une discussion passionnante et franche sur les perspectives de l'#IA, co-organisée avec l'équipe de 
@MetaFrance
. 

Un grand merci à tous pour la richesse des échanges ! 
------
Conversation (intime) avec 
@ylecun
 merci 
@MetaFrance
 et 
@RNumerique
 #LLMs #LLaMA cc 
@venries
 @faycalBoujemaa  #GenAI « ma prédiction : les gagnants seront les modèles ouverts »
------
Voice box: can synthesize multiple voices from text, clean up speech, can use a voice recording to synthesize the same voice in another language, etc.
From Meta AI.
------
Introducing Voicebox, a new breakthrough generative speech system based on Flow Matching, a new method proposed by Meta AI. It can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.

More details on this work & examples 
------
I like this paper. They prove that transformers are guaranteed to suffer from compounding errors when doing long reasoning chains (as 
@ylecun
  has argued), and much apparent "success" is just due to unreliable pattern matching / shortcut learning.
------
Demain matin à 8h13 sur Europe 1.
------
 Ce vendredi 16 juin à 8h13 sur #Europe1

 @dimitripavlenko reçoit @ylecun, vice-président du groupe chargé de l'IA chez @Meta
------
(1/2) BB3 data analysis: lots of troll users, but they're v. useful for training robust models. BB3 is superhuman, BB3x is more(!) superhuman. Still lots of scope.
------
My friend Jean Ponce was at Vivatech to present a new startup called Enhance Lab, spun off from his Inria group Willow.

Enhance Lab has an *amazing* image enhancement tech that does simultaneous demosaicing, denoising, super-resolution and HDR from raw  photo bursts.

[Full… Show more
------
 #InriaVivaTech | Willow présente Enhance Lab, une solution logicielle qui multiplie par 4 la résolution spatiale des photos de smartphone, soit jusqu'à 16 fois + de pixels. Utile pour gérer le bruit et la perte de détails ! 
En savoir + sur Willow : https://inria.fr/fr/willow
------
Co-organizing the Embodied AI Workshop at CVPR! With 6 speakers, 10 challenges, 20+ participating organizations, we will be exploring themes including generalist agents, foundation models, sim2real transfer and much more. Join us at CVPR 2023 in Vancouver! #cvpr2023 #embodiedai
------
2023 sur l'écume de l'Onde #Innovation
Mieux que #ChatGPT ? #Meta présente une #IA qui s’approche de l’intelligence humaine 

@Edu_Num
 
"plus proche que" est différent de "proche de" quand il s'agit d'une imitation/simulation du cerveau.

@ylecun

https://01net.com/actualites/mieux-chatgpt-meta-presente-ia-approche-intelligence-humaine.html… via 
@01net
------
How to shoot yourself in the foot with a bazooka in the form of insane immigration laws.
------
Nearly 40,000 foreign-born graduates of U.S. universities were recruited to Canada from 2017 to 2021. The USA is forcing some of the smartest people leave. 

The likelihood of getting an H1B went down from 1 in 4 to now 1 in 7 due to completely arbitrary caps set long ago. twitter.com/LettieriDC/sta…
------
After an impressive first salvo by GPT-4, I score this battle as a clear victory for 
@MIT
 seniors. 

John Henry would be proud.
------
For those who (like me) were interested in the "GPT can ace MIT" paper, 

Here's a great short writeup by three MIT EECS seniors explaining the many things wrong with analysis.

https://dub.sh/gptsucksatmit
------
So that paper about how GPT-4 could ace MIT's curriculum turns out to be deeply flawed in multiple ways. A great reminder that preprints are not peer-reviewed, but also that public volunteer review can be excellent (in this case, by a group of undergrads).
------
I’m incredibly excited to share a sneak peak of 
@wayve_ai
’s GAIA-1, a major step forward in action and language-conditioned world models for #AutonomousDriving. Here’s a glimpse of what GAIA-1 can do - more in the . (These are not real videos!)  But what's a world model?
------
Getting the insights of those pushing the frontier of technology is a necessity for effective regulation that does not hinder development. I very much enjoyed discussing the future of A.I. and regulation with 
@ylecun
.
------
Enregistrement complet de mon interview avec 
@dimitripavlenko

diffusée sur Europe 1 vendredi matin.
------
Une interview sur Europe 1 diffusée hier matin.
------
« En tant qu’humain, on est toujours troublé quand quelque chose est capable de parler, on lui attribue automatiquement une intelligence, mais c’est une erreur »,  selon @ylecun, vice-président du groupe chargé de l'IA chez @Meta à propos de l’intelligence artificielle #Europe1
------
Interview complète
------
i love the distinction between thought and language 
@ylecun
 makes here.

interacting a lot with LLMs made clear to me that the struggle of finding words, of trying them out to express a thought I feel … is unknown to LLMs.

intelligence is more than language.
It is a series of… Show more
------
Une interview sur Europe 1 diffusée hier matin. twitter.com/Europe1/status…
------
Ce débat risque/opportunité entre 
@ylecun
 et Yoshua Bengio mérite vraiment d'être lu (malheureusement sous paywall)  et me semble être largement en faveur de Le Cun (opportunité) qui met en avant de nombreux exemples concrets de traitement des menaces.
------
The fact that you can employ people to work for you that are smarter than you does not make your job disappear.

Similarly, we will all have AI assistants working with us that are smarter than us but will not make our job disappear.

It will make us smarter & more efficient.
------
Dans le cadre de notre club "Chatham House", nous recevons ce soir 
@ylecun
, VP & Chief AI Scientist 
@Meta
.

Une discussion passionnante et franche sur les perspectives de l'#IA, co-organisée avec l'équipe de 
@MetaFrance
. 

Un grand merci à tous pour la richesse des échanges ! 
------
Conversation (intime) avec 
@ylecun
 merci 
@MetaFrance
 et 
@RNumerique
 #LLMs #LLaMA cc 
@venries
 @faycalBoujemaa  #GenAI « ma prédiction : les gagnants seront les modèles ouverts »
------
Voice box: can synthesize multiple voices from text, clean up speech, can use a voice recording to synthesize the same voice in another language, etc.
From Meta AI.
------
Introducing Voicebox, a new breakthrough generative speech system based on Flow Matching, a new method proposed by Meta AI. It can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.

More details on this work & examples 
------
I like this paper. They prove that transformers are guaranteed to suffer from compounding errors when doing long reasoning chains (as 
@ylecun
  has argued), and much apparent "success" is just due to unreliable pattern matching / shortcut learning.
------
Demain matin à 8h13 sur Europe 1.
------
 Ce vendredi 16 juin à 8h13 sur #Europe1

 @dimitripavlenko reçoit @ylecun, vice-président du groupe chargé de l'IA chez @Meta
------
(1/2) BB3 data analysis: lots of troll users, but they're v. useful for training robust models. BB3 is superhuman, BB3x is more(!) superhuman. Still lots of scope.
------
A summary of my debate with 
@JacquesAttalie
 at Vivatech yesterday on CNBC.
------
Yoshua Bengio et moi débatterons en direct de la question "comment dépasser la guerre des intelligences ?" le mardi 11 juillet, dans le cadre des 37èmes Roncontres de Pétrarque organisées et diffusées par France Culture.
------
.
@ylecun
 shares his vision on #AI 

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives" 
By 
@VivaTech
 
v/ 
@jblefevre60
 
#VivaTech 

@JagersbergKnut
 
@theomitsa
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
How to shoot yourself in the foot with a bazooka in the form of insane immigration laws.
------
Nearly 40,000 foreign-born graduates of U.S. universities were recruited to Canada from 2017 to 2021. The USA is forcing some of the smartest people leave. 

The likelihood of getting an H1B went down from 1 in 4 to now 1 in 7 due to completely arbitrary caps set long ago. twitter.com/LettieriDC/sta…
------
After an impressive first salvo by GPT-4, I score this battle as a clear victory for 
@MIT
 seniors. 

John Henry would be proud.
------
For those who (like me) were interested in the "GPT can ace MIT" paper, 

Here's a great short writeup by three MIT EECS seniors explaining the many things wrong with analysis.

https://dub.sh/gptsucksatmit
------
So that paper about how GPT-4 could ace MIT's curriculum turns out to be deeply flawed in multiple ways. A great reminder that preprints are not peer-reviewed, but also that public volunteer review can be excellent (in this case, by a group of undergrads).
------
I’m incredibly excited to share a sneak peak of 
@wayve_ai
’s GAIA-1, a major step forward in action and language-conditioned world models for #AutonomousDriving. Here’s a glimpse of what GAIA-1 can do - more in the . (These are not real videos!)  But what's a world model?
------
Getting the insights of those pushing the frontier of technology is a necessity for effective regulation that does not hinder development. I very much enjoyed discussing the future of A.I. and regulation with 
@ylecun
.
------
Enregistrement complet de mon interview avec 
@dimitripavlenko

diffusée sur Europe 1 vendredi matin.
------
Une interview sur Europe 1 diffusée hier matin.
------
« En tant qu’humain, on est toujours troublé quand quelque chose est capable de parler, on lui attribue automatiquement une intelligence, mais c’est une erreur »,  selon @ylecun, vice-président du groupe chargé de l'IA chez @Meta à propos de l’intelligence artificielle #Europe1
------
Interview complète
------
i love the distinction between thought and language 
@ylecun
 makes here.

interacting a lot with LLMs made clear to me that the struggle of finding words, of trying them out to express a thought I feel … is unknown to LLMs.

intelligence is more than language.
It is a series of… Show more
------
Une interview sur Europe 1 diffusée hier matin. twitter.com/Europe1/status…
------
Ce débat risque/opportunité entre 
@ylecun
 et Yoshua Bengio mérite vraiment d'être lu (malheureusement sous paywall)  et me semble être largement en faveur de Le Cun (opportunité) qui met en avant de nombreux exemples concrets de traitement des menaces.
------
The fact that you can employ people to work for you that are smarter than you does not make your job disappear.

Similarly, we will all have AI assistants working with us that are smarter than us but will not make our job disappear.

It will make us smarter & more efficient.
------
Dans le cadre de notre club "Chatham House", nous recevons ce soir 
@ylecun
, VP & Chief AI Scientist 
@Meta
.

Une discussion passionnante et franche sur les perspectives de l'#IA, co-organisée avec l'équipe de 
@MetaFrance
. 

Un grand merci à tous pour la richesse des échanges ! 
------
Conversation (intime) avec 
@ylecun
 merci 
@MetaFrance
 et 
@RNumerique
 #LLMs #LLaMA cc 
@venries
 @faycalBoujemaa  #GenAI « ma prédiction : les gagnants seront les modèles ouverts »
------
Voice box: can synthesize multiple voices from text, clean up speech, can use a voice recording to synthesize the same voice in another language, etc.
From Meta AI.
------
Introducing Voicebox, a new breakthrough generative speech system based on Flow Matching, a new method proposed by Meta AI. It can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.

More details on this work & examples 
------
I like this paper. They prove that transformers are guaranteed to suffer from compounding errors when doing long reasoning chains (as 
@ylecun
  has argued), and much apparent "success" is just due to unreliable pattern matching / shortcut learning.
------
Demain matin à 8h13 sur Europe 1.
------
 Ce vendredi 16 juin à 8h13 sur #Europe1

 @dimitripavlenko reçoit @ylecun, vice-président du groupe chargé de l'IA chez @Meta
------
(1/2) BB3 data analysis: lots of troll users, but they're v. useful for training robust models. BB3 is superhuman, BB3x is more(!) superhuman. Still lots of scope.
------
A summary of my debate with 
@JacquesAttalie
 at Vivatech yesterday on CNBC.
------
Yoshua Bengio et moi débatterons en direct de la question "comment dépasser la guerre des intelligences ?" le mardi 11 juillet, dans le cadre des 37èmes Roncontres de Pétrarque organisées et diffusées par France Culture.
------
.
@ylecun
 shares his vision on #AI 

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives" 
By 
@VivaTech
 
v/ 
@jblefevre60
 
#VivaTech 

@JagersbergKnut
 
@theomitsa
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
Getting the insights of those pushing the frontier of technology is a necessity for effective regulation that does not hinder development. I very much enjoyed discussing the future of A.I. and regulation with 
@ylecun
.
------
Enregistrement complet de mon interview avec 
@dimitripavlenko

diffusée sur Europe 1 vendredi matin.
------
Une interview sur Europe 1 diffusée hier matin.
------
« En tant qu’humain, on est toujours troublé quand quelque chose est capable de parler, on lui attribue automatiquement une intelligence, mais c’est une erreur »,  selon @ylecun, vice-président du groupe chargé de l'IA chez @Meta à propos de l’intelligence artificielle #Europe1
------
Interview complète
------
i love the distinction between thought and language 
@ylecun
 makes here.

interacting a lot with LLMs made clear to me that the struggle of finding words, of trying them out to express a thought I feel … is unknown to LLMs.

intelligence is more than language.
It is a series of… Show more
------
Une interview sur Europe 1 diffusée hier matin. twitter.com/Europe1/status…
------
Ce débat risque/opportunité entre 
@ylecun
 et Yoshua Bengio mérite vraiment d'être lu (malheureusement sous paywall)  et me semble être largement en faveur de Le Cun (opportunité) qui met en avant de nombreux exemples concrets de traitement des menaces.
------
The fact that you can employ people to work for you that are smarter than you does not make your job disappear.

Similarly, we will all have AI assistants working with us that are smarter than us but will not make our job disappear.

It will make us smarter & more efficient.
------
Dans le cadre de notre club "Chatham House", nous recevons ce soir 
@ylecun
, VP & Chief AI Scientist 
@Meta
.

Une discussion passionnante et franche sur les perspectives de l'#IA, co-organisée avec l'équipe de 
@MetaFrance
. 

Un grand merci à tous pour la richesse des échanges ! 
------
Conversation (intime) avec 
@ylecun
 merci 
@MetaFrance
 et 
@RNumerique
 #LLMs #LLaMA cc 
@venries
 @faycalBoujemaa  #GenAI « ma prédiction : les gagnants seront les modèles ouverts »
------
Voice box: can synthesize multiple voices from text, clean up speech, can use a voice recording to synthesize the same voice in another language, etc.
From Meta AI.
------
Introducing Voicebox, a new breakthrough generative speech system based on Flow Matching, a new method proposed by Meta AI. It can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.

More details on this work & examples 
------
I like this paper. They prove that transformers are guaranteed to suffer from compounding errors when doing long reasoning chains (as 
@ylecun
  has argued), and much apparent "success" is just due to unreliable pattern matching / shortcut learning.
------
Demain matin à 8h13 sur Europe 1.
------
 Ce vendredi 16 juin à 8h13 sur #Europe1

 @dimitripavlenko reçoit @ylecun, vice-président du groupe chargé de l'IA chez @Meta
------
(1/2) BB3 data analysis: lots of troll users, but they're v. useful for training robust models. BB3 is superhuman, BB3x is more(!) superhuman. Still lots of scope.
------
A summary of my debate with 
@JacquesAttalie
 at Vivatech yesterday on CNBC.
------
Yoshua Bengio et moi débatterons en direct de la question "comment dépasser la guerre des intelligences ?" le mardi 11 juillet, dans le cadre des 37èmes Roncontres de Pétrarque organisées et diffusées par France Culture.
------
.
@ylecun
 shares his vision on #AI 

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives" 
By 
@VivaTech
 
v/ 
@jblefevre60
 
#VivaTech 

@JagersbergKnut
 
@theomitsa
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
Very excited to share our latest research work, MusicGen, released last Friday! MusicGen is a language model for textually and melody-guided music generation. 

 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models: https://github.com/facebookresearch/audiocraft…
 Samples: https://ai.honu.io/papers/musicgen/…
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
All 's on AI...

Yann LeCun 
@ylecun
, VP & Chief AI Scientist 
@Meta
, & Jacques Attali 
@jattali
, Futurologist & President 
@AttaliAssocies
, join us at #VivaTech to delve into the  of #AI & #tech!


@nxthompson
, CEO 
@theatlantic
------
New paper!
Ania 
@MolecularRobot
 Dawid did a fantastic job transcribing my lectures on Energy-Based Models that I gave at the summer school in Les Houches last year.
------
[beware, Tweet contains paper placement]
It was for sure interesting to understand better latent variable energy-based models and Yann's proposal. Check out our notes following @ylecun's three lectures at the Summer School on ML&Stat Phys! #LesHouches2022
https://arxiv.org/abs/2306.02572
------
Standing room only for Meta’s 
@ylecun
 and his optimistic take on the future of AI. Nice job by 
@TheAtlantic
 Nick Thompson. #VivaTech #Paris
------
Thank you to everyone who attended or tried to attend 
------
Salle comble pour la prise de parole de ⁦@ylecun⁩ à #Vivatech. Dans le Metavers on aurait pas ce genre de problème…
------
Arthur Mensch, cofounder of French AI startup Mistral, asking 
@EmmanuelMacron
 about EU-level regulation of AI.

Answers:
1. premature regulation would stifle innovation.
2. More investment in computing infrastructure. France has an advantage: low-emission nuclear energy.
3. "We… Show more
------
Interview complète
------
i love the distinction between thought and language 
@ylecun
 makes here.

interacting a lot with LLMs made clear to me that the struggle of finding words, of trying them out to express a thought I feel … is unknown to LLMs.

intelligence is more than language.
It is a series of… Show more
------
Une interview sur Europe 1 diffusée hier matin. twitter.com/Europe1/status…
------
Ce débat risque/opportunité entre 
@ylecun
 et Yoshua Bengio mérite vraiment d'être lu (malheureusement sous paywall)  et me semble être largement en faveur de Le Cun (opportunité) qui met en avant de nombreux exemples concrets de traitement des menaces.
------
The fact that you can employ people to work for you that are smarter than you does not make your job disappear.

Similarly, we will all have AI assistants working with us that are smarter than us but will not make our job disappear.

It will make us smarter & more efficient.
------
Dans le cadre de notre club "Chatham House", nous recevons ce soir 
@ylecun
, VP & Chief AI Scientist 
@Meta
.

Une discussion passionnante et franche sur les perspectives de l'#IA, co-organisée avec l'équipe de 
@MetaFrance
. 

Un grand merci à tous pour la richesse des échanges ! 
------
Conversation (intime) avec 
@ylecun
 merci 
@MetaFrance
 et 
@RNumerique
 #LLMs #LLaMA cc 
@venries
 @faycalBoujemaa  #GenAI « ma prédiction : les gagnants seront les modèles ouverts »
------
Voice box: can synthesize multiple voices from text, clean up speech, can use a voice recording to synthesize the same voice in another language, etc.
From Meta AI.
------
Introducing Voicebox, a new breakthrough generative speech system based on Flow Matching, a new method proposed by Meta AI. It can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.

More details on this work & examples 
------
I like this paper. They prove that transformers are guaranteed to suffer from compounding errors when doing long reasoning chains (as 
@ylecun
  has argued), and much apparent "success" is just due to unreliable pattern matching / shortcut learning.
------
Demain matin à 8h13 sur Europe 1.
------
 Ce vendredi 16 juin à 8h13 sur #Europe1

 @dimitripavlenko reçoit @ylecun, vice-président du groupe chargé de l'IA chez @Meta
------
(1/2) BB3 data analysis: lots of troll users, but they're v. useful for training robust models. BB3 is superhuman, BB3x is more(!) superhuman. Still lots of scope.
------
A summary of my debate with 
@JacquesAttalie
 at Vivatech yesterday on CNBC.
------
Yoshua Bengio et moi débatterons en direct de la question "comment dépasser la guerre des intelligences ?" le mardi 11 juillet, dans le cadre des 37èmes Roncontres de Pétrarque organisées et diffusées par France Culture.
------
.
@ylecun
 shares his vision on #AI 

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives" 
By 
@VivaTech
 
v/ 
@jblefevre60
 
#VivaTech 

@JagersbergKnut
 
@theomitsa
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
Very excited to share our latest research work, MusicGen, released last Friday! MusicGen is a language model for textually and melody-guided music generation. 

 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models: https://github.com/facebookresearch/audiocraft…
 Samples: https://ai.honu.io/papers/musicgen/…
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
All 's on AI...

Yann LeCun 
@ylecun
, VP & Chief AI Scientist 
@Meta
, & Jacques Attali 
@jattali
, Futurologist & President 
@AttaliAssocies
, join us at #VivaTech to delve into the  of #AI & #tech!


@nxthompson
, CEO 
@theatlantic
------
New paper!
Ania 
@MolecularRobot
 Dawid did a fantastic job transcribing my lectures on Energy-Based Models that I gave at the summer school in Les Houches last year.
------
[beware, Tweet contains paper placement]
It was for sure interesting to understand better latent variable energy-based models and Yann's proposal. Check out our notes following @ylecun's three lectures at the Summer School on ML&Stat Phys! #LesHouches2022
https://arxiv.org/abs/2306.02572
------
Standing room only for Meta’s 
@ylecun
 and his optimistic take on the future of AI. Nice job by 
@TheAtlantic
 Nick Thompson. #VivaTech #Paris
------
Thank you to everyone who attended or tried to attend 
------
Salle comble pour la prise de parole de ⁦@ylecun⁩ à #Vivatech. Dans le Metavers on aurait pas ce genre de problème…
------
Arthur Mensch, cofounder of French AI startup Mistral, asking 
@EmmanuelMacron
 about EU-level regulation of AI.

Answers:
1. premature regulation would stifle innovation.
2. More investment in computing infrastructure. France has an advantage: low-emission nuclear energy.
3. "We… Show more
------
Président 
@EmmanuelMacron
 on stage at Vivatech with startup founders.
------
At Vivatech
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Joëlle Pineau 
@jpineau1
 on stage at Vivatech.
------
Mistral gagnant?
https://fr.wikipedia.org/wiki/Mistral_gagnant_%28confiserie%29?wprov=sfla1…
------
France's Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI https://tcrn.ch/3N2P4iB by @ingridlunden
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
Conversation (intime) avec 
@ylecun
 merci 
@MetaFrance
 et 
@RNumerique
 #LLMs #LLaMA cc 
@venries
 @faycalBoujemaa  #GenAI « ma prédiction : les gagnants seront les modèles ouverts »
------
Voice box: can synthesize multiple voices from text, clean up speech, can use a voice recording to synthesize the same voice in another language, etc.
From Meta AI.
------
Introducing Voicebox, a new breakthrough generative speech system based on Flow Matching, a new method proposed by Meta AI. It can synthesize speech across six languages, perform noise removal, edit content, transfer audio style & more.

More details on this work & examples 
------
I like this paper. They prove that transformers are guaranteed to suffer from compounding errors when doing long reasoning chains (as 
@ylecun
  has argued), and much apparent "success" is just due to unreliable pattern matching / shortcut learning.
------
Demain matin à 8h13 sur Europe 1.
------
 Ce vendredi 16 juin à 8h13 sur #Europe1

 @dimitripavlenko reçoit @ylecun, vice-président du groupe chargé de l'IA chez @Meta
------
(1/2) BB3 data analysis: lots of troll users, but they're v. useful for training robust models. BB3 is superhuman, BB3x is more(!) superhuman. Still lots of scope.
------
A summary of my debate with 
@JacquesAttalie
 at Vivatech yesterday on CNBC.
------
Yoshua Bengio et moi débatterons en direct de la question "comment dépasser la guerre des intelligences ?" le mardi 11 juillet, dans le cadre des 37èmes Roncontres de Pétrarque organisées et diffusées par France Culture.
------
.
@ylecun
 shares his vision on #AI 

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives" 
By 
@VivaTech
 
v/ 
@jblefevre60
 
#VivaTech 

@JagersbergKnut
 
@theomitsa
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
Very excited to share our latest research work, MusicGen, released last Friday! MusicGen is a language model for textually and melody-guided music generation. 

 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models: https://github.com/facebookresearch/audiocraft…
 Samples: https://ai.honu.io/papers/musicgen/…
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
All 's on AI...

Yann LeCun 
@ylecun
, VP & Chief AI Scientist 
@Meta
, & Jacques Attali 
@jattali
, Futurologist & President 
@AttaliAssocies
, join us at #VivaTech to delve into the  of #AI & #tech!


@nxthompson
, CEO 
@theatlantic
------
New paper!
Ania 
@MolecularRobot
 Dawid did a fantastic job transcribing my lectures on Energy-Based Models that I gave at the summer school in Les Houches last year.
------
[beware, Tweet contains paper placement]
It was for sure interesting to understand better latent variable energy-based models and Yann's proposal. Check out our notes following @ylecun's three lectures at the Summer School on ML&Stat Phys! #LesHouches2022
https://arxiv.org/abs/2306.02572
------
Standing room only for Meta’s 
@ylecun
 and his optimistic take on the future of AI. Nice job by 
@TheAtlantic
 Nick Thompson. #VivaTech #Paris
------
Thank you to everyone who attended or tried to attend 
------
Salle comble pour la prise de parole de ⁦@ylecun⁩ à #Vivatech. Dans le Metavers on aurait pas ce genre de problème…
------
Arthur Mensch, cofounder of French AI startup Mistral, asking 
@EmmanuelMacron
 about EU-level regulation of AI.

Answers:
1. premature regulation would stifle innovation.
2. More investment in computing infrastructure. France has an advantage: low-emission nuclear energy.
3. "We… Show more
------
Président 
@EmmanuelMacron
 on stage at Vivatech with startup founders.
------
At Vivatech
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Joëlle Pineau 
@jpineau1
 on stage at Vivatech.
------
Mistral gagnant?
https://fr.wikipedia.org/wiki/Mistral_gagnant_%28confiserie%29?wprov=sfla1…
------
France's Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI https://tcrn.ch/3N2P4iB by @ingridlunden
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
We just released a new optimizer Prodigy. Based on D-Adaptation, Prodigy has stronger theoretical guarantees and we derive how to estimate the stepsize for Adam. We tested it on a wide range of deep nets, so I can confidently say: it does work in practice.
https://arxiv.org/abs/2306.06101
------
Old joke.
------
In 1961 it was predicted most unskilled jobs would be gone by 1971.  twitter.com/levie/status/1…
------
MusicGen rocks.
Literally.
------
Official MusicGen now also supports extended generation (different implem, same idea). Go to our colab to test it. And keep an eye on @camenduru for more cool stuff!
Of course, I tested it with an Interstellar deep remix as lo-fi with organic samples :)

https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing…
------
A summary of my debate with 
@JacquesAttalie
 at Vivatech yesterday on CNBC.
------
Yoshua Bengio et moi débatterons en direct de la question "comment dépasser la guerre des intelligences ?" le mardi 11 juillet, dans le cadre des 37èmes Roncontres de Pétrarque organisées et diffusées par France Culture.
------
.
@ylecun
 shares his vision on #AI 

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives" 
By 
@VivaTech
 
v/ 
@jblefevre60
 
#VivaTech 

@JagersbergKnut
 
@theomitsa
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
Very excited to share our latest research work, MusicGen, released last Friday! MusicGen is a language model for textually and melody-guided music generation. 

 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models: https://github.com/facebookresearch/audiocraft…
 Samples: https://ai.honu.io/papers/musicgen/…
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
All 's on AI...

Yann LeCun 
@ylecun
, VP & Chief AI Scientist 
@Meta
, & Jacques Attali 
@jattali
, Futurologist & President 
@AttaliAssocies
, join us at #VivaTech to delve into the  of #AI & #tech!


@nxthompson
, CEO 
@theatlantic
------
New paper!
Ania 
@MolecularRobot
 Dawid did a fantastic job transcribing my lectures on Energy-Based Models that I gave at the summer school in Les Houches last year.
------
[beware, Tweet contains paper placement]
It was for sure interesting to understand better latent variable energy-based models and Yann's proposal. Check out our notes following @ylecun's three lectures at the Summer School on ML&Stat Phys! #LesHouches2022
https://arxiv.org/abs/2306.02572
------
Standing room only for Meta’s 
@ylecun
 and his optimistic take on the future of AI. Nice job by 
@TheAtlantic
 Nick Thompson. #VivaTech #Paris
------
Thank you to everyone who attended or tried to attend 
------
Salle comble pour la prise de parole de ⁦@ylecun⁩ à #Vivatech. Dans le Metavers on aurait pas ce genre de problème…
------
Arthur Mensch, cofounder of French AI startup Mistral, asking 
@EmmanuelMacron
 about EU-level regulation of AI.

Answers:
1. premature regulation would stifle innovation.
2. More investment in computing infrastructure. France has an advantage: low-emission nuclear energy.
3. "We… Show more
------
Président 
@EmmanuelMacron
 on stage at Vivatech with startup founders.
------
At Vivatech
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Joëlle Pineau 
@jpineau1
 on stage at Vivatech.
------
Mistral gagnant?
https://fr.wikipedia.org/wiki/Mistral_gagnant_%28confiserie%29?wprov=sfla1…
------
France's Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI https://tcrn.ch/3N2P4iB by @ingridlunden
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
We just released a new optimizer Prodigy. Based on D-Adaptation, Prodigy has stronger theoretical guarantees and we derive how to estimate the stepsize for Adam. We tested it on a wide range of deep nets, so I can confidently say: it does work in practice.
https://arxiv.org/abs/2306.06101
------
Old joke.
------
In 1961 it was predicted most unskilled jobs would be gone by 1971.  twitter.com/levie/status/1…
------
MusicGen rocks.
Literally.
------
Official MusicGen now also supports extended generation (different implem, same idea). Go to our colab to test it. And keep an eye on @camenduru for more cool stuff!
Of course, I tested it with an Interstellar deep remix as lo-fi with organic samples :)

https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing…
------
Our work on the Massively Multilingual Speech (MMS) project has scaled speech-to-text & text-to-speech to support 1,100+ languages + trained new language identification models that can identify 4,000+ languages!

More info & access to pretrained models 
------
I-JEPA: Efficient method for Self-Supervised Learning of image features.
No need for data augmentation, just masking.
Joint embedding predictive architecture, not generative.
And it's open source, of course.

Blog: https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/…
Paper: https://arxiv.org/abs/2301.08243
Code &… Show more
------
Today we're releasing our work on I-JEPA — self-supervised computer vision that learns to understand the world by predicting it. It's the first model based on a component of @ylecun's vision to make AI systems learn and reason like animals and humans.

Details 
------
Introducing that simple idea :

Split Audio Tracks to MusicGen

Use Demucs to split your favorite song into tracks, then send one to MusicGen to get a completely new music piece ! 

Give it a try 
@huggingface
 https://huggingface.co/spaces/fffiloni/SplitTrack2MusicGen…
------
Best degense against human extinction by rogue AGIs:
Get them to destroy each other in a religious war over the ultimate question:
Vi vs Emacs.
------
A good article by the BBC about my views on the future of AI.
A pretty good summary of opinions I expressed at the Innovation Press Day held at Meta-Paris Tuesday.
------
Very excited to share our latest research work, MusicGen, released last Friday! MusicGen is a language model for textually and melody-guided music generation. 

 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models: https://github.com/facebookresearch/audiocraft…
 Samples: https://ai.honu.io/papers/musicgen/…
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
All 's on AI...

Yann LeCun 
@ylecun
, VP & Chief AI Scientist 
@Meta
, & Jacques Attali 
@jattali
, Futurologist & President 
@AttaliAssocies
, join us at #VivaTech to delve into the  of #AI & #tech!


@nxthompson
, CEO 
@theatlantic
------
New paper!
Ania 
@MolecularRobot
 Dawid did a fantastic job transcribing my lectures on Energy-Based Models that I gave at the summer school in Les Houches last year.
------
[beware, Tweet contains paper placement]
It was for sure interesting to understand better latent variable energy-based models and Yann's proposal. Check out our notes following @ylecun's three lectures at the Summer School on ML&Stat Phys! #LesHouches2022
https://arxiv.org/abs/2306.02572
------
Standing room only for Meta’s 
@ylecun
 and his optimistic take on the future of AI. Nice job by 
@TheAtlantic
 Nick Thompson. #VivaTech #Paris
------
Thank you to everyone who attended or tried to attend 
------
Salle comble pour la prise de parole de ⁦@ylecun⁩ à #Vivatech. Dans le Metavers on aurait pas ce genre de problème…
------
Arthur Mensch, cofounder of French AI startup Mistral, asking 
@EmmanuelMacron
 about EU-level regulation of AI.

Answers:
1. premature regulation would stifle innovation.
2. More investment in computing infrastructure. France has an advantage: low-emission nuclear energy.
3. "We… Show more
------
Président 
@EmmanuelMacron
 on stage at Vivatech with startup founders.
------
At Vivatech
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Joëlle Pineau 
@jpineau1
 on stage at Vivatech.
------
Mistral gagnant?
https://fr.wikipedia.org/wiki/Mistral_gagnant_%28confiserie%29?wprov=sfla1…
------
France's Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI https://tcrn.ch/3N2P4iB by @ingridlunden
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
We just released a new optimizer Prodigy. Based on D-Adaptation, Prodigy has stronger theoretical guarantees and we derive how to estimate the stepsize for Adam. We tested it on a wide range of deep nets, so I can confidently say: it does work in practice.
https://arxiv.org/abs/2306.06101
------
Old joke.
------
In 1961 it was predicted most unskilled jobs would be gone by 1971.  twitter.com/levie/status/1…
------
MusicGen rocks.
Literally.
------
Official MusicGen now also supports extended generation (different implem, same idea). Go to our colab to test it. And keep an eye on @camenduru for more cool stuff!
Of course, I tested it with an Interstellar deep remix as lo-fi with organic samples :)

https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing…
------
Our work on the Massively Multilingual Speech (MMS) project has scaled speech-to-text & text-to-speech to support 1,100+ languages + trained new language identification models that can identify 4,000+ languages!

More info & access to pretrained models 
------
I-JEPA: Efficient method for Self-Supervised Learning of image features.
No need for data augmentation, just masking.
Joint embedding predictive architecture, not generative.
And it's open source, of course.

Blog: https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/…
Paper: https://arxiv.org/abs/2301.08243
Code &… Show more
------
Today we're releasing our work on I-JEPA — self-supervised computer vision that learns to understand the world by predicting it. It's the first model based on a component of @ylecun's vision to make AI systems learn and reason like animals and humans.

Details 
------
Introducing that simple idea :

Split Audio Tracks to MusicGen

Use Demucs to split your favorite song into tracks, then send one to MusicGen to get a completely new music piece ! 

Give it a try 
@huggingface
 https://huggingface.co/spaces/fffiloni/SplitTrack2MusicGen…
------
Best degense against human extinction by rogue AGIs:
Get them to destroy each other in a religious war over the ultimate question:
Vi vs Emacs.
------
World models in autonomous driving FTW!
------
I agree with @ylecun and think autonomous driving is the best place to start. As an example, here's a generated video (this is not real!) from our AI's world model showing it is capable of reasoning and imagining  about overtaking a bus.  twitter.com/ylecun/status/…
------
Exactly.
Just because Auto-Regressive LLMs are not controllable doesn't mean that future AI system won't be controllable.
In fact, we've been focusing on Objective-Driven AI architectures in part *because* they are controllable, and also because they can reason and plan.
------
ai's are going to be very controllable. more than people realize today. we should stop fretting about runaway x-risk, and focus instead on what happens when everyone has the most powerful force amplifier in human history... that could cause near-term chaos
------
I expect artificial intelligence to power a productivity boom in the coming years: https://brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/…

However, it’s not at all obvious that that will translate into higher stock prices on average.  The distribution of gains depends on the nature of competition.
------
From @TheEconomist : Tracing the recent stockmarket surge to AI.
7/n

https://economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence…
------
Plongez dans l'ère de la performance et des possibilités ouvertes par l’ #IA avec Meta à #VivaTech ! Découvrez le fruit de plus de 10 ans de recherches en IA, ainsi que nos projets en cours pour mettre l’IA au service de votre activité #MetaAtVivaTech #MetaStandF38
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Standing room only for Meta’s 
@ylecun
 and his optimistic take on the future of AI. Nice job by 
@TheAtlantic
 Nick Thompson. #VivaTech #Paris
------
Thank you to everyone who attended or tried to attend 
------
Salle comble pour la prise de parole de ⁦@ylecun⁩ à #Vivatech. Dans le Metavers on aurait pas ce genre de problème…
------
Arthur Mensch, cofounder of French AI startup Mistral, asking 
@EmmanuelMacron
 about EU-level regulation of AI.

Answers:
1. premature regulation would stifle innovation.
2. More investment in computing infrastructure. France has an advantage: low-emission nuclear energy.
3. "We… Show more
------
Président 
@EmmanuelMacron
 on stage at Vivatech with startup founders.
------
At Vivatech
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Joëlle Pineau 
@jpineau1
 on stage at Vivatech.
------
Mistral gagnant?
https://fr.wikipedia.org/wiki/Mistral_gagnant_%28confiserie%29?wprov=sfla1…
------
France's Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI https://tcrn.ch/3N2P4iB by @ingridlunden
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
We just released a new optimizer Prodigy. Based on D-Adaptation, Prodigy has stronger theoretical guarantees and we derive how to estimate the stepsize for Adam. We tested it on a wide range of deep nets, so I can confidently say: it does work in practice.
https://arxiv.org/abs/2306.06101
------
Old joke.
------
In 1961 it was predicted most unskilled jobs would be gone by 1971.  twitter.com/levie/status/1…
------
MusicGen rocks.
Literally.
------
Official MusicGen now also supports extended generation (different implem, same idea). Go to our colab to test it. And keep an eye on @camenduru for more cool stuff!
Of course, I tested it with an Interstellar deep remix as lo-fi with organic samples :)

https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing…
------
Our work on the Massively Multilingual Speech (MMS) project has scaled speech-to-text & text-to-speech to support 1,100+ languages + trained new language identification models that can identify 4,000+ languages!

More info & access to pretrained models 
------
I-JEPA: Efficient method for Self-Supervised Learning of image features.
No need for data augmentation, just masking.
Joint embedding predictive architecture, not generative.
And it's open source, of course.

Blog: https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/…
Paper: https://arxiv.org/abs/2301.08243
Code &… Show more
------
Today we're releasing our work on I-JEPA — self-supervised computer vision that learns to understand the world by predicting it. It's the first model based on a component of @ylecun's vision to make AI systems learn and reason like animals and humans.

Details 
------
Introducing that simple idea :

Split Audio Tracks to MusicGen

Use Demucs to split your favorite song into tracks, then send one to MusicGen to get a completely new music piece ! 

Give it a try 
@huggingface
 https://huggingface.co/spaces/fffiloni/SplitTrack2MusicGen…
------
Best degense against human extinction by rogue AGIs:
Get them to destroy each other in a religious war over the ultimate question:
Vi vs Emacs.
------
World models in autonomous driving FTW!
------
I agree with @ylecun and think autonomous driving is the best place to start. As an example, here's a generated video (this is not real!) from our AI's world model showing it is capable of reasoning and imagining  about overtaking a bus.  twitter.com/ylecun/status/…
------
Exactly.
Just because Auto-Regressive LLMs are not controllable doesn't mean that future AI system won't be controllable.
In fact, we've been focusing on Objective-Driven AI architectures in part *because* they are controllable, and also because they can reason and plan.
------
ai's are going to be very controllable. more than people realize today. we should stop fretting about runaway x-risk, and focus instead on what happens when everyone has the most powerful force amplifier in human history... that could cause near-term chaos
------
I expect artificial intelligence to power a productivity boom in the coming years: https://brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/…

However, it’s not at all obvious that that will translate into higher stock prices on average.  The distribution of gains depends on the nature of competition.
------
From @TheEconomist : Tracing the recent stockmarket surge to AI.
7/n

https://economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence…
------
Plongez dans l'ère de la performance et des possibilités ouvertes par l’ #IA avec Meta à #VivaTech ! Découvrez le fruit de plus de 10 ans de recherches en IA, ainsi que nos projets en cours pour mettre l’IA au service de votre activité #MetaAtVivaTech #MetaStandF38
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Perhaps. But the ArXiv->conference paper culture also contributes to accelerating progress.
Think of it as stochastic optimization to a book culture batch optimization. https://twitter.com/pfau/status/1668178996972888064…
------
This is impressive.

META just released MusicGen, a Language Model designed for creating music.

Not just that, it produces high-quality music while being conditioned on text description or melodic features.

Best thing? 

You can try it FREE now.

Here is a Demo of converting… Show more
------
It won't be AGI unless it uses Emacs.
------
AGI will be able to exit vim.
------
tested, not perfect every melody, best one so far!looking forward to generate more than 30 seconds.
https://youtu.be/EWBzTXihiD8 来自 
@YouTube
 
@camenduru
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Président 
@EmmanuelMacron
 on stage at Vivatech with startup founders.
------
At Vivatech
------
Yann LeCun @ylecun, VP & Chief AI Scientist @Meta, shares his vision on #AI live at #VivaTech

"AI is an amplifier of human intelligence & when people are smarter, better things happen: people are more productive, happier & the economy strives."
------
Joëlle Pineau 
@jpineau1
 on stage at Vivatech.
------
Mistral gagnant?
https://fr.wikipedia.org/wiki/Mistral_gagnant_%28confiserie%29?wprov=sfla1…
------
France's Mistral AI blows in with a $113M seed round at a $260M valuation to take on OpenAI https://tcrn.ch/3N2P4iB by @ingridlunden
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
We just released a new optimizer Prodigy. Based on D-Adaptation, Prodigy has stronger theoretical guarantees and we derive how to estimate the stepsize for Adam. We tested it on a wide range of deep nets, so I can confidently say: it does work in practice.
https://arxiv.org/abs/2306.06101
------
Old joke.
------
In 1961 it was predicted most unskilled jobs would be gone by 1971.  twitter.com/levie/status/1…
------
MusicGen rocks.
Literally.
------
Official MusicGen now also supports extended generation (different implem, same idea). Go to our colab to test it. And keep an eye on @camenduru for more cool stuff!
Of course, I tested it with an Interstellar deep remix as lo-fi with organic samples :)

https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing…
------
Our work on the Massively Multilingual Speech (MMS) project has scaled speech-to-text & text-to-speech to support 1,100+ languages + trained new language identification models that can identify 4,000+ languages!

More info & access to pretrained models 
------
I-JEPA: Efficient method for Self-Supervised Learning of image features.
No need for data augmentation, just masking.
Joint embedding predictive architecture, not generative.
And it's open source, of course.

Blog: https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/…
Paper: https://arxiv.org/abs/2301.08243
Code &… Show more
------
Today we're releasing our work on I-JEPA — self-supervised computer vision that learns to understand the world by predicting it. It's the first model based on a component of @ylecun's vision to make AI systems learn and reason like animals and humans.

Details 
------
Introducing that simple idea :

Split Audio Tracks to MusicGen

Use Demucs to split your favorite song into tracks, then send one to MusicGen to get a completely new music piece ! 

Give it a try 
@huggingface
 https://huggingface.co/spaces/fffiloni/SplitTrack2MusicGen…
------
Best degense against human extinction by rogue AGIs:
Get them to destroy each other in a religious war over the ultimate question:
Vi vs Emacs.
------
World models in autonomous driving FTW!
------
I agree with @ylecun and think autonomous driving is the best place to start. As an example, here's a generated video (this is not real!) from our AI's world model showing it is capable of reasoning and imagining  about overtaking a bus.  twitter.com/ylecun/status/…
------
Exactly.
Just because Auto-Regressive LLMs are not controllable doesn't mean that future AI system won't be controllable.
In fact, we've been focusing on Objective-Driven AI architectures in part *because* they are controllable, and also because they can reason and plan.
------
ai's are going to be very controllable. more than people realize today. we should stop fretting about runaway x-risk, and focus instead on what happens when everyone has the most powerful force amplifier in human history... that could cause near-term chaos
------
I expect artificial intelligence to power a productivity boom in the coming years: https://brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/…

However, it’s not at all obvious that that will translate into higher stock prices on average.  The distribution of gains depends on the nature of competition.
------
From @TheEconomist : Tracing the recent stockmarket surge to AI.
7/n

https://economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence…
------
Plongez dans l'ère de la performance et des possibilités ouvertes par l’ #IA avec Meta à #VivaTech ! Découvrez le fruit de plus de 10 ans de recherches en IA, ainsi que nos projets en cours pour mettre l’IA au service de votre activité #MetaAtVivaTech #MetaStandF38
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Perhaps. But the ArXiv->conference paper culture also contributes to accelerating progress.
Think of it as stochastic optimization to a book culture batch optimization. https://twitter.com/pfau/status/1668178996972888064…
------
This is impressive.

META just released MusicGen, a Language Model designed for creating music.

Not just that, it produces high-quality music while being conditioned on text description or melodic features.

Best thing? 

You can try it FREE now.

Here is a Demo of converting… Show more
------
It won't be AGI unless it uses Emacs.
------
AGI will be able to exit vim.
------
tested, not perfect every melody, best one so far!looking forward to generate more than 30 seconds.
https://youtu.be/EWBzTXihiD8 来自 
@YouTube
 
@camenduru
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Ask Me Anything about AI, or any of the topics in Why AI Will Save The World, as responses to this tweet and I will answer as many as I can.
------
In response to a discussion between 
@geoffreyhinton
 and 
@AndrewYNg
 about AI risks.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
"The future cannot be predicted, but futures can be invented"  -- Dennis Gabor 1963.
"The best way to predict the future is to invent it"  -- Alan Kay 1971

If you can't predict whether a technology is going to be beneficial or not, build it so it is.

https://quoteinvestigator.com/2012/09/27/invent-the-future/?amp=1…
------
Heureux de débattre avec 
@ylecun
 à 
@VivaTech
 de la question: “ Peut-on on mettre l’Intelligence artificielle au service de l’économie de la vie et de la reconversion de l’économie de la mort?”
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
This little quiz in 
@nytimes
 is quite interesting. It also features some quotes from me, trying to bring some balance to the doomsters.
------
We just released a new optimizer Prodigy. Based on D-Adaptation, Prodigy has stronger theoretical guarantees and we derive how to estimate the stepsize for Adam. We tested it on a wide range of deep nets, so I can confidently say: it does work in practice.
https://arxiv.org/abs/2306.06101
------
Old joke.
------
In 1961 it was predicted most unskilled jobs would be gone by 1971.  twitter.com/levie/status/1…
------
MusicGen rocks.
Literally.
------
Official MusicGen now also supports extended generation (different implem, same idea). Go to our colab to test it. And keep an eye on @camenduru for more cool stuff!
Of course, I tested it with an Interstellar deep remix as lo-fi with organic samples :)

https://colab.research.google.com/drive/1fxGqfg96RBUvGxZ1XXN07s3DthrKUl4-?usp=sharing…
------
Our work on the Massively Multilingual Speech (MMS) project has scaled speech-to-text & text-to-speech to support 1,100+ languages + trained new language identification models that can identify 4,000+ languages!

More info & access to pretrained models 
------
I-JEPA: Efficient method for Self-Supervised Learning of image features.
No need for data augmentation, just masking.
Joint embedding predictive architecture, not generative.
And it's open source, of course.

Blog: https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/…
Paper: https://arxiv.org/abs/2301.08243
Code &… Show more
------
Today we're releasing our work on I-JEPA — self-supervised computer vision that learns to understand the world by predicting it. It's the first model based on a component of @ylecun's vision to make AI systems learn and reason like animals and humans.

Details 
------
Introducing that simple idea :

Split Audio Tracks to MusicGen

Use Demucs to split your favorite song into tracks, then send one to MusicGen to get a completely new music piece ! 

Give it a try 
@huggingface
 https://huggingface.co/spaces/fffiloni/SplitTrack2MusicGen…
------
Best degense against human extinction by rogue AGIs:
Get them to destroy each other in a religious war over the ultimate question:
Vi vs Emacs.
------
World models in autonomous driving FTW!
------
I agree with @ylecun and think autonomous driving is the best place to start. As an example, here's a generated video (this is not real!) from our AI's world model showing it is capable of reasoning and imagining  about overtaking a bus.  twitter.com/ylecun/status/…
------
Exactly.
Just because Auto-Regressive LLMs are not controllable doesn't mean that future AI system won't be controllable.
In fact, we've been focusing on Objective-Driven AI architectures in part *because* they are controllable, and also because they can reason and plan.
------
ai's are going to be very controllable. more than people realize today. we should stop fretting about runaway x-risk, and focus instead on what happens when everyone has the most powerful force amplifier in human history... that could cause near-term chaos
------
I expect artificial intelligence to power a productivity boom in the coming years: https://brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/…

However, it’s not at all obvious that that will translate into higher stock prices on average.  The distribution of gains depends on the nature of competition.
------
From @TheEconomist : Tracing the recent stockmarket surge to AI.
7/n

https://economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence…
------
Plongez dans l'ère de la performance et des possibilités ouvertes par l’ #IA avec Meta à #VivaTech ! Découvrez le fruit de plus de 10 ans de recherches en IA, ainsi que nos projets en cours pour mettre l’IA au service de votre activité #MetaAtVivaTech #MetaStandF38
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Perhaps. But the ArXiv->conference paper culture also contributes to accelerating progress.
Think of it as stochastic optimization to a book culture batch optimization. https://twitter.com/pfau/status/1668178996972888064…
------
This is impressive.

META just released MusicGen, a Language Model designed for creating music.

Not just that, it produces high-quality music while being conditioned on text description or melodic features.

Best thing? 

You can try it FREE now.

Here is a Demo of converting… Show more
------
It won't be AGI unless it uses Emacs.
------
AGI will be able to exit vim.
------
tested, not perfect every melody, best one so far!looking forward to generate more than 30 seconds.
https://youtu.be/EWBzTXihiD8 来自 
@YouTube
 
@camenduru
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Ask Me Anything about AI, or any of the topics in Why AI Will Save The World, as responses to this tweet and I will answer as many as I can.
------
In response to a discussion between 
@geoffreyhinton
 and 
@AndrewYNg
 about AI risks.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
"The future cannot be predicted, but futures can be invented"  -- Dennis Gabor 1963.
"The best way to predict the future is to invent it"  -- Alan Kay 1971

If you can't predict whether a technology is going to be beneficial or not, build it so it is.

https://quoteinvestigator.com/2012/09/27/invent-the-future/?amp=1…
------
Heureux de débattre avec 
@ylecun
 à 
@VivaTech
 de la question: “ Peut-on on mettre l’Intelligence artificielle au service de l’économie de la vie et de la reconversion de l’économie de la mort?”
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Now that 
@sama
 has clarified his comment in Delhi, let me clarify mine further.  

I completely stand by them. 

I’m in the 
@ylecun
 camp & he articulates his viewpoint here very well - 

https://youtu.be/TKW6ojS8afw
------
I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and… Show more
------
Princeton CS professor Arvind Narayanan 
@random_walker
 and PhD student Sayash Kapoor 
@sayashk
 run the "AI Snake Oil" series on Substack.
They are asking the right questions, such as:
- is licensing feasible to address AI risk?
- what are the real risks of AI?
- will open source… Show more
------
MusicGen Colab  Thanks to 
@jadecopet
  
@FelixKreuk
  
@itai_gat
  Tal Remez  David Kant  
@syhw
  
@adiyossLC
  
@honualx
 

page: https://ai.honu.io/papers/musicgen
arxiv: https://arxiv.org/abs/2306.05284
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/MusicGen-colab…
------
Necessary counterpoint.
------
Not really about AI optimism vs. pessimism, but the following is a collection of resources arguing that FOOM (i.e. a fast localized takeoff) is unlikely:
https://magnusvinding.com/2017/12/16/a-contra-ai-foom-reading-list/…
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
Our work on the Massively Multilingual Speech (MMS) project has scaled speech-to-text & text-to-speech to support 1,100+ languages + trained new language identification models that can identify 4,000+ languages!

More info & access to pretrained models 
------
I-JEPA: Efficient method for Self-Supervised Learning of image features.
No need for data augmentation, just masking.
Joint embedding predictive architecture, not generative.
And it's open source, of course.

Blog: https://ai.facebook.com/blog/yann-lecun-ai-model-i-jepa/…
Paper: https://arxiv.org/abs/2301.08243
Code &… Show more
------
Today we're releasing our work on I-JEPA — self-supervised computer vision that learns to understand the world by predicting it. It's the first model based on a component of @ylecun's vision to make AI systems learn and reason like animals and humans.

Details 
------
Introducing that simple idea :

Split Audio Tracks to MusicGen

Use Demucs to split your favorite song into tracks, then send one to MusicGen to get a completely new music piece ! 

Give it a try 
@huggingface
 https://huggingface.co/spaces/fffiloni/SplitTrack2MusicGen…
------
Best degense against human extinction by rogue AGIs:
Get them to destroy each other in a religious war over the ultimate question:
Vi vs Emacs.
------
World models in autonomous driving FTW!
------
I agree with @ylecun and think autonomous driving is the best place to start. As an example, here's a generated video (this is not real!) from our AI's world model showing it is capable of reasoning and imagining  about overtaking a bus.  twitter.com/ylecun/status/…
------
Exactly.
Just because Auto-Regressive LLMs are not controllable doesn't mean that future AI system won't be controllable.
In fact, we've been focusing on Objective-Driven AI architectures in part *because* they are controllable, and also because they can reason and plan.
------
ai's are going to be very controllable. more than people realize today. we should stop fretting about runaway x-risk, and focus instead on what happens when everyone has the most powerful force amplifier in human history... that could cause near-term chaos
------
I expect artificial intelligence to power a productivity boom in the coming years: https://brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/…

However, it’s not at all obvious that that will translate into higher stock prices on average.  The distribution of gains depends on the nature of competition.
------
From @TheEconomist : Tracing the recent stockmarket surge to AI.
7/n

https://economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence…
------
Plongez dans l'ère de la performance et des possibilités ouvertes par l’ #IA avec Meta à #VivaTech ! Découvrez le fruit de plus de 10 ans de recherches en IA, ainsi que nos projets en cours pour mettre l’IA au service de votre activité #MetaAtVivaTech #MetaStandF38
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Perhaps. But the ArXiv->conference paper culture also contributes to accelerating progress.
Think of it as stochastic optimization to a book culture batch optimization. https://twitter.com/pfau/status/1668178996972888064…
------
This is impressive.

META just released MusicGen, a Language Model designed for creating music.

Not just that, it produces high-quality music while being conditioned on text description or melodic features.

Best thing? 

You can try it FREE now.

Here is a Demo of converting… Show more
------
It won't be AGI unless it uses Emacs.
------
AGI will be able to exit vim.
------
tested, not perfect every melody, best one so far!looking forward to generate more than 30 seconds.
https://youtu.be/EWBzTXihiD8 来自 
@YouTube
 
@camenduru
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Ask Me Anything about AI, or any of the topics in Why AI Will Save The World, as responses to this tweet and I will answer as many as I can.
------
In response to a discussion between 
@geoffreyhinton
 and 
@AndrewYNg
 about AI risks.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
"The future cannot be predicted, but futures can be invented"  -- Dennis Gabor 1963.
"The best way to predict the future is to invent it"  -- Alan Kay 1971

If you can't predict whether a technology is going to be beneficial or not, build it so it is.

https://quoteinvestigator.com/2012/09/27/invent-the-future/?amp=1…
------
Heureux de débattre avec 
@ylecun
 à 
@VivaTech
 de la question: “ Peut-on on mettre l’Intelligence artificielle au service de l’économie de la vie et de la reconversion de l’économie de la mort?”
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Now that 
@sama
 has clarified his comment in Delhi, let me clarify mine further.  

I completely stand by them. 

I’m in the 
@ylecun
 camp & he articulates his viewpoint here very well - 

https://youtu.be/TKW6ojS8afw
------
I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and… Show more
------
Princeton CS professor Arvind Narayanan 
@random_walker
 and PhD student Sayash Kapoor 
@sayashk
 run the "AI Snake Oil" series on Substack.
They are asking the right questions, such as:
- is licensing feasible to address AI risk?
- what are the real risks of AI?
- will open source… Show more
------
MusicGen Colab  Thanks to 
@jadecopet
  
@FelixKreuk
  
@itai_gat
  Tal Remez  David Kant  
@syhw
  
@adiyossLC
  
@honualx
 

page: https://ai.honu.io/papers/musicgen
arxiv: https://arxiv.org/abs/2306.05284
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/MusicGen-colab…
------
Necessary counterpoint.
------
Not really about AI optimism vs. pessimism, but the following is a collection of resources arguing that FOOM (i.e. a fast localized takeoff) is unlikely:
https://magnusvinding.com/2017/12/16/a-contra-ai-foom-reading-list/…
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
World models in autonomous driving FTW!
------
I agree with @ylecun and think autonomous driving is the best place to start. As an example, here's a generated video (this is not real!) from our AI's world model showing it is capable of reasoning and imagining  about overtaking a bus.  twitter.com/ylecun/status/…
------
Exactly.
Just because Auto-Regressive LLMs are not controllable doesn't mean that future AI system won't be controllable.
In fact, we've been focusing on Objective-Driven AI architectures in part *because* they are controllable, and also because they can reason and plan.
------
ai's are going to be very controllable. more than people realize today. we should stop fretting about runaway x-risk, and focus instead on what happens when everyone has the most powerful force amplifier in human history... that could cause near-term chaos
------
I expect artificial intelligence to power a productivity boom in the coming years: https://brookings.edu/research/machines-of-mind-the-case-for-an-ai-powered-productivity-boom/…

However, it’s not at all obvious that that will translate into higher stock prices on average.  The distribution of gains depends on the nature of competition.
------
From @TheEconomist : Tracing the recent stockmarket surge to AI.
7/n

https://economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence…
------
Plongez dans l'ère de la performance et des possibilités ouvertes par l’ #IA avec Meta à #VivaTech ! Découvrez le fruit de plus de 10 ans de recherches en IA, ainsi que nos projets en cours pour mettre l’IA au service de votre activité #MetaAtVivaTech #MetaStandF38
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Perhaps. But the ArXiv->conference paper culture also contributes to accelerating progress.
Think of it as stochastic optimization to a book culture batch optimization. https://twitter.com/pfau/status/1668178996972888064…
------
This is impressive.

META just released MusicGen, a Language Model designed for creating music.

Not just that, it produces high-quality music while being conditioned on text description or melodic features.

Best thing? 

You can try it FREE now.

Here is a Demo of converting… Show more
------
It won't be AGI unless it uses Emacs.
------
AGI will be able to exit vim.
------
tested, not perfect every melody, best one so far!looking forward to generate more than 30 seconds.
https://youtu.be/EWBzTXihiD8 来自 
@YouTube
 
@camenduru
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Ask Me Anything about AI, or any of the topics in Why AI Will Save The World, as responses to this tweet and I will answer as many as I can.
------
In response to a discussion between 
@geoffreyhinton
 and 
@AndrewYNg
 about AI risks.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
"The future cannot be predicted, but futures can be invented"  -- Dennis Gabor 1963.
"The best way to predict the future is to invent it"  -- Alan Kay 1971

If you can't predict whether a technology is going to be beneficial or not, build it so it is.

https://quoteinvestigator.com/2012/09/27/invent-the-future/?amp=1…
------
Heureux de débattre avec 
@ylecun
 à 
@VivaTech
 de la question: “ Peut-on on mettre l’Intelligence artificielle au service de l’économie de la vie et de la reconversion de l’économie de la mort?”
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Now that 
@sama
 has clarified his comment in Delhi, let me clarify mine further.  

I completely stand by them. 

I’m in the 
@ylecun
 camp & he articulates his viewpoint here very well - 

https://youtu.be/TKW6ojS8afw
------
I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and… Show more
------
Princeton CS professor Arvind Narayanan 
@random_walker
 and PhD student Sayash Kapoor 
@sayashk
 run the "AI Snake Oil" series on Substack.
They are asking the right questions, such as:
- is licensing feasible to address AI risk?
- what are the real risks of AI?
- will open source… Show more
------
MusicGen Colab  Thanks to 
@jadecopet
  
@FelixKreuk
  
@itai_gat
  Tal Remez  David Kant  
@syhw
  
@adiyossLC
  
@honualx
 

page: https://ai.honu.io/papers/musicgen
arxiv: https://arxiv.org/abs/2306.05284
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/MusicGen-colab…
------
Necessary counterpoint.
------
Not really about AI optimism vs. pessimism, but the following is a collection of resources arguing that FOOM (i.e. a fast localized takeoff) is unlikely:
https://magnusvinding.com/2017/12/16/a-contra-ai-foom-reading-list/…
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
BAAI (Beijing Academy of AI) releases Aquila: a Chinese/English open source LLM with 7B and 33B models. 

https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md…
------
RLHF is doomed. We will have to crowdsource the finetuning of à few opensource LLM the way wikipedia was built. This take by 
@ylecun
 on LLM is priceless 
------
Interesting thread and blog post.
It's obvious that any technology (AI included) must be deployed safely.
Today, whenever a new technology is developed, it is thoroughly tested for safety before being deployed.
Sometimes, it is because of specific product regulations. But most of… Show more
------
𝗔 𝗣𝗟𝗘𝗔 𝗙𝗢𝗥 𝗦𝗢𝗟𝗨𝗧𝗜𝗢𝗡𝗜𝗦𝗠 𝗢𝗡 𝗔𝗜 𝗦𝗔𝗙𝗘𝗧𝗬

If you’re pro-technology, it is natural to react to fears of AI doom with anger or disgust. It smacks of techno-pessimism, and could lead to regulations that kill this technology or drastically slow it down.
------
When 
@_Laurent
 and I started learning about diffusion models, we were puzzled by the amount of jargon and concepts. 

So, we derived a model from scratch with our own graphics-people intuitions. Simple derivation, simple implementation, SOTA quality.

https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html…
------
On stage with Jacques Attali at Vivatech next week.
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Max pooling is a special case of inf-convolution (or sup-convolution), which is an addition in Legendre transform space.
------
Fourier is to convolution what Legendre is to inf-convolution.  https://en.wikipedia.org/wiki/Fourier_transform… https://en.wikipedia.org/wiki/Legendre_transformation…
------
Meta just released MusicGen, a simple and controllable model for music generation

MusicGen is a single stage auto-regressive Transformer model trained over a 32kHz EnCodec tokenizer with 4 codebooks sampled at 50 Hz. Unlike existing methods like MusicLM, MusicGen doesn't not… Show more
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Showcase of MusicGen, a simple and controllable model for music generation. I had a lot of fun playing with it!
https://github.com/facebookresearch/audiocraft…

(Cooler portraits made with #AdobeFirefly)
#MetaAI #AI #GenerativeAI #MusicGen #Audiocraft

@MetaAI
------
Perhaps. But the ArXiv->conference paper culture also contributes to accelerating progress.
Think of it as stochastic optimization to a book culture batch optimization. https://twitter.com/pfau/status/1668178996972888064…
------
This is impressive.

META just released MusicGen, a Language Model designed for creating music.

Not just that, it produces high-quality music while being conditioned on text description or melodic features.

Best thing? 

You can try it FREE now.

Here is a Demo of converting… Show more
------
It won't be AGI unless it uses Emacs.
------
AGI will be able to exit vim.
------
tested, not perfect every melody, best one so far!looking forward to generate more than 30 seconds.
https://youtu.be/EWBzTXihiD8 来自 
@YouTube
 
@camenduru
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Ask Me Anything about AI, or any of the topics in Why AI Will Save The World, as responses to this tweet and I will answer as many as I can.
------
In response to a discussion between 
@geoffreyhinton
 and 
@AndrewYNg
 about AI risks.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
"The future cannot be predicted, but futures can be invented"  -- Dennis Gabor 1963.
"The best way to predict the future is to invent it"  -- Alan Kay 1971

If you can't predict whether a technology is going to be beneficial or not, build it so it is.

https://quoteinvestigator.com/2012/09/27/invent-the-future/?amp=1…
------
Heureux de débattre avec 
@ylecun
 à 
@VivaTech
 de la question: “ Peut-on on mettre l’Intelligence artificielle au service de l’économie de la vie et de la reconversion de l’économie de la mort?”
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Now that 
@sama
 has clarified his comment in Delhi, let me clarify mine further.  

I completely stand by them. 

I’m in the 
@ylecun
 camp & he articulates his viewpoint here very well - 

https://youtu.be/TKW6ojS8afw
------
I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and… Show more
------
Princeton CS professor Arvind Narayanan 
@random_walker
 and PhD student Sayash Kapoor 
@sayashk
 run the "AI Snake Oil" series on Substack.
They are asking the right questions, such as:
- is licensing feasible to address AI risk?
- what are the real risks of AI?
- will open source… Show more
------
MusicGen Colab  Thanks to 
@jadecopet
  
@FelixKreuk
  
@itai_gat
  Tal Remez  David Kant  
@syhw
  
@adiyossLC
  
@honualx
 

page: https://ai.honu.io/papers/musicgen
arxiv: https://arxiv.org/abs/2306.05284
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/MusicGen-colab…
------
Necessary counterpoint.
------
Not really about AI optimism vs. pessimism, but the following is a collection of resources arguing that FOOM (i.e. a fast localized takeoff) is unlikely:
https://magnusvinding.com/2017/12/16/a-contra-ai-foom-reading-list/…
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
BAAI (Beijing Academy of AI) releases Aquila: a Chinese/English open source LLM with 7B and 33B models. 

https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md…
------
RLHF is doomed. We will have to crowdsource the finetuning of à few opensource LLM the way wikipedia was built. This take by 
@ylecun
 on LLM is priceless 
------
Interesting thread and blog post.
It's obvious that any technology (AI included) must be deployed safely.
Today, whenever a new technology is developed, it is thoroughly tested for safety before being deployed.
Sometimes, it is because of specific product regulations. But most of… Show more
------
𝗔 𝗣𝗟𝗘𝗔 𝗙𝗢𝗥 𝗦𝗢𝗟𝗨𝗧𝗜𝗢𝗡𝗜𝗦𝗠 𝗢𝗡 𝗔𝗜 𝗦𝗔𝗙𝗘𝗧𝗬

If you’re pro-technology, it is natural to react to fears of AI doom with anger or disgust. It smacks of techno-pessimism, and could lead to regulations that kill this technology or drastically slow it down.
------
When 
@_Laurent
 and I started learning about diffusion models, we were puzzled by the amount of jargon and concepts. 

So, we derived a model from scratch with our own graphics-people intuitions. Simple derivation, simple implementation, SOTA quality.

https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html…
------
On stage with Jacques Attali at Vivatech next week.
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Max pooling is a special case of inf-convolution (or sup-convolution), which is an addition in Legendre transform space.
------
Fourier is to convolution what Legendre is to inf-convolution.  https://en.wikipedia.org/wiki/Fourier_transform… https://en.wikipedia.org/wiki/Legendre_transformation…
------
Meta just released MusicGen, a simple and controllable model for music generation

MusicGen is a single stage auto-regressive Transformer model trained over a 32kHz EnCodec tokenizer with 4 codebooks sampled at 50 Hz. Unlike existing methods like MusicLM, MusicGen doesn't not… Show more
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Hallucinations in LLM are due to the Auto-Regressive prediction.

I think what I call "Objective Driven AI" will solve the problem: systems that plan their answer by optimizing a number of objective functions *at inference time*
------
LLM hallucinations will be largely eliminated by 2025. 

that’s a huge deal. the implications are far more profound than the threat of the models getting things a bit wrong today.
------
BlenderBot 3x from FAIR:
Learns by conversing with people.
Public data release: 6 million chat interactions.
------
 New work: BlenderBot 3x 
- Public data release & analysis of 6M chat interactions.
- Learns by conversing with people in the real world:  training on this data improves BB3 from 85.3% → 94.4% good messages.

paper: https://arxiv.org/abs/2306.04707
project: https://parl.ai/projects/bb3x/
------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
MusicGen is definitely good at EDM (chroma conditioning from Interstellar used + some EDM description). Sadly the Interstellar theme doesn't really make it through the Chroma transform...
------
Ask Me Anything about AI, or any of the topics in Why AI Will Save The World, as responses to this tweet and I will answer as many as I can.
------
In response to a discussion between 
@geoffreyhinton
 and 
@AndrewYNg
 about AI risks.
------
We all agree that we need to arrive at a consensus on a number of questions.
I agree with @geoffreyhinton that LLM have *some* level of understanding and that it is misleading to say they are "just statistics." 
However, their understanding of the world is very superficial, in… Show more
------
"The future cannot be predicted, but futures can be invented"  -- Dennis Gabor 1963.
"The best way to predict the future is to invent it"  -- Alan Kay 1971

If you can't predict whether a technology is going to be beneficial or not, build it so it is.

https://quoteinvestigator.com/2012/09/27/invent-the-future/?amp=1…
------
Heureux de débattre avec 
@ylecun
 à 
@VivaTech
 de la question: “ Peut-on on mettre l’Intelligence artificielle au service de l’économie de la vie et de la reconversion de l’économie de la mort?”
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Now that 
@sama
 has clarified his comment in Delhi, let me clarify mine further.  

I completely stand by them. 

I’m in the 
@ylecun
 camp & he articulates his viewpoint here very well - 

https://youtu.be/TKW6ojS8afw
------
I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and… Show more
------
Princeton CS professor Arvind Narayanan 
@random_walker
 and PhD student Sayash Kapoor 
@sayashk
 run the "AI Snake Oil" series on Substack.
They are asking the right questions, such as:
- is licensing feasible to address AI risk?
- what are the real risks of AI?
- will open source… Show more
------
MusicGen Colab  Thanks to 
@jadecopet
  
@FelixKreuk
  
@itai_gat
  Tal Remez  David Kant  
@syhw
  
@adiyossLC
  
@honualx
 

page: https://ai.honu.io/papers/musicgen
arxiv: https://arxiv.org/abs/2306.05284
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/MusicGen-colab…
------
Necessary counterpoint.
------
Not really about AI optimism vs. pessimism, but the following is a collection of resources arguing that FOOM (i.e. a fast localized takeoff) is unlikely:
https://magnusvinding.com/2017/12/16/a-contra-ai-foom-reading-list/…
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
BAAI (Beijing Academy of AI) releases Aquila: a Chinese/English open source LLM with 7B and 33B models. 

https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md…
------
RLHF is doomed. We will have to crowdsource the finetuning of à few opensource LLM the way wikipedia was built. This take by 
@ylecun
 on LLM is priceless 
------
Interesting thread and blog post.
It's obvious that any technology (AI included) must be deployed safely.
Today, whenever a new technology is developed, it is thoroughly tested for safety before being deployed.
Sometimes, it is because of specific product regulations. But most of… Show more
------
𝗔 𝗣𝗟𝗘𝗔 𝗙𝗢𝗥 𝗦𝗢𝗟𝗨𝗧𝗜𝗢𝗡𝗜𝗦𝗠 𝗢𝗡 𝗔𝗜 𝗦𝗔𝗙𝗘𝗧𝗬

If you’re pro-technology, it is natural to react to fears of AI doom with anger or disgust. It smacks of techno-pessimism, and could lead to regulations that kill this technology or drastically slow it down.
------
When 
@_Laurent
 and I started learning about diffusion models, we were puzzled by the amount of jargon and concepts. 

So, we derived a model from scratch with our own graphics-people intuitions. Simple derivation, simple implementation, SOTA quality.

https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html…
------
On stage with Jacques Attali at Vivatech next week.
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Max pooling is a special case of inf-convolution (or sup-convolution), which is an addition in Legendre transform space.
------
Fourier is to convolution what Legendre is to inf-convolution.  https://en.wikipedia.org/wiki/Fourier_transform… https://en.wikipedia.org/wiki/Legendre_transformation…
------
Meta just released MusicGen, a simple and controllable model for music generation

MusicGen is a single stage auto-regressive Transformer model trained over a 32kHz EnCodec tokenizer with 4 codebooks sampled at 50 Hz. Unlike existing methods like MusicLM, MusicGen doesn't not… Show more
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Hallucinations in LLM are due to the Auto-Regressive prediction.

I think what I call "Objective Driven AI" will solve the problem: systems that plan their answer by optimizing a number of objective functions *at inference time*
------
LLM hallucinations will be largely eliminated by 2025. 

that’s a huge deal. the implications are far more profound than the threat of the models getting things a bit wrong today.
------
BlenderBot 3x from FAIR:
Learns by conversing with people.
Public data release: 6 million chat interactions.
------
 New work: BlenderBot 3x 
- Public data release & analysis of 6M chat interactions.
- Learns by conversing with people in the real world:  training on this data improves BB3 from 85.3% → 94.4% good messages.

paper: https://arxiv.org/abs/2306.04707
project: https://parl.ai/projects/bb3x/
------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Who's building this?
Meta.
------
In March 2021 I contemplated leaving @OpenAI to start a company around the ideas that open source and open research were going to win. I decided it was too early but obviously that's no longer the case. Here was my thinking at the time. Who is building this? I Want to help them.
------
MusicGen paper.
------
Simple and Controllable Music Generation

paper page: https://huggingface.co/papers/2306.05284…

introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage… Show more
------
Zuck on Lex about LLM open sourcing: "It's agreed upon that open source software is generally more secure and safer."
------
Now that 
@sama
 has clarified his comment in Delhi, let me clarify mine further.  

I completely stand by them. 

I’m in the 
@ylecun
 camp & he articulates his viewpoint here very well - 

https://youtu.be/TKW6ojS8afw
------
I wanted to share a few thoughts on SamaA's comments in Delhi, Foundational Models, India's position and what could we possibly do as a nation. I think a lot of people in the ecosystem are missing the forest for the trees, that is, we are fixating on OpenAI's lead with GPT4 and… Show more
------
Princeton CS professor Arvind Narayanan 
@random_walker
 and PhD student Sayash Kapoor 
@sayashk
 run the "AI Snake Oil" series on Substack.
They are asking the right questions, such as:
- is licensing feasible to address AI risk?
- what are the real risks of AI?
- will open source… Show more
------
MusicGen Colab  Thanks to 
@jadecopet
  
@FelixKreuk
  
@itai_gat
  Tal Remez  David Kant  
@syhw
  
@adiyossLC
  
@honualx
 

page: https://ai.honu.io/papers/musicgen
arxiv: https://arxiv.org/abs/2306.05284
code: https://github.com/facebookresearch/audiocraft…
colab: please try it  https://github.com/camenduru/MusicGen-colab…
------
Necessary counterpoint.
------
Not really about AI optimism vs. pessimism, but the following is a collection of resources arguing that FOOM (i.e. a fast localized takeoff) is unlikely:
https://magnusvinding.com/2017/12/16/a-contra-ai-foom-reading-list/…
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
BAAI (Beijing Academy of AI) releases Aquila: a Chinese/English open source LLM with 7B and 33B models. 

https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md…
------
RLHF is doomed. We will have to crowdsource the finetuning of à few opensource LLM the way wikipedia was built. This take by 
@ylecun
 on LLM is priceless 
------
Interesting thread and blog post.
It's obvious that any technology (AI included) must be deployed safely.
Today, whenever a new technology is developed, it is thoroughly tested for safety before being deployed.
Sometimes, it is because of specific product regulations. But most of… Show more
------
𝗔 𝗣𝗟𝗘𝗔 𝗙𝗢𝗥 𝗦𝗢𝗟𝗨𝗧𝗜𝗢𝗡𝗜𝗦𝗠 𝗢𝗡 𝗔𝗜 𝗦𝗔𝗙𝗘𝗧𝗬

If you’re pro-technology, it is natural to react to fears of AI doom with anger or disgust. It smacks of techno-pessimism, and could lead to regulations that kill this technology or drastically slow it down.
------
When 
@_Laurent
 and I started learning about diffusion models, we were puzzled by the amount of jargon and concepts. 

So, we derived a model from scratch with our own graphics-people intuitions. Simple derivation, simple implementation, SOTA quality.

https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html…
------
On stage with Jacques Attali at Vivatech next week.
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Max pooling is a special case of inf-convolution (or sup-convolution), which is an addition in Legendre transform space.
------
Fourier is to convolution what Legendre is to inf-convolution.  https://en.wikipedia.org/wiki/Fourier_transform… https://en.wikipedia.org/wiki/Legendre_transformation…
------
Meta just released MusicGen, a simple and controllable model for music generation

MusicGen is a single stage auto-regressive Transformer model trained over a 32kHz EnCodec tokenizer with 4 codebooks sampled at 50 Hz. Unlike existing methods like MusicLM, MusicGen doesn't not… Show more
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Hallucinations in LLM are due to the Auto-Regressive prediction.

I think what I call "Objective Driven AI" will solve the problem: systems that plan their answer by optimizing a number of objective functions *at inference time*
------
LLM hallucinations will be largely eliminated by 2025. 

that’s a huge deal. the implications are far more profound than the threat of the models getting things a bit wrong today.
------
BlenderBot 3x from FAIR:
Learns by conversing with people.
Public data release: 6 million chat interactions.
------
 New work: BlenderBot 3x 
- Public data release & analysis of 6M chat interactions.
- Learns by conversing with people in the real world:  training on this data improves BB3 from 85.3% → 94.4% good messages.

paper: https://arxiv.org/abs/2306.04707
project: https://parl.ai/projects/bb3x/
------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Who's building this?
Meta.
------
In March 2021 I contemplated leaving @OpenAI to start a company around the ideas that open source and open research were going to win. I decided it was too early but obviously that's no longer the case. Here was my thinking at the time. Who is building this? I Want to help them.
------
MusicGen paper.
------
Simple and Controllable Music Generation

paper page: https://huggingface.co/papers/2306.05284…

introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage… Show more
------
Zuck on Lex about LLM open sourcing: "It's agreed upon that open source software is generally more secure and safer."
------
MusicGen samples.
------
Super excited to share that today we release MusicGen: a simple and controllable music generation. 
  
 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models avail under: https://github.com/facebookresearch/audiocraft…. 
 Samples can be found here: https://ai.honu.io/papers/musicgen/… 
See more details
------
Today we release MusicGen, a text-to-music auto-regressive model built on EnCodec. It also supports optional melody conditioning based on chroma-gram extraction! It requires only 50 autoregressive steps per second of audio. Really fun to remix known tune in all genre  + 
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
MusicGen can be conditioned on a chromagram.
------
Then, we introduce some optional chromagram based conditioning. This can be computed for any track, and gives a rough idea of the tune of a track, thus allowing easy and controllable "remixing" of any song you like.
Play with it on our HuggingFace demo : https://huggingface.co/spaces/facebook/MusicGen…
------
MusicGen from FAIR: 
Generates music from a text description.
Paper + open source code + models + demo on HuggingFace.
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
Mainstreaming of OSS LLM: 
French hobbyist magazine Hackable gives step-by-step instructions to run LLaMA on a Raspberry Pi.

Even a beefed-up RasPi 4 with 8GB takes 10 seconds per token...
------
BAAI (Beijing Academy of AI) releases Aquila: a Chinese/English open source LLM with 7B and 33B models. 

https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md…
------
RLHF is doomed. We will have to crowdsource the finetuning of à few opensource LLM the way wikipedia was built. This take by 
@ylecun
 on LLM is priceless 
------
Interesting thread and blog post.
It's obvious that any technology (AI included) must be deployed safely.
Today, whenever a new technology is developed, it is thoroughly tested for safety before being deployed.
Sometimes, it is because of specific product regulations. But most of… Show more
------
𝗔 𝗣𝗟𝗘𝗔 𝗙𝗢𝗥 𝗦𝗢𝗟𝗨𝗧𝗜𝗢𝗡𝗜𝗦𝗠 𝗢𝗡 𝗔𝗜 𝗦𝗔𝗙𝗘𝗧𝗬

If you’re pro-technology, it is natural to react to fears of AI doom with anger or disgust. It smacks of techno-pessimism, and could lead to regulations that kill this technology or drastically slow it down.
------
When 
@_Laurent
 and I started learning about diffusion models, we were puzzled by the amount of jargon and concepts. 

So, we derived a model from scratch with our own graphics-people intuitions. Simple derivation, simple implementation, SOTA quality.

https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html…
------
On stage with Jacques Attali at Vivatech next week.
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Max pooling is a special case of inf-convolution (or sup-convolution), which is an addition in Legendre transform space.
------
Fourier is to convolution what Legendre is to inf-convolution.  https://en.wikipedia.org/wiki/Fourier_transform… https://en.wikipedia.org/wiki/Legendre_transformation…
------
Meta just released MusicGen, a simple and controllable model for music generation

MusicGen is a single stage auto-regressive Transformer model trained over a 32kHz EnCodec tokenizer with 4 codebooks sampled at 50 Hz. Unlike existing methods like MusicLM, MusicGen doesn't not… Show more
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Hallucinations in LLM are due to the Auto-Regressive prediction.

I think what I call "Objective Driven AI" will solve the problem: systems that plan their answer by optimizing a number of objective functions *at inference time*
------
LLM hallucinations will be largely eliminated by 2025. 

that’s a huge deal. the implications are far more profound than the threat of the models getting things a bit wrong today.
------
BlenderBot 3x from FAIR:
Learns by conversing with people.
Public data release: 6 million chat interactions.
------
 New work: BlenderBot 3x 
- Public data release & analysis of 6M chat interactions.
- Learns by conversing with people in the real world:  training on this data improves BB3 from 85.3% → 94.4% good messages.

paper: https://arxiv.org/abs/2306.04707
project: https://parl.ai/projects/bb3x/
------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Who's building this?
Meta.
------
In March 2021 I contemplated leaving @OpenAI to start a company around the ideas that open source and open research were going to win. I decided it was too early but obviously that's no longer the case. Here was my thinking at the time. Who is building this? I Want to help them.
------
MusicGen paper.
------
Simple and Controllable Music Generation

paper page: https://huggingface.co/papers/2306.05284…

introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage… Show more
------
Zuck on Lex about LLM open sourcing: "It's agreed upon that open source software is generally more secure and safer."
------
MusicGen samples.
------
Super excited to share that today we release MusicGen: a simple and controllable music generation. 
  
 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models avail under: https://github.com/facebookresearch/audiocraft…. 
 Samples can be found here: https://ai.honu.io/papers/musicgen/… 
See more details
------
Today we release MusicGen, a text-to-music auto-regressive model built on EnCodec. It also supports optional melody conditioning based on chroma-gram extraction! It requires only 50 autoregressive steps per second of audio. Really fun to remix known tune in all genre  + 
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
MusicGen can be conditioned on a chromagram.
------
Then, we introduce some optional chromagram based conditioning. This can be computed for any track, and gives a rough idea of the tune of a track, thus allowing easy and controllable "remixing" of any song you like.
Play with it on our HuggingFace demo : https://huggingface.co/spaces/facebook/MusicGen…
------
MusicGen from FAIR: 
Generates music from a text description.
Paper + open source code + models + demo on HuggingFace.
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
On stage with Jacques Attali at Vivatech next week.
------
Don't miss @ylecun, VP & Chief AI Scientist at Meta, presenting his vision of the future of #IA alongside @jattali on June 14th from 1:35 PM to 2:00 PM (Stage 1). #MetaAtVivaTech #MetaStandF38
------
Max pooling is a special case of inf-convolution (or sup-convolution), which is an addition in Legendre transform space.
------
Fourier is to convolution what Legendre is to inf-convolution.  https://en.wikipedia.org/wiki/Fourier_transform… https://en.wikipedia.org/wiki/Legendre_transformation…
------
Meta just released MusicGen, a simple and controllable model for music generation

MusicGen is a single stage auto-regressive Transformer model trained over a 32kHz EnCodec tokenizer with 4 codebooks sampled at 50 Hz. Unlike existing methods like MusicLM, MusicGen doesn't not… Show more
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Hallucinations in LLM are due to the Auto-Regressive prediction.

I think what I call "Objective Driven AI" will solve the problem: systems that plan their answer by optimizing a number of objective functions *at inference time*
------
LLM hallucinations will be largely eliminated by 2025. 

that’s a huge deal. the implications are far more profound than the threat of the models getting things a bit wrong today.
------
BlenderBot 3x from FAIR:
Learns by conversing with people.
Public data release: 6 million chat interactions.
------
 New work: BlenderBot 3x 
- Public data release & analysis of 6M chat interactions.
- Learns by conversing with people in the real world:  training on this data improves BB3 from 85.3% → 94.4% good messages.

paper: https://arxiv.org/abs/2306.04707
project: https://parl.ai/projects/bb3x/
------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Who's building this?
Meta.
------
In March 2021 I contemplated leaving @OpenAI to start a company around the ideas that open source and open research were going to win. I decided it was too early but obviously that's no longer the case. Here was my thinking at the time. Who is building this? I Want to help them.
------
MusicGen paper.
------
Simple and Controllable Music Generation

paper page: https://huggingface.co/papers/2306.05284…

introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage… Show more
------
Zuck on Lex about LLM open sourcing: "It's agreed upon that open source software is generally more secure and safer."
------
MusicGen samples.
------
Super excited to share that today we release MusicGen: a simple and controllable music generation. 
  
 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models avail under: https://github.com/facebookresearch/audiocraft…. 
 Samples can be found here: https://ai.honu.io/papers/musicgen/… 
See more details
------
Today we release MusicGen, a text-to-music auto-regressive model built on EnCodec. It also supports optional melody conditioning based on chroma-gram extraction! It requires only 50 autoregressive steps per second of audio. Really fun to remix known tune in all genre  + 
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
MusicGen can be conditioned on a chromagram.
------
Then, we introduce some optional chromagram based conditioning. This can be computed for any track, and gives a rough idea of the tune of a track, thus allowing easy and controllable "remixing" of any song you like.
Play with it on our HuggingFace demo : https://huggingface.co/spaces/facebook/MusicGen…
------
MusicGen from FAIR: 
Generates music from a text description.
Paper + open source code + models + demo on HuggingFace.
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
Out today! We pre-train a health system language model, NYUTron, and evaluated it on diverse prediction tasks, including 30-day all-cause readmission, in-hospital mortality, comorbidity index, LOS, and insurance denial. https://nature.com/articles/s41586-023-06160-y…
------
ICYMI: 
@pmarca
's post is a MUST READ about AI.  Eloquent, iconoclastic, and important (even where he is off): https://a16z.com/2023/06/06/ai-will-save-the-world/…

"The development and proliferation of AI... is a moral obligation that we  have to ourselves, to our children, and to our future."
------
Hot. As in liquid helium hot.
------
My hot take: Trump may have been indicted because, due to criminal intent, he actually violated a number of criminal statutes.
------
free 
@ASSC26nyc
 event friday june 23:

#christofkoch & i resolve our 25-year NCC bet!

#luciamelloni unveils new GWT vs IIT results!


@StanDehaene
 
@melanieboly
 
@danieldennett
 comment!


@theamygdaloid
 & 
@BabaBrinkman
 play!


@heather_berlin
 & 
@de_dicto
 host!
------
Mark on Lex encore.

Important section on open sourcing AI models at 17:50.

- Lex: Do you think the LAMA or the language model underlying that version 2 will be open sourced? Do you have internal debate around that, the pros and cons and so on?
- Mark: Oh yeah. Well I mean, we… Show more
------
Here's my conversation with Mark Zuckerberg, his 2nd time on the podcast. We talk about the future of AI at Meta, Facebook, Instagram, and WhatsApp, both near-term open source development of AI and the journey of human civilization toward building AGI. https://youtube.com/watch?v=Ff4fRgnuFgQ…
------
LLaMA compared to Falcon.
Test script issues....
------
Is Falcon really better than LLaMA? 
Short take: probably not.

Longer take: we reproduced LLaMA 65B eval on MMLU and we got 61.4, close to the official number (63.4), much higher than its Open LLM Leaderboard number (48.8), and clearly higher than Falcon (52.7).

Code and prompt… Show more
------
The evidence is accumulating.
------
 GPT models have blown our minds with their astonishing capabilities. But, do they truly acquire the ability to perform reasoning tasks that humans find easy to execute? NO

We investigate the limits of Transformers *empirically* and *theoretically* on compositional tasks
------
I don't deserve the adjective "sanctus", but I'll take the shiny armor.
------
My friend who wishes to remain anonymous made this
------
Hallucinations in LLM are due to the Auto-Regressive prediction.

I think what I call "Objective Driven AI" will solve the problem: systems that plan their answer by optimizing a number of objective functions *at inference time*
------
LLM hallucinations will be largely eliminated by 2025. 

that’s a huge deal. the implications are far more profound than the threat of the models getting things a bit wrong today.
------
BlenderBot 3x from FAIR:
Learns by conversing with people.
Public data release: 6 million chat interactions.
------
 New work: BlenderBot 3x 
- Public data release & analysis of 6M chat interactions.
- Learns by conversing with people in the real world:  training on this data improves BB3 from 85.3% → 94.4% good messages.

paper: https://arxiv.org/abs/2306.04707
project: https://parl.ai/projects/bb3x/
------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Who's building this?
Meta.
------
In March 2021 I contemplated leaving @OpenAI to start a company around the ideas that open source and open research were going to win. I decided it was too early but obviously that's no longer the case. Here was my thinking at the time. Who is building this? I Want to help them.
------
MusicGen paper.
------
Simple and Controllable Music Generation

paper page: https://huggingface.co/papers/2306.05284…

introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage… Show more
------
Zuck on Lex about LLM open sourcing: "It's agreed upon that open source software is generally more secure and safer."
------
MusicGen samples.
------
Super excited to share that today we release MusicGen: a simple and controllable music generation. 
  
 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models avail under: https://github.com/facebookresearch/audiocraft…. 
 Samples can be found here: https://ai.honu.io/papers/musicgen/… 
See more details
------
Today we release MusicGen, a text-to-music auto-regressive model built on EnCodec. It also supports optional melody conditioning based on chroma-gram extraction! It requires only 50 autoregressive steps per second of audio. Really fun to remix known tune in all genre  + 
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
MusicGen can be conditioned on a chromagram.
------
Then, we introduce some optional chromagram based conditioning. This can be computed for any track, and gives a rough idea of the tune of a track, thus allowing easy and controllable "remixing" of any song you like.
Play with it on our HuggingFace demo : https://huggingface.co/spaces/facebook/MusicGen…
------
MusicGen from FAIR: 
Generates music from a text description.
Paper + open source code + models + demo on HuggingFace.
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
Out today! We pre-train a health system language model, NYUTron, and evaluated it on diverse prediction tasks, including 30-day all-cause readmission, in-hospital mortality, comorbidity index, LOS, and insurance denial. https://nature.com/articles/s41586-023-06160-y…
------
ICYMI: 
@pmarca
's post is a MUST READ about AI.  Eloquent, iconoclastic, and important (even where he is off): https://a16z.com/2023/06/06/ai-will-save-the-world/…

"The development and proliferation of AI... is a moral obligation that we  have to ourselves, to our children, and to our future."
------
Hot. As in liquid helium hot.
------
My hot take: Trump may have been indicted because, due to criminal intent, he actually violated a number of criminal statutes.
------
free 
@ASSC26nyc
 event friday june 23:

#christofkoch & i resolve our 25-year NCC bet!

#luciamelloni unveils new GWT vs IIT results!


@StanDehaene
 
@melanieboly
 
@danieldennett
 comment!


@theamygdaloid
 & 
@BabaBrinkman
 play!


@heather_berlin
 & 
@de_dicto
 host!
------
Mark on Lex encore.

Important section on open sourcing AI models at 17:50.

- Lex: Do you think the LAMA or the language model underlying that version 2 will be open sourced? Do you have internal debate around that, the pros and cons and so on?
- Mark: Oh yeah. Well I mean, we… Show more
------
Here's my conversation with Mark Zuckerberg, his 2nd time on the podcast. We talk about the future of AI at Meta, Facebook, Instagram, and WhatsApp, both near-term open source development of AI and the journey of human civilization toward building AGI. https://youtube.com/watch?v=Ff4fRgnuFgQ…
------
LLaMA compared to Falcon.
Test script issues....
------
Is Falcon really better than LLaMA? 
Short take: probably not.

Longer take: we reproduced LLaMA 65B eval on MMLU and we got 61.4, close to the official number (63.4), much higher than its Open LLM Leaderboard number (48.8), and clearly higher than Falcon (52.7).

Code and prompt… Show more
------
The evidence is accumulating.
------
 GPT models have blown our minds with their astonishing capabilities. But, do they truly acquire the ability to perform reasoning tasks that humans find easy to execute? NO

We investigate the limits of Transformers *empirically* and *theoretically* on compositional tasks
------
AI-Crypto comparisons are ridiculous… crypto was a technology with no real use cases… ai is a technology with almost every use case imaginable
------
- AI won't replace doctors. But doctors who use AI will replace doctors who don't.   

Get your headphones ready for a  discussion on

@20vcFund
 with 
@HarryStebbings
 in a couple of days!
------
AI for mathematics workshop.
Monday-Wednesday.
------
If you haven't signed up for the National Academies workshop on AI for Math, now is your chance! We have wonderful speakers like @vardi, @wellecks, Thierry Coquand, and @BlancheMinerva, and wonderful moderators like @ylecun, Terry Tao, and yours truly 

https://nationalacademies.org/our-work/ai-to-assist-mathematical-reasoning-a-workshop…
------
One of the strangest things about the world: 
So many people have opinions based on prejudice or dogma that merely being a rationalist can make you look like a contrarian.
------
Interesting observation.
------
I think many of the claims about LLM's reasoning capabilities miss the point that LLM's are not just trained on "facts" but also, quite often, the deductive closure of those facts. Thus reasoning becomes (approximate) retrieval. 1/
------
Black-box learning rate tuning is here!
------
Take your favorite optimizer (Adam, SGD, Lion) and feed it into Mechanic to get the learning rate. You give it the direction, it gives you the magnitude. The new optimizer has been tested on a wide range of deep learning problems: ViT, LSTM, ResNet, etc.
https://arxiv.org/abs/2306.00144
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
This new MusicGen model from Meta is seriously impressive!
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Who's building this?
Meta.
------
In March 2021 I contemplated leaving @OpenAI to start a company around the ideas that open source and open research were going to win. I decided it was too early but obviously that's no longer the case. Here was my thinking at the time. Who is building this? I Want to help them.
------
MusicGen paper.
------
Simple and Controllable Music Generation

paper page: https://huggingface.co/papers/2306.05284…

introduce MusicGen, a single Language Model (LM) that operates over several streams of compressed discrete music representation, i.e., tokens. Unlike prior work, MusicGen is comprised of a single-stage… Show more
------
Zuck on Lex about LLM open sourcing: "It's agreed upon that open source software is generally more secure and safer."
------
MusicGen samples.
------
Super excited to share that today we release MusicGen: a simple and controllable music generation. 
  
 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models avail under: https://github.com/facebookresearch/audiocraft…. 
 Samples can be found here: https://ai.honu.io/papers/musicgen/… 
See more details
------
Today we release MusicGen, a text-to-music auto-regressive model built on EnCodec. It also supports optional melody conditioning based on chroma-gram extraction! It requires only 50 autoregressive steps per second of audio. Really fun to remix known tune in all genre  + 
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
MusicGen can be conditioned on a chromagram.
------
Then, we introduce some optional chromagram based conditioning. This can be computed for any track, and gives a rough idea of the tune of a track, thus allowing easy and controllable "remixing" of any song you like.
Play with it on our HuggingFace demo : https://huggingface.co/spaces/facebook/MusicGen…
------
MusicGen from FAIR: 
Generates music from a text description.
Paper + open source code + models + demo on HuggingFace.
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
Out today! We pre-train a health system language model, NYUTron, and evaluated it on diverse prediction tasks, including 30-day all-cause readmission, in-hospital mortality, comorbidity index, LOS, and insurance denial. https://nature.com/articles/s41586-023-06160-y…
------
ICYMI: 
@pmarca
's post is a MUST READ about AI.  Eloquent, iconoclastic, and important (even where he is off): https://a16z.com/2023/06/06/ai-will-save-the-world/…

"The development and proliferation of AI... is a moral obligation that we  have to ourselves, to our children, and to our future."
------
Hot. As in liquid helium hot.
------
My hot take: Trump may have been indicted because, due to criminal intent, he actually violated a number of criminal statutes.
------
free 
@ASSC26nyc
 event friday june 23:

#christofkoch & i resolve our 25-year NCC bet!

#luciamelloni unveils new GWT vs IIT results!


@StanDehaene
 
@melanieboly
 
@danieldennett
 comment!


@theamygdaloid
 & 
@BabaBrinkman
 play!


@heather_berlin
 & 
@de_dicto
 host!
------
Mark on Lex encore.

Important section on open sourcing AI models at 17:50.

- Lex: Do you think the LAMA or the language model underlying that version 2 will be open sourced? Do you have internal debate around that, the pros and cons and so on?
- Mark: Oh yeah. Well I mean, we… Show more
------
Here's my conversation with Mark Zuckerberg, his 2nd time on the podcast. We talk about the future of AI at Meta, Facebook, Instagram, and WhatsApp, both near-term open source development of AI and the journey of human civilization toward building AGI. https://youtube.com/watch?v=Ff4fRgnuFgQ…
------
LLaMA compared to Falcon.
Test script issues....
------
Is Falcon really better than LLaMA? 
Short take: probably not.

Longer take: we reproduced LLaMA 65B eval on MMLU and we got 61.4, close to the official number (63.4), much higher than its Open LLM Leaderboard number (48.8), and clearly higher than Falcon (52.7).

Code and prompt… Show more
------
The evidence is accumulating.
------
 GPT models have blown our minds with their astonishing capabilities. But, do they truly acquire the ability to perform reasoning tasks that humans find easy to execute? NO

We investigate the limits of Transformers *empirically* and *theoretically* on compositional tasks
------
AI-Crypto comparisons are ridiculous… crypto was a technology with no real use cases… ai is a technology with almost every use case imaginable
------
- AI won't replace doctors. But doctors who use AI will replace doctors who don't.   

Get your headphones ready for a  discussion on

@20vcFund
 with 
@HarryStebbings
 in a couple of days!
------
AI for mathematics workshop.
Monday-Wednesday.
------
If you haven't signed up for the National Academies workshop on AI for Math, now is your chance! We have wonderful speakers like @vardi, @wellecks, Thierry Coquand, and @BlancheMinerva, and wonderful moderators like @ylecun, Terry Tao, and yours truly 

https://nationalacademies.org/our-work/ai-to-assist-mathematical-reasoning-a-workshop…
------
One of the strangest things about the world: 
So many people have opinions based on prejudice or dogma that merely being a rationalist can make you look like a contrarian.
------
Interesting observation.
------
I think many of the claims about LLM's reasoning capabilities miss the point that LLM's are not just trained on "facts" but also, quite often, the deductive closure of those facts. Thus reasoning becomes (approximate) retrieval. 1/
------
Black-box learning rate tuning is here!
------
Take your favorite optimizer (Adam, SGD, Lion) and feed it into Mechanic to get the learning rate. You give it the direction, it gives you the magnitude. The new optimizer has been tested on a wide range of deep learning problems: ViT, LSTM, ResNet, etc.
https://arxiv.org/abs/2306.00144
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
Discrete Cosine Transforms are eigenvectors of Laplacians with different boundary conditions. Wonderful paper by Strang. http://www-math.mit.edu/~gs/papers/dct.pdf…
------
I'm starting to think 
@ylecun
 may be right
------
Where AI doomerism comes from.
------
I'm often critical of Effective Altruism (EA) and I'm sure I'll get more pushback for this, but I've been thinking a lot lately about the discourse on AI doomerism, extinction risk, etc., and here's my big take on what's going on and why. 

Buckle up, friends, it gets spicy.
------
How can a technology designed to amplify human intelligence be viewed with such dread?
There are always risks associated with new technology.
But the question is whether the risks can be mitigated so as to make the benefits overwhelmingly worth the risks.
------
I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk. 

What are your thoughts? And, who do you think has a thoughtful perspective on how AI poses this risk that I should talk to?
------
AI is not going to take your job.
------
ChatGPT is Not a Technological Singularity https://cacm.acm.org/blogs/blog-cacm/273606-chatgpt-is-not-a-technological-singularity/fulltext… 

cc @ylecun @davidautor @pmarca
------
Transformer stages incrementally optimize a sparse compression criterion using a LISTA-like method.
------
I hope this work “White-box Transforms via Sparse Rate Reduction” http://arxiv.org/abs/2306.01129 will help both theoreticians and practitioners fully understand deep networks, particularly Transformers. Understanding is the only way to stop spreading mysteries, hypes, or even hysterias.
------
MusicGen samples.
------
Super excited to share that today we release MusicGen: a simple and controllable music generation. 
  
 Paper: https://arxiv.org/pdf/2306.05284.pdf…
 Code and models avail under: https://github.com/facebookresearch/audiocraft…. 
 Samples can be found here: https://ai.honu.io/papers/musicgen/… 
See more details
------
Today we release MusicGen, a text-to-music auto-regressive model built on EnCodec. It also supports optional melody conditioning based on chroma-gram extraction! It requires only 50 autoregressive steps per second of audio. Really fun to remix known tune in all genre  + 
------
We present MusicGen: A simple and controllable music generation model. MusicGen can be prompted by both text and melody. 
We release code (MIT) and models (CC-BY NC) for open research, reproducibility, and for the music community: https://github.com/facebookresearch/audiocraft…
------
MusicGen can be conditioned on a chromagram.
------
Then, we introduce some optional chromagram based conditioning. This can be computed for any track, and gives a rough idea of the tune of a track, thus allowing easy and controllable "remixing" of any song you like.
Play with it on our HuggingFace demo : https://huggingface.co/spaces/facebook/MusicGen…
------
MusicGen from FAIR: 
Generates music from a text description.
Paper + open source code + models + demo on HuggingFace.
------
We've just released MusicGen, and there is a @huggingface demo now, here is a thread about me playing with it just right now. https://huggingface.co/spaces/facebook/MusicGen…
A 
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
Out today! We pre-train a health system language model, NYUTron, and evaluated it on diverse prediction tasks, including 30-day all-cause readmission, in-hospital mortality, comorbidity index, LOS, and insurance denial. https://nature.com/articles/s41586-023-06160-y…
------
ICYMI: 
@pmarca
's post is a MUST READ about AI.  Eloquent, iconoclastic, and important (even where he is off): https://a16z.com/2023/06/06/ai-will-save-the-world/…

"The development and proliferation of AI... is a moral obligation that we  have to ourselves, to our children, and to our future."
------
Hot. As in liquid helium hot.
------
My hot take: Trump may have been indicted because, due to criminal intent, he actually violated a number of criminal statutes.
------
free 
@ASSC26nyc
 event friday june 23:

#christofkoch & i resolve our 25-year NCC bet!

#luciamelloni unveils new GWT vs IIT results!


@StanDehaene
 
@melanieboly
 
@danieldennett
 comment!


@theamygdaloid
 & 
@BabaBrinkman
 play!


@heather_berlin
 & 
@de_dicto
 host!
------
Mark on Lex encore.

Important section on open sourcing AI models at 17:50.

- Lex: Do you think the LAMA or the language model underlying that version 2 will be open sourced? Do you have internal debate around that, the pros and cons and so on?
- Mark: Oh yeah. Well I mean, we… Show more
------
Here's my conversation with Mark Zuckerberg, his 2nd time on the podcast. We talk about the future of AI at Meta, Facebook, Instagram, and WhatsApp, both near-term open source development of AI and the journey of human civilization toward building AGI. https://youtube.com/watch?v=Ff4fRgnuFgQ…
------
LLaMA compared to Falcon.
Test script issues....
------
Is Falcon really better than LLaMA? 
Short take: probably not.

Longer take: we reproduced LLaMA 65B eval on MMLU and we got 61.4, close to the official number (63.4), much higher than its Open LLM Leaderboard number (48.8), and clearly higher than Falcon (52.7).

Code and prompt… Show more
------
The evidence is accumulating.
------
 GPT models have blown our minds with their astonishing capabilities. But, do they truly acquire the ability to perform reasoning tasks that humans find easy to execute? NO

We investigate the limits of Transformers *empirically* and *theoretically* on compositional tasks
------
AI-Crypto comparisons are ridiculous… crypto was a technology with no real use cases… ai is a technology with almost every use case imaginable
------
- AI won't replace doctors. But doctors who use AI will replace doctors who don't.   

Get your headphones ready for a  discussion on

@20vcFund
 with 
@HarryStebbings
 in a couple of days!
------
AI for mathematics workshop.
Monday-Wednesday.
------
If you haven't signed up for the National Academies workshop on AI for Math, now is your chance! We have wonderful speakers like @vardi, @wellecks, Thierry Coquand, and @BlancheMinerva, and wonderful moderators like @ylecun, Terry Tao, and yours truly 

https://nationalacademies.org/our-work/ai-to-assist-mathematical-reasoning-a-workshop…
------
One of the strangest things about the world: 
So many people have opinions based on prejudice or dogma that merely being a rationalist can make you look like a contrarian.
------
Interesting observation.
------
I think many of the claims about LLM's reasoning capabilities miss the point that LLM's are not just trained on "facts" but also, quite often, the deductive closure of those facts. Thus reasoning becomes (approximate) retrieval. 1/
------
Black-box learning rate tuning is here!
------
Take your favorite optimizer (Adam, SGD, Lion) and feed it into Mechanic to get the learning rate. You give it the direction, it gives you the magnitude. The new optimizer has been tested on a wide range of deep learning problems: ViT, LSTM, ResNet, etc.
https://arxiv.org/abs/2306.00144
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
Discrete Cosine Transforms are eigenvectors of Laplacians with different boundary conditions. Wonderful paper by Strang. http://www-math.mit.edu/~gs/papers/dct.pdf…
------
I'm starting to think 
@ylecun
 may be right
------
Where AI doomerism comes from.
------
I'm often critical of Effective Altruism (EA) and I'm sure I'll get more pushback for this, but I've been thinking a lot lately about the discourse on AI doomerism, extinction risk, etc., and here's my big take on what's going on and why. 

Buckle up, friends, it gets spicy.
------
How can a technology designed to amplify human intelligence be viewed with such dread?
There are always risks associated with new technology.
But the question is whether the risks can be mitigated so as to make the benefits overwhelmingly worth the risks.
------
I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk. 

What are your thoughts? And, who do you think has a thoughtful perspective on how AI poses this risk that I should talk to?
------
AI is not going to take your job.
------
ChatGPT is Not a Technological Singularity https://cacm.acm.org/blogs/blog-cacm/273606-chatgpt-is-not-a-technological-singularity/fulltext… 

cc @ylecun @davidautor @pmarca
------
Transformer stages incrementally optimize a sparse compression criterion using a LISTA-like method.
------
I hope this work “White-box Transforms via Sparse Rate Reduction” http://arxiv.org/abs/2306.01129 will help both theoreticians and practitioners fully understand deep networks, particularly Transformers. Understanding is the only way to stop spreading mysteries, hypes, or even hysterias.
------
Comparison of the Wasserstein, Hellinger, Kullback-Leibler and reverse KL on the space of Gaussian distributions. http://djalil.chafai.net/blog/2020/01/22/about-the-hellinger-distance/…
------
A statistician's view of AGI doomer drama.
------
simply incredible.
------
Interesting.
------
New paper!! We show that pre-training language-image models *solely* on synthetic images from Stable Diffusion can outperform training on real images!!

Work done with @YonglongT (Google), Huiwen Chang (Google), @phillip_isola (MIT) and Lijie Fan (MIT)!!
------
Impressive list of Tech Speakers at #VivaTech 2023!

With 
@elonmusk
 
@Benioff
 
@ylecun
 Lee Young 
@Dan_Schulman
 
@DavaExplorer
 
@eberneke
 Bernard Arnault 
@PeggyJ
 
@LHSummers
 
@Yunus_Centre
 
@Cheydema
 
@Bob_Moritz
 
@m_berard
 
@MATUIDIBlaise


#tech #AI #innovation


@CurieuxExplorer
… Show more
------
Out today! We pre-train a health system language model, NYUTron, and evaluated it on diverse prediction tasks, including 30-day all-cause readmission, in-hospital mortality, comorbidity index, LOS, and insurance denial. https://nature.com/articles/s41586-023-06160-y…
------
ICYMI: 
@pmarca
's post is a MUST READ about AI.  Eloquent, iconoclastic, and important (even where he is off): https://a16z.com/2023/06/06/ai-will-save-the-world/…

"The development and proliferation of AI... is a moral obligation that we  have to ourselves, to our children, and to our future."
------
Hot. As in liquid helium hot.
------
My hot take: Trump may have been indicted because, due to criminal intent, he actually violated a number of criminal statutes.
------
free 
@ASSC26nyc
 event friday june 23:

#christofkoch & i resolve our 25-year NCC bet!

#luciamelloni unveils new GWT vs IIT results!


@StanDehaene
 
@melanieboly
 
@danieldennett
 comment!


@theamygdaloid
 & 
@BabaBrinkman
 play!


@heather_berlin
 & 
@de_dicto
 host!
------
Mark on Lex encore.

Important section on open sourcing AI models at 17:50.

- Lex: Do you think the LAMA or the language model underlying that version 2 will be open sourced? Do you have internal debate around that, the pros and cons and so on?
- Mark: Oh yeah. Well I mean, we… Show more
------
Here's my conversation with Mark Zuckerberg, his 2nd time on the podcast. We talk about the future of AI at Meta, Facebook, Instagram, and WhatsApp, both near-term open source development of AI and the journey of human civilization toward building AGI. https://youtube.com/watch?v=Ff4fRgnuFgQ…
------
LLaMA compared to Falcon.
Test script issues....
------
Is Falcon really better than LLaMA? 
Short take: probably not.

Longer take: we reproduced LLaMA 65B eval on MMLU and we got 61.4, close to the official number (63.4), much higher than its Open LLM Leaderboard number (48.8), and clearly higher than Falcon (52.7).

Code and prompt… Show more
------
The evidence is accumulating.
------
 GPT models have blown our minds with their astonishing capabilities. But, do they truly acquire the ability to perform reasoning tasks that humans find easy to execute? NO

We investigate the limits of Transformers *empirically* and *theoretically* on compositional tasks
------
AI-Crypto comparisons are ridiculous… crypto was a technology with no real use cases… ai is a technology with almost every use case imaginable
------
- AI won't replace doctors. But doctors who use AI will replace doctors who don't.   

Get your headphones ready for a  discussion on

@20vcFund
 with 
@HarryStebbings
 in a couple of days!
------
AI for mathematics workshop.
Monday-Wednesday.
------
If you haven't signed up for the National Academies workshop on AI for Math, now is your chance! We have wonderful speakers like @vardi, @wellecks, Thierry Coquand, and @BlancheMinerva, and wonderful moderators like @ylecun, Terry Tao, and yours truly 

https://nationalacademies.org/our-work/ai-to-assist-mathematical-reasoning-a-workshop…
------
One of the strangest things about the world: 
So many people have opinions based on prejudice or dogma that merely being a rationalist can make you look like a contrarian.
------
Interesting observation.
------
I think many of the claims about LLM's reasoning capabilities miss the point that LLM's are not just trained on "facts" but also, quite often, the deductive closure of those facts. Thus reasoning becomes (approximate) retrieval. 1/
------
Black-box learning rate tuning is here!
------
Take your favorite optimizer (Adam, SGD, Lion) and feed it into Mechanic to get the learning rate. You give it the direction, it gives you the magnitude. The new optimizer has been tested on a wide range of deep learning problems: ViT, LSTM, ResNet, etc.
https://arxiv.org/abs/2306.00144
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
Discrete Cosine Transforms are eigenvectors of Laplacians with different boundary conditions. Wonderful paper by Strang. http://www-math.mit.edu/~gs/papers/dct.pdf…
------
I'm starting to think 
@ylecun
 may be right
------
Where AI doomerism comes from.
------
I'm often critical of Effective Altruism (EA) and I'm sure I'll get more pushback for this, but I've been thinking a lot lately about the discourse on AI doomerism, extinction risk, etc., and here's my big take on what's going on and why. 

Buckle up, friends, it gets spicy.
------
How can a technology designed to amplify human intelligence be viewed with such dread?
There are always risks associated with new technology.
But the question is whether the risks can be mitigated so as to make the benefits overwhelmingly worth the risks.
------
I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk. 

What are your thoughts? And, who do you think has a thoughtful perspective on how AI poses this risk that I should talk to?
------
AI is not going to take your job.
------
ChatGPT is Not a Technological Singularity https://cacm.acm.org/blogs/blog-cacm/273606-chatgpt-is-not-a-technological-singularity/fulltext… 

cc @ylecun @davidautor @pmarca
------
Transformer stages incrementally optimize a sparse compression criterion using a LISTA-like method.
------
I hope this work “White-box Transforms via Sparse Rate Reduction” http://arxiv.org/abs/2306.01129 will help both theoreticians and practitioners fully understand deep networks, particularly Transformers. Understanding is the only way to stop spreading mysteries, hypes, or even hysterias.
------
Comparison of the Wasserstein, Hellinger, Kullback-Leibler and reverse KL on the space of Gaussian distributions. http://djalil.chafai.net/blog/2020/01/22/about-the-hellinger-distance/…
------
A statistician's view of AGI doomer drama.
------
simply incredible.
------
Interesting.
------
New paper!! We show that pre-training language-image models *solely* on synthetic images from Stable Diffusion can outperform training on real images!!

Work done with @YonglongT (Google), Huiwen Chang (Google), @phillip_isola (MIT) and Lijie Fan (MIT)!!
------
L'IA sera le moteur d'un nouveau départ pour l'économie, la culture, l'éducation et la démocratie.

Accompagné de 
@laurentsolly
, j'en ai parlé avec 
@olivierveran
------
Haine, désinformation : sur Facebook ou Instagram, l’IA contribue à supprimer des discours dangereux.

Mais nous devons anticiper les dérives, pour que l’IA ne nuise pas à notre démocratie mais la protège ! 

J’en ai parlé avec Meta, @ylecun et @laurentsolly.
------
1/The false and sensationalist coverage of the purported Air Force simulation where an AI-drone decided to kill an operator will be remembered as a highly regrettable episode of AI doomsaying hype. Lets be honest about what are, and what are not, real risks.
------
This is worth repeating.
------
To be clear, at this time and for the foreseeable future, there does not exist any AI model or technique that could represent an extinction risk for humanity. Not even in nascent form, and not even if you extrapolate capabilities far into the future via scaling laws.
------
Imagine a future in which your daily interaction with the world of information is mediated by an AI assistant.

This AI assistant would be like an active repository of all human knowledge.

It will become your best rampart *against* misinformation.
------
AN AIRFORCE DRONE OPTIMISED FOR POINTS WENT ROGUE AND  KILLED OPERATOR!: a thousand retweets
“In a simulation” - 100 retweets
“In a paper ‘what if” scenario brainstormed around a desk” - 10 retweets
------
free 
@ASSC26nyc
 event friday june 23:

#christofkoch & i resolve our 25-year NCC bet!

#luciamelloni unveils new GWT vs IIT results!


@StanDehaene
 
@melanieboly
 
@danieldennett
 comment!


@theamygdaloid
 & 
@BabaBrinkman
 play!


@heather_berlin
 & 
@de_dicto
 host!
------
Mark on Lex encore.

Important section on open sourcing AI models at 17:50.

- Lex: Do you think the LAMA or the language model underlying that version 2 will be open sourced? Do you have internal debate around that, the pros and cons and so on?
- Mark: Oh yeah. Well I mean, we… Show more
------
Here's my conversation with Mark Zuckerberg, his 2nd time on the podcast. We talk about the future of AI at Meta, Facebook, Instagram, and WhatsApp, both near-term open source development of AI and the journey of human civilization toward building AGI. https://youtube.com/watch?v=Ff4fRgnuFgQ…
------
LLaMA compared to Falcon.
Test script issues....
------
Is Falcon really better than LLaMA? 
Short take: probably not.

Longer take: we reproduced LLaMA 65B eval on MMLU and we got 61.4, close to the official number (63.4), much higher than its Open LLM Leaderboard number (48.8), and clearly higher than Falcon (52.7).

Code and prompt… Show more
------
The evidence is accumulating.
------
 GPT models have blown our minds with their astonishing capabilities. But, do they truly acquire the ability to perform reasoning tasks that humans find easy to execute? NO

We investigate the limits of Transformers *empirically* and *theoretically* on compositional tasks
------
AI-Crypto comparisons are ridiculous… crypto was a technology with no real use cases… ai is a technology with almost every use case imaginable
------
- AI won't replace doctors. But doctors who use AI will replace doctors who don't.   

Get your headphones ready for a  discussion on

@20vcFund
 with 
@HarryStebbings
 in a couple of days!
------
AI for mathematics workshop.
Monday-Wednesday.
------
If you haven't signed up for the National Academies workshop on AI for Math, now is your chance! We have wonderful speakers like @vardi, @wellecks, Thierry Coquand, and @BlancheMinerva, and wonderful moderators like @ylecun, Terry Tao, and yours truly 

https://nationalacademies.org/our-work/ai-to-assist-mathematical-reasoning-a-workshop…
------
One of the strangest things about the world: 
So many people have opinions based on prejudice or dogma that merely being a rationalist can make you look like a contrarian.
------
Interesting observation.
------
I think many of the claims about LLM's reasoning capabilities miss the point that LLM's are not just trained on "facts" but also, quite often, the deductive closure of those facts. Thus reasoning becomes (approximate) retrieval. 1/
------
Black-box learning rate tuning is here!
------
Take your favorite optimizer (Adam, SGD, Lion) and feed it into Mechanic to get the learning rate. You give it the direction, it gives you the magnitude. The new optimizer has been tested on a wide range of deep learning problems: ViT, LSTM, ResNet, etc.
https://arxiv.org/abs/2306.00144
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
Discrete Cosine Transforms are eigenvectors of Laplacians with different boundary conditions. Wonderful paper by Strang. http://www-math.mit.edu/~gs/papers/dct.pdf…
------
I'm starting to think 
@ylecun
 may be right
------
Where AI doomerism comes from.
------
I'm often critical of Effective Altruism (EA) and I'm sure I'll get more pushback for this, but I've been thinking a lot lately about the discourse on AI doomerism, extinction risk, etc., and here's my big take on what's going on and why. 

Buckle up, friends, it gets spicy.
------
How can a technology designed to amplify human intelligence be viewed with such dread?
There are always risks associated with new technology.
But the question is whether the risks can be mitigated so as to make the benefits overwhelmingly worth the risks.
------
I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk. 

What are your thoughts? And, who do you think has a thoughtful perspective on how AI poses this risk that I should talk to?
------
AI is not going to take your job.
------
ChatGPT is Not a Technological Singularity https://cacm.acm.org/blogs/blog-cacm/273606-chatgpt-is-not-a-technological-singularity/fulltext… 

cc @ylecun @davidautor @pmarca
------
Transformer stages incrementally optimize a sparse compression criterion using a LISTA-like method.
------
I hope this work “White-box Transforms via Sparse Rate Reduction” http://arxiv.org/abs/2306.01129 will help both theoreticians and practitioners fully understand deep networks, particularly Transformers. Understanding is the only way to stop spreading mysteries, hypes, or even hysterias.
------
Comparison of the Wasserstein, Hellinger, Kullback-Leibler and reverse KL on the space of Gaussian distributions. http://djalil.chafai.net/blog/2020/01/22/about-the-hellinger-distance/…
------
A statistician's view of AGI doomer drama.
------
simply incredible.
------
Interesting.
------
New paper!! We show that pre-training language-image models *solely* on synthetic images from Stable Diffusion can outperform training on real images!!

Work done with @YonglongT (Google), Huiwen Chang (Google), @phillip_isola (MIT) and Lijie Fan (MIT)!!
------
L'IA sera le moteur d'un nouveau départ pour l'économie, la culture, l'éducation et la démocratie.

Accompagné de 
@laurentsolly
, j'en ai parlé avec 
@olivierveran
------
Haine, désinformation : sur Facebook ou Instagram, l’IA contribue à supprimer des discours dangereux.

Mais nous devons anticiper les dérives, pour que l’IA ne nuise pas à notre démocratie mais la protège ! 

J’en ai parlé avec Meta, @ylecun et @laurentsolly.
------
1/The false and sensationalist coverage of the purported Air Force simulation where an AI-drone decided to kill an operator will be remembered as a highly regrettable episode of AI doomsaying hype. Lets be honest about what are, and what are not, real risks.
------
This is worth repeating.
------
To be clear, at this time and for the foreseeable future, there does not exist any AI model or technique that could represent an extinction risk for humanity. Not even in nascent form, and not even if you extrapolate capabilities far into the future via scaling laws.
------
Imagine a future in which your daily interaction with the world of information is mediated by an AI assistant.

This AI assistant would be like an active repository of all human knowledge.

It will become your best rampart *against* misinformation.
------
AN AIRFORCE DRONE OPTIMISED FOR POINTS WENT ROGUE AND  KILLED OPERATOR!: a thousand retweets
“In a simulation” - 100 retweets
“In a paper ‘what if” scenario brainstormed around a desk” - 10 retweets
------
In this interview with Le Monde, Yoshua Bengio expresses his fears of some catastrophe scenarios that could be enabled by progress in AI.

One such scenario he is worried about is a flood of disinformation and political propaganda on social networks. He says that we have a "moral… Show more
------
Today marks the 8th anniversary of the public launch of FAIR-Paris.

The Parisian site of FAIR (Meta's Fundamental AI Research organization) is one of 7 sites and one of the largest.

*Amazing* research has come out of FAIR-Paris over the years.

FAIR-Paris hosts around 30… Show more
------
Sensible attitude against AI doomerism from the unequaled 
@kchonyc
 !
It's too bad that the long sequence of numerous beneficial little wins brought about by AI does make for media titles as catchy as "AI is gonna kill us all."
------
This is an important clarification about the AI drone that supposedly killed its operator: it was a hypothetical "wargamed" scenario. It didn't involve any AI agent or RL.

Source RTed below claims to know the team that delivered the scenario to the Air Force.
------
Correct, this was a scenario rather than a simulation. The reporting is quite misleading
------
Joint 
@Experiential_AI
 x 
@NUnetsi
 breakfast to kick off 
@ylecun
’s Distinguished seminar 
@Northeastern
!
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
- AI won't replace doctors. But doctors who use AI will replace doctors who don't.   

Get your headphones ready for a  discussion on

@20vcFund
 with 
@HarryStebbings
 in a couple of days!
------
AI for mathematics workshop.
Monday-Wednesday.
------
If you haven't signed up for the National Academies workshop on AI for Math, now is your chance! We have wonderful speakers like @vardi, @wellecks, Thierry Coquand, and @BlancheMinerva, and wonderful moderators like @ylecun, Terry Tao, and yours truly 

https://nationalacademies.org/our-work/ai-to-assist-mathematical-reasoning-a-workshop…
------
One of the strangest things about the world: 
So many people have opinions based on prejudice or dogma that merely being a rationalist can make you look like a contrarian.
------
Interesting observation.
------
I think many of the claims about LLM's reasoning capabilities miss the point that LLM's are not just trained on "facts" but also, quite often, the deductive closure of those facts. Thus reasoning becomes (approximate) retrieval. 1/
------
Black-box learning rate tuning is here!
------
Take your favorite optimizer (Adam, SGD, Lion) and feed it into Mechanic to get the learning rate. You give it the direction, it gives you the magnitude. The new optimizer has been tested on a wide range of deep learning problems: ViT, LSTM, ResNet, etc.
https://arxiv.org/abs/2306.00144
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
Discrete Cosine Transforms are eigenvectors of Laplacians with different boundary conditions. Wonderful paper by Strang. http://www-math.mit.edu/~gs/papers/dct.pdf…
------
I'm starting to think 
@ylecun
 may be right
------
Where AI doomerism comes from.
------
I'm often critical of Effective Altruism (EA) and I'm sure I'll get more pushback for this, but I've been thinking a lot lately about the discourse on AI doomerism, extinction risk, etc., and here's my big take on what's going on and why. 

Buckle up, friends, it gets spicy.
------
How can a technology designed to amplify human intelligence be viewed with such dread?
There are always risks associated with new technology.
But the question is whether the risks can be mitigated so as to make the benefits overwhelmingly worth the risks.
------
I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk. 

What are your thoughts? And, who do you think has a thoughtful perspective on how AI poses this risk that I should talk to?
------
AI is not going to take your job.
------
ChatGPT is Not a Technological Singularity https://cacm.acm.org/blogs/blog-cacm/273606-chatgpt-is-not-a-technological-singularity/fulltext… 

cc @ylecun @davidautor @pmarca
------
Transformer stages incrementally optimize a sparse compression criterion using a LISTA-like method.
------
I hope this work “White-box Transforms via Sparse Rate Reduction” http://arxiv.org/abs/2306.01129 will help both theoreticians and practitioners fully understand deep networks, particularly Transformers. Understanding is the only way to stop spreading mysteries, hypes, or even hysterias.
------
Comparison of the Wasserstein, Hellinger, Kullback-Leibler and reverse KL on the space of Gaussian distributions. http://djalil.chafai.net/blog/2020/01/22/about-the-hellinger-distance/…
------
A statistician's view of AGI doomer drama.
------
simply incredible.
------
Interesting.
------
New paper!! We show that pre-training language-image models *solely* on synthetic images from Stable Diffusion can outperform training on real images!!

Work done with @YonglongT (Google), Huiwen Chang (Google), @phillip_isola (MIT) and Lijie Fan (MIT)!!
------
L'IA sera le moteur d'un nouveau départ pour l'économie, la culture, l'éducation et la démocratie.

Accompagné de 
@laurentsolly
, j'en ai parlé avec 
@olivierveran
------
Haine, désinformation : sur Facebook ou Instagram, l’IA contribue à supprimer des discours dangereux.

Mais nous devons anticiper les dérives, pour que l’IA ne nuise pas à notre démocratie mais la protège ! 

J’en ai parlé avec Meta, @ylecun et @laurentsolly.
------
1/The false and sensationalist coverage of the purported Air Force simulation where an AI-drone decided to kill an operator will be remembered as a highly regrettable episode of AI doomsaying hype. Lets be honest about what are, and what are not, real risks.
------
This is worth repeating.
------
To be clear, at this time and for the foreseeable future, there does not exist any AI model or technique that could represent an extinction risk for humanity. Not even in nascent form, and not even if you extrapolate capabilities far into the future via scaling laws.
------
Imagine a future in which your daily interaction with the world of information is mediated by an AI assistant.

This AI assistant would be like an active repository of all human knowledge.

It will become your best rampart *against* misinformation.
------
AN AIRFORCE DRONE OPTIMISED FOR POINTS WENT ROGUE AND  KILLED OPERATOR!: a thousand retweets
“In a simulation” - 100 retweets
“In a paper ‘what if” scenario brainstormed around a desk” - 10 retweets
------
In this interview with Le Monde, Yoshua Bengio expresses his fears of some catastrophe scenarios that could be enabled by progress in AI.

One such scenario he is worried about is a flood of disinformation and political propaganda on social networks. He says that we have a "moral… Show more
------
Today marks the 8th anniversary of the public launch of FAIR-Paris.

The Parisian site of FAIR (Meta's Fundamental AI Research organization) is one of 7 sites and one of the largest.

*Amazing* research has come out of FAIR-Paris over the years.

FAIR-Paris hosts around 30… Show more
------
Sensible attitude against AI doomerism from the unequaled 
@kchonyc
 !
It's too bad that the long sequence of numerous beneficial little wins brought about by AI does make for media titles as catchy as "AI is gonna kill us all."
------
This is an important clarification about the AI drone that supposedly killed its operator: it was a hypothetical "wargamed" scenario. It didn't involve any AI agent or RL.

Source RTed below claims to know the team that delivered the scenario to the Air Force.
------
Correct, this was a scenario rather than a simulation. The reporting is quite misleading
------
Joint 
@Experiential_AI
 x 
@NUnetsi
 breakfast to kick off 
@ylecun
’s Distinguished seminar 
@Northeastern
!
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
Japan recently reaffirmed that it will not enforce copyrights on data used in AI training.

The policy allows AI to use any data “regardless of whether it is for non-profit or commercial purposes, whether it is an act other than  reproduction, or whether it is content obtained… Show more
------
Japan has become a machine learning paradise.
------
This is a monumentality important development in the AI copyright battle - first precedent is set

https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/…
------
yeah the model makes occasional mistakes, is demonstrated to be full of biases, and cannot be trusted to supply reliable information. but arent you thankful for all the hard work that we do to make sure it doesnt actively try and kill you? you woke up alive today. thanks to us.
------
It is admirable to apply the precautionary principle, and build & deploy transformative AI technology with exceptional care. But how is that best achieved by distracting from very real AI risks by making a remote, fanciful risk of extinction from AI a global priority? 
------
I’ve worked my whole life on AI because I believe in its incredible potential to advance science & medicine, and improve billions of people's lives. But as with any transformative technology we should apply the precautionary principle, and build & deploy it with exceptional care twitter.com/ai_risks/statu…
------
AI will save the world, not destroy it.
A good piece by 
@pmarca
 about the destructive moral panic around AI.
------
Why AI Will Save The World
By Marc Andreessen

The era of Artificial Intelligence is here, and boy are people freaking out.

Fortunately, I am here to bring the good news: AI will not destroy the world, and in fact may save it.

------
Discrete Cosine Transforms are eigenvectors of Laplacians with different boundary conditions. Wonderful paper by Strang. http://www-math.mit.edu/~gs/papers/dct.pdf…
------
I'm starting to think 
@ylecun
 may be right
------
Where AI doomerism comes from.
------
I'm often critical of Effective Altruism (EA) and I'm sure I'll get more pushback for this, but I've been thinking a lot lately about the discourse on AI doomerism, extinction risk, etc., and here's my big take on what's going on and why. 

Buckle up, friends, it gets spicy.
------
How can a technology designed to amplify human intelligence be viewed with such dread?
There are always risks associated with new technology.
But the question is whether the risks can be mitigated so as to make the benefits overwhelmingly worth the risks.
------
I'd like to have a real conversation about whether AI is a risk for human extinction. Honestly, I don't get how AI poses this risk. 

What are your thoughts? And, who do you think has a thoughtful perspective on how AI poses this risk that I should talk to?
------
AI is not going to take your job.
------
ChatGPT is Not a Technological Singularity https://cacm.acm.org/blogs/blog-cacm/273606-chatgpt-is-not-a-technological-singularity/fulltext… 

cc @ylecun @davidautor @pmarca
------
Transformer stages incrementally optimize a sparse compression criterion using a LISTA-like method.
------
I hope this work “White-box Transforms via Sparse Rate Reduction” http://arxiv.org/abs/2306.01129 will help both theoreticians and practitioners fully understand deep networks, particularly Transformers. Understanding is the only way to stop spreading mysteries, hypes, or even hysterias.
------
Comparison of the Wasserstein, Hellinger, Kullback-Leibler and reverse KL on the space of Gaussian distributions. http://djalil.chafai.net/blog/2020/01/22/about-the-hellinger-distance/…
------
A statistician's view of AGI doomer drama.
------
simply incredible.
------
Interesting.
------
New paper!! We show that pre-training language-image models *solely* on synthetic images from Stable Diffusion can outperform training on real images!!

Work done with @YonglongT (Google), Huiwen Chang (Google), @phillip_isola (MIT) and Lijie Fan (MIT)!!
------
L'IA sera le moteur d'un nouveau départ pour l'économie, la culture, l'éducation et la démocratie.

Accompagné de 
@laurentsolly
, j'en ai parlé avec 
@olivierveran
------
Haine, désinformation : sur Facebook ou Instagram, l’IA contribue à supprimer des discours dangereux.

Mais nous devons anticiper les dérives, pour que l’IA ne nuise pas à notre démocratie mais la protège ! 

J’en ai parlé avec Meta, @ylecun et @laurentsolly.
------
1/The false and sensationalist coverage of the purported Air Force simulation where an AI-drone decided to kill an operator will be remembered as a highly regrettable episode of AI doomsaying hype. Lets be honest about what are, and what are not, real risks.
------
This is worth repeating.
------
To be clear, at this time and for the foreseeable future, there does not exist any AI model or technique that could represent an extinction risk for humanity. Not even in nascent form, and not even if you extrapolate capabilities far into the future via scaling laws.
------
Imagine a future in which your daily interaction with the world of information is mediated by an AI assistant.

This AI assistant would be like an active repository of all human knowledge.

It will become your best rampart *against* misinformation.
------
AN AIRFORCE DRONE OPTIMISED FOR POINTS WENT ROGUE AND  KILLED OPERATOR!: a thousand retweets
“In a simulation” - 100 retweets
“In a paper ‘what if” scenario brainstormed around a desk” - 10 retweets
------
In this interview with Le Monde, Yoshua Bengio expresses his fears of some catastrophe scenarios that could be enabled by progress in AI.

One such scenario he is worried about is a flood of disinformation and political propaganda on social networks. He says that we have a "moral… Show more
------
Today marks the 8th anniversary of the public launch of FAIR-Paris.

The Parisian site of FAIR (Meta's Fundamental AI Research organization) is one of 7 sites and one of the largest.

*Amazing* research has come out of FAIR-Paris over the years.

FAIR-Paris hosts around 30… Show more
------
Sensible attitude against AI doomerism from the unequaled 
@kchonyc
 !
It's too bad that the long sequence of numerous beneficial little wins brought about by AI does make for media titles as catchy as "AI is gonna kill us all."
------
This is an important clarification about the AI drone that supposedly killed its operator: it was a hypothetical "wargamed" scenario. It didn't involve any AI agent or RL.

Source RTed below claims to know the team that delivered the scenario to the Air Force.
------
Correct, this was a scenario rather than a simulation. The reporting is quite misleading
------
Joint 
@Experiential_AI
 x 
@NUnetsi
 breakfast to kick off 
@ylecun
’s Distinguished seminar 
@Northeastern
!
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
Japan recently reaffirmed that it will not enforce copyrights on data used in AI training.

The policy allows AI to use any data “regardless of whether it is for non-profit or commercial purposes, whether it is an act other than  reproduction, or whether it is content obtained… Show more
------
Japan has become a machine learning paradise.
------
This is a monumentality important development in the AI copyright battle - first precedent is set

https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/…
------
yeah the model makes occasional mistakes, is demonstrated to be full of biases, and cannot be trusted to supply reliable information. but arent you thankful for all the hard work that we do to make sure it doesnt actively try and kill you? you woke up alive today. thanks to us.
------
It is admirable to apply the precautionary principle, and build & deploy transformative AI technology with exceptional care. But how is that best achieved by distracting from very real AI risks by making a remote, fanciful risk of extinction from AI a global priority? 
------
I’ve worked my whole life on AI because I believe in its incredible potential to advance science & medicine, and improve billions of people's lives. But as with any transformative technology we should apply the precautionary principle, and build & deploy it with exceptional care twitter.com/ai_risks/statu…
------
So much news today! Quest 3 is official—our most powerful headset yet with pancake optics for a slimmer profile, improved comfort, a next-gen 
@Qualcomm
 Snapdragon chipset for over 2x the graphical performance, and better resolution and display
------
Eigenvalues of random matrices with iid entries converge to the Wigner circle law. This is universal (does not depend on the law of the entries), as proved by Tao and Vu in 2010. For Gaussian matrices, this defines a determinental point process. https://en.wikipedia.org/wiki/Circular_law…
------
Comparison of the Wasserstein, Hellinger, Kullback-Leibler and reverse KL on the space of Gaussian distributions. http://djalil.chafai.net/blog/2020/01/22/about-the-hellinger-distance/…
------
A statistician's view of AGI doomer drama.
------
simply incredible.
------
Interesting.
------
New paper!! We show that pre-training language-image models *solely* on synthetic images from Stable Diffusion can outperform training on real images!!

Work done with @YonglongT (Google), Huiwen Chang (Google), @phillip_isola (MIT) and Lijie Fan (MIT)!!
------
L'IA sera le moteur d'un nouveau départ pour l'économie, la culture, l'éducation et la démocratie.

Accompagné de 
@laurentsolly
, j'en ai parlé avec 
@olivierveran
------
Haine, désinformation : sur Facebook ou Instagram, l’IA contribue à supprimer des discours dangereux.

Mais nous devons anticiper les dérives, pour que l’IA ne nuise pas à notre démocratie mais la protège ! 

J’en ai parlé avec Meta, @ylecun et @laurentsolly.
------
1/The false and sensationalist coverage of the purported Air Force simulation where an AI-drone decided to kill an operator will be remembered as a highly regrettable episode of AI doomsaying hype. Lets be honest about what are, and what are not, real risks.
------
This is worth repeating.
------
To be clear, at this time and for the foreseeable future, there does not exist any AI model or technique that could represent an extinction risk for humanity. Not even in nascent form, and not even if you extrapolate capabilities far into the future via scaling laws.
------
Imagine a future in which your daily interaction with the world of information is mediated by an AI assistant.

This AI assistant would be like an active repository of all human knowledge.

It will become your best rampart *against* misinformation.
------
AN AIRFORCE DRONE OPTIMISED FOR POINTS WENT ROGUE AND  KILLED OPERATOR!: a thousand retweets
“In a simulation” - 100 retweets
“In a paper ‘what if” scenario brainstormed around a desk” - 10 retweets
------
In this interview with Le Monde, Yoshua Bengio expresses his fears of some catastrophe scenarios that could be enabled by progress in AI.

One such scenario he is worried about is a flood of disinformation and political propaganda on social networks. He says that we have a "moral… Show more
------
Today marks the 8th anniversary of the public launch of FAIR-Paris.

The Parisian site of FAIR (Meta's Fundamental AI Research organization) is one of 7 sites and one of the largest.

*Amazing* research has come out of FAIR-Paris over the years.

FAIR-Paris hosts around 30… Show more
------
Sensible attitude against AI doomerism from the unequaled 
@kchonyc
 !
It's too bad that the long sequence of numerous beneficial little wins brought about by AI does make for media titles as catchy as "AI is gonna kill us all."
------
This is an important clarification about the AI drone that supposedly killed its operator: it was a hypothetical "wargamed" scenario. It didn't involve any AI agent or RL.

Source RTed below claims to know the team that delivered the scenario to the Air Force.
------
Correct, this was a scenario rather than a simulation. The reporting is quite misleading
------
Joint 
@Experiential_AI
 x 
@NUnetsi
 breakfast to kick off 
@ylecun
’s Distinguished seminar 
@Northeastern
!
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
Japan recently reaffirmed that it will not enforce copyrights on data used in AI training.

The policy allows AI to use any data “regardless of whether it is for non-profit or commercial purposes, whether it is an act other than  reproduction, or whether it is content obtained… Show more
------
Japan has become a machine learning paradise.
------
This is a monumentality important development in the AI copyright battle - first precedent is set

https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/…
------
yeah the model makes occasional mistakes, is demonstrated to be full of biases, and cannot be trusted to supply reliable information. but arent you thankful for all the hard work that we do to make sure it doesnt actively try and kill you? you woke up alive today. thanks to us.
------
It is admirable to apply the precautionary principle, and build & deploy transformative AI technology with exceptional care. But how is that best achieved by distracting from very real AI risks by making a remote, fanciful risk of extinction from AI a global priority? 
------
I’ve worked my whole life on AI because I believe in its incredible potential to advance science & medicine, and improve billions of people's lives. But as with any transformative technology we should apply the precautionary principle, and build & deploy it with exceptional care twitter.com/ai_risks/statu…
------
So much news today! Quest 3 is official—our most powerful headset yet with pancake optics for a slimmer profile, improved comfort, a next-gen 
@Qualcomm
 Snapdragon chipset for over 2x the graphical performance, and better resolution and display
------
Eigenvalues of random matrices with iid entries converge to the Wigner circle law. This is universal (does not depend on the law of the entries), as proved by Tao and Vu in 2010. For Gaussian matrices, this defines a determinental point process. https://en.wikipedia.org/wiki/Circular_law…
------
Yes. I don't find AGI to be a useful concept. We can build systems that are more general or more specialized and systems that are more skilled at reasoning or less skilled. But I don't see any reason to believe there is a magic threshold of generality and reasoning skill. 1/
------
Nice essay by a historian about information revolutions.

"If we pour a precious new elixir into a leaky cup and it leaks, we need to fix the cup, not fear the elixir. "
H/T 
@amcafee
------
New essay on future of AI

"For 20 generations we have been living in an information revolution"

"We fear the artist & writer will starve, but artist & writer are already starving b/c our copyright system serves mainly monopolies... Policy is everything"

https://unlocked.microsoft.com/ai-anthology/ada-palmer/…
------
The silent majority of AI.
------
But most AI people work in the quiet middle: We see huge benefits from people using AI in healthcare, education, …, and we see serious AI risks & harms but believe we can minimize them with careful engineering & regulation, just as happened with electricity, cars, planes, ….
------
AI has 2 loud groups: “AI Safety” builds hype by evoking existential risks from AI to distract from the real harms, while developing AI at full speed; “AI Ethics” sees AI faults & dangers everywhere—building their brand of “criti-hype”, claiming the wise path is to not use AI.
------
A sensible piece by Nello Cristianini about AI existential risk.
Or lack thereof.

"If we’re going to label AI an ‘extinction risk’, we need to clarify how it could happen"
------
Ditto.
------
How many of the signatories have used their expertise, their influence, their resources to rigourously analyze and expose the risks of current AI systems, and to build solutions that address real harms?  That is what we need. Not letters, headlines and inflammatory statements. twitter.com/ai_risks/statu…
------
 We will be doing a tutorial on LLMs and Planning at #ICAPS2023. So, if the many splendors of Prague are not enough of an attraction for you, there is now this..

 https://icaps23.icaps-conference.org/program/tutorials/llms/…
------
L'IA sera le moteur d'un nouveau départ pour l'économie, la culture, l'éducation et la démocratie.

Accompagné de 
@laurentsolly
, j'en ai parlé avec 
@olivierveran
------
Haine, désinformation : sur Facebook ou Instagram, l’IA contribue à supprimer des discours dangereux.

Mais nous devons anticiper les dérives, pour que l’IA ne nuise pas à notre démocratie mais la protège ! 

J’en ai parlé avec Meta, @ylecun et @laurentsolly.
------
1/The false and sensationalist coverage of the purported Air Force simulation where an AI-drone decided to kill an operator will be remembered as a highly regrettable episode of AI doomsaying hype. Lets be honest about what are, and what are not, real risks.
------
This is worth repeating.
------
To be clear, at this time and for the foreseeable future, there does not exist any AI model or technique that could represent an extinction risk for humanity. Not even in nascent form, and not even if you extrapolate capabilities far into the future via scaling laws.
------
Imagine a future in which your daily interaction with the world of information is mediated by an AI assistant.

This AI assistant would be like an active repository of all human knowledge.

It will become your best rampart *against* misinformation.
------
AN AIRFORCE DRONE OPTIMISED FOR POINTS WENT ROGUE AND  KILLED OPERATOR!: a thousand retweets
“In a simulation” - 100 retweets
“In a paper ‘what if” scenario brainstormed around a desk” - 10 retweets
------
In this interview with Le Monde, Yoshua Bengio expresses his fears of some catastrophe scenarios that could be enabled by progress in AI.

One such scenario he is worried about is a flood of disinformation and political propaganda on social networks. He says that we have a "moral… Show more
------
Today marks the 8th anniversary of the public launch of FAIR-Paris.

The Parisian site of FAIR (Meta's Fundamental AI Research organization) is one of 7 sites and one of the largest.

*Amazing* research has come out of FAIR-Paris over the years.

FAIR-Paris hosts around 30… Show more
------
Sensible attitude against AI doomerism from the unequaled 
@kchonyc
 !
It's too bad that the long sequence of numerous beneficial little wins brought about by AI does make for media titles as catchy as "AI is gonna kill us all."
------
This is an important clarification about the AI drone that supposedly killed its operator: it was a hypothetical "wargamed" scenario. It didn't involve any AI agent or RL.

Source RTed below claims to know the team that delivered the scenario to the Air Force.
------
Correct, this was a scenario rather than a simulation. The reporting is quite misleading
------
Joint 
@Experiential_AI
 x 
@NUnetsi
 breakfast to kick off 
@ylecun
’s Distinguished seminar 
@Northeastern
!
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
Japan recently reaffirmed that it will not enforce copyrights on data used in AI training.

The policy allows AI to use any data “regardless of whether it is for non-profit or commercial purposes, whether it is an act other than  reproduction, or whether it is content obtained… Show more
------
Japan has become a machine learning paradise.
------
This is a monumentality important development in the AI copyright battle - first precedent is set

https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/…
------
yeah the model makes occasional mistakes, is demonstrated to be full of biases, and cannot be trusted to supply reliable information. but arent you thankful for all the hard work that we do to make sure it doesnt actively try and kill you? you woke up alive today. thanks to us.
------
It is admirable to apply the precautionary principle, and build & deploy transformative AI technology with exceptional care. But how is that best achieved by distracting from very real AI risks by making a remote, fanciful risk of extinction from AI a global priority? 
------
I’ve worked my whole life on AI because I believe in its incredible potential to advance science & medicine, and improve billions of people's lives. But as with any transformative technology we should apply the precautionary principle, and build & deploy it with exceptional care twitter.com/ai_risks/statu…
------
So much news today! Quest 3 is official—our most powerful headset yet with pancake optics for a slimmer profile, improved comfort, a next-gen 
@Qualcomm
 Snapdragon chipset for over 2x the graphical performance, and better resolution and display
------
Eigenvalues of random matrices with iid entries converge to the Wigner circle law. This is universal (does not depend on the law of the entries), as proved by Tao and Vu in 2010. For Gaussian matrices, this defines a determinental point process. https://en.wikipedia.org/wiki/Circular_law…
------
Yes. I don't find AGI to be a useful concept. We can build systems that are more general or more specialized and systems that are more skilled at reasoning or less skilled. But I don't see any reason to believe there is a magic threshold of generality and reasoning skill. 1/
------
Nice essay by a historian about information revolutions.

"If we pour a precious new elixir into a leaky cup and it leaks, we need to fix the cup, not fear the elixir. "
H/T 
@amcafee
------
New essay on future of AI

"For 20 generations we have been living in an information revolution"

"We fear the artist & writer will starve, but artist & writer are already starving b/c our copyright system serves mainly monopolies... Policy is everything"

https://unlocked.microsoft.com/ai-anthology/ada-palmer/…
------
The silent majority of AI.
------
But most AI people work in the quiet middle: We see huge benefits from people using AI in healthcare, education, …, and we see serious AI risks & harms but believe we can minimize them with careful engineering & regulation, just as happened with electricity, cars, planes, ….
------
AI has 2 loud groups: “AI Safety” builds hype by evoking existential risks from AI to distract from the real harms, while developing AI at full speed; “AI Ethics” sees AI faults & dangers everywhere—building their brand of “criti-hype”, claiming the wise path is to not use AI.
------
A sensible piece by Nello Cristianini about AI existential risk.
Or lack thereof.

"If we’re going to label AI an ‘extinction risk’, we need to clarify how it could happen"
------
Ditto.
------
How many of the signatories have used their expertise, their influence, their resources to rigourously analyze and expose the risks of current AI systems, and to build solutions that address real harms?  That is what we need. Not letters, headlines and inflammatory statements. twitter.com/ai_risks/statu…
------
 We will be doing a tutorial on LLMs and Planning at #ICAPS2023. So, if the many splendors of Prague are not enough of an attraction for you, there is now this..

 https://icaps23.icaps-conference.org/program/tutorials/llms/…
------
"...the plea will hopefully stop others from doing the same. I'm so much smarter than everyone that it's okay if I do it, but very, very dangerous if anyone else does it."
------
"I am the brightest mind in AI, and also the most powerful and influential. I think my work can have disastrous consequences and end humanity. So I will keep working on it full speed, but also sign this plea urging you to be afraid and allocate some money to keep an eye on me."
------
The thing to remember about academic science is that:
1. No one is in it for the money. The currency is intellectual influence and prestige.
2. If you write science fiction and try to pass it as fact, your career is over (unlike, say, AI doomism).
------
The thing to remember about academic science is that nobody in the system - journal editors, grantmakers, conference organizers, tenure committees, deans, university administrators, PhD defense committees, or scientists - gets paid an extra $10,000 if the theory is actually true.
------
1/4) Several people I admire immensely have signed this, but respectfully, I'm afraid I just don't agree with the claim that "mitigating the risk of extinction from AI should be a global priority".

I think this statement is naive and a mistake.
------
We’ve released a statement on the risk of extinction from AI.

Signatories include:
- Three Turing Award winners
- Authors of the standard textbooks on AI/DL/RL
- CEOs and Execs from OpenAI, Microsoft, Google, Google DeepMind, Anthropic
- Many more

https://safe.ai/statement-on-ai-risk…
------
Super-human AI is nowhere near the top of the list of existential risks.
In large part because it doesn't exist yet.

Until we have a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature.
------
When I think of existential risks to large parts of humanity:
* The next pandemic
* Climate change→massive depopulation
* Another asteroid
AI will be a key part of our solution. So if you want humanity to survive & thrive the next 1000 years, lets make AI go faster, not slower.
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between 
@ylecun
 and 
@AndrewYNg
 , is available here:
------
In this interview with Le Monde, Yoshua Bengio expresses his fears of some catastrophe scenarios that could be enabled by progress in AI.

One such scenario he is worried about is a flood of disinformation and political propaganda on social networks. He says that we have a "moral… Show more
------
Today marks the 8th anniversary of the public launch of FAIR-Paris.

The Parisian site of FAIR (Meta's Fundamental AI Research organization) is one of 7 sites and one of the largest.

*Amazing* research has come out of FAIR-Paris over the years.

FAIR-Paris hosts around 30… Show more
------
Sensible attitude against AI doomerism from the unequaled 
@kchonyc
 !
It's too bad that the long sequence of numerous beneficial little wins brought about by AI does make for media titles as catchy as "AI is gonna kill us all."
------
This is an important clarification about the AI drone that supposedly killed its operator: it was a hypothetical "wargamed" scenario. It didn't involve any AI agent or RL.

Source RTed below claims to know the team that delivered the scenario to the Air Force.
------
Correct, this was a scenario rather than a simulation. The reporting is quite misleading
------
Joint 
@Experiential_AI
 x 
@NUnetsi
 breakfast to kick off 
@ylecun
’s Distinguished seminar 
@Northeastern
!
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
Japan recently reaffirmed that it will not enforce copyrights on data used in AI training.

The policy allows AI to use any data “regardless of whether it is for non-profit or commercial purposes, whether it is an act other than  reproduction, or whether it is content obtained… Show more
------
Japan has become a machine learning paradise.
------
This is a monumentality important development in the AI copyright battle - first precedent is set

https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/…
------
yeah the model makes occasional mistakes, is demonstrated to be full of biases, and cannot be trusted to supply reliable information. but arent you thankful for all the hard work that we do to make sure it doesnt actively try and kill you? you woke up alive today. thanks to us.
------
It is admirable to apply the precautionary principle, and build & deploy transformative AI technology with exceptional care. But how is that best achieved by distracting from very real AI risks by making a remote, fanciful risk of extinction from AI a global priority? 
------
I’ve worked my whole life on AI because I believe in its incredible potential to advance science & medicine, and improve billions of people's lives. But as with any transformative technology we should apply the precautionary principle, and build & deploy it with exceptional care twitter.com/ai_risks/statu…
------
So much news today! Quest 3 is official—our most powerful headset yet with pancake optics for a slimmer profile, improved comfort, a next-gen 
@Qualcomm
 Snapdragon chipset for over 2x the graphical performance, and better resolution and display
------
Eigenvalues of random matrices with iid entries converge to the Wigner circle law. This is universal (does not depend on the law of the entries), as proved by Tao and Vu in 2010. For Gaussian matrices, this defines a determinental point process. https://en.wikipedia.org/wiki/Circular_law…
------
Yes. I don't find AGI to be a useful concept. We can build systems that are more general or more specialized and systems that are more skilled at reasoning or less skilled. But I don't see any reason to believe there is a magic threshold of generality and reasoning skill. 1/
------
Nice essay by a historian about information revolutions.

"If we pour a precious new elixir into a leaky cup and it leaks, we need to fix the cup, not fear the elixir. "
H/T 
@amcafee
------
New essay on future of AI

"For 20 generations we have been living in an information revolution"

"We fear the artist & writer will starve, but artist & writer are already starving b/c our copyright system serves mainly monopolies... Policy is everything"

https://unlocked.microsoft.com/ai-anthology/ada-palmer/…
------
The silent majority of AI.
------
But most AI people work in the quiet middle: We see huge benefits from people using AI in healthcare, education, …, and we see serious AI risks & harms but believe we can minimize them with careful engineering & regulation, just as happened with electricity, cars, planes, ….
------
AI has 2 loud groups: “AI Safety” builds hype by evoking existential risks from AI to distract from the real harms, while developing AI at full speed; “AI Ethics” sees AI faults & dangers everywhere—building their brand of “criti-hype”, claiming the wise path is to not use AI.
------
A sensible piece by Nello Cristianini about AI existential risk.
Or lack thereof.

"If we’re going to label AI an ‘extinction risk’, we need to clarify how it could happen"
------
Ditto.
------
How many of the signatories have used their expertise, their influence, their resources to rigourously analyze and expose the risks of current AI systems, and to build solutions that address real harms?  That is what we need. Not letters, headlines and inflammatory statements. twitter.com/ai_risks/statu…
------
 We will be doing a tutorial on LLMs and Planning at #ICAPS2023. So, if the many splendors of Prague are not enough of an attraction for you, there is now this..

 https://icaps23.icaps-conference.org/program/tutorials/llms/…
------
"...the plea will hopefully stop others from doing the same. I'm so much smarter than everyone that it's okay if I do it, but very, very dangerous if anyone else does it."
------
"I am the brightest mind in AI, and also the most powerful and influential. I think my work can have disastrous consequences and end humanity. So I will keep working on it full speed, but also sign this plea urging you to be afraid and allocate some money to keep an eye on me."
------
The thing to remember about academic science is that:
1. No one is in it for the money. The currency is intellectual influence and prestige.
2. If you write science fiction and try to pass it as fact, your career is over (unlike, say, AI doomism).
------
The thing to remember about academic science is that nobody in the system - journal editors, grantmakers, conference organizers, tenure committees, deans, university administrators, PhD defense committees, or scientists - gets paid an extra $10,000 if the theory is actually true.
------
1/4) Several people I admire immensely have signed this, but respectfully, I'm afraid I just don't agree with the claim that "mitigating the risk of extinction from AI should be a global priority".

I think this statement is naive and a mistake.
------
We’ve released a statement on the risk of extinction from AI.

Signatories include:
- Three Turing Award winners
- Authors of the standard textbooks on AI/DL/RL
- CEOs and Execs from OpenAI, Microsoft, Google, Google DeepMind, Anthropic
- Many more

https://safe.ai/statement-on-ai-risk…
------
Super-human AI is nowhere near the top of the list of existential risks.
In large part because it doesn't exist yet.

Until we have a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature.
------
When I think of existential risks to large parts of humanity:
* The next pandemic
* Climate change→massive depopulation
* Another asteroid
AI will be a key part of our solution. So if you want humanity to survive & thrive the next 1000 years, lets make AI go faster, not slower.
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between 
@ylecun
 and 
@AndrewYNg
 , is available here:
------
"Clearly we are not anywhere close to human-level intelligence, otherwise we would have level 5 autonomous driving"
-- 
@ylecun
 

Available with timestamp here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=660…
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between @ylecun and @AndrewYNg , is available here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=608…
------
Truth.
------
There’s a very high correlation between people who think that AI take off is imminent and simple and will take over the world and people who regularly express amazingly simplistic ideas about how the world we already live in works.
------
Great thread on Hinton's infamous prediction about AI replacing radiologists: "thinkers have a pattern where they are so divorced from implementation details that applications seem trivial, when in reality, the small details are exactly where value accrues."
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… twitter.com/ylecun/status/… Show more
------
Curious about what kind of representations are learned with SSL? What makes them learn meaningful representations? their characteristics at intermediate layers? Check out our recent paper: https://arxiv.org/abs/2305.15614 (with 
@ml_norms
 
@ziv_ravid
 Shai Dekel and 
@ylecun
)
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… Show more
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now. twitter.com/erikbryn/statu…
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
Finally a generated portrait that doesn't make me look like Teuvo Kohonen (though I have less superpowers and more grey hairs).
Admittedly looking better than the real thing.
I'll take it 
------
Thanks Yann!
------
Japan recently reaffirmed that it will not enforce copyrights on data used in AI training.

The policy allows AI to use any data “regardless of whether it is for non-profit or commercial purposes, whether it is an act other than  reproduction, or whether it is content obtained… Show more
------
Japan has become a machine learning paradise.
------
This is a monumentality important development in the AI copyright battle - first precedent is set

https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/…
------
yeah the model makes occasional mistakes, is demonstrated to be full of biases, and cannot be trusted to supply reliable information. but arent you thankful for all the hard work that we do to make sure it doesnt actively try and kill you? you woke up alive today. thanks to us.
------
It is admirable to apply the precautionary principle, and build & deploy transformative AI technology with exceptional care. But how is that best achieved by distracting from very real AI risks by making a remote, fanciful risk of extinction from AI a global priority? 
------
I’ve worked my whole life on AI because I believe in its incredible potential to advance science & medicine, and improve billions of people's lives. But as with any transformative technology we should apply the precautionary principle, and build & deploy it with exceptional care twitter.com/ai_risks/statu…
------
So much news today! Quest 3 is official—our most powerful headset yet with pancake optics for a slimmer profile, improved comfort, a next-gen 
@Qualcomm
 Snapdragon chipset for over 2x the graphical performance, and better resolution and display
------
Eigenvalues of random matrices with iid entries converge to the Wigner circle law. This is universal (does not depend on the law of the entries), as proved by Tao and Vu in 2010. For Gaussian matrices, this defines a determinental point process. https://en.wikipedia.org/wiki/Circular_law…
------
Yes. I don't find AGI to be a useful concept. We can build systems that are more general or more specialized and systems that are more skilled at reasoning or less skilled. But I don't see any reason to believe there is a magic threshold of generality and reasoning skill. 1/
------
Nice essay by a historian about information revolutions.

"If we pour a precious new elixir into a leaky cup and it leaks, we need to fix the cup, not fear the elixir. "
H/T 
@amcafee
------
New essay on future of AI

"For 20 generations we have been living in an information revolution"

"We fear the artist & writer will starve, but artist & writer are already starving b/c our copyright system serves mainly monopolies... Policy is everything"

https://unlocked.microsoft.com/ai-anthology/ada-palmer/…
------
The silent majority of AI.
------
But most AI people work in the quiet middle: We see huge benefits from people using AI in healthcare, education, …, and we see serious AI risks & harms but believe we can minimize them with careful engineering & regulation, just as happened with electricity, cars, planes, ….
------
AI has 2 loud groups: “AI Safety” builds hype by evoking existential risks from AI to distract from the real harms, while developing AI at full speed; “AI Ethics” sees AI faults & dangers everywhere—building their brand of “criti-hype”, claiming the wise path is to not use AI.
------
A sensible piece by Nello Cristianini about AI existential risk.
Or lack thereof.

"If we’re going to label AI an ‘extinction risk’, we need to clarify how it could happen"
------
Ditto.
------
How many of the signatories have used their expertise, their influence, their resources to rigourously analyze and expose the risks of current AI systems, and to build solutions that address real harms?  That is what we need. Not letters, headlines and inflammatory statements. twitter.com/ai_risks/statu…
------
 We will be doing a tutorial on LLMs and Planning at #ICAPS2023. So, if the many splendors of Prague are not enough of an attraction for you, there is now this..

 https://icaps23.icaps-conference.org/program/tutorials/llms/…
------
"...the plea will hopefully stop others from doing the same. I'm so much smarter than everyone that it's okay if I do it, but very, very dangerous if anyone else does it."
------
"I am the brightest mind in AI, and also the most powerful and influential. I think my work can have disastrous consequences and end humanity. So I will keep working on it full speed, but also sign this plea urging you to be afraid and allocate some money to keep an eye on me."
------
The thing to remember about academic science is that:
1. No one is in it for the money. The currency is intellectual influence and prestige.
2. If you write science fiction and try to pass it as fact, your career is over (unlike, say, AI doomism).
------
The thing to remember about academic science is that nobody in the system - journal editors, grantmakers, conference organizers, tenure committees, deans, university administrators, PhD defense committees, or scientists - gets paid an extra $10,000 if the theory is actually true.
------
1/4) Several people I admire immensely have signed this, but respectfully, I'm afraid I just don't agree with the claim that "mitigating the risk of extinction from AI should be a global priority".

I think this statement is naive and a mistake.
------
We’ve released a statement on the risk of extinction from AI.

Signatories include:
- Three Turing Award winners
- Authors of the standard textbooks on AI/DL/RL
- CEOs and Execs from OpenAI, Microsoft, Google, Google DeepMind, Anthropic
- Many more

https://safe.ai/statement-on-ai-risk…
------
Super-human AI is nowhere near the top of the list of existential risks.
In large part because it doesn't exist yet.

Until we have a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature.
------
When I think of existential risks to large parts of humanity:
* The next pandemic
* Climate change→massive depopulation
* Another asteroid
AI will be a key part of our solution. So if you want humanity to survive & thrive the next 1000 years, lets make AI go faster, not slower.
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between 
@ylecun
 and 
@AndrewYNg
 , is available here:
------
"Clearly we are not anywhere close to human-level intelligence, otherwise we would have level 5 autonomous driving"
-- 
@ylecun
 

Available with timestamp here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=660…
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between @ylecun and @AndrewYNg , is available here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=608…
------
Truth.
------
There’s a very high correlation between people who think that AI take off is imminent and simple and will take over the world and people who regularly express amazingly simplistic ideas about how the world we already live in works.
------
Great thread on Hinton's infamous prediction about AI replacing radiologists: "thinkers have a pattern where they are so divorced from implementation details that applications seem trivial, when in reality, the small details are exactly where value accrues."
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… twitter.com/ylecun/status/… Show more
------
Curious about what kind of representations are learned with SSL? What makes them learn meaningful representations? their characteristics at intermediate layers? Check out our recent paper: https://arxiv.org/abs/2305.15614 (with 
@ml_norms
 
@ziv_ravid
 Shai Dekel and 
@ylecun
)
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… Show more
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now. twitter.com/erikbryn/statu…
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now.
------
AI will transform a large number of jobs in the coming years. Both workers and companies need to be prepared for significant disruption in wages and demand.

But contrary to some predictions, I don't anticipate mass unemployment due to AI this decade.
------
Some folks seem to think I ignore or don't care about AI ethics, safety, and alignment.

I need to remind them that a group of us co-founded the Partnership on AI in 2016 precisely to study, discuss, and address questions of AI ethics, safety, and alignment back in 2016.… Show more
------
Clarification: Although the initial discussions were with Demis, it was @mustafasuleymn who became the co-founder of PAI for Google/DeepMind.
------
So much news today! Quest 3 is official—our most powerful headset yet with pancake optics for a slimmer profile, improved comfort, a next-gen 
@Qualcomm
 Snapdragon chipset for over 2x the graphical performance, and better resolution and display
------
Eigenvalues of random matrices with iid entries converge to the Wigner circle law. This is universal (does not depend on the law of the entries), as proved by Tao and Vu in 2010. For Gaussian matrices, this defines a determinental point process. https://en.wikipedia.org/wiki/Circular_law…
------
Yes. I don't find AGI to be a useful concept. We can build systems that are more general or more specialized and systems that are more skilled at reasoning or less skilled. But I don't see any reason to believe there is a magic threshold of generality and reasoning skill. 1/
------
Nice essay by a historian about information revolutions.

"If we pour a precious new elixir into a leaky cup and it leaks, we need to fix the cup, not fear the elixir. "
H/T 
@amcafee
------
New essay on future of AI

"For 20 generations we have been living in an information revolution"

"We fear the artist & writer will starve, but artist & writer are already starving b/c our copyright system serves mainly monopolies... Policy is everything"

https://unlocked.microsoft.com/ai-anthology/ada-palmer/…
------
The silent majority of AI.
------
But most AI people work in the quiet middle: We see huge benefits from people using AI in healthcare, education, …, and we see serious AI risks & harms but believe we can minimize them with careful engineering & regulation, just as happened with electricity, cars, planes, ….
------
AI has 2 loud groups: “AI Safety” builds hype by evoking existential risks from AI to distract from the real harms, while developing AI at full speed; “AI Ethics” sees AI faults & dangers everywhere—building their brand of “criti-hype”, claiming the wise path is to not use AI.
------
A sensible piece by Nello Cristianini about AI existential risk.
Or lack thereof.

"If we’re going to label AI an ‘extinction risk’, we need to clarify how it could happen"
------
Ditto.
------
How many of the signatories have used their expertise, their influence, their resources to rigourously analyze and expose the risks of current AI systems, and to build solutions that address real harms?  That is what we need. Not letters, headlines and inflammatory statements. twitter.com/ai_risks/statu…
------
 We will be doing a tutorial on LLMs and Planning at #ICAPS2023. So, if the many splendors of Prague are not enough of an attraction for you, there is now this..

 https://icaps23.icaps-conference.org/program/tutorials/llms/…
------
"...the plea will hopefully stop others from doing the same. I'm so much smarter than everyone that it's okay if I do it, but very, very dangerous if anyone else does it."
------
"I am the brightest mind in AI, and also the most powerful and influential. I think my work can have disastrous consequences and end humanity. So I will keep working on it full speed, but also sign this plea urging you to be afraid and allocate some money to keep an eye on me."
------
The thing to remember about academic science is that:
1. No one is in it for the money. The currency is intellectual influence and prestige.
2. If you write science fiction and try to pass it as fact, your career is over (unlike, say, AI doomism).
------
The thing to remember about academic science is that nobody in the system - journal editors, grantmakers, conference organizers, tenure committees, deans, university administrators, PhD defense committees, or scientists - gets paid an extra $10,000 if the theory is actually true.
------
1/4) Several people I admire immensely have signed this, but respectfully, I'm afraid I just don't agree with the claim that "mitigating the risk of extinction from AI should be a global priority".

I think this statement is naive and a mistake.
------
We’ve released a statement on the risk of extinction from AI.

Signatories include:
- Three Turing Award winners
- Authors of the standard textbooks on AI/DL/RL
- CEOs and Execs from OpenAI, Microsoft, Google, Google DeepMind, Anthropic
- Many more

https://safe.ai/statement-on-ai-risk…
------
Super-human AI is nowhere near the top of the list of existential risks.
In large part because it doesn't exist yet.

Until we have a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature.
------
When I think of existential risks to large parts of humanity:
* The next pandemic
* Climate change→massive depopulation
* Another asteroid
AI will be a key part of our solution. So if you want humanity to survive & thrive the next 1000 years, lets make AI go faster, not slower.
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between 
@ylecun
 and 
@AndrewYNg
 , is available here:
------
"Clearly we are not anywhere close to human-level intelligence, otherwise we would have level 5 autonomous driving"
-- 
@ylecun
 

Available with timestamp here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=660…
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between @ylecun and @AndrewYNg , is available here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=608…
------
Truth.
------
There’s a very high correlation between people who think that AI take off is imminent and simple and will take over the world and people who regularly express amazingly simplistic ideas about how the world we already live in works.
------
Great thread on Hinton's infamous prediction about AI replacing radiologists: "thinkers have a pattern where they are so divorced from implementation details that applications seem trivial, when in reality, the small details are exactly where value accrues."
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… twitter.com/ylecun/status/… Show more
------
Curious about what kind of representations are learned with SSL? What makes them learn meaningful representations? their characteristics at intermediate layers? Check out our recent paper: https://arxiv.org/abs/2305.15614 (with 
@ml_norms
 
@ziv_ravid
 Shai Dekel and 
@ylecun
)
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… Show more
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now. twitter.com/erikbryn/statu…
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now.
------
AI will transform a large number of jobs in the coming years. Both workers and companies need to be prepared for significant disruption in wages and demand.

But contrary to some predictions, I don't anticipate mass unemployment due to AI this decade.
------
Some folks seem to think I ignore or don't care about AI ethics, safety, and alignment.

I need to remind them that a group of us co-founded the Partnership on AI in 2016 precisely to study, discuss, and address questions of AI ethics, safety, and alignment back in 2016.… Show more
------
Clarification: Although the initial discussions were with Demis, it was @mustafasuleymn who became the co-founder of PAI for Google/DeepMind.
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  
@ylecun
   ). A few months ago, 
@ml_norms
 proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
Understanding what is going on in SSL algorithms and why they work so well is difficult! In this paper we attempt to understand what these algos learn . 

Blessed to work with such amazing collaborators

@ziv_ravid
 , 
@GalantiTomer
, Shai Dekel, and 
@ylecun
 !
Check out the thread!
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  @ylecun   ). A few months ago, @ml_norms proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
I propose a new acronym for the AI-ensconced red-hot tech giants:
MAGMA
Meta, Amazon, Google, Microsoft, Apple.
------
Some are asking "what about Nvidia?"
They are in a different category.
If AI was a car race between the MAGMAs, Nvidia would be supplying the engines.
------
Nice piece about 
@reidhoffman
 

Reid Hoffman Is on a Mission: To Show A.I. Can Improve Humanity
------
This is insane. 

A paralyzed man can walk thanks again to AI.

Plus, huge announcments from Neuralink, TikTok, Dharmesh, and 12 new AI tools.

Here's the rundown of everything going on in AI right now:
------
Geoff only started thinking about these things a couple of months ago.
Before then, he didn't think machines were anywhere close to reaching human-level AI and never really thought about AI safety, alignment, or the potential effects on society.
He went through some sort of… Show more
------
I was at Hinton’s talk in Cambridge today. Well aware of the spectacle of such a figure at such a time, and curious, still, I expected a scientist at a research university giving a talk. I was struck by how out of touch he is with debates+scholarship in AI/tech.
------
To those who think AGI is upon us:
1. why don't we have level-5 autonomous driving? 
Any 17 year old can learn to drive in 20 hours of training.

2. Why don't we have domestic robots that can clear the dinner table and fill the dishwasher? 
Any 10 year old can learn to do that in… Show more
------
AI has 2 loud groups: “AI Safety” builds hype by evoking existential risks from AI to distract from the real harms, while developing AI at full speed; “AI Ethics” sees AI faults & dangers everywhere—building their brand of “criti-hype”, claiming the wise path is to not use AI.
------
A sensible piece by Nello Cristianini about AI existential risk.
Or lack thereof.

"If we’re going to label AI an ‘extinction risk’, we need to clarify how it could happen"
------
Ditto.
------
How many of the signatories have used their expertise, their influence, their resources to rigourously analyze and expose the risks of current AI systems, and to build solutions that address real harms?  That is what we need. Not letters, headlines and inflammatory statements. twitter.com/ai_risks/statu…
------
 We will be doing a tutorial on LLMs and Planning at #ICAPS2023. So, if the many splendors of Prague are not enough of an attraction for you, there is now this..

 https://icaps23.icaps-conference.org/program/tutorials/llms/…
------
"...the plea will hopefully stop others from doing the same. I'm so much smarter than everyone that it's okay if I do it, but very, very dangerous if anyone else does it."
------
"I am the brightest mind in AI, and also the most powerful and influential. I think my work can have disastrous consequences and end humanity. So I will keep working on it full speed, but also sign this plea urging you to be afraid and allocate some money to keep an eye on me."
------
The thing to remember about academic science is that:
1. No one is in it for the money. The currency is intellectual influence and prestige.
2. If you write science fiction and try to pass it as fact, your career is over (unlike, say, AI doomism).
------
The thing to remember about academic science is that nobody in the system - journal editors, grantmakers, conference organizers, tenure committees, deans, university administrators, PhD defense committees, or scientists - gets paid an extra $10,000 if the theory is actually true.
------
1/4) Several people I admire immensely have signed this, but respectfully, I'm afraid I just don't agree with the claim that "mitigating the risk of extinction from AI should be a global priority".

I think this statement is naive and a mistake.
------
We’ve released a statement on the risk of extinction from AI.

Signatories include:
- Three Turing Award winners
- Authors of the standard textbooks on AI/DL/RL
- CEOs and Execs from OpenAI, Microsoft, Google, Google DeepMind, Anthropic
- Many more

https://safe.ai/statement-on-ai-risk…
------
Super-human AI is nowhere near the top of the list of existential risks.
In large part because it doesn't exist yet.

Until we have a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature.
------
When I think of existential risks to large parts of humanity:
* The next pandemic
* Climate change→massive depopulation
* Another asteroid
AI will be a key part of our solution. So if you want humanity to survive & thrive the next 1000 years, lets make AI go faster, not slower.
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between 
@ylecun
 and 
@AndrewYNg
 , is available here:
------
"Clearly we are not anywhere close to human-level intelligence, otherwise we would have level 5 autonomous driving"
-- 
@ylecun
 

Available with timestamp here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=660…
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between @ylecun and @AndrewYNg , is available here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=608…
------
Truth.
------
There’s a very high correlation between people who think that AI take off is imminent and simple and will take over the world and people who regularly express amazingly simplistic ideas about how the world we already live in works.
------
Great thread on Hinton's infamous prediction about AI replacing radiologists: "thinkers have a pattern where they are so divorced from implementation details that applications seem trivial, when in reality, the small details are exactly where value accrues."
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… twitter.com/ylecun/status/… Show more
------
Curious about what kind of representations are learned with SSL? What makes them learn meaningful representations? their characteristics at intermediate layers? Check out our recent paper: https://arxiv.org/abs/2305.15614 (with 
@ml_norms
 
@ziv_ravid
 Shai Dekel and 
@ylecun
)
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… Show more
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now. twitter.com/erikbryn/statu…
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now.
------
AI will transform a large number of jobs in the coming years. Both workers and companies need to be prepared for significant disruption in wages and demand.

But contrary to some predictions, I don't anticipate mass unemployment due to AI this decade.
------
Some folks seem to think I ignore or don't care about AI ethics, safety, and alignment.

I need to remind them that a group of us co-founded the Partnership on AI in 2016 precisely to study, discuss, and address questions of AI ethics, safety, and alignment back in 2016.… Show more
------
Clarification: Although the initial discussions were with Demis, it was @mustafasuleymn who became the co-founder of PAI for Google/DeepMind.
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  
@ylecun
   ). A few months ago, 
@ml_norms
 proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
Understanding what is going on in SSL algorithms and why they work so well is difficult! In this paper we attempt to understand what these algos learn . 

Blessed to work with such amazing collaborators

@ziv_ravid
 , 
@GalantiTomer
, Shai Dekel, and 
@ylecun
 !
Check out the thread!
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  @ylecun   ). A few months ago, @ml_norms proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
I propose a new acronym for the AI-ensconced red-hot tech giants:
MAGMA
Meta, Amazon, Google, Microsoft, Apple.
------
Some are asking "what about Nvidia?"
They are in a different category.
If AI was a car race between the MAGMAs, Nvidia would be supplying the engines.
------
Nice piece about 
@reidhoffman
 

Reid Hoffman Is on a Mission: To Show A.I. Can Improve Humanity
------
This is insane. 

A paralyzed man can walk thanks again to AI.

Plus, huge announcments from Neuralink, TikTok, Dharmesh, and 12 new AI tools.

Here's the rundown of everything going on in AI right now:
------
Geoff only started thinking about these things a couple of months ago.
Before then, he didn't think machines were anywhere close to reaching human-level AI and never really thought about AI safety, alignment, or the potential effects on society.
He went through some sort of… Show more
------
I was at Hinton’s talk in Cambridge today. Well aware of the spectacle of such a figure at such a time, and curious, still, I expected a scientist at a research university giving a talk. I was struck by how out of touch he is with debates+scholarship in AI/tech.
------
To those who think AGI is upon us:
1. why don't we have level-5 autonomous driving? 
Any 17 year old can learn to drive in 20 hours of training.

2. Why don't we have domestic robots that can clear the dinner table and fill the dishwasher? 
Any 10 year old can learn to do that in… Show more
------
Congratulations Carlos!
------
CDS Associate Professor of Mathematics and Data Science Carlos Fernandez-Granda has been appointed as the Interim Director of CDS, effective September 1, 2023!
------
Video of my Distinguished Lecture at the Institute for Experiential AI at Northeastern University on May 24.

Video: https://youtu.be/mViTAXCg1xQ

Slides: https://drive.google.com/file/d/1YMzZTpcYW2tgufZe0ST2xC7eF5xVUz2f/view?usp=drivesdk…
------
New talk from 
@ylecun
: 

"auto-regressive LLMs are doomed" 

Errors accumulate exponentially. "This is not fixable with the current architecture... the shelf life of autoregressive LLMs is very short-- in 5 years nobody in their right mind will use them."
https://youtu.be/mViTAXCg1xQ?t=951…
------
Merci 
@babgi
 !

List of my lecture series: https://youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7…

List of recent talks: https://youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ…

NYU Deep Learning course: https://youtube.com/playlist?list=PL80I41oVxglKcAHllsU0txr3OuTTaWX2v…
------
La leçon inaugurale à propos du deep learning de @ylecun au Collège de France est passionnante. 1h30 qui ne seront certainement pas perdues. 
https://youtube.com/watch?v=TdLa5h-x2nA…
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
"...the plea will hopefully stop others from doing the same. I'm so much smarter than everyone that it's okay if I do it, but very, very dangerous if anyone else does it."
------
"I am the brightest mind in AI, and also the most powerful and influential. I think my work can have disastrous consequences and end humanity. So I will keep working on it full speed, but also sign this plea urging you to be afraid and allocate some money to keep an eye on me."
------
The thing to remember about academic science is that:
1. No one is in it for the money. The currency is intellectual influence and prestige.
2. If you write science fiction and try to pass it as fact, your career is over (unlike, say, AI doomism).
------
The thing to remember about academic science is that nobody in the system - journal editors, grantmakers, conference organizers, tenure committees, deans, university administrators, PhD defense committees, or scientists - gets paid an extra $10,000 if the theory is actually true.
------
1/4) Several people I admire immensely have signed this, but respectfully, I'm afraid I just don't agree with the claim that "mitigating the risk of extinction from AI should be a global priority".

I think this statement is naive and a mistake.
------
We’ve released a statement on the risk of extinction from AI.

Signatories include:
- Three Turing Award winners
- Authors of the standard textbooks on AI/DL/RL
- CEOs and Execs from OpenAI, Microsoft, Google, Google DeepMind, Anthropic
- Many more

https://safe.ai/statement-on-ai-risk…
------
Super-human AI is nowhere near the top of the list of existential risks.
In large part because it doesn't exist yet.

Until we have a basic design for even dog-level AI (let alone human level), discussing how to make it safe is premature.
------
When I think of existential risks to large parts of humanity:
* The next pandemic
* Climate change→massive depopulation
* Another asteroid
AI will be a key part of our solution. So if you want humanity to survive & thrive the next 1000 years, lets make AI go faster, not slower.
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between 
@ylecun
 and 
@AndrewYNg
 , is available here:
------
"Clearly we are not anywhere close to human-level intelligence, otherwise we would have level 5 autonomous driving"
-- 
@ylecun
 

Available with timestamp here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=660…
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between @ylecun and @AndrewYNg , is available here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=608…
------
Truth.
------
There’s a very high correlation between people who think that AI take off is imminent and simple and will take over the world and people who regularly express amazingly simplistic ideas about how the world we already live in works.
------
Great thread on Hinton's infamous prediction about AI replacing radiologists: "thinkers have a pattern where they are so divorced from implementation details that applications seem trivial, when in reality, the small details are exactly where value accrues."
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… twitter.com/ylecun/status/… Show more
------
Curious about what kind of representations are learned with SSL? What makes them learn meaningful representations? their characteristics at intermediate layers? Check out our recent paper: https://arxiv.org/abs/2305.15614 (with 
@ml_norms
 
@ziv_ravid
 Shai Dekel and 
@ylecun
)
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… Show more
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now. twitter.com/erikbryn/statu…
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now.
------
AI will transform a large number of jobs in the coming years. Both workers and companies need to be prepared for significant disruption in wages and demand.

But contrary to some predictions, I don't anticipate mass unemployment due to AI this decade.
------
Some folks seem to think I ignore or don't care about AI ethics, safety, and alignment.

I need to remind them that a group of us co-founded the Partnership on AI in 2016 precisely to study, discuss, and address questions of AI ethics, safety, and alignment back in 2016.… Show more
------
Clarification: Although the initial discussions were with Demis, it was @mustafasuleymn who became the co-founder of PAI for Google/DeepMind.
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  
@ylecun
   ). A few months ago, 
@ml_norms
 proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
Understanding what is going on in SSL algorithms and why they work so well is difficult! In this paper we attempt to understand what these algos learn . 

Blessed to work with such amazing collaborators

@ziv_ravid
 , 
@GalantiTomer
, Shai Dekel, and 
@ylecun
 !
Check out the thread!
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  @ylecun   ). A few months ago, @ml_norms proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
I propose a new acronym for the AI-ensconced red-hot tech giants:
MAGMA
Meta, Amazon, Google, Microsoft, Apple.
------
Some are asking "what about Nvidia?"
They are in a different category.
If AI was a car race between the MAGMAs, Nvidia would be supplying the engines.
------
Nice piece about 
@reidhoffman
 

Reid Hoffman Is on a Mission: To Show A.I. Can Improve Humanity
------
This is insane. 

A paralyzed man can walk thanks again to AI.

Plus, huge announcments from Neuralink, TikTok, Dharmesh, and 12 new AI tools.

Here's the rundown of everything going on in AI right now:
------
Geoff only started thinking about these things a couple of months ago.
Before then, he didn't think machines were anywhere close to reaching human-level AI and never really thought about AI safety, alignment, or the potential effects on society.
He went through some sort of… Show more
------
I was at Hinton’s talk in Cambridge today. Well aware of the spectacle of such a figure at such a time, and curious, still, I expected a scientist at a research university giving a talk. I was struck by how out of touch he is with debates+scholarship in AI/tech.
------
To those who think AGI is upon us:
1. why don't we have level-5 autonomous driving? 
Any 17 year old can learn to drive in 20 hours of training.

2. Why don't we have domestic robots that can clear the dinner table and fill the dishwasher? 
Any 10 year old can learn to do that in… Show more
------
Congratulations Carlos!
------
CDS Associate Professor of Mathematics and Data Science Carlos Fernandez-Granda has been appointed as the Interim Director of CDS, effective September 1, 2023!
------
Video of my Distinguished Lecture at the Institute for Experiential AI at Northeastern University on May 24.

Video: https://youtu.be/mViTAXCg1xQ

Slides: https://drive.google.com/file/d/1YMzZTpcYW2tgufZe0ST2xC7eF5xVUz2f/view?usp=drivesdk…
------
New talk from 
@ylecun
: 

"auto-regressive LLMs are doomed" 

Errors accumulate exponentially. "This is not fixable with the current architecture... the shelf life of autoregressive LLMs is very short-- in 5 years nobody in their right mind will use them."
https://youtu.be/mViTAXCg1xQ?t=951…
------
Merci 
@babgi
 !

List of my lecture series: https://youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7…

List of recent talks: https://youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ…

NYU Deep Learning course: https://youtube.com/playlist?list=PL80I41oVxglKcAHllsU0txr3OuTTaWX2v…
------
La leçon inaugurale à propos du deep learning de @ylecun au Collège de France est passionnante. 1h30 qui ne seront certainement pas perdues. 
https://youtube.com/watch?v=TdLa5h-x2nA…
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
Well, obviously.
Everyone wants open source base models except a few folks in Silicon Valley, a handful of AI doomers, and whoever they manage to scare in governments,
------
Sam Altman just asked students at the Technical University of Munich (TUM) who thinks that OpenAI should start open sourcing models like GPT-5 on day one.

Lots of hands were raised, and @sama  responded "woah, we're definitely not gonna do that, but that's interesting to know"
------
New ICML paper.
------
Happy that our work on understanding the interplay between architecture/data-augmentation on Self-Supervised Learning downstream perfs. has been accepted at #ICML2023! YES, you can successfully use SSL with ``bad'' DA as long as your DN archit. is right
https://arxiv.org/abs/2302.02774
------
Well put as usual by 
@MelMitchell1
, on how people who make versions of the superintelligence argument implicitly assume that intelligence is some kind of quantity you can just have "more" of, instead of a specific adaptation to specific problems
------
I'm reading Yoshua Bengio's new blog post,  "How Rogue AIs may Arise".  

https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/…

Mostly it's the same arguments as in earlier writings by Bostrom, Russell, etc.

Lots to say about all this but there's one issue I want to point out.  

 (1/8)
------
"Clearly we are not anywhere close to human-level intelligence, otherwise we would have level 5 autonomous driving"
-- 
@ylecun
 

Available with timestamp here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=660…
------
"How can [...] you design seatbelts for a car if the car doesn't exist?" 
-- Yan LeCun 

On the topic of AGI, AI safety, and doomers, an excerpt from a conversation between @ylecun and @AndrewYNg , is available here:
https://youtube.com/live/BY9KV8uCtj4?feature=share&t=608…
------
Truth.
------
There’s a very high correlation between people who think that AI take off is imminent and simple and will take over the world and people who regularly express amazingly simplistic ideas about how the world we already live in works.
------
Great thread on Hinton's infamous prediction about AI replacing radiologists: "thinkers have a pattern where they are so divorced from implementation details that applications seem trivial, when in reality, the small details are exactly where value accrues."
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… twitter.com/ylecun/status/… Show more
------
Curious about what kind of representations are learned with SSL? What makes them learn meaningful representations? their characteristics at intermediate layers? Check out our recent paper: https://arxiv.org/abs/2305.15614 (with 
@ml_norms
 
@ziv_ravid
 Shai Dekel and 
@ylecun
)
------
I don't talk much about this - I obtained one of the first FDA approvals in ML + radiology and it informs much of how I think about AI systems and their impact on the world. If you're a pure technologist, you should read the following:

There's so much to unpack for both why… Show more
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now. twitter.com/erikbryn/statu…
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now.
------
AI will transform a large number of jobs in the coming years. Both workers and companies need to be prepared for significant disruption in wages and demand.

But contrary to some predictions, I don't anticipate mass unemployment due to AI this decade.
------
Some folks seem to think I ignore or don't care about AI ethics, safety, and alignment.

I need to remind them that a group of us co-founded the Partnership on AI in 2016 precisely to study, discuss, and address questions of AI ethics, safety, and alignment back in 2016.… Show more
------
Clarification: Although the initial discussions were with Demis, it was @mustafasuleymn who became the co-founder of PAI for Google/DeepMind.
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  
@ylecun
   ). A few months ago, 
@ml_norms
 proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
Understanding what is going on in SSL algorithms and why they work so well is difficult! In this paper we attempt to understand what these algos learn . 

Blessed to work with such amazing collaborators

@ziv_ravid
 , 
@GalantiTomer
, Shai Dekel, and 
@ylecun
 !
Check out the thread!
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  @ylecun   ). A few months ago, @ml_norms proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
I propose a new acronym for the AI-ensconced red-hot tech giants:
MAGMA
Meta, Amazon, Google, Microsoft, Apple.
------
Some are asking "what about Nvidia?"
They are in a different category.
If AI was a car race between the MAGMAs, Nvidia would be supplying the engines.
------
Nice piece about 
@reidhoffman
 

Reid Hoffman Is on a Mission: To Show A.I. Can Improve Humanity
------
This is insane. 

A paralyzed man can walk thanks again to AI.

Plus, huge announcments from Neuralink, TikTok, Dharmesh, and 12 new AI tools.

Here's the rundown of everything going on in AI right now:
------
Geoff only started thinking about these things a couple of months ago.
Before then, he didn't think machines were anywhere close to reaching human-level AI and never really thought about AI safety, alignment, or the potential effects on society.
He went through some sort of… Show more
------
I was at Hinton’s talk in Cambridge today. Well aware of the spectacle of such a figure at such a time, and curious, still, I expected a scientist at a research university giving a talk. I was struck by how out of touch he is with debates+scholarship in AI/tech.
------
To those who think AGI is upon us:
1. why don't we have level-5 autonomous driving? 
Any 17 year old can learn to drive in 20 hours of training.

2. Why don't we have domestic robots that can clear the dinner table and fill the dishwasher? 
Any 10 year old can learn to do that in… Show more
------
Congratulations Carlos!
------
CDS Associate Professor of Mathematics and Data Science Carlos Fernandez-Granda has been appointed as the Interim Director of CDS, effective September 1, 2023!
------
Video of my Distinguished Lecture at the Institute for Experiential AI at Northeastern University on May 24.

Video: https://youtu.be/mViTAXCg1xQ

Slides: https://drive.google.com/file/d/1YMzZTpcYW2tgufZe0ST2xC7eF5xVUz2f/view?usp=drivesdk…
------
New talk from 
@ylecun
: 

"auto-regressive LLMs are doomed" 

Errors accumulate exponentially. "This is not fixable with the current architecture... the shelf life of autoregressive LLMs is very short-- in 5 years nobody in their right mind will use them."
https://youtu.be/mViTAXCg1xQ?t=951…
------
Merci 
@babgi
 !

List of my lecture series: https://youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7…

List of recent talks: https://youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ…

NYU Deep Learning course: https://youtube.com/playlist?list=PL80I41oVxglKcAHllsU0txr3OuTTaWX2v…
------
La leçon inaugurale à propos du deep learning de @ylecun au Collège de France est passionnante. 1h30 qui ne seront certainement pas perdues. 
https://youtube.com/watch?v=TdLa5h-x2nA…
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
Well, obviously.
Everyone wants open source base models except a few folks in Silicon Valley, a handful of AI doomers, and whoever they manage to scare in governments,
------
Sam Altman just asked students at the Technical University of Munich (TUM) who thinks that OpenAI should start open sourcing models like GPT-5 on day one.

Lots of hands were raised, and @sama  responded "woah, we're definitely not gonna do that, but that's interesting to know"
------
New ICML paper.
------
Happy that our work on understanding the interplay between architecture/data-augmentation on Self-Supervised Learning downstream perfs. has been accepted at #ICML2023! YES, you can successfully use SSL with ``bad'' DA as long as your DN archit. is right
https://arxiv.org/abs/2302.02774
------
Well put as usual by 
@MelMitchell1
, on how people who make versions of the superintelligence argument implicitly assume that intelligence is some kind of quantity you can just have "more" of, instead of a specific adaptation to specific problems
------
I'm reading Yoshua Bengio's new blog post,  "How Rogue AIs may Arise".  

https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/…

Mostly it's the same arguments as in earlier writings by Bostrom, Russell, etc.

Lots to say about all this but there's one issue I want to point out.  

 (1/8)
------
Since AI base models are going to become a basic infrastructure, people (and the industry) will demand that it be open source.
Just like the software infrastructure of the internet.
Also, human feedback *must* be crowd-sourced, Wikipedia style, if we want those base systems to… Show more
------
Yann LeCun makes a lot of sense short term, when he talks about human-augmenting AI and personal assistants being core infrastructure that has to be open source. @ylecun That's why I admire @StabilityAI, @MetaAI, @huggingface, @SingularityNET & co. Hope the world builds AI Linux!
------
“Most good ideas still come from academia.” 

Prof 
@ylecun
 on the role of academia in AI and the importance of good ideas (even if you don’t have access to 50k gpus for compute). Fireside chat 
@Northeastern
 with 
@Experiential_AI
’s 
@usamaf
.
------
“The math behind inference comes from statistical physics, so if you’re given the chance to take mobile app development or quantum mechanics, take quantum mechanics.” 
@ylecun
 on educational gaps for CS students in his fireside chat with 
@Experiential_AI
 Exec Dir 
@usamaf
------
Haha.
Auto-Regressive LLMs gonna auto-regress.
Your hands must remain on the keyboard at all time.
Level-2 Writing assistance? Yes!
Level-5 autonomous writing? No!

"Here’s What Happens When Your Lawyer Uses ChatGPT"
------
This must be said and repeated.
Yes, Geoff was totally wrong to predict a drop in radiologist positions.
We knew that it was wrong when he said it.
We have data now.
------
AI will transform a large number of jobs in the coming years. Both workers and companies need to be prepared for significant disruption in wages and demand.

But contrary to some predictions, I don't anticipate mass unemployment due to AI this decade.
------
Some folks seem to think I ignore or don't care about AI ethics, safety, and alignment.

I need to remind them that a group of us co-founded the Partnership on AI in 2016 precisely to study, discuss, and address questions of AI ethics, safety, and alignment back in 2016.… Show more
------
Clarification: Although the initial discussions were with Demis, it was @mustafasuleymn who became the co-founder of PAI for Google/DeepMind.
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  
@ylecun
   ). A few months ago, 
@ml_norms
 proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
Understanding what is going on in SSL algorithms and why they work so well is difficult! In this paper we attempt to understand what these algos learn . 

Blessed to work with such amazing collaborators

@ziv_ravid
 , 
@GalantiTomer
, Shai Dekel, and 
@ylecun
 !
Check out the thread!
------
Ever wondered why Self-Supervised Learning (SSL) works and what classes it learns? I've been pondering this question quite a bit! (I blame  @ylecun   ). A few months ago, @ml_norms proposed, "Let's demystify SSL!" and that's exactly what we tried to do.
------
I propose a new acronym for the AI-ensconced red-hot tech giants:
MAGMA
Meta, Amazon, Google, Microsoft, Apple.
------
Some are asking "what about Nvidia?"
They are in a different category.
If AI was a car race between the MAGMAs, Nvidia would be supplying the engines.
------
Nice piece about 
@reidhoffman
 

Reid Hoffman Is on a Mission: To Show A.I. Can Improve Humanity
------
This is insane. 

A paralyzed man can walk thanks again to AI.

Plus, huge announcments from Neuralink, TikTok, Dharmesh, and 12 new AI tools.

Here's the rundown of everything going on in AI right now:
------
Geoff only started thinking about these things a couple of months ago.
Before then, he didn't think machines were anywhere close to reaching human-level AI and never really thought about AI safety, alignment, or the potential effects on society.
He went through some sort of… Show more
------
I was at Hinton’s talk in Cambridge today. Well aware of the spectacle of such a figure at such a time, and curious, still, I expected a scientist at a research university giving a talk. I was struck by how out of touch he is with debates+scholarship in AI/tech.
------
To those who think AGI is upon us:
1. why don't we have level-5 autonomous driving? 
Any 17 year old can learn to drive in 20 hours of training.

2. Why don't we have domestic robots that can clear the dinner table and fill the dishwasher? 
Any 10 year old can learn to do that in… Show more
------
Congratulations Carlos!
------
CDS Associate Professor of Mathematics and Data Science Carlos Fernandez-Granda has been appointed as the Interim Director of CDS, effective September 1, 2023!
------
Video of my Distinguished Lecture at the Institute for Experiential AI at Northeastern University on May 24.

Video: https://youtu.be/mViTAXCg1xQ

Slides: https://drive.google.com/file/d/1YMzZTpcYW2tgufZe0ST2xC7eF5xVUz2f/view?usp=drivesdk…
------
New talk from 
@ylecun
: 

"auto-regressive LLMs are doomed" 

Errors accumulate exponentially. "This is not fixable with the current architecture... the shelf life of autoregressive LLMs is very short-- in 5 years nobody in their right mind will use them."
https://youtu.be/mViTAXCg1xQ?t=951…
------
Merci 
@babgi
 !

List of my lecture series: https://youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7…

List of recent talks: https://youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ…

NYU Deep Learning course: https://youtube.com/playlist?list=PL80I41oVxglKcAHllsU0txr3OuTTaWX2v…
------
La leçon inaugurale à propos du deep learning de @ylecun au Collège de France est passionnante. 1h30 qui ne seront certainement pas perdues. 
https://youtube.com/watch?v=TdLa5h-x2nA…
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
Well, obviously.
Everyone wants open source base models except a few folks in Silicon Valley, a handful of AI doomers, and whoever they manage to scare in governments,
------
Sam Altman just asked students at the Technical University of Munich (TUM) who thinks that OpenAI should start open sourcing models like GPT-5 on day one.

Lots of hands were raised, and @sama  responded "woah, we're definitely not gonna do that, but that's interesting to know"
------
New ICML paper.
------
Happy that our work on understanding the interplay between architecture/data-augmentation on Self-Supervised Learning downstream perfs. has been accepted at #ICML2023! YES, you can successfully use SSL with ``bad'' DA as long as your DN archit. is right
https://arxiv.org/abs/2302.02774
------
Well put as usual by 
@MelMitchell1
, on how people who make versions of the superintelligence argument implicitly assume that intelligence is some kind of quantity you can just have "more" of, instead of a specific adaptation to specific problems
------
I'm reading Yoshua Bengio's new blog post,  "How Rogue AIs may Arise".  

https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/…

Mostly it's the same arguments as in earlier writings by Bostrom, Russell, etc.

Lots to say about all this but there's one issue I want to point out.  

 (1/8)
------
Since AI base models are going to become a basic infrastructure, people (and the industry) will demand that it be open source.
Just like the software infrastructure of the internet.
Also, human feedback *must* be crowd-sourced, Wikipedia style, if we want those base systems to… Show more
------
Yann LeCun makes a lot of sense short term, when he talks about human-augmenting AI and personal assistants being core infrastructure that has to be open source. @ylecun That's why I admire @StabilityAI, @MetaAI, @huggingface, @SingularityNET & co. Hope the world builds AI Linux!
------
“Most good ideas still come from academia.” 

Prof 
@ylecun
 on the role of academia in AI and the importance of good ideas (even if you don’t have access to 50k gpus for compute). Fireside chat 
@Northeastern
 with 
@Experiential_AI
’s 
@usamaf
.
------
“The math behind inference comes from statistical physics, so if you’re given the chance to take mobile app development or quantum mechanics, take quantum mechanics.” 
@ylecun
 on educational gaps for CS students in his fireside chat with 
@Experiential_AI
 Exec Dir 
@usamaf
------
How do we build safe, ethical AI? 

We need to make models, code, data open source. 

Prof 
@ylecun
 during his fireside chat with 
@Northeastern
 and 
@Experiential_AI
’s 
@usamaf
------
Full house for my talk at Northeastern University.
------
Thank you 
@ylecun
 for visiting us at 
@Harvard
  and spending time with our students.  I can report that indeed Yann is not wrinkled, but the force of open source is strong with this one.
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not. twitter.com/s_batzoglou/st…
------
Ditto.
In what should be a risk-benefit analysis, one should consider benefits, not just risks.
------
i just can't watch _that_ senate hearing beyond some select excerpts. i can't believe the discourse on AI is about "oh AI may kill all of us unless i get to dictate wtf should be done" by a few clueless dudes, without any discussion on some immediate benefits & harms.

(1/2)
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
Nice piece about 
@reidhoffman
 

Reid Hoffman Is on a Mission: To Show A.I. Can Improve Humanity
------
This is insane. 

A paralyzed man can walk thanks again to AI.

Plus, huge announcments from Neuralink, TikTok, Dharmesh, and 12 new AI tools.

Here's the rundown of everything going on in AI right now:
------
Geoff only started thinking about these things a couple of months ago.
Before then, he didn't think machines were anywhere close to reaching human-level AI and never really thought about AI safety, alignment, or the potential effects on society.
He went through some sort of… Show more
------
I was at Hinton’s talk in Cambridge today. Well aware of the spectacle of such a figure at such a time, and curious, still, I expected a scientist at a research university giving a talk. I was struck by how out of touch he is with debates+scholarship in AI/tech.
------
To those who think AGI is upon us:
1. why don't we have level-5 autonomous driving? 
Any 17 year old can learn to drive in 20 hours of training.

2. Why don't we have domestic robots that can clear the dinner table and fill the dishwasher? 
Any 10 year old can learn to do that in… Show more
------
Congratulations Carlos!
------
CDS Associate Professor of Mathematics and Data Science Carlos Fernandez-Granda has been appointed as the Interim Director of CDS, effective September 1, 2023!
------
Video of my Distinguished Lecture at the Institute for Experiential AI at Northeastern University on May 24.

Video: https://youtu.be/mViTAXCg1xQ

Slides: https://drive.google.com/file/d/1YMzZTpcYW2tgufZe0ST2xC7eF5xVUz2f/view?usp=drivesdk…
------
New talk from 
@ylecun
: 

"auto-regressive LLMs are doomed" 

Errors accumulate exponentially. "This is not fixable with the current architecture... the shelf life of autoregressive LLMs is very short-- in 5 years nobody in their right mind will use them."
https://youtu.be/mViTAXCg1xQ?t=951…
------
Merci 
@babgi
 !

List of my lecture series: https://youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7…

List of recent talks: https://youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ…

NYU Deep Learning course: https://youtube.com/playlist?list=PL80I41oVxglKcAHllsU0txr3OuTTaWX2v…
------
La leçon inaugurale à propos du deep learning de @ylecun au Collège de France est passionnante. 1h30 qui ne seront certainement pas perdues. 
https://youtube.com/watch?v=TdLa5h-x2nA…
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
Well, obviously.
Everyone wants open source base models except a few folks in Silicon Valley, a handful of AI doomers, and whoever they manage to scare in governments,
------
Sam Altman just asked students at the Technical University of Munich (TUM) who thinks that OpenAI should start open sourcing models like GPT-5 on day one.

Lots of hands were raised, and @sama  responded "woah, we're definitely not gonna do that, but that's interesting to know"
------
New ICML paper.
------
Happy that our work on understanding the interplay between architecture/data-augmentation on Self-Supervised Learning downstream perfs. has been accepted at #ICML2023! YES, you can successfully use SSL with ``bad'' DA as long as your DN archit. is right
https://arxiv.org/abs/2302.02774
------
Well put as usual by 
@MelMitchell1
, on how people who make versions of the superintelligence argument implicitly assume that intelligence is some kind of quantity you can just have "more" of, instead of a specific adaptation to specific problems
------
I'm reading Yoshua Bengio's new blog post,  "How Rogue AIs may Arise".  

https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/…

Mostly it's the same arguments as in earlier writings by Bostrom, Russell, etc.

Lots to say about all this but there's one issue I want to point out.  

 (1/8)
------
Since AI base models are going to become a basic infrastructure, people (and the industry) will demand that it be open source.
Just like the software infrastructure of the internet.
Also, human feedback *must* be crowd-sourced, Wikipedia style, if we want those base systems to… Show more
------
Yann LeCun makes a lot of sense short term, when he talks about human-augmenting AI and personal assistants being core infrastructure that has to be open source. @ylecun That's why I admire @StabilityAI, @MetaAI, @huggingface, @SingularityNET & co. Hope the world builds AI Linux!
------
“Most good ideas still come from academia.” 

Prof 
@ylecun
 on the role of academia in AI and the importance of good ideas (even if you don’t have access to 50k gpus for compute). Fireside chat 
@Northeastern
 with 
@Experiential_AI
’s 
@usamaf
.
------
“The math behind inference comes from statistical physics, so if you’re given the chance to take mobile app development or quantum mechanics, take quantum mechanics.” 
@ylecun
 on educational gaps for CS students in his fireside chat with 
@Experiential_AI
 Exec Dir 
@usamaf
------
How do we build safe, ethical AI? 

We need to make models, code, data open source. 

Prof 
@ylecun
 during his fireside chat with 
@Northeastern
 and 
@Experiential_AI
’s 
@usamaf
------
Full house for my talk at Northeastern University.
------
Thank you 
@ylecun
 for visiting us at 
@Harvard
  and spending time with our students.  I can report that indeed Yann is not wrinkled, but the force of open source is strong with this one.
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not. twitter.com/s_batzoglou/st…
------
Ditto.
In what should be a risk-benefit analysis, one should consider benefits, not just risks.
------
i just can't watch _that_ senate hearing beyond some select excerpts. i can't believe the discourse on AI is about "oh AI may kill all of us unless i get to dictate wtf should be done" by a few clueless dudes, without any discussion on some immediate benefits & harms.

(1/2)
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
"There is this idea that the desire to dominate is linked with intelligence. 

It is not the smartest among us that want to dominate. 

To dominate other entities, you do not need to be smarter than them but you do need to want to dominate them."

 with 
@ylecun
------
 Like Geoffrey Hinton, I was shocked, amazed, and somewhat frightened by Google's PaLM GPT's ability to explain jokes, when I learned of it a year ago.

I now think that was a mistake. More generally, we mis-take GPT's omniscience for intelligence.

In the case of jokes, 1/2
------
anon period in NLP venues is a bad idea that does a lot of harm and no good whatsoever. let's get rid of it. 

(if someone can demonstrate a good outcome, and I mean demonstrate, not just hand-wave about equality, I am open to hearing and being convinced otherwise).
------
Congratulations Carlos!
------
CDS Associate Professor of Mathematics and Data Science Carlos Fernandez-Granda has been appointed as the Interim Director of CDS, effective September 1, 2023!
------
Video of my Distinguished Lecture at the Institute for Experiential AI at Northeastern University on May 24.

Video: https://youtu.be/mViTAXCg1xQ

Slides: https://drive.google.com/file/d/1YMzZTpcYW2tgufZe0ST2xC7eF5xVUz2f/view?usp=drivesdk…
------
New talk from 
@ylecun
: 

"auto-regressive LLMs are doomed" 

Errors accumulate exponentially. "This is not fixable with the current architecture... the shelf life of autoregressive LLMs is very short-- in 5 years nobody in their right mind will use them."
https://youtu.be/mViTAXCg1xQ?t=951…
------
Merci 
@babgi
 !

List of my lecture series: https://youtube.com/playlist?list=PL80I41oVxglJ0kTDV7i3aHBIXe65nTxE7…

List of recent talks: https://youtube.com/playlist?list=PL80I41oVxglK--is17UhoHVosOLFEJzKQ…

NYU Deep Learning course: https://youtube.com/playlist?list=PL80I41oVxglKcAHllsU0txr3OuTTaWX2v…
------
La leçon inaugurale à propos du deep learning de @ylecun au Collège de France est passionnante. 1h30 qui ne seront certainement pas perdues. 
https://youtube.com/watch?v=TdLa5h-x2nA…
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
Well, obviously.
Everyone wants open source base models except a few folks in Silicon Valley, a handful of AI doomers, and whoever they manage to scare in governments,
------
Sam Altman just asked students at the Technical University of Munich (TUM) who thinks that OpenAI should start open sourcing models like GPT-5 on day one.

Lots of hands were raised, and @sama  responded "woah, we're definitely not gonna do that, but that's interesting to know"
------
New ICML paper.
------
Happy that our work on understanding the interplay between architecture/data-augmentation on Self-Supervised Learning downstream perfs. has been accepted at #ICML2023! YES, you can successfully use SSL with ``bad'' DA as long as your DN archit. is right
https://arxiv.org/abs/2302.02774
------
Well put as usual by 
@MelMitchell1
, on how people who make versions of the superintelligence argument implicitly assume that intelligence is some kind of quantity you can just have "more" of, instead of a specific adaptation to specific problems
------
I'm reading Yoshua Bengio's new blog post,  "How Rogue AIs may Arise".  

https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/…

Mostly it's the same arguments as in earlier writings by Bostrom, Russell, etc.

Lots to say about all this but there's one issue I want to point out.  

 (1/8)
------
Since AI base models are going to become a basic infrastructure, people (and the industry) will demand that it be open source.
Just like the software infrastructure of the internet.
Also, human feedback *must* be crowd-sourced, Wikipedia style, if we want those base systems to… Show more
------
Yann LeCun makes a lot of sense short term, when he talks about human-augmenting AI and personal assistants being core infrastructure that has to be open source. @ylecun That's why I admire @StabilityAI, @MetaAI, @huggingface, @SingularityNET & co. Hope the world builds AI Linux!
------
“Most good ideas still come from academia.” 

Prof 
@ylecun
 on the role of academia in AI and the importance of good ideas (even if you don’t have access to 50k gpus for compute). Fireside chat 
@Northeastern
 with 
@Experiential_AI
’s 
@usamaf
.
------
“The math behind inference comes from statistical physics, so if you’re given the chance to take mobile app development or quantum mechanics, take quantum mechanics.” 
@ylecun
 on educational gaps for CS students in his fireside chat with 
@Experiential_AI
 Exec Dir 
@usamaf
------
How do we build safe, ethical AI? 

We need to make models, code, data open source. 

Prof 
@ylecun
 during his fireside chat with 
@Northeastern
 and 
@Experiential_AI
’s 
@usamaf
------
Full house for my talk at Northeastern University.
------
Thank you 
@ylecun
 for visiting us at 
@Harvard
  and spending time with our students.  I can report that indeed Yann is not wrinkled, but the force of open source is strong with this one.
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not. twitter.com/s_batzoglou/st…
------
Ditto.
In what should be a risk-benefit analysis, one should consider benefits, not just risks.
------
i just can't watch _that_ senate hearing beyond some select excerpts. i can't believe the discourse on AI is about "oh AI may kill all of us unless i get to dictate wtf should be done" by a few clueless dudes, without any discussion on some immediate benefits & harms.

(1/2)
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
"There is this idea that the desire to dominate is linked with intelligence. 

It is not the smartest among us that want to dominate. 

To dominate other entities, you do not need to be smarter than them but you do need to want to dominate them."

 with 
@ylecun
------
 Like Geoffrey Hinton, I was shocked, amazed, and somewhat frightened by Google's PaLM GPT's ability to explain jokes, when I learned of it a year ago.

I now think that was a mistake. More generally, we mis-take GPT's omniscience for intelligence.

In the case of jokes, 1/2
------
anon period in NLP venues is a bad idea that does a lot of harm and no good whatsoever. let's get rid of it. 

(if someone can demonstrate a good outcome, and I mean demonstrate, not just hand-wave about equality, I am open to hearing and being convinced otherwise).
------
 x 1000
This is MASSIVE folks! (blind reaction) 

TTS and STT in one model, that understands 1100 languages, better than whisper! and is able to generate audio in those languages?

Incredible thanks to 
@ylecun
 
@boztank
 and tons of other folks who made this happen and… Show more
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
A thread on MMS by author 
@MichaelAuli
------
New work! The Massively Multilingual Speech (MMS) project scales speech technology to 1,100-4,000 languages using self-supervised learning with wav2vec 2.0.
Paper: https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/…
Blog: https://ai.facebook.com/blog/multilingual-model-speech-recognition/…
Code/models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
Correct link to paper:
https://scontent-lga3-2.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX9NNLzC&_nc_ht=scontent-lga3-2.xx&oh=00_AfDZGkLV3haLgAXkFFhYmxMG8D9J2WV1hKDqYAQNPW4-4g&oe=6471ACCF…
------
LIMA :
LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance.

From 
@MetaAI
------
 A little 48-page paper investigating the planning abilities of LLMs including GPT4--in a variety of autonomous *and* LLM-modulo settings (work with 
@karthikv792
, 
@mattdmarq
 & 
@sarath_ssreedh
).   

https://arxiv.org/abs/2305.15771
------
Well, obviously.
Everyone wants open source base models except a few folks in Silicon Valley, a handful of AI doomers, and whoever they manage to scare in governments,
------
Sam Altman just asked students at the Technical University of Munich (TUM) who thinks that OpenAI should start open sourcing models like GPT-5 on day one.

Lots of hands were raised, and @sama  responded "woah, we're definitely not gonna do that, but that's interesting to know"
------
New ICML paper.
------
Happy that our work on understanding the interplay between architecture/data-augmentation on Self-Supervised Learning downstream perfs. has been accepted at #ICML2023! YES, you can successfully use SSL with ``bad'' DA as long as your DN archit. is right
https://arxiv.org/abs/2302.02774
------
Well put as usual by 
@MelMitchell1
, on how people who make versions of the superintelligence argument implicitly assume that intelligence is some kind of quantity you can just have "more" of, instead of a specific adaptation to specific problems
------
I'm reading Yoshua Bengio's new blog post,  "How Rogue AIs may Arise".  

https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/…

Mostly it's the same arguments as in earlier writings by Bostrom, Russell, etc.

Lots to say about all this but there's one issue I want to point out.  

 (1/8)
------
Since AI base models are going to become a basic infrastructure, people (and the industry) will demand that it be open source.
Just like the software infrastructure of the internet.
Also, human feedback *must* be crowd-sourced, Wikipedia style, if we want those base systems to… Show more
------
Yann LeCun makes a lot of sense short term, when he talks about human-augmenting AI and personal assistants being core infrastructure that has to be open source. @ylecun That's why I admire @StabilityAI, @MetaAI, @huggingface, @SingularityNET & co. Hope the world builds AI Linux!
------
“Most good ideas still come from academia.” 

Prof 
@ylecun
 on the role of academia in AI and the importance of good ideas (even if you don’t have access to 50k gpus for compute). Fireside chat 
@Northeastern
 with 
@Experiential_AI
’s 
@usamaf
.
------
“The math behind inference comes from statistical physics, so if you’re given the chance to take mobile app development or quantum mechanics, take quantum mechanics.” 
@ylecun
 on educational gaps for CS students in his fireside chat with 
@Experiential_AI
 Exec Dir 
@usamaf
------
How do we build safe, ethical AI? 

We need to make models, code, data open source. 

Prof 
@ylecun
 during his fireside chat with 
@Northeastern
 and 
@Experiential_AI
’s 
@usamaf
------
Full house for my talk at Northeastern University.
------
Thank you 
@ylecun
 for visiting us at 
@Harvard
  and spending time with our students.  I can report that indeed Yann is not wrinkled, but the force of open source is strong with this one.
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not. twitter.com/s_batzoglou/st…
------
Ditto.
In what should be a risk-benefit analysis, one should consider benefits, not just risks.
------
i just can't watch _that_ senate hearing beyond some select excerpts. i can't believe the discourse on AI is about "oh AI may kill all of us unless i get to dictate wtf should be done" by a few clueless dudes, without any discussion on some immediate benefits & harms.

(1/2)
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
"There is this idea that the desire to dominate is linked with intelligence. 

It is not the smartest among us that want to dominate. 

To dominate other entities, you do not need to be smarter than them but you do need to want to dominate them."

 with 
@ylecun
------
 Like Geoffrey Hinton, I was shocked, amazed, and somewhat frightened by Google's PaLM GPT's ability to explain jokes, when I learned of it a year ago.

I now think that was a mistake. More generally, we mis-take GPT's omniscience for intelligence.

In the case of jokes, 1/2
------
anon period in NLP venues is a bad idea that does a lot of harm and no good whatsoever. let's get rid of it. 

(if someone can demonstrate a good outcome, and I mean demonstrate, not just hand-wave about equality, I am open to hearing and being convinced otherwise).
------
 x 1000
This is MASSIVE folks! (blind reaction) 

TTS and STT in one model, that understands 1100 languages, better than whisper! and is able to generate audio in those languages?

Incredible thanks to 
@ylecun
 
@boztank
 and tons of other folks who made this happen and… Show more
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
A thread on MMS by author 
@MichaelAuli
------
New work! The Massively Multilingual Speech (MMS) project scales speech technology to 1,100-4,000 languages using self-supervised learning with wav2vec 2.0.
Paper: https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/…
Blog: https://ai.facebook.com/blog/multilingual-model-speech-recognition/…
Code/models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
Correct link to paper:
https://scontent-lga3-2.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX9NNLzC&_nc_ht=scontent-lga3-2.xx&oh=00_AfDZGkLV3haLgAXkFFhYmxMG8D9J2WV1hKDqYAQNPW4-4g&oe=6471ACCF…
------
LIMA :
LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance.

From 
@MetaAI
------
LIMA, a 65B LLaMa fine-tuned only with supervised learning on 1000 curated examples, without any RLHF,  demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.https://reddit.com/r/MachineLearning/comments/13oe5ot/lima_a_65bparam_llama_finetuned_with_standard/…
------
Join us on June 22 for our public debate on #ArtificialIntelligence: Be it Resolved, AI research and development poses an existential threat.  

PRO: MIT physicist and AI researcher 
@tegmark
 

CON: Chief scientist 
@MetaAI
 and Turing Award winner 
@ylecun
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
ChatGPT is the modern version of Flaubert's "Dictionary of Received Ideas" (Dictionnaire des idées reçues), that is, a powerful cliché parroting engine.

And, as they say in trading: "what most people know isn't worth knowing."
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
Since AI base models are going to become a basic infrastructure, people (and the industry) will demand that it be open source.
Just like the software infrastructure of the internet.
Also, human feedback *must* be crowd-sourced, Wikipedia style, if we want those base systems to… Show more
------
Yann LeCun makes a lot of sense short term, when he talks about human-augmenting AI and personal assistants being core infrastructure that has to be open source. @ylecun That's why I admire @StabilityAI, @MetaAI, @huggingface, @SingularityNET & co. Hope the world builds AI Linux!
------
“Most good ideas still come from academia.” 

Prof 
@ylecun
 on the role of academia in AI and the importance of good ideas (even if you don’t have access to 50k gpus for compute). Fireside chat 
@Northeastern
 with 
@Experiential_AI
’s 
@usamaf
.
------
“The math behind inference comes from statistical physics, so if you’re given the chance to take mobile app development or quantum mechanics, take quantum mechanics.” 
@ylecun
 on educational gaps for CS students in his fireside chat with 
@Experiential_AI
 Exec Dir 
@usamaf
------
How do we build safe, ethical AI? 

We need to make models, code, data open source. 

Prof 
@ylecun
 during his fireside chat with 
@Northeastern
 and 
@Experiential_AI
’s 
@usamaf
------
Full house for my talk at Northeastern University.
------
Thank you 
@ylecun
 for visiting us at 
@Harvard
  and spending time with our students.  I can report that indeed Yann is not wrinkled, but the force of open source is strong with this one.
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not. twitter.com/s_batzoglou/st…
------
Ditto.
In what should be a risk-benefit analysis, one should consider benefits, not just risks.
------
i just can't watch _that_ senate hearing beyond some select excerpts. i can't believe the discourse on AI is about "oh AI may kill all of us unless i get to dictate wtf should be done" by a few clueless dudes, without any discussion on some immediate benefits & harms.

(1/2)
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
"There is this idea that the desire to dominate is linked with intelligence. 

It is not the smartest among us that want to dominate. 

To dominate other entities, you do not need to be smarter than them but you do need to want to dominate them."

 with 
@ylecun
------
 Like Geoffrey Hinton, I was shocked, amazed, and somewhat frightened by Google's PaLM GPT's ability to explain jokes, when I learned of it a year ago.

I now think that was a mistake. More generally, we mis-take GPT's omniscience for intelligence.

In the case of jokes, 1/2
------
anon period in NLP venues is a bad idea that does a lot of harm and no good whatsoever. let's get rid of it. 

(if someone can demonstrate a good outcome, and I mean demonstrate, not just hand-wave about equality, I am open to hearing and being convinced otherwise).
------
 x 1000
This is MASSIVE folks! (blind reaction) 

TTS and STT in one model, that understands 1100 languages, better than whisper! and is able to generate audio in those languages?

Incredible thanks to 
@ylecun
 
@boztank
 and tons of other folks who made this happen and… Show more
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
A thread on MMS by author 
@MichaelAuli
------
New work! The Massively Multilingual Speech (MMS) project scales speech technology to 1,100-4,000 languages using self-supervised learning with wav2vec 2.0.
Paper: https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/…
Blog: https://ai.facebook.com/blog/multilingual-model-speech-recognition/…
Code/models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
Correct link to paper:
https://scontent-lga3-2.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX9NNLzC&_nc_ht=scontent-lga3-2.xx&oh=00_AfDZGkLV3haLgAXkFFhYmxMG8D9J2WV1hKDqYAQNPW4-4g&oe=6471ACCF…
------
LIMA :
LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance.

From 
@MetaAI
------
LIMA, a 65B LLaMa fine-tuned only with supervised learning on 1000 curated examples, without any RLHF,  demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.https://reddit.com/r/MachineLearning/comments/13oe5ot/lima_a_65bparam_llama_finetuned_with_standard/…
------
Join us on June 22 for our public debate on #ArtificialIntelligence: Be it Resolved, AI research and development poses an existential threat.  

PRO: MIT physicist and AI researcher 
@tegmark
 

CON: Chief scientist 
@MetaAI
 and Turing Award winner 
@ylecun
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
ChatGPT is the modern version of Flaubert's "Dictionary of Received Ideas" (Dictionnaire des idées reçues), that is, a powerful cliché parroting engine.

And, as they say in trading: "what most people know isn't worth knowing."
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
AI won't take your job. But it will transform it and create new ones.
This NYT article has quotes from economists who specialize in the effect of technology on labor markets, such David Autor, Daron Acemoglu, and 
@erikbryn
 :
"Everybody I talk to, supersmart people, doctors,… Show more
------
How do we build safe, ethical AI? 

We need to make models, code, data open source. 

Prof 
@ylecun
 during his fireside chat with 
@Northeastern
 and 
@Experiential_AI
’s 
@usamaf
------
Full house for my talk at Northeastern University.
------
Thank you 
@ylecun
 for visiting us at 
@Harvard
  and spending time with our students.  I can report that indeed Yann is not wrinkled, but the force of open source is strong with this one.
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not. twitter.com/s_batzoglou/st…
------
Ditto.
In what should be a risk-benefit analysis, one should consider benefits, not just risks.
------
i just can't watch _that_ senate hearing beyond some select excerpts. i can't believe the discourse on AI is about "oh AI may kill all of us unless i get to dictate wtf should be done" by a few clueless dudes, without any discussion on some immediate benefits & harms.

(1/2)
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
"There is this idea that the desire to dominate is linked with intelligence. 

It is not the smartest among us that want to dominate. 

To dominate other entities, you do not need to be smarter than them but you do need to want to dominate them."

 with 
@ylecun
------
 Like Geoffrey Hinton, I was shocked, amazed, and somewhat frightened by Google's PaLM GPT's ability to explain jokes, when I learned of it a year ago.

I now think that was a mistake. More generally, we mis-take GPT's omniscience for intelligence.

In the case of jokes, 1/2
------
anon period in NLP venues is a bad idea that does a lot of harm and no good whatsoever. let's get rid of it. 

(if someone can demonstrate a good outcome, and I mean demonstrate, not just hand-wave about equality, I am open to hearing and being convinced otherwise).
------
 x 1000
This is MASSIVE folks! (blind reaction) 

TTS and STT in one model, that understands 1100 languages, better than whisper! and is able to generate audio in those languages?

Incredible thanks to 
@ylecun
 
@boztank
 and tons of other folks who made this happen and… Show more
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
A thread on MMS by author 
@MichaelAuli
------
New work! The Massively Multilingual Speech (MMS) project scales speech technology to 1,100-4,000 languages using self-supervised learning with wav2vec 2.0.
Paper: https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/…
Blog: https://ai.facebook.com/blog/multilingual-model-speech-recognition/…
Code/models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
Correct link to paper:
https://scontent-lga3-2.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX9NNLzC&_nc_ht=scontent-lga3-2.xx&oh=00_AfDZGkLV3haLgAXkFFhYmxMG8D9J2WV1hKDqYAQNPW4-4g&oe=6471ACCF…
------
LIMA :
LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance.

From 
@MetaAI
------
LIMA, a 65B LLaMa fine-tuned only with supervised learning on 1000 curated examples, without any RLHF,  demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.https://reddit.com/r/MachineLearning/comments/13oe5ot/lima_a_65bparam_llama_finetuned_with_standard/…
------
Join us on June 22 for our public debate on #ArtificialIntelligence: Be it Resolved, AI research and development poses an existential threat.  

PRO: MIT physicist and AI researcher 
@tegmark
 

CON: Chief scientist 
@MetaAI
 and Turing Award winner 
@ylecun
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
ChatGPT is the modern version of Flaubert's "Dictionary of Received Ideas" (Dictionnaire des idées reçues), that is, a powerful cliché parroting engine.

And, as they say in trading: "what most people know isn't worth knowing."
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
AI won't take your job. But it will transform it and create new ones.
This NYT article has quotes from economists who specialize in the effect of technology on labor markets, such David Autor, Daron Acemoglu, and 
@erikbryn
 :
"Everybody I talk to, supersmart people, doctors,… Show more
------
There's are lots of potential harms from AI to be concerned about.

But if you want a brief respite, read "The Optimist’s Guide to Artificial Intelligence and Work" by Sarah Kessler and Ephrat Livni which quotes me on how AI can help us do new things.
------
Learn to write like an LLM!

Question: what do you think of person A's declaration that X is caused by Y ?

LLM Answer: As an AI language model, I don't have personal opinions. However, I can provide information on the topic.  Person A is a renowned scientist known for his work… Show more
------
Many people are more capable than their boss.
AI systems may become more capable than you, but you'll still be their boss.
If you feel threatened by having a staff -- of humans or machines -- that is smarter than you, you are not a good boss.
------
Wondering if people who are afraid of open-source AI infrastructure have, in fact, a deep distrust of human intelligence.
Do they doubt that the benefits of AI will be overwhelming compared to the risks of misuse?
Would they have had similar fears about the open internet?
------
Since we are talking about insults,
This is one of the two rarest, most original, witty, and intelligent ones involving mutations of my name.
I'll let you guess what the other one is.
------
Yann LeCum
------
No need to find the ones that work in French. 
I've heard them all since elementary school.
------
Are there any countries that rival the US in terms of scientific research?

VP & Chief AI Scientist at 
@Meta
, 
@ylecun
:

"The only European country that rivals the US in terms of the quality of job for an academic or a scientist is Switzerland."
------
Research interest in AI  has soared

Cc: 
@ylecun
 
@Scobleizer
 
@erikbryn
 
@amcafee
------
India  will soon produce more CO2 emissions than the EU 
------
Envisioning & disrupting adverse AI outcomes: Video taken at SXSW (in 2017!) describing a workshop I had just co-organized. We collected worrying outcomes, then had red & blue teams fight out possibility of each vs. being halted by proactive efforts. We need to do more of this.
------
 Intelligence artificielle : promesses et menaces #IA Interview de @erichorvitz par @TechF24 & @Sylvain_Mornet #innovation 
------
"There is this idea that the desire to dominate is linked with intelligence. 

It is not the smartest among us that want to dominate. 

To dominate other entities, you do not need to be smarter than them but you do need to want to dominate them."

 with 
@ylecun
------
 Like Geoffrey Hinton, I was shocked, amazed, and somewhat frightened by Google's PaLM GPT's ability to explain jokes, when I learned of it a year ago.

I now think that was a mistake. More generally, we mis-take GPT's omniscience for intelligence.

In the case of jokes, 1/2
------
anon period in NLP venues is a bad idea that does a lot of harm and no good whatsoever. let's get rid of it. 

(if someone can demonstrate a good outcome, and I mean demonstrate, not just hand-wave about equality, I am open to hearing and being convinced otherwise).
------
 x 1000
This is MASSIVE folks! (blind reaction) 

TTS and STT in one model, that understands 1100 languages, better than whisper! and is able to generate audio in those languages?

Incredible thanks to 
@ylecun
 
@boztank
 and tons of other folks who made this happen and… Show more
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
A thread on MMS by author 
@MichaelAuli
------
New work! The Massively Multilingual Speech (MMS) project scales speech technology to 1,100-4,000 languages using self-supervised learning with wav2vec 2.0.
Paper: https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/…
Blog: https://ai.facebook.com/blog/multilingual-model-speech-recognition/…
Code/models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
Correct link to paper:
https://scontent-lga3-2.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX9NNLzC&_nc_ht=scontent-lga3-2.xx&oh=00_AfDZGkLV3haLgAXkFFhYmxMG8D9J2WV1hKDqYAQNPW4-4g&oe=6471ACCF…
------
LIMA :
LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance.

From 
@MetaAI
------
LIMA, a 65B LLaMa fine-tuned only with supervised learning on 1000 curated examples, without any RLHF,  demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.https://reddit.com/r/MachineLearning/comments/13oe5ot/lima_a_65bparam_llama_finetuned_with_standard/…
------
Join us on June 22 for our public debate on #ArtificialIntelligence: Be it Resolved, AI research and development poses an existential threat.  

PRO: MIT physicist and AI researcher 
@tegmark
 

CON: Chief scientist 
@MetaAI
 and Turing Award winner 
@ylecun
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
ChatGPT is the modern version of Flaubert's "Dictionary of Received Ideas" (Dictionnaire des idées reçues), that is, a powerful cliché parroting engine.

And, as they say in trading: "what most people know isn't worth knowing."
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
AI won't take your job. But it will transform it and create new ones.
This NYT article has quotes from economists who specialize in the effect of technology on labor markets, such David Autor, Daron Acemoglu, and 
@erikbryn
 :
"Everybody I talk to, supersmart people, doctors,… Show more
------
There's are lots of potential harms from AI to be concerned about.

But if you want a brief respite, read "The Optimist’s Guide to Artificial Intelligence and Work" by Sarah Kessler and Ephrat Livni which quotes me on how AI can help us do new things.
------
Learn to write like an LLM!

Question: what do you think of person A's declaration that X is caused by Y ?

LLM Answer: As an AI language model, I don't have personal opinions. However, I can provide information on the topic.  Person A is a renowned scientist known for his work… Show more
------
Many people are more capable than their boss.
AI systems may become more capable than you, but you'll still be their boss.
If you feel threatened by having a staff -- of humans or machines -- that is smarter than you, you are not a good boss.
------
Wondering if people who are afraid of open-source AI infrastructure have, in fact, a deep distrust of human intelligence.
Do they doubt that the benefits of AI will be overwhelming compared to the risks of misuse?
Would they have had similar fears about the open internet?
------
Since we are talking about insults,
This is one of the two rarest, most original, witty, and intelligent ones involving mutations of my name.
I'll let you guess what the other one is.
------
Yann LeCum
------
No need to find the ones that work in French. 
I've heard them all since elementary school.
------
Are there any countries that rival the US in terms of scientific research?

VP & Chief AI Scientist at 
@Meta
, 
@ylecun
:

"The only European country that rivals the US in terms of the quality of job for an academic or a scientist is Switzerland."
------
Research interest in AI  has soared

Cc: 
@ylecun
 
@Scobleizer
 
@erikbryn
 
@amcafee
------
India  will soon produce more CO2 emissions than the EU 
------
I have to admit, this insult is actually funny 
I'm certainly less fluent in English than a 13B-parameter auto-regressive LLM.
(I wanted to say "a two-bit 13B LLM", but that might have been misinterpreted).
I'm hoping I don't confabulate as much though.
------
Turing award laureate, I doubt this guy can even pass the test
------
The insult was:
  "Turing Award laureate, I doubt this guy can even pass the test"

But the author seems spooked by my retweet.
------
3 obstacles for a piece of content to have an impact on people.
1. Production
2. Dissemination
3. Attention

Computers & networks have made production & dissemination easy.
The bottleneck is now capturing the audience's attention.

Generative AI increases 1, but not 2 nor 3.
------
AI has actually played a hugely *positive* role in 2 and 3:
Content moderation on social networks makes massive use of AI to take down or down-rank objectionable content, including dangerous misinformation.

This has made huge progress in recent years because of transformers and… Show more
------
Look in the upper arm of this galaxy- you'll see a star appear to blink in and out of existence. That's a supernova! Very recently discovered in m101: the Pinwheel galaxy (which I happened to be shooting when this happened)
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
 x 1000
This is MASSIVE folks! (blind reaction) 

TTS and STT in one model, that understands 1100 languages, better than whisper! and is able to generate audio in those languages?

Incredible thanks to 
@ylecun
 
@boztank
 and tons of other folks who made this happen and… Show more
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
A thread on MMS by author 
@MichaelAuli
------
New work! The Massively Multilingual Speech (MMS) project scales speech technology to 1,100-4,000 languages using self-supervised learning with wav2vec 2.0.
Paper: https://research.facebook.com/publications/scaling-speech-technology-to-1000-languages/…
Blog: https://ai.facebook.com/blog/multilingual-model-speech-recognition/…
Code/models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
------
MMS: Massively Multilingual Speech.
- Can do speech2text and text speech in 1100 languages.
- Can recognize 4000 spoken languages.
- Code and models available under the CC-BY-NC 4.0 license.
- half the word error rate of Whisper.

Code+Models: https://github.com/facebookresearch/fairseq/tree/main/examples/mms…
Paper:… Show more
------
Correct link to paper:
https://scontent-lga3-2.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX9NNLzC&_nc_ht=scontent-lga3-2.xx&oh=00_AfDZGkLV3haLgAXkFFhYmxMG8D9J2WV1hKDqYAQNPW4-4g&oe=6471ACCF…
------
LIMA :
LLaMA 65B + 1000 supervised samples = {GPT4, Bard} level performance.

From 
@MetaAI
------
LIMA, a 65B LLaMa fine-tuned only with supervised learning on 1000 curated examples, without any RLHF,  demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.https://reddit.com/r/MachineLearning/comments/13oe5ot/lima_a_65bparam_llama_finetuned_with_standard/…
------
Join us on June 22 for our public debate on #ArtificialIntelligence: Be it Resolved, AI research and development poses an existential threat.  

PRO: MIT physicist and AI researcher 
@tegmark
 

CON: Chief scientist 
@MetaAI
 and Turing Award winner 
@ylecun
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
ChatGPT is the modern version of Flaubert's "Dictionary of Received Ideas" (Dictionnaire des idées reçues), that is, a powerful cliché parroting engine.

And, as they say in trading: "what most people know isn't worth knowing."
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
AI won't take your job. But it will transform it and create new ones.
This NYT article has quotes from economists who specialize in the effect of technology on labor markets, such David Autor, Daron Acemoglu, and 
@erikbryn
 :
"Everybody I talk to, supersmart people, doctors,… Show more
------
There's are lots of potential harms from AI to be concerned about.

But if you want a brief respite, read "The Optimist’s Guide to Artificial Intelligence and Work" by Sarah Kessler and Ephrat Livni which quotes me on how AI can help us do new things.
------
Learn to write like an LLM!

Question: what do you think of person A's declaration that X is caused by Y ?

LLM Answer: As an AI language model, I don't have personal opinions. However, I can provide information on the topic.  Person A is a renowned scientist known for his work… Show more
------
Many people are more capable than their boss.
AI systems may become more capable than you, but you'll still be their boss.
If you feel threatened by having a staff -- of humans or machines -- that is smarter than you, you are not a good boss.
------
Wondering if people who are afraid of open-source AI infrastructure have, in fact, a deep distrust of human intelligence.
Do they doubt that the benefits of AI will be overwhelming compared to the risks of misuse?
Would they have had similar fears about the open internet?
------
Since we are talking about insults,
This is one of the two rarest, most original, witty, and intelligent ones involving mutations of my name.
I'll let you guess what the other one is.
------
Yann LeCum
------
No need to find the ones that work in French. 
I've heard them all since elementary school.
------
Are there any countries that rival the US in terms of scientific research?

VP & Chief AI Scientist at 
@Meta
, 
@ylecun
:

"The only European country that rivals the US in terms of the quality of job for an academic or a scientist is Switzerland."
------
Research interest in AI  has soared

Cc: 
@ylecun
 
@Scobleizer
 
@erikbryn
 
@amcafee
------
India  will soon produce more CO2 emissions than the EU 
------
I have to admit, this insult is actually funny 
I'm certainly less fluent in English than a 13B-parameter auto-regressive LLM.
(I wanted to say "a two-bit 13B LLM", but that might have been misinterpreted).
I'm hoping I don't confabulate as much though.
------
Turing award laureate, I doubt this guy can even pass the test
------
The insult was:
  "Turing Award laureate, I doubt this guy can even pass the test"

But the author seems spooked by my retweet.
------
3 obstacles for a piece of content to have an impact on people.
1. Production
2. Dissemination
3. Attention

Computers & networks have made production & dissemination easy.
The bottleneck is now capturing the audience's attention.

Generative AI increases 1, but not 2 nor 3.
------
AI has actually played a hugely *positive* role in 2 and 3:
Content moderation on social networks makes massive use of AI to take down or down-rank objectionable content, including dangerous misinformation.

This has made huge progress in recent years because of transformers and… Show more
------
Look in the upper arm of this galaxy- you'll see a star appear to blink in and out of existence. That's a supernova! Very recently discovered in m101: the Pinwheel galaxy (which I happened to be shooting when this happened)
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
Why's no one talking about the last time an emerging technology was rapidly slowed down due to perceived risk? 

- Blocked Golden Rice, many lives lost https://geneticliteracyproject.org/2023/04/20/farmers-in-the-philippines-blocked-from-commercially-releasing-gmo-golden-rice-and-eggplant-by-10-day-supreme-court-ruling/… 

- Stoked FUD re emerging biotech that helped stoke covid-vaccine FUD   https://thedailybeast.com/lefties-planted-the-anti-science-seed-fueling-vaccine-skepticism…

- EU… Show more
------
You have to admit, it would be the most amazing show to hear 
@ylecun
 and 
@elonmusk
 in discussion on the future of AI on 20VC  
------
LIMA, a 65B LLaMa fine-tuned only with supervised learning on 1000 curated examples, without any RLHF,  demonstrates remarkably strong performance, generalizes well to unseen tasks not in training data. Comparable to GPT-4, Bard, DaVinc003 in human studies.https://reddit.com/r/MachineLearning/comments/13oe5ot/lima_a_65bparam_llama_finetuned_with_standard/…
------
Join us on June 22 for our public debate on #ArtificialIntelligence: Be it Resolved, AI research and development poses an existential threat.  

PRO: MIT physicist and AI researcher 
@tegmark
 

CON: Chief scientist 
@MetaAI
 and Turing Award winner 
@ylecun
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
ChatGPT is the modern version of Flaubert's "Dictionary of Received Ideas" (Dictionnaire des idées reçues), that is, a powerful cliché parroting engine.

And, as they say in trading: "what most people know isn't worth knowing."
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
AI won't take your job. But it will transform it and create new ones.
This NYT article has quotes from economists who specialize in the effect of technology on labor markets, such David Autor, Daron Acemoglu, and 
@erikbryn
 :
"Everybody I talk to, supersmart people, doctors,… Show more
------
There's are lots of potential harms from AI to be concerned about.

But if you want a brief respite, read "The Optimist’s Guide to Artificial Intelligence and Work" by Sarah Kessler and Ephrat Livni which quotes me on how AI can help us do new things.
------
Learn to write like an LLM!

Question: what do you think of person A's declaration that X is caused by Y ?

LLM Answer: As an AI language model, I don't have personal opinions. However, I can provide information on the topic.  Person A is a renowned scientist known for his work… Show more
------
Many people are more capable than their boss.
AI systems may become more capable than you, but you'll still be their boss.
If you feel threatened by having a staff -- of humans or machines -- that is smarter than you, you are not a good boss.
------
Wondering if people who are afraid of open-source AI infrastructure have, in fact, a deep distrust of human intelligence.
Do they doubt that the benefits of AI will be overwhelming compared to the risks of misuse?
Would they have had similar fears about the open internet?
------
Since we are talking about insults,
This is one of the two rarest, most original, witty, and intelligent ones involving mutations of my name.
I'll let you guess what the other one is.
------
Yann LeCum
------
No need to find the ones that work in French. 
I've heard them all since elementary school.
------
Are there any countries that rival the US in terms of scientific research?

VP & Chief AI Scientist at 
@Meta
, 
@ylecun
:

"The only European country that rivals the US in terms of the quality of job for an academic or a scientist is Switzerland."
------
Research interest in AI  has soared

Cc: 
@ylecun
 
@Scobleizer
 
@erikbryn
 
@amcafee
------
India  will soon produce more CO2 emissions than the EU 
------
I have to admit, this insult is actually funny 
I'm certainly less fluent in English than a 13B-parameter auto-regressive LLM.
(I wanted to say "a two-bit 13B LLM", but that might have been misinterpreted).
I'm hoping I don't confabulate as much though.
------
Turing award laureate, I doubt this guy can even pass the test
------
The insult was:
  "Turing Award laureate, I doubt this guy can even pass the test"

But the author seems spooked by my retweet.
------
3 obstacles for a piece of content to have an impact on people.
1. Production
2. Dissemination
3. Attention

Computers & networks have made production & dissemination easy.
The bottleneck is now capturing the audience's attention.

Generative AI increases 1, but not 2 nor 3.
------
AI has actually played a hugely *positive* role in 2 and 3:
Content moderation on social networks makes massive use of AI to take down or down-rank objectionable content, including dangerous misinformation.

This has made huge progress in recent years because of transformers and… Show more
------
Look in the upper arm of this galaxy- you'll see a star appear to blink in and out of existence. That's a supernova! Very recently discovered in m101: the Pinwheel galaxy (which I happened to be shooting when this happened)
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
Why's no one talking about the last time an emerging technology was rapidly slowed down due to perceived risk? 

- Blocked Golden Rice, many lives lost https://geneticliteracyproject.org/2023/04/20/farmers-in-the-philippines-blocked-from-commercially-releasing-gmo-golden-rice-and-eggplant-by-10-day-supreme-court-ruling/… 

- Stoked FUD re emerging biotech that helped stoke covid-vaccine FUD   https://thedailybeast.com/lefties-planted-the-anti-science-seed-fueling-vaccine-skepticism…

- EU… Show more
------
You have to admit, it would be the most amazing show to hear 
@ylecun
 and 
@elonmusk
 in discussion on the future of AI on 20VC  
------
1. Make nearby neurons have correlated outputs.
2. ....
3. Explain perceptual organization.
------
So excited to finally share the work from my PhD! With amazing coauthors @hyo_hyodong_lee, @dfinz, @JamesJDiCarlo,  @stanford_vpnl, and @dyamins 

: https://biorxiv.org/content/10.1101/2023.05.18.541361v1…
: https://github.com/neuroailab/TDANN…
: Thread below
------
Good interview of Rodney Brooks in IEEE Spectrum about AI in general, and the LLM craze in particular.

Favorite quote:
- It sounds like you don’t think GPT-5 or GPT-6 is going to make a lot of progress on these issues.
- Brooks: No, because it doesn’t have any underlying model… Show more
------
On the incentives of doom prophecies
------
Wrinkled so much, I am not.
But when 900 years old I reach, look as good I will not.
------
As friend who wishes to remain anonymous forwarded me this, enjoy
------
AI won't take your job. But it will transform it and create new ones.
This NYT article has quotes from economists who specialize in the effect of technology on labor markets, such David Autor, Daron Acemoglu, and 
@erikbryn
 :
"Everybody I talk to, supersmart people, doctors,… Show more
------
There's are lots of potential harms from AI to be concerned about.

But if you want a brief respite, read "The Optimist’s Guide to Artificial Intelligence and Work" by Sarah Kessler and Ephrat Livni which quotes me on how AI can help us do new things.
------
Learn to write like an LLM!

Question: what do you think of person A's declaration that X is caused by Y ?

LLM Answer: As an AI language model, I don't have personal opinions. However, I can provide information on the topic.  Person A is a renowned scientist known for his work… Show more
------
Many people are more capable than their boss.
AI systems may become more capable than you, but you'll still be their boss.
If you feel threatened by having a staff -- of humans or machines -- that is smarter than you, you are not a good boss.
------
Wondering if people who are afraid of open-source AI infrastructure have, in fact, a deep distrust of human intelligence.
Do they doubt that the benefits of AI will be overwhelming compared to the risks of misuse?
Would they have had similar fears about the open internet?
------
Since we are talking about insults,
This is one of the two rarest, most original, witty, and intelligent ones involving mutations of my name.
I'll let you guess what the other one is.
------
Yann LeCum
------
No need to find the ones that work in French. 
I've heard them all since elementary school.
------
Are there any countries that rival the US in terms of scientific research?

VP & Chief AI Scientist at 
@Meta
, 
@ylecun
:

"The only European country that rivals the US in terms of the quality of job for an academic or a scientist is Switzerland."
------
Research interest in AI  has soared

Cc: 
@ylecun
 
@Scobleizer
 
@erikbryn
 
@amcafee
------
India  will soon produce more CO2 emissions than the EU 
------
I have to admit, this insult is actually funny 
I'm certainly less fluent in English than a 13B-parameter auto-regressive LLM.
(I wanted to say "a two-bit 13B LLM", but that might have been misinterpreted).
I'm hoping I don't confabulate as much though.
------
Turing award laureate, I doubt this guy can even pass the test
------
The insult was:
  "Turing Award laureate, I doubt this guy can even pass the test"

But the author seems spooked by my retweet.
------
3 obstacles for a piece of content to have an impact on people.
1. Production
2. Dissemination
3. Attention

Computers & networks have made production & dissemination easy.
The bottleneck is now capturing the audience's attention.

Generative AI increases 1, but not 2 nor 3.
------
AI has actually played a hugely *positive* role in 2 and 3:
Content moderation on social networks makes massive use of AI to take down or down-rank objectionable content, including dangerous misinformation.

This has made huge progress in recent years because of transformers and… Show more
------
Look in the upper arm of this galaxy- you'll see a star appear to blink in and out of existence. That's a supernova! Very recently discovered in m101: the Pinwheel galaxy (which I happened to be shooting when this happened)
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
Why's no one talking about the last time an emerging technology was rapidly slowed down due to perceived risk? 

- Blocked Golden Rice, many lives lost https://geneticliteracyproject.org/2023/04/20/farmers-in-the-philippines-blocked-from-commercially-releasing-gmo-golden-rice-and-eggplant-by-10-day-supreme-court-ruling/… 

- Stoked FUD re emerging biotech that helped stoke covid-vaccine FUD   https://thedailybeast.com/lefties-planted-the-anti-science-seed-fueling-vaccine-skepticism…

- EU… Show more
------
You have to admit, it would be the most amazing show to hear 
@ylecun
 and 
@elonmusk
 in discussion on the future of AI on 20VC  
------
1. Make nearby neurons have correlated outputs.
2. ....
3. Explain perceptual organization.
------
So excited to finally share the work from my PhD! With amazing coauthors @hyo_hyodong_lee, @dfinz, @JamesJDiCarlo,  @stanford_vpnl, and @dyamins 

: https://biorxiv.org/content/10.1101/2023.05.18.541361v1…
: https://github.com/neuroailab/TDANN…
: Thread below
------
Good interview of Rodney Brooks in IEEE Spectrum about AI in general, and the LLM craze in particular.

Favorite quote:
- It sounds like you don’t think GPT-5 or GPT-6 is going to make a lot of progress on these issues.
- Brooks: No, because it doesn’t have any underlying model… Show more
------
On the incentives of doom prophecies
------

------
- Engineer: I invented this new thing. I call it a ballpen 
- TwitterSphere: OMG, people could write horrible things with it, like misinformation, propaganda, hate speech. Ban it now!
- Writing Doomers: imagine if everyone can get a ballpen. This could destroy society. There… Show more
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Quote from the article:
"A Stanford researcher [...] soon used [Alpaca] to generate problematic text, according to screenshots seen by The New York Times. In one instance, the system provided instructions for disposing of a dead body without being caught."

Should all murder… Show more
------
A series of AI announcements by Meta:
- MTIA v1: an AI chip for fast inference: https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/…
- RSC: 5 exaflops, 16,000 GPU Research Super Cluster for AI research: https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/…
- AI-focused data centers: https://ai.facebook.com/blog/meta-ai-infrastructure-overview/…
------
 Just announced! Join live us on May 18th for #AtScaleMetaAI, a one-day virtual event sharing a look at the next generation of AI infrastructure and innovations powering Meta’s products and services today and in the future.

RSVP 
------
100% agree. Let’s please not regulate based on a couple of company’s commercial interests
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
Are there any countries that rival the US in terms of scientific research?

VP & Chief AI Scientist at 
@Meta
, 
@ylecun
:

"The only European country that rivals the US in terms of the quality of job for an academic or a scientist is Switzerland."
------
Research interest in AI  has soared

Cc: 
@ylecun
 
@Scobleizer
 
@erikbryn
 
@amcafee
------
India  will soon produce more CO2 emissions than the EU 
------
I have to admit, this insult is actually funny 
I'm certainly less fluent in English than a 13B-parameter auto-regressive LLM.
(I wanted to say "a two-bit 13B LLM", but that might have been misinterpreted).
I'm hoping I don't confabulate as much though.
------
Turing award laureate, I doubt this guy can even pass the test
------
The insult was:
  "Turing Award laureate, I doubt this guy can even pass the test"

But the author seems spooked by my retweet.
------
3 obstacles for a piece of content to have an impact on people.
1. Production
2. Dissemination
3. Attention

Computers & networks have made production & dissemination easy.
The bottleneck is now capturing the audience's attention.

Generative AI increases 1, but not 2 nor 3.
------
AI has actually played a hugely *positive* role in 2 and 3:
Content moderation on social networks makes massive use of AI to take down or down-rank objectionable content, including dangerous misinformation.

This has made huge progress in recent years because of transformers and… Show more
------
Look in the upper arm of this galaxy- you'll see a star appear to blink in and out of existence. That's a supernova! Very recently discovered in m101: the Pinwheel galaxy (which I happened to be shooting when this happened)
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
Why's no one talking about the last time an emerging technology was rapidly slowed down due to perceived risk? 

- Blocked Golden Rice, many lives lost https://geneticliteracyproject.org/2023/04/20/farmers-in-the-philippines-blocked-from-commercially-releasing-gmo-golden-rice-and-eggplant-by-10-day-supreme-court-ruling/… 

- Stoked FUD re emerging biotech that helped stoke covid-vaccine FUD   https://thedailybeast.com/lefties-planted-the-anti-science-seed-fueling-vaccine-skepticism…

- EU… Show more
------
You have to admit, it would be the most amazing show to hear 
@ylecun
 and 
@elonmusk
 in discussion on the future of AI on 20VC  
------
1. Make nearby neurons have correlated outputs.
2. ....
3. Explain perceptual organization.
------
So excited to finally share the work from my PhD! With amazing coauthors @hyo_hyodong_lee, @dfinz, @JamesJDiCarlo,  @stanford_vpnl, and @dyamins 

: https://biorxiv.org/content/10.1101/2023.05.18.541361v1…
: https://github.com/neuroailab/TDANN…
: Thread below
------
Good interview of Rodney Brooks in IEEE Spectrum about AI in general, and the LLM craze in particular.

Favorite quote:
- It sounds like you don’t think GPT-5 or GPT-6 is going to make a lot of progress on these issues.
- Brooks: No, because it doesn’t have any underlying model… Show more
------
On the incentives of doom prophecies
------

------
- Engineer: I invented this new thing. I call it a ballpen 
- TwitterSphere: OMG, people could write horrible things with it, like misinformation, propaganda, hate speech. Ban it now!
- Writing Doomers: imagine if everyone can get a ballpen. This could destroy society. There… Show more
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Quote from the article:
"A Stanford researcher [...] soon used [Alpaca] to generate problematic text, according to screenshots seen by The New York Times. In one instance, the system provided instructions for disposing of a dead body without being caught."

Should all murder… Show more
------
A series of AI announcements by Meta:
- MTIA v1: an AI chip for fast inference: https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/…
- RSC: 5 exaflops, 16,000 GPU Research Super Cluster for AI research: https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/…
- AI-focused data centers: https://ai.facebook.com/blog/meta-ai-infrastructure-overview/…
------
 Just announced! Join live us on May 18th for #AtScaleMetaAI, a one-day virtual event sharing a look at the next generation of AI infrastructure and innovations powering Meta’s products and services today and in the future.

RSVP 
------
100% agree. Let’s please not regulate based on a couple of company’s commercial interests
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
I don't get it. Training a LLM on "trusted" data doesn't make its output more trustable.

You can make a LLM-based app safer by working at the application level, or with an adversarial model approach -- I don't see how one can make an LLM safer per se.
------
What does the future of trusted AI-enabled Health Assurance look like? Enter Hippocratic.

We're thrilled to leverage our Creation strategy, co-lead Hippocratic's $50M seed & welcome Munjal Shah & team to the GC family!

From @htaneja & @AlexandreMomeni ↓
https://generalcatalyst.com/perspectives/our-co-creation-of-hippocratic-ai…
------
Covid vaccines saved about 20 million lives.
------
Global impact of the first year of COVID-19 vaccination: a mathematical modelling study https://thelancet.com/journals/laninf/article/PIIS1473-3099%2822%2900320-6/fulltext…
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
I have to admit, this insult is actually funny 
I'm certainly less fluent in English than a 13B-parameter auto-regressive LLM.
(I wanted to say "a two-bit 13B LLM", but that might have been misinterpreted).
I'm hoping I don't confabulate as much though.
------
Turing award laureate, I doubt this guy can even pass the test
------
The insult was:
  "Turing Award laureate, I doubt this guy can even pass the test"

But the author seems spooked by my retweet.
------
3 obstacles for a piece of content to have an impact on people.
1. Production
2. Dissemination
3. Attention

Computers & networks have made production & dissemination easy.
The bottleneck is now capturing the audience's attention.

Generative AI increases 1, but not 2 nor 3.
------
AI has actually played a hugely *positive* role in 2 and 3:
Content moderation on social networks makes massive use of AI to take down or down-rank objectionable content, including dangerous misinformation.

This has made huge progress in recent years because of transformers and… Show more
------
Look in the upper arm of this galaxy- you'll see a star appear to blink in and out of existence. That's a supernova! Very recently discovered in m101: the Pinwheel galaxy (which I happened to be shooting when this happened)
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
Why's no one talking about the last time an emerging technology was rapidly slowed down due to perceived risk? 

- Blocked Golden Rice, many lives lost https://geneticliteracyproject.org/2023/04/20/farmers-in-the-philippines-blocked-from-commercially-releasing-gmo-golden-rice-and-eggplant-by-10-day-supreme-court-ruling/… 

- Stoked FUD re emerging biotech that helped stoke covid-vaccine FUD   https://thedailybeast.com/lefties-planted-the-anti-science-seed-fueling-vaccine-skepticism…

- EU… Show more
------
You have to admit, it would be the most amazing show to hear 
@ylecun
 and 
@elonmusk
 in discussion on the future of AI on 20VC  
------
1. Make nearby neurons have correlated outputs.
2. ....
3. Explain perceptual organization.
------
So excited to finally share the work from my PhD! With amazing coauthors @hyo_hyodong_lee, @dfinz, @JamesJDiCarlo,  @stanford_vpnl, and @dyamins 

: https://biorxiv.org/content/10.1101/2023.05.18.541361v1…
: https://github.com/neuroailab/TDANN…
: Thread below
------
Good interview of Rodney Brooks in IEEE Spectrum about AI in general, and the LLM craze in particular.

Favorite quote:
- It sounds like you don’t think GPT-5 or GPT-6 is going to make a lot of progress on these issues.
- Brooks: No, because it doesn’t have any underlying model… Show more
------
On the incentives of doom prophecies
------

------
- Engineer: I invented this new thing. I call it a ballpen 
- TwitterSphere: OMG, people could write horrible things with it, like misinformation, propaganda, hate speech. Ban it now!
- Writing Doomers: imagine if everyone can get a ballpen. This could destroy society. There… Show more
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Quote from the article:
"A Stanford researcher [...] soon used [Alpaca] to generate problematic text, according to screenshots seen by The New York Times. In one instance, the system provided instructions for disposing of a dead body without being caught."

Should all murder… Show more
------
A series of AI announcements by Meta:
- MTIA v1: an AI chip for fast inference: https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/…
- RSC: 5 exaflops, 16,000 GPU Research Super Cluster for AI research: https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/…
- AI-focused data centers: https://ai.facebook.com/blog/meta-ai-infrastructure-overview/…
------
 Just announced! Join live us on May 18th for #AtScaleMetaAI, a one-day virtual event sharing a look at the next generation of AI infrastructure and innovations powering Meta’s products and services today and in the future.

RSVP 
------
100% agree. Let’s please not regulate based on a couple of company’s commercial interests
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
I don't get it. Training a LLM on "trusted" data doesn't make its output more trustable.

You can make a LLM-based app safer by working at the application level, or with an adversarial model approach -- I don't see how one can make an LLM safer per se.
------
What does the future of trusted AI-enabled Health Assurance look like? Enter Hippocratic.

We're thrilled to leverage our Creation strategy, co-lead Hippocratic's $50M seed & welcome Munjal Shah & team to the GC family!

From @htaneja & @AlexandreMomeni ↓
https://generalcatalyst.com/perspectives/our-co-creation-of-hippocratic-ai…
------
Covid vaccines saved about 20 million lives.
------
Global impact of the first year of COVID-19 vaccination: a mathematical modelling study https://thelancet.com/journals/laninf/article/PIIS1473-3099%2822%2900320-6/fulltext…
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
Tech doomerism is a species of hype.
------
“The most important thing to remember about tech doomerism in general is that it’s a form of advertising, a species of hype.”

The apocalypse isn’t coming. We must resist cynicism and fear about AI | Stephen Marche | The Guardian https://theguardian.com/commentisfree/2023/may/15/artificial-intelligence-cynicism-technology…
------
LLMs do not tell you the answer to your question. They tell you “when people ask questions like that, this is what the answers that other people tend to give tend to look like”
Over time, that difference may or may not narrow, depending on what kind of question you’re asking.
------
An opinion piece by Canadian writer Stephen Marche in the Guardian against AI doomerism.
He makes a few points I've made before, such as:
1. "I have heard geniuses – bona fide geniuses – declare that medical schools should no longer teach radiology because it would all be… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
My interview with 
@HarryStebbings
 on the #20VC podcast.
All about AI, the limitations of current systems, future capabilities of AI, the potential impact on the economy, society, and humanity as a whole.
No, we don't have human-level AI yet.
Yes, we will get to human-level and… Show more
------
SUPERNOVA ALERT : SN2023ixf was just discovered a few hours ago in the Pinwheel Galaxy, M101! At 21 million light years away it’s the closest supernova in a decade- currently rising rapidly and should be viewable soon in amateur telescopes!

https://wis-tns.org/astronotes/astronote/2023-119…
------
Why's no one talking about the last time an emerging technology was rapidly slowed down due to perceived risk? 

- Blocked Golden Rice, many lives lost https://geneticliteracyproject.org/2023/04/20/farmers-in-the-philippines-blocked-from-commercially-releasing-gmo-golden-rice-and-eggplant-by-10-day-supreme-court-ruling/… 

- Stoked FUD re emerging biotech that helped stoke covid-vaccine FUD   https://thedailybeast.com/lefties-planted-the-anti-science-seed-fueling-vaccine-skepticism…

- EU… Show more
------
You have to admit, it would be the most amazing show to hear 
@ylecun
 and 
@elonmusk
 in discussion on the future of AI on 20VC  
------
1. Make nearby neurons have correlated outputs.
2. ....
3. Explain perceptual organization.
------
So excited to finally share the work from my PhD! With amazing coauthors @hyo_hyodong_lee, @dfinz, @JamesJDiCarlo,  @stanford_vpnl, and @dyamins 

: https://biorxiv.org/content/10.1101/2023.05.18.541361v1…
: https://github.com/neuroailab/TDANN…
: Thread below
------
Good interview of Rodney Brooks in IEEE Spectrum about AI in general, and the LLM craze in particular.

Favorite quote:
- It sounds like you don’t think GPT-5 or GPT-6 is going to make a lot of progress on these issues.
- Brooks: No, because it doesn’t have any underlying model… Show more
------
On the incentives of doom prophecies
------

------
- Engineer: I invented this new thing. I call it a ballpen 
- TwitterSphere: OMG, people could write horrible things with it, like misinformation, propaganda, hate speech. Ban it now!
- Writing Doomers: imagine if everyone can get a ballpen. This could destroy society. There… Show more
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Quote from the article:
"A Stanford researcher [...] soon used [Alpaca] to generate problematic text, according to screenshots seen by The New York Times. In one instance, the system provided instructions for disposing of a dead body without being caught."

Should all murder… Show more
------
A series of AI announcements by Meta:
- MTIA v1: an AI chip for fast inference: https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/…
- RSC: 5 exaflops, 16,000 GPU Research Super Cluster for AI research: https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/…
- AI-focused data centers: https://ai.facebook.com/blog/meta-ai-infrastructure-overview/…
------
 Just announced! Join live us on May 18th for #AtScaleMetaAI, a one-day virtual event sharing a look at the next generation of AI infrastructure and innovations powering Meta’s products and services today and in the future.

RSVP 
------
100% agree. Let’s please not regulate based on a couple of company’s commercial interests
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
I don't get it. Training a LLM on "trusted" data doesn't make its output more trustable.

You can make a LLM-based app safer by working at the application level, or with an adversarial model approach -- I don't see how one can make an LLM safer per se.
------
What does the future of trusted AI-enabled Health Assurance look like? Enter Hippocratic.

We're thrilled to leverage our Creation strategy, co-lead Hippocratic's $50M seed & welcome Munjal Shah & team to the GC family!

From @htaneja & @AlexandreMomeni ↓
https://generalcatalyst.com/perspectives/our-co-creation-of-hippocratic-ai…
------
Covid vaccines saved about 20 million lives.
------
Global impact of the first year of COVID-19 vaccination: a mathematical modelling study https://thelancet.com/journals/laninf/article/PIIS1473-3099%2822%2900320-6/fulltext…
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
Tech doomerism is a species of hype.
------
“The most important thing to remember about tech doomerism in general is that it’s a form of advertising, a species of hype.”

The apocalypse isn’t coming. We must resist cynicism and fear about AI | Stephen Marche | The Guardian https://theguardian.com/commentisfree/2023/may/15/artificial-intelligence-cynicism-technology…
------
LLMs do not tell you the answer to your question. They tell you “when people ask questions like that, this is what the answers that other people tend to give tend to look like”
Over time, that difference may or may not narrow, depending on what kind of question you’re asking.
------
An opinion piece by Canadian writer Stephen Marche in the Guardian against AI doomerism.
He makes a few points I've made before, such as:
1. "I have heard geniuses – bona fide geniuses – declare that medical schools should no longer teach radiology because it would all be… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
My interview with 
@HarryStebbings
 on the #20VC podcast.
All about AI, the limitations of current systems, future capabilities of AI, the potential impact on the economy, society, and humanity as a whole.
No, we don't have human-level AI yet.
Yes, we will get to human-level and… Show more
------
Desktop playing link
------
A distillation of my main points in the 20VC podcast.
------
"AI is not dangerous. AI is going to bring a new form of enlightenment to humanity & make us more creative". 

An honour to do this 20VC with @ylecun, one of the OGs in AI. 

Here are my top 10 takeaways from the discussion:
------
I knew EU regulators would be freaking out about AI. I didn't anticipate that this freaking out would take the form of unbelievably stupid draft regulations, though in retrospect it's obvious. Regulators gonna regulate.
------
1. Make nearby neurons have correlated outputs.
2. ....
3. Explain perceptual organization.
------
So excited to finally share the work from my PhD! With amazing coauthors @hyo_hyodong_lee, @dfinz, @JamesJDiCarlo,  @stanford_vpnl, and @dyamins 

: https://biorxiv.org/content/10.1101/2023.05.18.541361v1…
: https://github.com/neuroailab/TDANN…
: Thread below
------
Good interview of Rodney Brooks in IEEE Spectrum about AI in general, and the LLM craze in particular.

Favorite quote:
- It sounds like you don’t think GPT-5 or GPT-6 is going to make a lot of progress on these issues.
- Brooks: No, because it doesn’t have any underlying model… Show more
------
On the incentives of doom prophecies
------

------
- Engineer: I invented this new thing. I call it a ballpen 
- TwitterSphere: OMG, people could write horrible things with it, like misinformation, propaganda, hate speech. Ban it now!
- Writing Doomers: imagine if everyone can get a ballpen. This could destroy society. There… Show more
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Quote from the article:
"A Stanford researcher [...] soon used [Alpaca] to generate problematic text, according to screenshots seen by The New York Times. In one instance, the system provided instructions for disposing of a dead body without being caught."

Should all murder… Show more
------
A series of AI announcements by Meta:
- MTIA v1: an AI chip for fast inference: https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/…
- RSC: 5 exaflops, 16,000 GPU Research Super Cluster for AI research: https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/…
- AI-focused data centers: https://ai.facebook.com/blog/meta-ai-infrastructure-overview/…
------
 Just announced! Join live us on May 18th for #AtScaleMetaAI, a one-day virtual event sharing a look at the next generation of AI infrastructure and innovations powering Meta’s products and services today and in the future.

RSVP 
------
100% agree. Let’s please not regulate based on a couple of company’s commercial interests
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
I don't get it. Training a LLM on "trusted" data doesn't make its output more trustable.

You can make a LLM-based app safer by working at the application level, or with an adversarial model approach -- I don't see how one can make an LLM safer per se.
------
What does the future of trusted AI-enabled Health Assurance look like? Enter Hippocratic.

We're thrilled to leverage our Creation strategy, co-lead Hippocratic's $50M seed & welcome Munjal Shah & team to the GC family!

From @htaneja & @AlexandreMomeni ↓
https://generalcatalyst.com/perspectives/our-co-creation-of-hippocratic-ai…
------
Covid vaccines saved about 20 million lives.
------
Global impact of the first year of COVID-19 vaccination: a mathematical modelling study https://thelancet.com/journals/laninf/article/PIIS1473-3099%2822%2900320-6/fulltext…
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
Tech doomerism is a species of hype.
------
“The most important thing to remember about tech doomerism in general is that it’s a form of advertising, a species of hype.”

The apocalypse isn’t coming. We must resist cynicism and fear about AI | Stephen Marche | The Guardian https://theguardian.com/commentisfree/2023/may/15/artificial-intelligence-cynicism-technology…
------
LLMs do not tell you the answer to your question. They tell you “when people ask questions like that, this is what the answers that other people tend to give tend to look like”
Over time, that difference may or may not narrow, depending on what kind of question you’re asking.
------
An opinion piece by Canadian writer Stephen Marche in the Guardian against AI doomerism.
He makes a few points I've made before, such as:
1. "I have heard geniuses – bona fide geniuses – declare that medical schools should no longer teach radiology because it would all be… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
My interview with 
@HarryStebbings
 on the #20VC podcast.
All about AI, the limitations of current systems, future capabilities of AI, the potential impact on the economy, society, and humanity as a whole.
No, we don't have human-level AI yet.
Yes, we will get to human-level and… Show more
------
Desktop playing link
------
A distillation of my main points in the 20VC podcast.
------
"AI is not dangerous. AI is going to bring a new form of enlightenment to humanity & make us more creative". 

An honour to do this 20VC with @ylecun, one of the OGs in AI. 

Here are my top 10 takeaways from the discussion:
------
I knew EU regulators would be freaking out about AI. I didn't anticipate that this freaking out would take the form of unbelievably stupid draft regulations, though in retrospect it's obvious. Regulators gonna regulate.
------
Fascinating discussion between 
@ylecun
 and 
@harari_yuval
.  
@harari_yuval
's main concern is whether society can adapt to progress at such speed or will make irreversible mistakes and whether AI favors dictators or democracies.
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in @LePoint.

The annihilation of democracy or a new era of Enlightenment?

By @guillaumgrallet & Héloïse Pons.

https://lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php…
------
What characterizes AI doomers (as well as many pessimists) is a limitless imagination for catastrophe scenarios and a complete lack of imagination (or competence) for ways to avoid them.
------
Imagine that the set of possible scenarios is a large tree in which each branch is a series of events.
"Good" scenarios constitute a tiny subset of that tree.
It's very, very easy to imagine any of the innumerable ways things could escape from the Good Subtree.
It's a bit harder… Show more
------
We can all imagine innumerable scenarios in which a jet airliner flight goes bad.
Yet engineers have found ways to make air transport incredibly safe and reliable.
That requires skills that the air transport doomers don't have.
------
Two common misconceptions about AI: 
(1) the fallacy of the hard take-off scenario.
(2) the idea that intelligent agents will necessarily want to dominate.
Full 20VC podcast coming up tomorrow.
------
“The fact that the minute you turn on a super intelligent AI system, it is going to take over the world. That is ridiculous.”

Tomorrow on 20VC, @ylecun with one of the best 20VCs ever.  
------
MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

abs: https://arxiv.org/abs/2305.07185
paper page: https://huggingface.co/papers/2305.07185…
------
Excellent initiative de Maurice Lévy.
------
Avec YourArt, Maurice Lévy souhaite "faire en sorte" que l'art "soit ouvert à tous".

(Ré)écoutez l'interview du président du conseil de surveillance du groupe Publicis et cofondateur de la plateforme YourArt, invité du 7h50 dans #le7930inter.  https://l.franceinter.fr/gdB
------
Quote from the article:
"A Stanford researcher [...] soon used [Alpaca] to generate problematic text, according to screenshots seen by The New York Times. In one instance, the system provided instructions for disposing of a dead body without being caught."

Should all murder… Show more
------
A series of AI announcements by Meta:
- MTIA v1: an AI chip for fast inference: https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/…
- RSC: 5 exaflops, 16,000 GPU Research Super Cluster for AI research: https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/…
- AI-focused data centers: https://ai.facebook.com/blog/meta-ai-infrastructure-overview/…
------
 Just announced! Join live us on May 18th for #AtScaleMetaAI, a one-day virtual event sharing a look at the next generation of AI infrastructure and innovations powering Meta’s products and services today and in the future.

RSVP 
------
100% agree. Let’s please not regulate based on a couple of company’s commercial interests
------
A NYT article on the debate around whether LLM base models should be closed or open.

Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.

They argue that openness can be… Show more
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
I don't get it. Training a LLM on "trusted" data doesn't make its output more trustable.

You can make a LLM-based app safer by working at the application level, or with an adversarial model approach -- I don't see how one can make an LLM safer per se.
------
What does the future of trusted AI-enabled Health Assurance look like? Enter Hippocratic.

We're thrilled to leverage our Creation strategy, co-lead Hippocratic's $50M seed & welcome Munjal Shah & team to the GC family!

From @htaneja & @AlexandreMomeni ↓
https://generalcatalyst.com/perspectives/our-co-creation-of-hippocratic-ai…
------
Covid vaccines saved about 20 million lives.
------
Global impact of the first year of COVID-19 vaccination: a mathematical modelling study https://thelancet.com/journals/laninf/article/PIIS1473-3099%2822%2900320-6/fulltext…
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
Tech doomerism is a species of hype.
------
“The most important thing to remember about tech doomerism in general is that it’s a form of advertising, a species of hype.”

The apocalypse isn’t coming. We must resist cynicism and fear about AI | Stephen Marche | The Guardian https://theguardian.com/commentisfree/2023/may/15/artificial-intelligence-cynicism-technology…
------
LLMs do not tell you the answer to your question. They tell you “when people ask questions like that, this is what the answers that other people tend to give tend to look like”
Over time, that difference may or may not narrow, depending on what kind of question you’re asking.
------
An opinion piece by Canadian writer Stephen Marche in the Guardian against AI doomerism.
He makes a few points I've made before, such as:
1. "I have heard geniuses – bona fide geniuses – declare that medical schools should no longer teach radiology because it would all be… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
My interview with 
@HarryStebbings
 on the #20VC podcast.
All about AI, the limitations of current systems, future capabilities of AI, the potential impact on the economy, society, and humanity as a whole.
No, we don't have human-level AI yet.
Yes, we will get to human-level and… Show more
------
Desktop playing link
------
A distillation of my main points in the 20VC podcast.
------
"AI is not dangerous. AI is going to bring a new form of enlightenment to humanity & make us more creative". 

An honour to do this 20VC with @ylecun, one of the OGs in AI. 

Here are my top 10 takeaways from the discussion:
------
I knew EU regulators would be freaking out about AI. I didn't anticipate that this freaking out would take the form of unbelievably stupid draft regulations, though in retrospect it's obvious. Regulators gonna regulate.
------
Fascinating discussion between 
@ylecun
 and 
@harari_yuval
.  
@harari_yuval
's main concern is whether society can adapt to progress at such speed or will make irreversible mistakes and whether AI favors dictators or democracies.
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in @LePoint.

The annihilation of democracy or a new era of Enlightenment?

By @guillaumgrallet & Héloïse Pons.

https://lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php…
------
What characterizes AI doomers (as well as many pessimists) is a limitless imagination for catastrophe scenarios and a complete lack of imagination (or competence) for ways to avoid them.
------
Imagine that the set of possible scenarios is a large tree in which each branch is a series of events.
"Good" scenarios constitute a tiny subset of that tree.
It's very, very easy to imagine any of the innumerable ways things could escape from the Good Subtree.
It's a bit harder… Show more
------
We can all imagine innumerable scenarios in which a jet airliner flight goes bad.
Yet engineers have found ways to make air transport incredibly safe and reliable.
That requires skills that the air transport doomers don't have.
------
Two common misconceptions about AI: 
(1) the fallacy of the hard take-off scenario.
(2) the idea that intelligent agents will necessarily want to dominate.
Full 20VC podcast coming up tomorrow.
------
“The fact that the minute you turn on a super intelligent AI system, it is going to take over the world. That is ridiculous.”

Tomorrow on 20VC, @ylecun with one of the best 20VCs ever.  
------
MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

abs: https://arxiv.org/abs/2305.07185
paper page: https://huggingface.co/papers/2305.07185…
------
Excellent initiative de Maurice Lévy.
------
Avec YourArt, Maurice Lévy souhaite "faire en sorte" que l'art "soit ouvert à tous".

(Ré)écoutez l'interview du président du conseil de surveillance du groupe Publicis et cofondateur de la plateforme YourArt, invité du 7h50 dans #le7930inter.  https://l.franceinter.fr/gdB
------
Simple facts about guns.
------
With regard to gun violence, Britain looks like most other advanced industrial countries. America, meanwhile, might as well be on another planet.

My take:
------
China  dominates large parts of the global green energy supply chain
------
EV adoption is much faster in Europe than in the US.
------
Read the great piece below by @Noahpinion on the EV revolution   twitter.com/Noahpinion/sta…
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Myth:

AI will kill employment.

Truth:

"AI is going to bring a new Renaissance for humanity, because AI is going to amplify everybody's intelligence.

This is gonna create as many jobs as it makes disappear."


@ylecun
------
I don't get it. Training a LLM on "trusted" data doesn't make its output more trustable.

You can make a LLM-based app safer by working at the application level, or with an adversarial model approach -- I don't see how one can make an LLM safer per se.
------
What does the future of trusted AI-enabled Health Assurance look like? Enter Hippocratic.

We're thrilled to leverage our Creation strategy, co-lead Hippocratic's $50M seed & welcome Munjal Shah & team to the GC family!

From @htaneja & @AlexandreMomeni ↓
https://generalcatalyst.com/perspectives/our-co-creation-of-hippocratic-ai…
------
Covid vaccines saved about 20 million lives.
------
Global impact of the first year of COVID-19 vaccination: a mathematical modelling study https://thelancet.com/journals/laninf/article/PIIS1473-3099%2822%2900320-6/fulltext…
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
Tech doomerism is a species of hype.
------
“The most important thing to remember about tech doomerism in general is that it’s a form of advertising, a species of hype.”

The apocalypse isn’t coming. We must resist cynicism and fear about AI | Stephen Marche | The Guardian https://theguardian.com/commentisfree/2023/may/15/artificial-intelligence-cynicism-technology…
------
LLMs do not tell you the answer to your question. They tell you “when people ask questions like that, this is what the answers that other people tend to give tend to look like”
Over time, that difference may or may not narrow, depending on what kind of question you’re asking.
------
An opinion piece by Canadian writer Stephen Marche in the Guardian against AI doomerism.
He makes a few points I've made before, such as:
1. "I have heard geniuses – bona fide geniuses – declare that medical schools should no longer teach radiology because it would all be… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
My interview with 
@HarryStebbings
 on the #20VC podcast.
All about AI, the limitations of current systems, future capabilities of AI, the potential impact on the economy, society, and humanity as a whole.
No, we don't have human-level AI yet.
Yes, we will get to human-level and… Show more
------
Desktop playing link
------
A distillation of my main points in the 20VC podcast.
------
"AI is not dangerous. AI is going to bring a new form of enlightenment to humanity & make us more creative". 

An honour to do this 20VC with @ylecun, one of the OGs in AI. 

Here are my top 10 takeaways from the discussion:
------
I knew EU regulators would be freaking out about AI. I didn't anticipate that this freaking out would take the form of unbelievably stupid draft regulations, though in retrospect it's obvious. Regulators gonna regulate.
------
Fascinating discussion between 
@ylecun
 and 
@harari_yuval
.  
@harari_yuval
's main concern is whether society can adapt to progress at such speed or will make irreversible mistakes and whether AI favors dictators or democracies.
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in @LePoint.

The annihilation of democracy or a new era of Enlightenment?

By @guillaumgrallet & Héloïse Pons.

https://lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php…
------
What characterizes AI doomers (as well as many pessimists) is a limitless imagination for catastrophe scenarios and a complete lack of imagination (or competence) for ways to avoid them.
------
Imagine that the set of possible scenarios is a large tree in which each branch is a series of events.
"Good" scenarios constitute a tiny subset of that tree.
It's very, very easy to imagine any of the innumerable ways things could escape from the Good Subtree.
It's a bit harder… Show more
------
We can all imagine innumerable scenarios in which a jet airliner flight goes bad.
Yet engineers have found ways to make air transport incredibly safe and reliable.
That requires skills that the air transport doomers don't have.
------
Two common misconceptions about AI: 
(1) the fallacy of the hard take-off scenario.
(2) the idea that intelligent agents will necessarily want to dominate.
Full 20VC podcast coming up tomorrow.
------
“The fact that the minute you turn on a super intelligent AI system, it is going to take over the world. That is ridiculous.”

Tomorrow on 20VC, @ylecun with one of the best 20VCs ever.  
------
MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

abs: https://arxiv.org/abs/2305.07185
paper page: https://huggingface.co/papers/2305.07185…
------
Excellent initiative de Maurice Lévy.
------
Avec YourArt, Maurice Lévy souhaite "faire en sorte" que l'art "soit ouvert à tous".

(Ré)écoutez l'interview du président du conseil de surveillance du groupe Publicis et cofondateur de la plateforme YourArt, invité du 7h50 dans #le7930inter.  https://l.franceinter.fr/gdB
------
Simple facts about guns.
------
With regard to gun violence, Britain looks like most other advanced industrial countries. America, meanwhile, might as well be on another planet.

My take:
------
China  dominates large parts of the global green energy supply chain
------
EV adoption is much faster in Europe than in the US.
------
Read the great piece below by @Noahpinion on the EV revolution   twitter.com/Noahpinion/sta…
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Highlights from a conversation about the future with 
@ylecun
, NYU professor and Meta’s Chief AI Scientist - courtesy of 
@LePoint
’s 
@guillaumgrallet
  and 
@ponsheloise

https://bit.ly/hararilecun
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in 
@LePoint
.

The annihilation of democracy or a new era of Enlightenment?

By 
@guillaumgrallet
 & Héloïse Pons.
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
Hear from one of the 'Godfathers of AI' and Chief AI Scientist at 

@MetaAI
, 
@ylecun
 on Wednesday, May 24, 2023! Plus a special fireside chat with our Executive Director, 
@usamaf
 Register ASAP to join us at 
@Northeastern
 or online: https://bit.ly/41rLaFl
------
Tech doomerism is a species of hype.
------
“The most important thing to remember about tech doomerism in general is that it’s a form of advertising, a species of hype.”

The apocalypse isn’t coming. We must resist cynicism and fear about AI | Stephen Marche | The Guardian https://theguardian.com/commentisfree/2023/may/15/artificial-intelligence-cynicism-technology…
------
LLMs do not tell you the answer to your question. They tell you “when people ask questions like that, this is what the answers that other people tend to give tend to look like”
Over time, that difference may or may not narrow, depending on what kind of question you’re asking.
------
An opinion piece by Canadian writer Stephen Marche in the Guardian against AI doomerism.
He makes a few points I've made before, such as:
1. "I have heard geniuses – bona fide geniuses – declare that medical schools should no longer teach radiology because it would all be… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
From the point of view of a 19th Century farmer, machines have taken over all the jobs in the 21st Century.
Jobs that occupied most people in the 19th Century now occupy small amounts of people or have disappeared.
Most 21st jobs would be entirely incomprehensible for a 19th… Show more
------
My interview with 
@HarryStebbings
 on the #20VC podcast.
All about AI, the limitations of current systems, future capabilities of AI, the potential impact on the economy, society, and humanity as a whole.
No, we don't have human-level AI yet.
Yes, we will get to human-level and… Show more
------
Desktop playing link
------
A distillation of my main points in the 20VC podcast.
------
"AI is not dangerous. AI is going to bring a new form of enlightenment to humanity & make us more creative". 

An honour to do this 20VC with @ylecun, one of the OGs in AI. 

Here are my top 10 takeaways from the discussion:
------
I knew EU regulators would be freaking out about AI. I didn't anticipate that this freaking out would take the form of unbelievably stupid draft regulations, though in retrospect it's obvious. Regulators gonna regulate.
------
Fascinating discussion between 
@ylecun
 and 
@harari_yuval
.  
@harari_yuval
's main concern is whether society can adapt to progress at such speed or will make irreversible mistakes and whether AI favors dictators or democracies.
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in @LePoint.

The annihilation of democracy or a new era of Enlightenment?

By @guillaumgrallet & Héloïse Pons.

https://lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php…
------
What characterizes AI doomers (as well as many pessimists) is a limitless imagination for catastrophe scenarios and a complete lack of imagination (or competence) for ways to avoid them.
------
Imagine that the set of possible scenarios is a large tree in which each branch is a series of events.
"Good" scenarios constitute a tiny subset of that tree.
It's very, very easy to imagine any of the innumerable ways things could escape from the Good Subtree.
It's a bit harder… Show more
------
We can all imagine innumerable scenarios in which a jet airliner flight goes bad.
Yet engineers have found ways to make air transport incredibly safe and reliable.
That requires skills that the air transport doomers don't have.
------
Two common misconceptions about AI: 
(1) the fallacy of the hard take-off scenario.
(2) the idea that intelligent agents will necessarily want to dominate.
Full 20VC podcast coming up tomorrow.
------
“The fact that the minute you turn on a super intelligent AI system, it is going to take over the world. That is ridiculous.”

Tomorrow on 20VC, @ylecun with one of the best 20VCs ever.  
------
MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

abs: https://arxiv.org/abs/2305.07185
paper page: https://huggingface.co/papers/2305.07185…
------
Excellent initiative de Maurice Lévy.
------
Avec YourArt, Maurice Lévy souhaite "faire en sorte" que l'art "soit ouvert à tous".

(Ré)écoutez l'interview du président du conseil de surveillance du groupe Publicis et cofondateur de la plateforme YourArt, invité du 7h50 dans #le7930inter.  https://l.franceinter.fr/gdB
------
Simple facts about guns.
------
With regard to gun violence, Britain looks like most other advanced industrial countries. America, meanwhile, might as well be on another planet.

My take:
------
China  dominates large parts of the global green energy supply chain
------
EV adoption is much faster in Europe than in the US.
------
Read the great piece below by @Noahpinion on the EV revolution   twitter.com/Noahpinion/sta…
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Highlights from a conversation about the future with 
@ylecun
, NYU professor and Meta’s Chief AI Scientist - courtesy of 
@LePoint
’s 
@guillaumgrallet
  and 
@ponsheloise

https://bit.ly/hararilecun
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in 
@LePoint
.

The annihilation of democracy or a new era of Enlightenment?

By 
@guillaumgrallet
 & Héloïse Pons.
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
$ cat >lol.txt
Y2K articles before year 2000:
"OMG, rogue Y2K is going to kill us all!"
Y2K articles after year 2000:
"Hahaha, remember how everyone was so scared of Y2K?  ROFL!"
^D
$ sed 's/Y2K/AGI/' lol.txt | sed 's/2000/20XX/'
------
The Y2K problem was of interest from 1994 to 2000
------
Remember Karl Popper's paradox of tolerance?
"The seemingly self-contradictory idea that in order to maintain a tolerant society, the society must retain the right to be intolerant of intolerance."

Here is an Internet-age corollary:
"In order to maintain a constructive… Show more
------
Wondering how "runaway AI" can run away if it's been "running into walls" for several years now
------
Coming soon.
------
It is coming and better than even I could have hoped for with AI OG @ylecun. 

Stay tuned, absolute  coming on Monday. 
------
Desktop playing link
------
A distillation of my main points in the 20VC podcast.
------
"AI is not dangerous. AI is going to bring a new form of enlightenment to humanity & make us more creative". 

An honour to do this 20VC with @ylecun, one of the OGs in AI. 

Here are my top 10 takeaways from the discussion:
------
I knew EU regulators would be freaking out about AI. I didn't anticipate that this freaking out would take the form of unbelievably stupid draft regulations, though in retrospect it's obvious. Regulators gonna regulate.
------
Fascinating discussion between 
@ylecun
 and 
@harari_yuval
.  
@harari_yuval
's main concern is whether society can adapt to progress at such speed or will make irreversible mistakes and whether AI favors dictators or democracies.
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in @LePoint.

The annihilation of democracy or a new era of Enlightenment?

By @guillaumgrallet & Héloïse Pons.

https://lepoint.fr/sciences-nature/yuval-harari-sapiens-versus-yann-le-cun-meta-on-artificial-intelligence-11-05-2023-2519782_1924.php…
------
What characterizes AI doomers (as well as many pessimists) is a limitless imagination for catastrophe scenarios and a complete lack of imagination (or competence) for ways to avoid them.
------
Imagine that the set of possible scenarios is a large tree in which each branch is a series of events.
"Good" scenarios constitute a tiny subset of that tree.
It's very, very easy to imagine any of the innumerable ways things could escape from the Good Subtree.
It's a bit harder… Show more
------
We can all imagine innumerable scenarios in which a jet airliner flight goes bad.
Yet engineers have found ways to make air transport incredibly safe and reliable.
That requires skills that the air transport doomers don't have.
------
Two common misconceptions about AI: 
(1) the fallacy of the hard take-off scenario.
(2) the idea that intelligent agents will necessarily want to dominate.
Full 20VC podcast coming up tomorrow.
------
“The fact that the minute you turn on a super intelligent AI system, it is going to take over the world. That is ridiculous.”

Tomorrow on 20VC, @ylecun with one of the best 20VCs ever.  
------
MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

abs: https://arxiv.org/abs/2305.07185
paper page: https://huggingface.co/papers/2305.07185…
------
Excellent initiative de Maurice Lévy.
------
Avec YourArt, Maurice Lévy souhaite "faire en sorte" que l'art "soit ouvert à tous".

(Ré)écoutez l'interview du président du conseil de surveillance du groupe Publicis et cofondateur de la plateforme YourArt, invité du 7h50 dans #le7930inter.  https://l.franceinter.fr/gdB
------
Simple facts about guns.
------
With regard to gun violence, Britain looks like most other advanced industrial countries. America, meanwhile, might as well be on another planet.

My take:
------
China  dominates large parts of the global green energy supply chain
------
EV adoption is much faster in Europe than in the US.
------
Read the great piece below by @Noahpinion on the EV revolution   twitter.com/Noahpinion/sta…
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Highlights from a conversation about the future with 
@ylecun
, NYU professor and Meta’s Chief AI Scientist - courtesy of 
@LePoint
’s 
@guillaumgrallet
  and 
@ponsheloise

https://bit.ly/hararilecun
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in 
@LePoint
.

The annihilation of democracy or a new era of Enlightenment?

By 
@guillaumgrallet
 & Héloïse Pons.
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
$ cat >lol.txt
Y2K articles before year 2000:
"OMG, rogue Y2K is going to kill us all!"
Y2K articles after year 2000:
"Hahaha, remember how everyone was so scared of Y2K?  ROFL!"
^D
$ sed 's/Y2K/AGI/' lol.txt | sed 's/2000/20XX/'
------
The Y2K problem was of interest from 1994 to 2000
------
Remember Karl Popper's paradox of tolerance?
"The seemingly self-contradictory idea that in order to maintain a tolerant society, the society must retain the right to be intolerant of intolerance."

Here is an Internet-age corollary:
"In order to maintain a constructive… Show more
------
Wondering how "runaway AI" can run away if it's been "running into walls" for several years now
------
Coming soon.
------
It is coming and better than even I could have hoped for with AI OG @ylecun. 

Stay tuned, absolute  coming on Monday. 
------
ChatGPT has now a big problem.

Google just updated its free competitor, Bard.

Here are 8 things impossible on ChatGPT but that Bard can do (for free):
------
Un article dans 
@LePoint
 où 
@harari_yuval
 et moi débatons de l'impact futur de l'intelligence artificielle sur la science et la société, qu'il soit potentiellement positif ou négatif.
------
Intelligence artificielle : anéantissement de la démocratie ou nouveau siècle des Lumières ?

L’historien @harari_yuval et le chercheur @ylecun lancent le débat.

Par @ponsheloise et @guillaumgrallet 

https://lepoint.fr/sciences-nature/intelligence-artificielle-le-debat-choc-et-inedit-harari-le-cun-11-05-2023-2519779_1924.php…
------
Article de 
@ponsheloise
 et 
@guillaumgrallet
 pour 
@LePoint
------
"The annihilation of democracy or new age of Enlightenment? Best-seller Sapiens author Yuval Noah Harari and Meta head of research Yann LeCun debate."
------
Article by 
@ponsheloise
 and 
@guillaumgrallet
 for 
@LePoint
------
"Most AI researchers do not think that AI poses an existential threat to humanity." — 
@pmddomingos
 (
@uwcse
), replying to 
@geoffreyhinton
's warning and agreeing with 
@ylecun
. At 8/11pm with 
@jeremiecharris
, 
@ghadfield
 (
@UofTLaw
, 
@cifar_news
), and 
@spaikin
 | Producer: 
@ebombicino
------
Version française
------
We can all imagine innumerable scenarios in which a jet airliner flight goes bad.
Yet engineers have found ways to make air transport incredibly safe and reliable.
That requires skills that the air transport doomers don't have.
------
Two common misconceptions about AI: 
(1) the fallacy of the hard take-off scenario.
(2) the idea that intelligent agents will necessarily want to dominate.
Full 20VC podcast coming up tomorrow.
------
“The fact that the minute you turn on a super intelligent AI system, it is going to take over the world. That is ridiculous.”

Tomorrow on 20VC, @ylecun with one of the best 20VCs ever.  
------
MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers

abs: https://arxiv.org/abs/2305.07185
paper page: https://huggingface.co/papers/2305.07185…
------
Excellent initiative de Maurice Lévy.
------
Avec YourArt, Maurice Lévy souhaite "faire en sorte" que l'art "soit ouvert à tous".

(Ré)écoutez l'interview du président du conseil de surveillance du groupe Publicis et cofondateur de la plateforme YourArt, invité du 7h50 dans #le7930inter.  https://l.franceinter.fr/gdB
------
Simple facts about guns.
------
With regard to gun violence, Britain looks like most other advanced industrial countries. America, meanwhile, might as well be on another planet.

My take:
------
China  dominates large parts of the global green energy supply chain
------
EV adoption is much faster in Europe than in the US.
------
Read the great piece below by @Noahpinion on the EV revolution   twitter.com/Noahpinion/sta…
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Highlights from a conversation about the future with 
@ylecun
, NYU professor and Meta’s Chief AI Scientist - courtesy of 
@LePoint
’s 
@guillaumgrallet
  and 
@ponsheloise

https://bit.ly/hararilecun
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in 
@LePoint
.

The annihilation of democracy or a new era of Enlightenment?

By 
@guillaumgrallet
 & Héloïse Pons.
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
$ cat >lol.txt
Y2K articles before year 2000:
"OMG, rogue Y2K is going to kill us all!"
Y2K articles after year 2000:
"Hahaha, remember how everyone was so scared of Y2K?  ROFL!"
^D
$ sed 's/Y2K/AGI/' lol.txt | sed 's/2000/20XX/'
------
The Y2K problem was of interest from 1994 to 2000
------
Remember Karl Popper's paradox of tolerance?
"The seemingly self-contradictory idea that in order to maintain a tolerant society, the society must retain the right to be intolerant of intolerance."

Here is an Internet-age corollary:
"In order to maintain a constructive… Show more
------
Wondering how "runaway AI" can run away if it's been "running into walls" for several years now
------
Coming soon.
------
It is coming and better than even I could have hoped for with AI OG @ylecun. 

Stay tuned, absolute  coming on Monday. 
------
ChatGPT has now a big problem.

Google just updated its free competitor, Bard.

Here are 8 things impossible on ChatGPT but that Bard can do (for free):
------
Un article dans 
@LePoint
 où 
@harari_yuval
 et moi débatons de l'impact futur de l'intelligence artificielle sur la science et la société, qu'il soit potentiellement positif ou négatif.
------
Intelligence artificielle : anéantissement de la démocratie ou nouveau siècle des Lumières ?

L’historien @harari_yuval et le chercheur @ylecun lancent le débat.

Par @ponsheloise et @guillaumgrallet 

https://lepoint.fr/sciences-nature/intelligence-artificielle-le-debat-choc-et-inedit-harari-le-cun-11-05-2023-2519779_1924.php…
------
Article de 
@ponsheloise
 et 
@guillaumgrallet
 pour 
@LePoint
------
"The annihilation of democracy or new age of Enlightenment? Best-seller Sapiens author Yuval Noah Harari and Meta head of research Yann LeCun debate."
------
Article by 
@ponsheloise
 and 
@guillaumgrallet
 for 
@LePoint
------
"Most AI researchers do not think that AI poses an existential threat to humanity." — 
@pmddomingos
 (
@uwcse
), replying to 
@geoffreyhinton
's warning and agreeing with 
@ylecun
. At 8/11pm with 
@jeremiecharris
, 
@ghadfield
 (
@UofTLaw
, 
@cifar_news
), and 
@spaikin
 | Producer: 
@ebombicino
------
Version française
------
Video of my recent talk at the "AI and the Barrier of Meaning" workshop at the Santa Fe Institute.  

Title: "Towards Machines That Can Understand, Reason, & Plan¨ 

The audience was a mix of AI researchers, cognitive scientists, and philosophers.  

Slides here:… Show more
------
English version here.
------
The whole story behind this 2012 paper from my NYU lab at the link below.

It includes the story behind the paper, links to the papers, the letter I sent to 
@SergeBelongie
 and the reviews.

Times have changed.

https://docs.google.com/document/d/1jhXEog1A_PhZIdqXCe9S-F8cLB_yfYjKhMoNwJx1nbc/edit?usp=sharing…
------
The popularity of #DeepLearning in #ComputerVision is only a recent a trend.  A letter before the ImageNet moment from an unhappy author to a program chair lamenting that reviewers are not receptive to deep learning methods.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
Simple facts about guns.
------
With regard to gun violence, Britain looks like most other advanced industrial countries. America, meanwhile, might as well be on another planet.

My take:
------
China  dominates large parts of the global green energy supply chain
------
EV adoption is much faster in Europe than in the US.
------
Read the great piece below by @Noahpinion on the EV revolution   twitter.com/Noahpinion/sta…
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Highlights from a conversation about the future with 
@ylecun
, NYU professor and Meta’s Chief AI Scientist - courtesy of 
@LePoint
’s 
@guillaumgrallet
  and 
@ponsheloise

https://bit.ly/hararilecun
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in 
@LePoint
.

The annihilation of democracy or a new era of Enlightenment?

By 
@guillaumgrallet
 & Héloïse Pons.
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
$ cat >lol.txt
Y2K articles before year 2000:
"OMG, rogue Y2K is going to kill us all!"
Y2K articles after year 2000:
"Hahaha, remember how everyone was so scared of Y2K?  ROFL!"
^D
$ sed 's/Y2K/AGI/' lol.txt | sed 's/2000/20XX/'
------
The Y2K problem was of interest from 1994 to 2000
------
Remember Karl Popper's paradox of tolerance?
"The seemingly self-contradictory idea that in order to maintain a tolerant society, the society must retain the right to be intolerant of intolerance."

Here is an Internet-age corollary:
"In order to maintain a constructive… Show more
------
Wondering how "runaway AI" can run away if it's been "running into walls" for several years now
------
Coming soon.
------
It is coming and better than even I could have hoped for with AI OG @ylecun. 

Stay tuned, absolute  coming on Monday. 
------
ChatGPT has now a big problem.

Google just updated its free competitor, Bard.

Here are 8 things impossible on ChatGPT but that Bard can do (for free):
------
Un article dans 
@LePoint
 où 
@harari_yuval
 et moi débatons de l'impact futur de l'intelligence artificielle sur la science et la société, qu'il soit potentiellement positif ou négatif.
------
Intelligence artificielle : anéantissement de la démocratie ou nouveau siècle des Lumières ?

L’historien @harari_yuval et le chercheur @ylecun lancent le débat.

Par @ponsheloise et @guillaumgrallet 

https://lepoint.fr/sciences-nature/intelligence-artificielle-le-debat-choc-et-inedit-harari-le-cun-11-05-2023-2519779_1924.php…
------
Article de 
@ponsheloise
 et 
@guillaumgrallet
 pour 
@LePoint
------
"The annihilation of democracy or new age of Enlightenment? Best-seller Sapiens author Yuval Noah Harari and Meta head of research Yann LeCun debate."
------
Article by 
@ponsheloise
 and 
@guillaumgrallet
 for 
@LePoint
------
"Most AI researchers do not think that AI poses an existential threat to humanity." — 
@pmddomingos
 (
@uwcse
), replying to 
@geoffreyhinton
's warning and agreeing with 
@ylecun
. At 8/11pm with 
@jeremiecharris
, 
@ghadfield
 (
@UofTLaw
, 
@cifar_news
), and 
@spaikin
 | Producer: 
@ebombicino
------
Version française
------
Video of my recent talk at the "AI and the Barrier of Meaning" workshop at the Santa Fe Institute.  

Title: "Towards Machines That Can Understand, Reason, & Plan¨ 

The audience was a mix of AI researchers, cognitive scientists, and philosophers.  

Slides here:… Show more
------
English version here.
------
The whole story behind this 2012 paper from my NYU lab at the link below.

It includes the story behind the paper, links to the papers, the letter I sent to 
@SergeBelongie
 and the reviews.

Times have changed.

https://docs.google.com/document/d/1jhXEog1A_PhZIdqXCe9S-F8cLB_yfYjKhMoNwJx1nbc/edit?usp=sharing…
------
The popularity of #DeepLearning in #ComputerVision is only a recent a trend.  A letter before the ImageNet moment from an unhappy author to a program chair lamenting that reviewers are not receptive to deep learning methods.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
From someone who has studied how the media report on the tech industry.
------
What's wrong with current AI media coverage? 
These 7 flaws:

https://niritweissblatt.medium.com/7-ways-ai-media-coverage-is-failing-us-61cf287d27fc…


------
A compact recap of a few arguments against AI doomism.
------
1. Since nobody knows how to make an AGI, it is tautological that nobody knows how to make a nonbad AGI.
2. That said, if the architecture of the system is such that its outputs *must* minimize a set of objective functions at *inference* *time* , then the problem is merely to… Show more
------
Self-attention or no self-attention?
That is the question.
------
Pretraining without Attention (https://arxiv.org/abs/2212.10544) - BiGS is alternative to BERT trained on up to 4096 tokens. 

Attention can be overkill. Below shows *every* word-word interaction for every sentence over 23 layers of BiGS (no heads, no n^2).
------
We have enough minerals for EVs.

EVs cut carbon emissions a lot.

Range anxiety isn't going to be a thing.

EVs won't hurt the developing world or supercharge suburban sprawl.

EVs are, in fact, awesome.
------
Highlights from a conversation about the future with 
@ylecun
, NYU professor and Meta’s Chief AI Scientist - courtesy of 
@LePoint
’s 
@guillaumgrallet
  and 
@ponsheloise

https://bit.ly/hararilecun
------
Now in open access in English:
The debate between best-seller Sapiens author Yuval Noah Harari and Meta Chief AI Scientist Yann LeCun in 
@LePoint
.

The annihilation of democracy or a new era of Enlightenment?

By 
@guillaumgrallet
 & Héloïse Pons.
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
$ cat >lol.txt
Y2K articles before year 2000:
"OMG, rogue Y2K is going to kill us all!"
Y2K articles after year 2000:
"Hahaha, remember how everyone was so scared of Y2K?  ROFL!"
^D
$ sed 's/Y2K/AGI/' lol.txt | sed 's/2000/20XX/'
------
The Y2K problem was of interest from 1994 to 2000
------
Remember Karl Popper's paradox of tolerance?
"The seemingly self-contradictory idea that in order to maintain a tolerant society, the society must retain the right to be intolerant of intolerance."

Here is an Internet-age corollary:
"In order to maintain a constructive… Show more
------
Wondering how "runaway AI" can run away if it's been "running into walls" for several years now
------
Coming soon.
------
It is coming and better than even I could have hoped for with AI OG @ylecun. 

Stay tuned, absolute  coming on Monday. 
------
ChatGPT has now a big problem.

Google just updated its free competitor, Bard.

Here are 8 things impossible on ChatGPT but that Bard can do (for free):
------
Un article dans 
@LePoint
 où 
@harari_yuval
 et moi débatons de l'impact futur de l'intelligence artificielle sur la science et la société, qu'il soit potentiellement positif ou négatif.
------
Intelligence artificielle : anéantissement de la démocratie ou nouveau siècle des Lumières ?

L’historien @harari_yuval et le chercheur @ylecun lancent le débat.

Par @ponsheloise et @guillaumgrallet 

https://lepoint.fr/sciences-nature/intelligence-artificielle-le-debat-choc-et-inedit-harari-le-cun-11-05-2023-2519779_1924.php…
------
Article de 
@ponsheloise
 et 
@guillaumgrallet
 pour 
@LePoint
------
"The annihilation of democracy or new age of Enlightenment? Best-seller Sapiens author Yuval Noah Harari and Meta head of research Yann LeCun debate."
------
Article by 
@ponsheloise
 and 
@guillaumgrallet
 for 
@LePoint
------
"Most AI researchers do not think that AI poses an existential threat to humanity." — 
@pmddomingos
 (
@uwcse
), replying to 
@geoffreyhinton
's warning and agreeing with 
@ylecun
. At 8/11pm with 
@jeremiecharris
, 
@ghadfield
 (
@UofTLaw
, 
@cifar_news
), and 
@spaikin
 | Producer: 
@ebombicino
------
Version française
------
Video of my recent talk at the "AI and the Barrier of Meaning" workshop at the Santa Fe Institute.  

Title: "Towards Machines That Can Understand, Reason, & Plan¨ 

The audience was a mix of AI researchers, cognitive scientists, and philosophers.  

Slides here:… Show more
------
English version here.
------
The whole story behind this 2012 paper from my NYU lab at the link below.

It includes the story behind the paper, links to the papers, the letter I sent to 
@SergeBelongie
 and the reviews.

Times have changed.

https://docs.google.com/document/d/1jhXEog1A_PhZIdqXCe9S-F8cLB_yfYjKhMoNwJx1nbc/edit?usp=sharing…
------
The popularity of #DeepLearning in #ComputerVision is only a recent a trend.  A letter before the ImageNet moment from an unhappy author to a program chair lamenting that reviewers are not receptive to deep learning methods.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
From someone who has studied how the media report on the tech industry.
------
What's wrong with current AI media coverage? 
These 7 flaws:

https://niritweissblatt.medium.com/7-ways-ai-media-coverage-is-failing-us-61cf287d27fc…


------
A compact recap of a few arguments against AI doomism.
------
1. Since nobody knows how to make an AGI, it is tautological that nobody knows how to make a nonbad AGI.
2. That said, if the architecture of the system is such that its outputs *must* minimize a set of objective functions at *inference* *time* , then the problem is merely to… Show more
------
Self-attention or no self-attention?
That is the question.
------
Pretraining without Attention (https://arxiv.org/abs/2212.10544) - BiGS is alternative to BERT trained on up to 4096 tokens. 

Attention can be overkill. Below shows *every* word-word interaction for every sentence over 23 layers of BiGS (no heads, no n^2).
------
A List of Things People Blamed on Short Skirts


------
Over the last 24 hours we’ve been in touch with a Twitter engineer who posted an issue with his Pixel phone and WhatsApp. 

We believe this is a bug on Android that mis-attributes information in their Privacy Dashboard and have asked Google to investigate and remediate.
------
WhatsApp has been using the microphone in the background, while I was asleep and since I woke up at 6AM (and that's just a part of the timeline!) What's going on?
------
Behavior of dynamical system depends on the eigenvalues. In 2D it can be classified according to the trace and determinant. https://en.wikipedia.org/wiki/Stability_theory…  https://en.wikipedia.org/wiki/Linear_dynamical_system…
------
Introducing ImageBind by Meta AI: the first AI model capable of binding data from six modalities at once. This breakthrough brings machines one step closer to the human ability to bind together information from many different senses.

More on this new open source work 
------
(1/2)Le 8 mai 1842 se produisit la première grande catastrophe ferroviaire en France :  un train allant de Versailles à Paris dérailla à Meudon, avec un bilan terrible. Un débat s’empara de la presse à propos des risques de ce nouveau mode de locomotion qu’était le chemin de fer.
------
$ cat >lol.txt
Y2K articles before year 2000:
"OMG, rogue Y2K is going to kill us all!"
Y2K articles after year 2000:
"Hahaha, remember how everyone was so scared of Y2K?  ROFL!"
^D
$ sed 's/Y2K/AGI/' lol.txt | sed 's/2000/20XX/'
------
The Y2K problem was of interest from 1994 to 2000
------
Remember Karl Popper's paradox of tolerance?
"The seemingly self-contradictory idea that in order to maintain a tolerant society, the society must retain the right to be intolerant of intolerance."

Here is an Internet-age corollary:
"In order to maintain a constructive… Show more
------
Wondering how "runaway AI" can run away if it's been "running into walls" for several years now
------
Coming soon.
------
It is coming and better than even I could have hoped for with AI OG @ylecun. 

Stay tuned, absolute  coming on Monday. 
------
ChatGPT has now a big problem.

Google just updated its free competitor, Bard.

Here are 8 things impossible on ChatGPT but that Bard can do (for free):
------
Un article dans 
@LePoint
 où 
@harari_yuval
 et moi débatons de l'impact futur de l'intelligence artificielle sur la science et la société, qu'il soit potentiellement positif ou négatif.
------
Intelligence artificielle : anéantissement de la démocratie ou nouveau siècle des Lumières ?

L’historien @harari_yuval et le chercheur @ylecun lancent le débat.

Par @ponsheloise et @guillaumgrallet 

https://lepoint.fr/sciences-nature/intelligence-artificielle-le-debat-choc-et-inedit-harari-le-cun-11-05-2023-2519779_1924.php…
------
Article de 
@ponsheloise
 et 
@guillaumgrallet
 pour 
@LePoint
------
"The annihilation of democracy or new age of Enlightenment? Best-seller Sapiens author Yuval Noah Harari and Meta head of research Yann LeCun debate."
------
Article by 
@ponsheloise
 and 
@guillaumgrallet
 for 
@LePoint
------
"Most AI researchers do not think that AI poses an existential threat to humanity." — 
@pmddomingos
 (
@uwcse
), replying to 
@geoffreyhinton
's warning and agreeing with 
@ylecun
. At 8/11pm with 
@jeremiecharris
, 
@ghadfield
 (
@UofTLaw
, 
@cifar_news
), and 
@spaikin
 | Producer: 
@ebombicino
------
Version française
------
Video of my recent talk at the "AI and the Barrier of Meaning" workshop at the Santa Fe Institute.  

Title: "Towards Machines That Can Understand, Reason, & Plan¨ 

The audience was a mix of AI researchers, cognitive scientists, and philosophers.  

Slides here:… Show more
------
English version here.
------
The whole story behind this 2012 paper from my NYU lab at the link below.

It includes the story behind the paper, links to the papers, the letter I sent to 
@SergeBelongie
 and the reviews.

Times have changed.

https://docs.google.com/document/d/1jhXEog1A_PhZIdqXCe9S-F8cLB_yfYjKhMoNwJx1nbc/edit?usp=sharing…
------
The popularity of #DeepLearning in #ComputerVision is only a recent a trend.  A letter before the ImageNet moment from an unhappy author to a program chair lamenting that reviewers are not receptive to deep learning methods.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
From someone who has studied how the media report on the tech industry.
------
What's wrong with current AI media coverage? 
These 7 flaws:

https://niritweissblatt.medium.com/7-ways-ai-media-coverage-is-failing-us-61cf287d27fc…


------
A compact recap of a few arguments against AI doomism.
------
1. Since nobody knows how to make an AGI, it is tautological that nobody knows how to make a nonbad AGI.
2. That said, if the architecture of the system is such that its outputs *must* minimize a set of objective functions at *inference* *time* , then the problem is merely to… Show more
------
Self-attention or no self-attention?
That is the question.
------
Pretraining without Attention (https://arxiv.org/abs/2212.10544) - BiGS is alternative to BERT trained on up to 4096 tokens. 

Attention can be overkill. Below shows *every* word-word interaction for every sentence over 23 layers of BiGS (no heads, no n^2).
------
A List of Things People Blamed on Short Skirts


------
Over the last 24 hours we’ve been in touch with a Twitter engineer who posted an issue with his Pixel phone and WhatsApp. 

We believe this is a bug on Android that mis-attributes information in their Privacy Dashboard and have asked Google to investigate and remediate.
------
WhatsApp has been using the microphone in the background, while I was asleep and since I woke up at 6AM (and that's just a part of the timeline!) What's going on?
------
Behavior of dynamical system depends on the eigenvalues. In 2D it can be classified according to the trace and determinant. https://en.wikipedia.org/wiki/Stability_theory…  https://en.wikipedia.org/wiki/Linear_dynamical_system…
------
Introducing ImageBind by Meta AI: the first AI model capable of binding data from six modalities at once. This breakthrough brings machines one step closer to the human ability to bind together information from many different senses.

More on this new open source work 
------
IMAGEBIND: One Embedding Space To Bind Them All.

Learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data.

An open source project by Meta-FAIR.

Paper: https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf…
Demo: https://imagebind.metademolab.com
Code:… Show more
------
These are not all he same people but a lot of them are. 

It’s neither compassionate nor cost-effective to treat people this way.
------
A huge policy mistake in one graph.
------
Similar statements can be made for almost all developed country except the US.
------
Just a reminder that Japan has:

* mentally ill people
* Video games
* Porn
* Only 1.5% of the population being Xtian
* Trans people
* Violent movies
* A population of 125.7 million
* 2 people killed by guns all of last year
* 0 Mass shootings

It's the guns, stupid 1/n
------
Un article dans 
@LePoint
 où 
@harari_yuval
 et moi débatons de l'impact futur de l'intelligence artificielle sur la science et la société, qu'il soit potentiellement positif ou négatif.
------
Intelligence artificielle : anéantissement de la démocratie ou nouveau siècle des Lumières ?

L’historien @harari_yuval et le chercheur @ylecun lancent le débat.

Par @ponsheloise et @guillaumgrallet 

https://lepoint.fr/sciences-nature/intelligence-artificielle-le-debat-choc-et-inedit-harari-le-cun-11-05-2023-2519779_1924.php…
------
Article de 
@ponsheloise
 et 
@guillaumgrallet
 pour 
@LePoint
------
"The annihilation of democracy or new age of Enlightenment? Best-seller Sapiens author Yuval Noah Harari and Meta head of research Yann LeCun debate."
------
Article by 
@ponsheloise
 and 
@guillaumgrallet
 for 
@LePoint
------
"Most AI researchers do not think that AI poses an existential threat to humanity." — 
@pmddomingos
 (
@uwcse
), replying to 
@geoffreyhinton
's warning and agreeing with 
@ylecun
. At 8/11pm with 
@jeremiecharris
, 
@ghadfield
 (
@UofTLaw
, 
@cifar_news
), and 
@spaikin
 | Producer: 
@ebombicino
------
Version française
------
Video of my recent talk at the "AI and the Barrier of Meaning" workshop at the Santa Fe Institute.  

Title: "Towards Machines That Can Understand, Reason, & Plan¨ 

The audience was a mix of AI researchers, cognitive scientists, and philosophers.  

Slides here:… Show more
------
English version here.
------
The whole story behind this 2012 paper from my NYU lab at the link below.

It includes the story behind the paper, links to the papers, the letter I sent to 
@SergeBelongie
 and the reviews.

Times have changed.

https://docs.google.com/document/d/1jhXEog1A_PhZIdqXCe9S-F8cLB_yfYjKhMoNwJx1nbc/edit?usp=sharing…
------
The popularity of #DeepLearning in #ComputerVision is only a recent a trend.  A letter before the ImageNet moment from an unhappy author to a program chair lamenting that reviewers are not receptive to deep learning methods.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
From someone who has studied how the media report on the tech industry.
------
What's wrong with current AI media coverage? 
These 7 flaws:

https://niritweissblatt.medium.com/7-ways-ai-media-coverage-is-failing-us-61cf287d27fc…


------
A compact recap of a few arguments against AI doomism.
------
1. Since nobody knows how to make an AGI, it is tautological that nobody knows how to make a nonbad AGI.
2. That said, if the architecture of the system is such that its outputs *must* minimize a set of objective functions at *inference* *time* , then the problem is merely to… Show more
------
Self-attention or no self-attention?
That is the question.
------
Pretraining without Attention (https://arxiv.org/abs/2212.10544) - BiGS is alternative to BERT trained on up to 4096 tokens. 

Attention can be overkill. Below shows *every* word-word interaction for every sentence over 23 layers of BiGS (no heads, no n^2).
------
A List of Things People Blamed on Short Skirts


------
Over the last 24 hours we’ve been in touch with a Twitter engineer who posted an issue with his Pixel phone and WhatsApp. 

We believe this is a bug on Android that mis-attributes information in their Privacy Dashboard and have asked Google to investigate and remediate.
------
WhatsApp has been using the microphone in the background, while I was asleep and since I woke up at 6AM (and that's just a part of the timeline!) What's going on?
------
Behavior of dynamical system depends on the eigenvalues. In 2D it can be classified according to the trace and determinant. https://en.wikipedia.org/wiki/Stability_theory…  https://en.wikipedia.org/wiki/Linear_dynamical_system…
------
Introducing ImageBind by Meta AI: the first AI model capable of binding data from six modalities at once. This breakthrough brings machines one step closer to the human ability to bind together information from many different senses.

More on this new open source work 
------
IMAGEBIND: One Embedding Space To Bind Them All.

Learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data.

An open source project by Meta-FAIR.

Paper: https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf…
Demo: https://imagebind.metademolab.com
Code:… Show more
------
These are not all he same people but a lot of them are. 

It’s neither compassionate nor cost-effective to treat people this way.
------
A huge policy mistake in one graph.
------
Similar statements can be made for almost all developed country except the US.
------
Just a reminder that Japan has:

* mentally ill people
* Video games
* Porn
* Only 1.5% of the population being Xtian
* Trans people
* Violent movies
* A population of 125.7 million
* 2 people killed by guns all of last year
* 0 Mass shootings

It's the guns, stupid 1/n
------
On June 22, 
@tegmark
 and I will be debating the question:
"Be it resolved, AI research and development poses an existential threat."

Max will argue for YES, and I will argue for NO.
------
If some ill-intentioned person can produce an evil AGI, then large groups of well-intentioned, well-funded, and well-organized people can produce AI systems that are specialized in taking down evil AGIs.
Call it the AGI police.

No need to bomb data centers.
------
From the horse's mouth.

AI will cause disruption in the labor market, but will *not* cause mass unemployment.
------
Yann is right. AI isn't about to cause mass unemployment.

But it is about to boost productivity causing disruptions to the labor market, with winners and losers.

Policymakers, managers, technologist and the rest of us  need to manage this transition to create shared prosperity. twitter.com/ylecun/status/…
------
This is not wrong.
There is also AlphaGo, AlphaZero, Pluribus (poker), and Cicero (Diplomacy): massive reasoning *and* learning, but in narrow domains.
------
The phases of AI:
Deep Blue phase: massive reasoning, no learning
Watson phase: mishmash of reasoning and learning
AlexNet: massive learning, no reasoning
ChatGPT phase: massive learning posing as reasoning
------
Duh!
------
Ilya Sutskever unambiguously confirming what we all knew but just wanted to hear admitted:

OpenAI's current closing up is for competitive reasons, not because of safety concerns

https://youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0…
------
Especially relevant now I keep seeing people claiming that LLMs will demolish employment
------
This whole room of people is one Excel spreadsheet. Imagine all the middle-class unemployment Excel created
------
Version française
------
Video of my recent talk at the "AI and the Barrier of Meaning" workshop at the Santa Fe Institute.  

Title: "Towards Machines That Can Understand, Reason, & Plan¨ 

The audience was a mix of AI researchers, cognitive scientists, and philosophers.  

Slides here:… Show more
------
English version here.
------
The whole story behind this 2012 paper from my NYU lab at the link below.

It includes the story behind the paper, links to the papers, the letter I sent to 
@SergeBelongie
 and the reviews.

Times have changed.

https://docs.google.com/document/d/1jhXEog1A_PhZIdqXCe9S-F8cLB_yfYjKhMoNwJx1nbc/edit?usp=sharing…
------
The popularity of #DeepLearning in #ComputerVision is only a recent a trend.  A letter before the ImageNet moment from an unhappy author to a program chair lamenting that reviewers are not receptive to deep learning methods.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
From someone who has studied how the media report on the tech industry.
------
What's wrong with current AI media coverage? 
These 7 flaws:

https://niritweissblatt.medium.com/7-ways-ai-media-coverage-is-failing-us-61cf287d27fc…


------
A compact recap of a few arguments against AI doomism.
------
1. Since nobody knows how to make an AGI, it is tautological that nobody knows how to make a nonbad AGI.
2. That said, if the architecture of the system is such that its outputs *must* minimize a set of objective functions at *inference* *time* , then the problem is merely to… Show more
------
Self-attention or no self-attention?
That is the question.
------
Pretraining without Attention (https://arxiv.org/abs/2212.10544) - BiGS is alternative to BERT trained on up to 4096 tokens. 

Attention can be overkill. Below shows *every* word-word interaction for every sentence over 23 layers of BiGS (no heads, no n^2).
------
A List of Things People Blamed on Short Skirts


------
Over the last 24 hours we’ve been in touch with a Twitter engineer who posted an issue with his Pixel phone and WhatsApp. 

We believe this is a bug on Android that mis-attributes information in their Privacy Dashboard and have asked Google to investigate and remediate.
------
WhatsApp has been using the microphone in the background, while I was asleep and since I woke up at 6AM (and that's just a part of the timeline!) What's going on?
------
Behavior of dynamical system depends on the eigenvalues. In 2D it can be classified according to the trace and determinant. https://en.wikipedia.org/wiki/Stability_theory…  https://en.wikipedia.org/wiki/Linear_dynamical_system…
------
Introducing ImageBind by Meta AI: the first AI model capable of binding data from six modalities at once. This breakthrough brings machines one step closer to the human ability to bind together information from many different senses.

More on this new open source work 
------
IMAGEBIND: One Embedding Space To Bind Them All.

Learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data.

An open source project by Meta-FAIR.

Paper: https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf…
Demo: https://imagebind.metademolab.com
Code:… Show more
------
These are not all he same people but a lot of them are. 

It’s neither compassionate nor cost-effective to treat people this way.
------
A huge policy mistake in one graph.
------
Similar statements can be made for almost all developed country except the US.
------
Just a reminder that Japan has:

* mentally ill people
* Video games
* Porn
* Only 1.5% of the population being Xtian
* Trans people
* Violent movies
* A population of 125.7 million
* 2 people killed by guns all of last year
* 0 Mass shootings

It's the guns, stupid 1/n
------
On June 22, 
@tegmark
 and I will be debating the question:
"Be it resolved, AI research and development poses an existential threat."

Max will argue for YES, and I will argue for NO.
------
If some ill-intentioned person can produce an evil AGI, then large groups of well-intentioned, well-funded, and well-organized people can produce AI systems that are specialized in taking down evil AGIs.
Call it the AGI police.

No need to bomb data centers.
------
From the horse's mouth.

AI will cause disruption in the labor market, but will *not* cause mass unemployment.
------
Yann is right. AI isn't about to cause mass unemployment.

But it is about to boost productivity causing disruptions to the labor market, with winners and losers.

Policymakers, managers, technologist and the rest of us  need to manage this transition to create shared prosperity. twitter.com/ylecun/status/…
------
This is not wrong.
There is also AlphaGo, AlphaZero, Pluribus (poker), and Cicero (Diplomacy): massive reasoning *and* learning, but in narrow domains.
------
The phases of AI:
Deep Blue phase: massive reasoning, no learning
Watson phase: mishmash of reasoning and learning
AlexNet: massive learning, no reasoning
ChatGPT phase: massive learning posing as reasoning
------
Duh!
------
Ilya Sutskever unambiguously confirming what we all knew but just wanted to hear admitted:

OpenAI's current closing up is for competitive reasons, not because of safety concerns

https://youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0…
------
Especially relevant now I keep seeing people claiming that LLMs will demolish employment
------
This whole room of people is one Excel spreadsheet. Imagine all the middle-class unemployment Excel created
------
Kids these days don't fully appreciate the advantages they have over earlier generations. 

If they were students of physics in the 1870s looking to learn electromagnetism, they would have to contend with a set of 20 equations. 

It was character-building stuff as you can see
------
FAIR has been open-sourcing high-impact AI-related stuff for almost 10 years now.
That includes PyTorch & LLaMA.
More to come....
------
My hottest take is, after ages of all of us really not liking @Meta and tons of research dislike towards that platform;

Suddenly, "TO ME", @Meta, and @ylecun seem to having the most level-headed, un-hyped (not talking about accuracy) AI participation in today's discourse.
------
I have asked a number of CEOs now if they had to lay off a pool of workers would aggressive users of AI be in the laid off pool?

No, I hear from everyone. 

I haven’t had a single CEO yet say that the AI worker would go. 

They know that even if the AI did every task perfectly… Show more
------
This article does a nice job of explaining why evidence-based medicine is not the gold standard for public health research. 

Evidence-based medicine was established to reduce reliance on doctor’s “gut-feelings”. 
If we want science, we need epidemiology.
------
Huge revolution underway in AI drug discovery 

  Cumulative investments in AI drug discovery companies up 3x in 4 yrs, reaching $24.6bn in 2022

  Morgan Stanley est. AI drug development could generate additional 50 novel therapies worth $50bn in sales in next 10 yrs
------
From someone who has studied how the media report on the tech industry.
------
What's wrong with current AI media coverage? 
These 7 flaws:

https://niritweissblatt.medium.com/7-ways-ai-media-coverage-is-failing-us-61cf287d27fc…


------
A compact recap of a few arguments against AI doomism.
------
1. Since nobody knows how to make an AGI, it is tautological that nobody knows how to make a nonbad AGI.
2. That said, if the architecture of the system is such that its outputs *must* minimize a set of objective functions at *inference* *time* , then the problem is merely to… Show more
------
Self-attention or no self-attention?
That is the question.
------
Pretraining without Attention (https://arxiv.org/abs/2212.10544) - BiGS is alternative to BERT trained on up to 4096 tokens. 

Attention can be overkill. Below shows *every* word-word interaction for every sentence over 23 layers of BiGS (no heads, no n^2).
------
A List of Things People Blamed on Short Skirts


------
Over the last 24 hours we’ve been in touch with a Twitter engineer who posted an issue with his Pixel phone and WhatsApp. 

We believe this is a bug on Android that mis-attributes information in their Privacy Dashboard and have asked Google to investigate and remediate.
------
WhatsApp has been using the microphone in the background, while I was asleep and since I woke up at 6AM (and that's just a part of the timeline!) What's going on?
------
Behavior of dynamical system depends on the eigenvalues. In 2D it can be classified according to the trace and determinant. https://en.wikipedia.org/wiki/Stability_theory…  https://en.wikipedia.org/wiki/Linear_dynamical_system…
------
Introducing ImageBind by Meta AI: the first AI model capable of binding data from six modalities at once. This breakthrough brings machines one step closer to the human ability to bind together information from many different senses.

More on this new open source work 
------
IMAGEBIND: One Embedding Space To Bind Them All.

Learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data.

An open source project by Meta-FAIR.

Paper: https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf…
Demo: https://imagebind.metademolab.com
Code:… Show more
------
These are not all he same people but a lot of them are. 

It’s neither compassionate nor cost-effective to treat people this way.
------
A huge policy mistake in one graph.
------
Similar statements can be made for almost all developed country except the US.
------
Just a reminder that Japan has:

* mentally ill people
* Video games
* Porn
* Only 1.5% of the population being Xtian
* Trans people
* Violent movies
* A population of 125.7 million
* 2 people killed by guns all of last year
* 0 Mass shootings

It's the guns, stupid 1/n
------
On June 22, 
@tegmark
 and I will be debating the question:
"Be it resolved, AI research and development poses an existential threat."

Max will argue for YES, and I will argue for NO.
------
If some ill-intentioned person can produce an evil AGI, then large groups of well-intentioned, well-funded, and well-organized people can produce AI systems that are specialized in taking down evil AGIs.
Call it the AGI police.

No need to bomb data centers.
------
From the horse's mouth.

AI will cause disruption in the labor market, but will *not* cause mass unemployment.
------
Yann is right. AI isn't about to cause mass unemployment.

But it is about to boost productivity causing disruptions to the labor market, with winners and losers.

Policymakers, managers, technologist and the rest of us  need to manage this transition to create shared prosperity. twitter.com/ylecun/status/…
------
This is not wrong.
There is also AlphaGo, AlphaZero, Pluribus (poker), and Cicero (Diplomacy): massive reasoning *and* learning, but in narrow domains.
------
The phases of AI:
Deep Blue phase: massive reasoning, no learning
Watson phase: mishmash of reasoning and learning
AlexNet: massive learning, no reasoning
ChatGPT phase: massive learning posing as reasoning
------
Duh!
------
Ilya Sutskever unambiguously confirming what we all knew but just wanted to hear admitted:

OpenAI's current closing up is for competitive reasons, not because of safety concerns

https://youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0…
------
Especially relevant now I keep seeing people claiming that LLMs will demolish employment
------
This whole room of people is one Excel spreadsheet. Imagine all the middle-class unemployment Excel created
------
Kids these days don't fully appreciate the advantages they have over earlier generations. 

If they were students of physics in the 1870s looking to learn electromagnetism, they would have to contend with a set of 20 equations. 

It was character-building stuff as you can see
------
FAIR has been open-sourcing high-impact AI-related stuff for almost 10 years now.
That includes PyTorch & LLaMA.
More to come....
------
My hottest take is, after ages of all of us really not liking @Meta and tons of research dislike towards that platform;

Suddenly, "TO ME", @Meta, and @ylecun seem to having the most level-headed, un-hyped (not talking about accuracy) AI participation in today's discourse.
------
I have asked a number of CEOs now if they had to lay off a pool of workers would aggressive users of AI be in the laid off pool?

No, I hear from everyone. 

I haven’t had a single CEO yet say that the AI worker would go. 

They know that even if the AI did every task perfectly… Show more
------
This article does a nice job of explaining why evidence-based medicine is not the gold standard for public health research. 

Evidence-based medicine was established to reduce reliance on doctor’s “gut-feelings”. 
If we want science, we need epidemiology.
------
In many animal species, evolution encodes objectives.
It is up to the individuals to figure out the behaviors that optimize these objectives.

Encoding objectives rather than behaviors is much simpler, more efficient, and more adaptive way for evolution to specify complex… Show more
------
Remember when naïve hackers were called script kiddies?

What would be the equivalent designation for folks who think they are AI experts after a couple hours of LLM prompt engineering?

Prompt kiddies?
------
I love and admire Geoff, but we knew then, and we know now, that he was wrong.
AI *is* taking over radiology (albeit slowly) but he was wrong to say that we should stop training radiologists.
AI is transforming the profession, not replacing it.
------
Six years ago, Geoffrey Hinton asserted that AI would take over radiology within five years, suggesting we cease training radiologists. 

Was he correct?

The situation is more complex than simply being right or wrong. While AI has surpassed radiologists in certain diagnostic… Show more
------
"LLaMA moment"
is the new AI epiphany.
------
"Llama moment" is now the new term for "Cambrian explosion of low-budget models finetuned on an expensive base model". 

Prediction: multimodal models will hit a Llama moment soon. GPT-4's promised vision API is slow to roll out, and won't be open. OSS has superhuman speed. twitter.com/karpathy/statu…
------
AI hype is ridiculous in all directions.
As in:
- LLMs have superhuman intelligence
- LLMs are useless parrots
- LLM hallucinations will destroy society
- scaling is all you need
- deep learning has hit a wall
- AI doesn't exist and never will 
- AI is going to kill us all
------
Lots of exaggeration about AI lately.

The hype is that LLMs have anything to do with intelligence.
The FUD is that AIs will enslave us.

I like this cartoon in the New Yorker because it suggests the ridiculousness of both memes.
------
Over the last 24 hours we’ve been in touch with a Twitter engineer who posted an issue with his Pixel phone and WhatsApp. 

We believe this is a bug on Android that mis-attributes information in their Privacy Dashboard and have asked Google to investigate and remediate.
------
WhatsApp has been using the microphone in the background, while I was asleep and since I woke up at 6AM (and that's just a part of the timeline!) What's going on?
------
Behavior of dynamical system depends on the eigenvalues. In 2D it can be classified according to the trace and determinant. https://en.wikipedia.org/wiki/Stability_theory…  https://en.wikipedia.org/wiki/Linear_dynamical_system…
------
Introducing ImageBind by Meta AI: the first AI model capable of binding data from six modalities at once. This breakthrough brings machines one step closer to the human ability to bind together information from many different senses.

More on this new open source work 
------
IMAGEBIND: One Embedding Space To Bind Them All.

Learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data.

An open source project by Meta-FAIR.

Paper: https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf…
Demo: https://imagebind.metademolab.com
Code:… Show more
------
These are not all he same people but a lot of them are. 

It’s neither compassionate nor cost-effective to treat people this way.
------
A huge policy mistake in one graph.
------
Similar statements can be made for almost all developed country except the US.
------
Just a reminder that Japan has:

* mentally ill people
* Video games
* Porn
* Only 1.5% of the population being Xtian
* Trans people
* Violent movies
* A population of 125.7 million
* 2 people killed by guns all of last year
* 0 Mass shootings

It's the guns, stupid 1/n
------
On June 22, 
@tegmark
 and I will be debating the question:
"Be it resolved, AI research and development poses an existential threat."

Max will argue for YES, and I will argue for NO.
------
If some ill-intentioned person can produce an evil AGI, then large groups of well-intentioned, well-funded, and well-organized people can produce AI systems that are specialized in taking down evil AGIs.
Call it the AGI police.

No need to bomb data centers.
------
From the horse's mouth.

AI will cause disruption in the labor market, but will *not* cause mass unemployment.
------
Yann is right. AI isn't about to cause mass unemployment.

But it is about to boost productivity causing disruptions to the labor market, with winners and losers.

Policymakers, managers, technologist and the rest of us  need to manage this transition to create shared prosperity. twitter.com/ylecun/status/…
------
This is not wrong.
There is also AlphaGo, AlphaZero, Pluribus (poker), and Cicero (Diplomacy): massive reasoning *and* learning, but in narrow domains.
------
The phases of AI:
Deep Blue phase: massive reasoning, no learning
Watson phase: mishmash of reasoning and learning
AlexNet: massive learning, no reasoning
ChatGPT phase: massive learning posing as reasoning
------
Duh!
------
Ilya Sutskever unambiguously confirming what we all knew but just wanted to hear admitted:

OpenAI's current closing up is for competitive reasons, not because of safety concerns

https://youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0…
------
Especially relevant now I keep seeing people claiming that LLMs will demolish employment
------
This whole room of people is one Excel spreadsheet. Imagine all the middle-class unemployment Excel created
------
Kids these days don't fully appreciate the advantages they have over earlier generations. 

If they were students of physics in the 1870s looking to learn electromagnetism, they would have to contend with a set of 20 equations. 

It was character-building stuff as you can see
------
FAIR has been open-sourcing high-impact AI-related stuff for almost 10 years now.
That includes PyTorch & LLaMA.
More to come....
------
My hottest take is, after ages of all of us really not liking @Meta and tons of research dislike towards that platform;

Suddenly, "TO ME", @Meta, and @ylecun seem to having the most level-headed, un-hyped (not talking about accuracy) AI participation in today's discourse.
------
I have asked a number of CEOs now if they had to lay off a pool of workers would aggressive users of AI be in the laid off pool?

No, I hear from everyone. 

I haven’t had a single CEO yet say that the AI worker would go. 

They know that even if the AI did every task perfectly… Show more
------
This article does a nice job of explaining why evidence-based medicine is not the gold standard for public health research. 

Evidence-based medicine was established to reduce reliance on doctor’s “gut-feelings”. 
If we want science, we need epidemiology.
------
In many animal species, evolution encodes objectives.
It is up to the individuals to figure out the behaviors that optimize these objectives.

Encoding objectives rather than behaviors is much simpler, more efficient, and more adaptive way for evolution to specify complex… Show more
------
Remember when naïve hackers were called script kiddies?

What would be the equivalent designation for folks who think they are AI experts after a couple hours of LLM prompt engineering?

Prompt kiddies?
------
I love and admire Geoff, but we knew then, and we know now, that he was wrong.
AI *is* taking over radiology (albeit slowly) but he was wrong to say that we should stop training radiologists.
AI is transforming the profession, not replacing it.
------
Six years ago, Geoffrey Hinton asserted that AI would take over radiology within five years, suggesting we cease training radiologists. 

Was he correct?

The situation is more complex than simply being right or wrong. While AI has surpassed radiologists in certain diagnostic… Show more
------
"LLaMA moment"
is the new AI epiphany.
------
"Llama moment" is now the new term for "Cambrian explosion of low-budget models finetuned on an expensive base model". 

Prediction: multimodal models will hit a Llama moment soon. GPT-4's promised vision API is slow to roll out, and won't be open. OSS has superhuman speed. twitter.com/karpathy/statu…
------
AI hype is ridiculous in all directions.
As in:
- LLMs have superhuman intelligence
- LLMs are useless parrots
- LLM hallucinations will destroy society
- scaling is all you need
- deep learning has hit a wall
- AI doesn't exist and never will 
- AI is going to kill us all
------
Lots of exaggeration about AI lately.

The hype is that LLMs have anything to do with intelligence.
The FUD is that AIs will enslave us.

I like this cartoon in the New Yorker because it suggests the ridiculousness of both memes.
------
Yes
------
Oops haven't tweeted too much recently; I'm mostly watching with interest the open source LLM ecosystem experiencing early signs of a cambrian explosion. Roughly speaking the story as of now:

1. Pretraining LLM base models remains very expensive. Think: supercomputer + months.… Show more
------
If you are worried about "AI causing mass unemployment" listen to economists who have studied the impact of technological revolutions on the labor market, like 
@erikbryn
 .

DO NOT listen to computer scientists who are concerned by the social consequences of their work.
------
A fireside chat and Q&A about the present and future of AI, moderated by philosopher Frédérique de Vignemont and hosted by NYU-Paris.
------
A common fallacy about intelligence:
"A humans who is X is also Y, hence AI that is X must also be Y."
With (X,Y) in { ( intelligent, dominant), (fluent writer, intelligent), (polyglot, intelligent), (chess champion, intelligent), (bar exam wiz, good lawyer), ....}
------
IMAGEBIND: One Embedding Space To Bind Them All.

Learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data.

An open source project by Meta-FAIR.

Paper: https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf…
Demo: https://imagebind.metademolab.com
Code:… Show more
------
These are not all he same people but a lot of them are. 

It’s neither compassionate nor cost-effective to treat people this way.
------
A huge policy mistake in one graph.
------
Similar statements can be made for almost all developed country except the US.
------
Just a reminder that Japan has:

* mentally ill people
* Video games
* Porn
* Only 1.5% of the population being Xtian
* Trans people
* Violent movies
* A population of 125.7 million
* 2 people killed by guns all of last year
* 0 Mass shootings

It's the guns, stupid 1/n
------
On June 22, 
@tegmark
 and I will be debating the question:
"Be it resolved, AI research and development poses an existential threat."

Max will argue for YES, and I will argue for NO.
------
If some ill-intentioned person can produce an evil AGI, then large groups of well-intentioned, well-funded, and well-organized people can produce AI systems that are specialized in taking down evil AGIs.
Call it the AGI police.

No need to bomb data centers.
------
From the horse's mouth.

AI will cause disruption in the labor market, but will *not* cause mass unemployment.
------
Yann is right. AI isn't about to cause mass unemployment.

But it is about to boost productivity causing disruptions to the labor market, with winners and losers.

Policymakers, managers, technologist and the rest of us  need to manage this transition to create shared prosperity. twitter.com/ylecun/status/…
------
This is not wrong.
There is also AlphaGo, AlphaZero, Pluribus (poker), and Cicero (Diplomacy): massive reasoning *and* learning, but in narrow domains.
------
The phases of AI:
Deep Blue phase: massive reasoning, no learning
Watson phase: mishmash of reasoning and learning
AlexNet: massive learning, no reasoning
ChatGPT phase: massive learning posing as reasoning
------
Duh!
------
Ilya Sutskever unambiguously confirming what we all knew but just wanted to hear admitted:

OpenAI's current closing up is for competitive reasons, not because of safety concerns

https://youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0…
------
Especially relevant now I keep seeing people claiming that LLMs will demolish employment
------
This whole room of people is one Excel spreadsheet. Imagine all the middle-class unemployment Excel created
------
Kids these days don't fully appreciate the advantages they have over earlier generations. 

If they were students of physics in the 1870s looking to learn electromagnetism, they would have to contend with a set of 20 equations. 

It was character-building stuff as you can see
------
FAIR has been open-sourcing high-impact AI-related stuff for almost 10 years now.
That includes PyTorch & LLaMA.
More to come....
------
My hottest take is, after ages of all of us really not liking @Meta and tons of research dislike towards that platform;

Suddenly, "TO ME", @Meta, and @ylecun seem to having the most level-headed, un-hyped (not talking about accuracy) AI participation in today's discourse.
------
I have asked a number of CEOs now if they had to lay off a pool of workers would aggressive users of AI be in the laid off pool?

No, I hear from everyone. 

I haven’t had a single CEO yet say that the AI worker would go. 

They know that even if the AI did every task perfectly… Show more
------
This article does a nice job of explaining why evidence-based medicine is not the gold standard for public health research. 

Evidence-based medicine was established to reduce reliance on doctor’s “gut-feelings”. 
If we want science, we need epidemiology.
------
In many animal species, evolution encodes objectives.
It is up to the individuals to figure out the behaviors that optimize these objectives.

Encoding objectives rather than behaviors is much simpler, more efficient, and more adaptive way for evolution to specify complex… Show more
------
Remember when naïve hackers were called script kiddies?

What would be the equivalent designation for folks who think they are AI experts after a couple hours of LLM prompt engineering?

Prompt kiddies?
------
I love and admire Geoff, but we knew then, and we know now, that he was wrong.
AI *is* taking over radiology (albeit slowly) but he was wrong to say that we should stop training radiologists.
AI is transforming the profession, not replacing it.
------
Six years ago, Geoffrey Hinton asserted that AI would take over radiology within five years, suggesting we cease training radiologists. 

Was he correct?

The situation is more complex than simply being right or wrong. While AI has surpassed radiologists in certain diagnostic… Show more
------
"LLaMA moment"
is the new AI epiphany.
------
"Llama moment" is now the new term for "Cambrian explosion of low-budget models finetuned on an expensive base model". 

Prediction: multimodal models will hit a Llama moment soon. GPT-4's promised vision API is slow to roll out, and won't be open. OSS has superhuman speed. twitter.com/karpathy/statu…
------
AI hype is ridiculous in all directions.
As in:
- LLMs have superhuman intelligence
- LLMs are useless parrots
- LLM hallucinations will destroy society
- scaling is all you need
- deep learning has hit a wall
- AI doesn't exist and never will 
- AI is going to kill us all
------
Lots of exaggeration about AI lately.

The hype is that LLMs have anything to do with intelligence.
The FUD is that AIs will enslave us.

I like this cartoon in the New Yorker because it suggests the ridiculousness of both memes.
------
Yes
------
Oops haven't tweeted too much recently; I'm mostly watching with interest the open source LLM ecosystem experiencing early signs of a cambrian explosion. Roughly speaking the story as of now:

1. Pretraining LLM base models remains very expensive. Think: supercomputer + months.… Show more
------
If you are worried about "AI causing mass unemployment" listen to economists who have studied the impact of technological revolutions on the labor market, like 
@erikbryn
 .

DO NOT listen to computer scientists who are concerned by the social consequences of their work.
------
A fireside chat and Q&A about the present and future of AI, moderated by philosopher Frédérique de Vignemont and hosted by NYU-Paris.
------
A common fallacy about intelligence:
"A humans who is X is also Y, hence AI that is X must also be Y."
With (X,Y) in { ( intelligent, dominant), (fluent writer, intelligent), (polyglot, intelligent), (chess champion, intelligent), (bar exam wiz, good lawyer), ....}
------
Could a technique for mapping planetary craters developed here be used in future space missions? Scientists have used the new 
@MetaAI
 Segment Anything Model to better understand planetary surfaces & create new possibilities in space exploration https://fal.cn/3xRmJ 
@ylecun
------
A comparison of open 7B LLMs
------
Curious how the RedPajama effort by @togethercompute is progressing and where it stacks up? We evaluated the 7B model they just released 2h ago! Here is how it looks 800B tokens in. (Eval took 16 minutes on 32 A100s.)  twitter.com/togethercomput…
------
Astonished that a scientist would attract so much attention.
Thank you, everyone.
------
Self-supervised learning is a key ingredient in recent AI breakthroughs. To lower barriers + help democratize access to this research, we compiled The SSL Cookbook: a practical guide for researchers navigating the intricacies of this research space. 
------
I literally have the best job in the world. 

Develop a passion for a topic. 

Speak to the worlds leading experts and OGs in the space. 

Share their knowledge with the world. 

Episode coming with 
@ylecun
 is incredible.  
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
On June 22, 
@tegmark
 and I will be debating the question:
"Be it resolved, AI research and development poses an existential threat."

Max will argue for YES, and I will argue for NO.
------
If some ill-intentioned person can produce an evil AGI, then large groups of well-intentioned, well-funded, and well-organized people can produce AI systems that are specialized in taking down evil AGIs.
Call it the AGI police.

No need to bomb data centers.
------
From the horse's mouth.

AI will cause disruption in the labor market, but will *not* cause mass unemployment.
------
Yann is right. AI isn't about to cause mass unemployment.

But it is about to boost productivity causing disruptions to the labor market, with winners and losers.

Policymakers, managers, technologist and the rest of us  need to manage this transition to create shared prosperity. twitter.com/ylecun/status/…
------
This is not wrong.
There is also AlphaGo, AlphaZero, Pluribus (poker), and Cicero (Diplomacy): massive reasoning *and* learning, but in narrow domains.
------
The phases of AI:
Deep Blue phase: massive reasoning, no learning
Watson phase: mishmash of reasoning and learning
AlexNet: massive learning, no reasoning
ChatGPT phase: massive learning posing as reasoning
------
Duh!
------
Ilya Sutskever unambiguously confirming what we all knew but just wanted to hear admitted:

OpenAI's current closing up is for competitive reasons, not because of safety concerns

https://youtube.com/clip/UgkxNziUvKPwXiOfjWO_WJIzA7OwMcXOphN0…
------
Especially relevant now I keep seeing people claiming that LLMs will demolish employment
------
This whole room of people is one Excel spreadsheet. Imagine all the middle-class unemployment Excel created
------
Kids these days don't fully appreciate the advantages they have over earlier generations. 

If they were students of physics in the 1870s looking to learn electromagnetism, they would have to contend with a set of 20 equations. 

It was character-building stuff as you can see
------
FAIR has been open-sourcing high-impact AI-related stuff for almost 10 years now.
That includes PyTorch & LLaMA.
More to come....
------
My hottest take is, after ages of all of us really not liking @Meta and tons of research dislike towards that platform;

Suddenly, "TO ME", @Meta, and @ylecun seem to having the most level-headed, un-hyped (not talking about accuracy) AI participation in today's discourse.
------
I have asked a number of CEOs now if they had to lay off a pool of workers would aggressive users of AI be in the laid off pool?

No, I hear from everyone. 

I haven’t had a single CEO yet say that the AI worker would go. 

They know that even if the AI did every task perfectly… Show more
------
This article does a nice job of explaining why evidence-based medicine is not the gold standard for public health research. 

Evidence-based medicine was established to reduce reliance on doctor’s “gut-feelings”. 
If we want science, we need epidemiology.
------
In many animal species, evolution encodes objectives.
It is up to the individuals to figure out the behaviors that optimize these objectives.

Encoding objectives rather than behaviors is much simpler, more efficient, and more adaptive way for evolution to specify complex… Show more
------
Remember when naïve hackers were called script kiddies?

What would be the equivalent designation for folks who think they are AI experts after a couple hours of LLM prompt engineering?

Prompt kiddies?
------
I love and admire Geoff, but we knew then, and we know now, that he was wrong.
AI *is* taking over radiology (albeit slowly) but he was wrong to say that we should stop training radiologists.
AI is transforming the profession, not replacing it.
------
Six years ago, Geoffrey Hinton asserted that AI would take over radiology within five years, suggesting we cease training radiologists. 

Was he correct?

The situation is more complex than simply being right or wrong. While AI has surpassed radiologists in certain diagnostic… Show more
------
"LLaMA moment"
is the new AI epiphany.
------
"Llama moment" is now the new term for "Cambrian explosion of low-budget models finetuned on an expensive base model". 

Prediction: multimodal models will hit a Llama moment soon. GPT-4's promised vision API is slow to roll out, and won't be open. OSS has superhuman speed. twitter.com/karpathy/statu…
------
AI hype is ridiculous in all directions.
As in:
- LLMs have superhuman intelligence
- LLMs are useless parrots
- LLM hallucinations will destroy society
- scaling is all you need
- deep learning has hit a wall
- AI doesn't exist and never will 
- AI is going to kill us all
------
Lots of exaggeration about AI lately.

The hype is that LLMs have anything to do with intelligence.
The FUD is that AIs will enslave us.

I like this cartoon in the New Yorker because it suggests the ridiculousness of both memes.
------
Yes
------
Oops haven't tweeted too much recently; I'm mostly watching with interest the open source LLM ecosystem experiencing early signs of a cambrian explosion. Roughly speaking the story as of now:

1. Pretraining LLM base models remains very expensive. Think: supercomputer + months.… Show more
------
If you are worried about "AI causing mass unemployment" listen to economists who have studied the impact of technological revolutions on the labor market, like 
@erikbryn
 .

DO NOT listen to computer scientists who are concerned by the social consequences of their work.
------
A fireside chat and Q&A about the present and future of AI, moderated by philosopher Frédérique de Vignemont and hosted by NYU-Paris.
------
A common fallacy about intelligence:
"A humans who is X is also Y, hence AI that is X must also be Y."
With (X,Y) in { ( intelligent, dominant), (fluent writer, intelligent), (polyglot, intelligent), (chess champion, intelligent), (bar exam wiz, good lawyer), ....}
------
Could a technique for mapping planetary craters developed here be used in future space missions? Scientists have used the new 
@MetaAI
 Segment Anything Model to better understand planetary surfaces & create new possibilities in space exploration https://fal.cn/3xRmJ 
@ylecun
------
A comparison of open 7B LLMs
------
Curious how the RedPajama effort by @togethercompute is progressing and where it stacks up? We evaluated the 7B model they just released 2h ago! Here is how it looks 800B tokens in. (Eval took 16 minutes on 32 A100s.)  twitter.com/togethercomput…
------
Astonished that a scientist would attract so much attention.
Thank you, everyone.
------
Self-supervised learning is a key ingredient in recent AI breakthroughs. To lower barriers + help democratize access to this research, we compiled The SSL Cookbook: a practical guide for researchers navigating the intricacies of this research space. 
------
I literally have the best job in the world. 

Develop a passion for a topic. 

Speak to the worlds leading experts and OGs in the space. 

Share their knowledge with the world. 

Episode coming with 
@ylecun
 is incredible.  
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
Open source LLMs popping up everywhere.
This is the way.
------
Today is the Llama moment for coding! 

StarCoder-15B reaches 40.8% on HumanEval benchmark, beating the 30x bigger PaLM.

Coding holds a very special place in NLP. Most software in the world has AI-friendly APIs. LLMs good at coding will master the digital tools, greatly… Show more
------
Some regions need to change their modus operandi when it comes to the practice of scientific research and the incentive mechanisms.
------
“The Geography of Retracted Papers.”
https://dapp.orvium.io/deposits/6442fee5c93d17c257de17d2/view…
------
On the usefulness of risk-benefit analysis.
------
Optimists vs Pessimists
------
Kids these days don't fully appreciate the advantages they have over earlier generations. 

If they were students of physics in the 1870s looking to learn electromagnetism, they would have to contend with a set of 20 equations. 

It was character-building stuff as you can see
------
FAIR has been open-sourcing high-impact AI-related stuff for almost 10 years now.
That includes PyTorch & LLaMA.
More to come....
------
My hottest take is, after ages of all of us really not liking @Meta and tons of research dislike towards that platform;

Suddenly, "TO ME", @Meta, and @ylecun seem to having the most level-headed, un-hyped (not talking about accuracy) AI participation in today's discourse.
------
I have asked a number of CEOs now if they had to lay off a pool of workers would aggressive users of AI be in the laid off pool?

No, I hear from everyone. 

I haven’t had a single CEO yet say that the AI worker would go. 

They know that even if the AI did every task perfectly… Show more
------
This article does a nice job of explaining why evidence-based medicine is not the gold standard for public health research. 

Evidence-based medicine was established to reduce reliance on doctor’s “gut-feelings”. 
If we want science, we need epidemiology.
------
In many animal species, evolution encodes objectives.
It is up to the individuals to figure out the behaviors that optimize these objectives.

Encoding objectives rather than behaviors is much simpler, more efficient, and more adaptive way for evolution to specify complex… Show more
------
Remember when naïve hackers were called script kiddies?

What would be the equivalent designation for folks who think they are AI experts after a couple hours of LLM prompt engineering?

Prompt kiddies?
------
I love and admire Geoff, but we knew then, and we know now, that he was wrong.
AI *is* taking over radiology (albeit slowly) but he was wrong to say that we should stop training radiologists.
AI is transforming the profession, not replacing it.
------
Six years ago, Geoffrey Hinton asserted that AI would take over radiology within five years, suggesting we cease training radiologists. 

Was he correct?

The situation is more complex than simply being right or wrong. While AI has surpassed radiologists in certain diagnostic… Show more
------
"LLaMA moment"
is the new AI epiphany.
------
"Llama moment" is now the new term for "Cambrian explosion of low-budget models finetuned on an expensive base model". 

Prediction: multimodal models will hit a Llama moment soon. GPT-4's promised vision API is slow to roll out, and won't be open. OSS has superhuman speed. twitter.com/karpathy/statu…
------
AI hype is ridiculous in all directions.
As in:
- LLMs have superhuman intelligence
- LLMs are useless parrots
- LLM hallucinations will destroy society
- scaling is all you need
- deep learning has hit a wall
- AI doesn't exist and never will 
- AI is going to kill us all
------
Lots of exaggeration about AI lately.

The hype is that LLMs have anything to do with intelligence.
The FUD is that AIs will enslave us.

I like this cartoon in the New Yorker because it suggests the ridiculousness of both memes.
------
Yes
------
Oops haven't tweeted too much recently; I'm mostly watching with interest the open source LLM ecosystem experiencing early signs of a cambrian explosion. Roughly speaking the story as of now:

1. Pretraining LLM base models remains very expensive. Think: supercomputer + months.… Show more
------
If you are worried about "AI causing mass unemployment" listen to economists who have studied the impact of technological revolutions on the labor market, like 
@erikbryn
 .

DO NOT listen to computer scientists who are concerned by the social consequences of their work.
------
A fireside chat and Q&A about the present and future of AI, moderated by philosopher Frédérique de Vignemont and hosted by NYU-Paris.
------
A common fallacy about intelligence:
"A humans who is X is also Y, hence AI that is X must also be Y."
With (X,Y) in { ( intelligent, dominant), (fluent writer, intelligent), (polyglot, intelligent), (chess champion, intelligent), (bar exam wiz, good lawyer), ....}
------
Could a technique for mapping planetary craters developed here be used in future space missions? Scientists have used the new 
@MetaAI
 Segment Anything Model to better understand planetary surfaces & create new possibilities in space exploration https://fal.cn/3xRmJ 
@ylecun
------
A comparison of open 7B LLMs
------
Curious how the RedPajama effort by @togethercompute is progressing and where it stacks up? We evaluated the 7B model they just released 2h ago! Here is how it looks 800B tokens in. (Eval took 16 minutes on 32 A100s.)  twitter.com/togethercomput…
------
Astonished that a scientist would attract so much attention.
Thank you, everyone.
------
Self-supervised learning is a key ingredient in recent AI breakthroughs. To lower barriers + help democratize access to this research, we compiled The SSL Cookbook: a practical guide for researchers navigating the intricacies of this research space. 
------
I literally have the best job in the world. 

Develop a passion for a topic. 

Speak to the worlds leading experts and OGs in the space. 

Share their knowledge with the world. 

Episode coming with 
@ylecun
 is incredible.  
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
Open source LLMs popping up everywhere.
This is the way.
------
Today is the Llama moment for coding! 

StarCoder-15B reaches 40.8% on HumanEval benchmark, beating the 30x bigger PaLM.

Coding holds a very special place in NLP. Most software in the world has AI-friendly APIs. LLMs good at coding will master the digital tools, greatly… Show more
------
Some regions need to change their modus operandi when it comes to the practice of scientific research and the incentive mechanisms.
------
“The Geography of Retracted Papers.”
https://dapp.orvium.io/deposits/6442fee5c93d17c257de17d2/view…
------
On the usefulness of risk-benefit analysis.
------
Optimists vs Pessimists
------
Best AI advice I can give you right now:

Learn how to train LLMs now.

Closed source models are winning now, but small, task-specific, open-source models are the future.
------
This is absolutely correct.
The most common reaction by AI researchers to these prophecies of doom is face palming.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Our neocortex is entirely controlled by our lizard brain.
Our future superhuman exocortex will be controlled by our neocortex.

We can design AI to have superhuman intelligence *and* be submissive. 
For an entity to control another, it has to *want* to take control.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Note to picky neuroscientists: replace "lizard brain" by "basal ganglia".
------
We can design AI systems to be both super-intelligent *and* submissive to humans.
I always wonder why people just assume that intelligent entities will necessarily want to dominate.
That's just plain false, even within the human species.
------
Good political, business, and academic leaders surround themselves with staff whose members are often smarter than themselves.

That's a common counter-example of 
@geoffreyhinton
's claim that more intelligent things almost always control less intelligent things.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
In many animal species, evolution encodes objectives.
It is up to the individuals to figure out the behaviors that optimize these objectives.

Encoding objectives rather than behaviors is much simpler, more efficient, and more adaptive way for evolution to specify complex… Show more
------
Remember when naïve hackers were called script kiddies?

What would be the equivalent designation for folks who think they are AI experts after a couple hours of LLM prompt engineering?

Prompt kiddies?
------
I love and admire Geoff, but we knew then, and we know now, that he was wrong.
AI *is* taking over radiology (albeit slowly) but he was wrong to say that we should stop training radiologists.
AI is transforming the profession, not replacing it.
------
Six years ago, Geoffrey Hinton asserted that AI would take over radiology within five years, suggesting we cease training radiologists. 

Was he correct?

The situation is more complex than simply being right or wrong. While AI has surpassed radiologists in certain diagnostic… Show more
------
"LLaMA moment"
is the new AI epiphany.
------
"Llama moment" is now the new term for "Cambrian explosion of low-budget models finetuned on an expensive base model". 

Prediction: multimodal models will hit a Llama moment soon. GPT-4's promised vision API is slow to roll out, and won't be open. OSS has superhuman speed. twitter.com/karpathy/statu…
------
AI hype is ridiculous in all directions.
As in:
- LLMs have superhuman intelligence
- LLMs are useless parrots
- LLM hallucinations will destroy society
- scaling is all you need
- deep learning has hit a wall
- AI doesn't exist and never will 
- AI is going to kill us all
------
Lots of exaggeration about AI lately.

The hype is that LLMs have anything to do with intelligence.
The FUD is that AIs will enslave us.

I like this cartoon in the New Yorker because it suggests the ridiculousness of both memes.
------
Yes
------
Oops haven't tweeted too much recently; I'm mostly watching with interest the open source LLM ecosystem experiencing early signs of a cambrian explosion. Roughly speaking the story as of now:

1. Pretraining LLM base models remains very expensive. Think: supercomputer + months.… Show more
------
If you are worried about "AI causing mass unemployment" listen to economists who have studied the impact of technological revolutions on the labor market, like 
@erikbryn
 .

DO NOT listen to computer scientists who are concerned by the social consequences of their work.
------
A fireside chat and Q&A about the present and future of AI, moderated by philosopher Frédérique de Vignemont and hosted by NYU-Paris.
------
A common fallacy about intelligence:
"A humans who is X is also Y, hence AI that is X must also be Y."
With (X,Y) in { ( intelligent, dominant), (fluent writer, intelligent), (polyglot, intelligent), (chess champion, intelligent), (bar exam wiz, good lawyer), ....}
------
Could a technique for mapping planetary craters developed here be used in future space missions? Scientists have used the new 
@MetaAI
 Segment Anything Model to better understand planetary surfaces & create new possibilities in space exploration https://fal.cn/3xRmJ 
@ylecun
------
A comparison of open 7B LLMs
------
Curious how the RedPajama effort by @togethercompute is progressing and where it stacks up? We evaluated the 7B model they just released 2h ago! Here is how it looks 800B tokens in. (Eval took 16 minutes on 32 A100s.)  twitter.com/togethercomput…
------
Astonished that a scientist would attract so much attention.
Thank you, everyone.
------
Self-supervised learning is a key ingredient in recent AI breakthroughs. To lower barriers + help democratize access to this research, we compiled The SSL Cookbook: a practical guide for researchers navigating the intricacies of this research space. 
------
I literally have the best job in the world. 

Develop a passion for a topic. 

Speak to the worlds leading experts and OGs in the space. 

Share their knowledge with the world. 

Episode coming with 
@ylecun
 is incredible.  
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
Open source LLMs popping up everywhere.
This is the way.
------
Today is the Llama moment for coding! 

StarCoder-15B reaches 40.8% on HumanEval benchmark, beating the 30x bigger PaLM.

Coding holds a very special place in NLP. Most software in the world has AI-friendly APIs. LLMs good at coding will master the digital tools, greatly… Show more
------
Some regions need to change their modus operandi when it comes to the practice of scientific research and the incentive mechanisms.
------
“The Geography of Retracted Papers.”
https://dapp.orvium.io/deposits/6442fee5c93d17c257de17d2/view…
------
On the usefulness of risk-benefit analysis.
------
Optimists vs Pessimists
------
Best AI advice I can give you right now:

Learn how to train LLMs now.

Closed source models are winning now, but small, task-specific, open-source models are the future.
------
This is absolutely correct.
The most common reaction by AI researchers to these prophecies of doom is face palming.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Our neocortex is entirely controlled by our lizard brain.
Our future superhuman exocortex will be controlled by our neocortex.

We can design AI to have superhuman intelligence *and* be submissive. 
For an entity to control another, it has to *want* to take control.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Note to picky neuroscientists: replace "lizard brain" by "basal ganglia".
------
We can design AI systems to be both super-intelligent *and* submissive to humans.
I always wonder why people just assume that intelligent entities will necessarily want to dominate.
That's just plain false, even within the human species.
------
Good political, business, and academic leaders surround themselves with staff whose members are often smarter than themselves.

That's a common counter-example of 
@geoffreyhinton
's claim that more intelligent things almost always control less intelligent things.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Quote from 
@geoffreyhinton
 :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
My summary of 
@lexfridman
 interviewing 
@ylecun
 from early 2022. I've been reading a lot on AI safety and wanted to better understand LeCun's perspective as he has publicly disagreed with folks like Tegmark.

https://aiadventures.net/summaries/lex-fridman-yann-lecun.html…

This was my favorite part of the conversation.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Gods and superhuman AI systems have a few things in common:
They are invented by people.
People fear they may run the world.
People fight about what it all means.
They don't actually exist.
------
A certain strand of AGI conversations remind me a bit of medieval philosophers, or Descartes trying to prove things about god through logic - trying to prove something about the unknowable by reasoning from first principles, as though god was maths and theology was geometry
------
In case you are wondering:
I have no doubt that superhuman AI systems will eventually exist.

But today they don't, and we don't even have a basic design for them.
So discussing how to make them safe is a bit like discussing how to make transatlantic flights safe in 1920.
------
Enter your questions for my session with Harry on 20VC Friday.
------
Beyond excited for our 20VC on Friday with @ylecun. 

Twitter, what are your must-ask questions? Working on the schedule as we speak! 

Work your magic...
------
Yes
------
Oops haven't tweeted too much recently; I'm mostly watching with interest the open source LLM ecosystem experiencing early signs of a cambrian explosion. Roughly speaking the story as of now:

1. Pretraining LLM base models remains very expensive. Think: supercomputer + months.… Show more
------
If you are worried about "AI causing mass unemployment" listen to economists who have studied the impact of technological revolutions on the labor market, like 
@erikbryn
 .

DO NOT listen to computer scientists who are concerned by the social consequences of their work.
------
A fireside chat and Q&A about the present and future of AI, moderated by philosopher Frédérique de Vignemont and hosted by NYU-Paris.
------
A common fallacy about intelligence:
"A humans who is X is also Y, hence AI that is X must also be Y."
With (X,Y) in { ( intelligent, dominant), (fluent writer, intelligent), (polyglot, intelligent), (chess champion, intelligent), (bar exam wiz, good lawyer), ....}
------
Could a technique for mapping planetary craters developed here be used in future space missions? Scientists have used the new 
@MetaAI
 Segment Anything Model to better understand planetary surfaces & create new possibilities in space exploration https://fal.cn/3xRmJ 
@ylecun
------
A comparison of open 7B LLMs
------
Curious how the RedPajama effort by @togethercompute is progressing and where it stacks up? We evaluated the 7B model they just released 2h ago! Here is how it looks 800B tokens in. (Eval took 16 minutes on 32 A100s.)  twitter.com/togethercomput…
------
Astonished that a scientist would attract so much attention.
Thank you, everyone.
------
Self-supervised learning is a key ingredient in recent AI breakthroughs. To lower barriers + help democratize access to this research, we compiled The SSL Cookbook: a practical guide for researchers navigating the intricacies of this research space. 
------
I literally have the best job in the world. 

Develop a passion for a topic. 

Speak to the worlds leading experts and OGs in the space. 

Share their knowledge with the world. 

Episode coming with 
@ylecun
 is incredible.  
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
Open source LLMs popping up everywhere.
This is the way.
------
Today is the Llama moment for coding! 

StarCoder-15B reaches 40.8% on HumanEval benchmark, beating the 30x bigger PaLM.

Coding holds a very special place in NLP. Most software in the world has AI-friendly APIs. LLMs good at coding will master the digital tools, greatly… Show more
------
Some regions need to change their modus operandi when it comes to the practice of scientific research and the incentive mechanisms.
------
“The Geography of Retracted Papers.”
https://dapp.orvium.io/deposits/6442fee5c93d17c257de17d2/view…
------
On the usefulness of risk-benefit analysis.
------
Optimists vs Pessimists
------
Best AI advice I can give you right now:

Learn how to train LLMs now.

Closed source models are winning now, but small, task-specific, open-source models are the future.
------
This is absolutely correct.
The most common reaction by AI researchers to these prophecies of doom is face palming.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Our neocortex is entirely controlled by our lizard brain.
Our future superhuman exocortex will be controlled by our neocortex.

We can design AI to have superhuman intelligence *and* be submissive. 
For an entity to control another, it has to *want* to take control.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Note to picky neuroscientists: replace "lizard brain" by "basal ganglia".
------
We can design AI systems to be both super-intelligent *and* submissive to humans.
I always wonder why people just assume that intelligent entities will necessarily want to dominate.
That's just plain false, even within the human species.
------
Good political, business, and academic leaders surround themselves with staff whose members are often smarter than themselves.

That's a common counter-example of 
@geoffreyhinton
's claim that more intelligent things almost always control less intelligent things.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Quote from 
@geoffreyhinton
 :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
My summary of 
@lexfridman
 interviewing 
@ylecun
 from early 2022. I've been reading a lot on AI safety and wanted to better understand LeCun's perspective as he has publicly disagreed with folks like Tegmark.

https://aiadventures.net/summaries/lex-fridman-yann-lecun.html…

This was my favorite part of the conversation.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Gods and superhuman AI systems have a few things in common:
They are invented by people.
People fear they may run the world.
People fight about what it all means.
They don't actually exist.
------
A certain strand of AGI conversations remind me a bit of medieval philosophers, or Descartes trying to prove things about god through logic - trying to prove something about the unknowable by reasoning from first principles, as though god was maths and theology was geometry
------
In case you are wondering:
I have no doubt that superhuman AI systems will eventually exist.

But today they don't, and we don't even have a basic design for them.
So discussing how to make them safe is a bit like discussing how to make transatlantic flights safe in 1920.
------
Enter your questions for my session with Harry on 20VC Friday.
------
Beyond excited for our 20VC on Friday with @ylecun. 

Twitter, what are your must-ask questions? Working on the schedule as we speak! 

Work your magic...
------
Rather than asking AI researchers how soon machines will become "smarter than people", perhaps we should be asking cognitive scientists, who actually know something about human intelligence?
------
Classement des pays européens par la part d’électricité bas carbone dans leur mix électrique (données 2022)
Il va falloir se débarrasser de tout ce gris…

https://ember-climate.org/insights/research/european-electricity-review-2023/…
------
Chris Lattner of LLVM and Swift fame just announced a new programming language for ML that is high-performance and backwards compatible with Python (works with Python libraries). Could be a game changer.
------
As the cofounder and chair of the ICLR Foundation, and despite being post-PhD with more than 10 papers, I am very much in favor of letting authors use the tools they deem most useful to help them write technical papers, including LLMs.
------
"LLMs are Few-Shot Paper Writers.…so what?"

Some views from an ML research conference (ICLR) on the topic.
------
Nice demo of Mojo, a new Python-compatible language with a parallelizing compiler that can import Python libraries.
------
You might have heard about this new "Mojo" language created by @clattner_llvm and his team at @Modular_AI. If you want to check out what it looks like in practice, here's a 7 minute demo:
https://youtu.be/6GvB5lZJqcE
------
the work on fine tuning llms in parameter efficient ways that is coming out is just so cool and clever. really shows the power of open source + flexible frameworks that allow you to easily write model blocks and just type loss.backwards()
------
Self-supervised learning is a key ingredient in recent AI breakthroughs. To lower barriers + help democratize access to this research, we compiled The SSL Cookbook: a practical guide for researchers navigating the intricacies of this research space. 
------
I literally have the best job in the world. 

Develop a passion for a topic. 

Speak to the worlds leading experts and OGs in the space. 

Share their knowledge with the world. 

Episode coming with 
@ylecun
 is incredible.  
------
An artificial intelligence system trained on words and sentences alone will never approximate human understanding. | 
@ylecun
 & 
@Jake_Browning00
 in 
@NoemaMag
------
Open source LLMs popping up everywhere.
This is the way.
------
Today is the Llama moment for coding! 

StarCoder-15B reaches 40.8% on HumanEval benchmark, beating the 30x bigger PaLM.

Coding holds a very special place in NLP. Most software in the world has AI-friendly APIs. LLMs good at coding will master the digital tools, greatly… Show more
------
Some regions need to change their modus operandi when it comes to the practice of scientific research and the incentive mechanisms.
------
“The Geography of Retracted Papers.”
https://dapp.orvium.io/deposits/6442fee5c93d17c257de17d2/view…
------
On the usefulness of risk-benefit analysis.
------
Optimists vs Pessimists
------
Best AI advice I can give you right now:

Learn how to train LLMs now.

Closed source models are winning now, but small, task-specific, open-source models are the future.
------
This is absolutely correct.
The most common reaction by AI researchers to these prophecies of doom is face palming.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Our neocortex is entirely controlled by our lizard brain.
Our future superhuman exocortex will be controlled by our neocortex.

We can design AI to have superhuman intelligence *and* be submissive. 
For an entity to control another, it has to *want* to take control.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Note to picky neuroscientists: replace "lizard brain" by "basal ganglia".
------
We can design AI systems to be both super-intelligent *and* submissive to humans.
I always wonder why people just assume that intelligent entities will necessarily want to dominate.
That's just plain false, even within the human species.
------
Good political, business, and academic leaders surround themselves with staff whose members are often smarter than themselves.

That's a common counter-example of 
@geoffreyhinton
's claim that more intelligent things almost always control less intelligent things.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Quote from 
@geoffreyhinton
 :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
My summary of 
@lexfridman
 interviewing 
@ylecun
 from early 2022. I've been reading a lot on AI safety and wanted to better understand LeCun's perspective as he has publicly disagreed with folks like Tegmark.

https://aiadventures.net/summaries/lex-fridman-yann-lecun.html…

This was my favorite part of the conversation.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Gods and superhuman AI systems have a few things in common:
They are invented by people.
People fear they may run the world.
People fight about what it all means.
They don't actually exist.
------
A certain strand of AGI conversations remind me a bit of medieval philosophers, or Descartes trying to prove things about god through logic - trying to prove something about the unknowable by reasoning from first principles, as though god was maths and theology was geometry
------
In case you are wondering:
I have no doubt that superhuman AI systems will eventually exist.

But today they don't, and we don't even have a basic design for them.
So discussing how to make them safe is a bit like discussing how to make transatlantic flights safe in 1920.
------
Enter your questions for my session with Harry on 20VC Friday.
------
Beyond excited for our 20VC on Friday with @ylecun. 

Twitter, what are your must-ask questions? Working on the schedule as we speak! 

Work your magic...
------
Rather than asking AI researchers how soon machines will become "smarter than people", perhaps we should be asking cognitive scientists, who actually know something about human intelligence?
------
Classement des pays européens par la part d’électricité bas carbone dans leur mix électrique (données 2022)
Il va falloir se débarrasser de tout ce gris…

https://ember-climate.org/insights/research/european-electricity-review-2023/…
------
Chris Lattner of LLVM and Swift fame just announced a new programming language for ML that is high-performance and backwards compatible with Python (works with Python libraries). Could be a game changer.
------
As the cofounder and chair of the ICLR Foundation, and despite being post-PhD with more than 10 papers, I am very much in favor of letting authors use the tools they deem most useful to help them write technical papers, including LLMs.
------
"LLMs are Few-Shot Paper Writers.…so what?"

Some views from an ML research conference (ICLR) on the topic.
------
Nice demo of Mojo, a new Python-compatible language with a parallelizing compiler that can import Python libraries.
------
You might have heard about this new "Mojo" language created by @clattner_llvm and his team at @Modular_AI. If you want to check out what it looks like in practice, here's a 7 minute demo:
https://youtu.be/6GvB5lZJqcE
------
the work on fine tuning llms in parameter efficient ways that is coming out is just so cool and clever. really shows the power of open source + flexible frameworks that allow you to easily write model blocks and just type loss.backwards()
------
The pessimist's template:
"[x] is a major problem in the world and [y] is going to make it a lot worse"

x in {climate change, inequalities, authoritarianism, unemployment, disinformation,...}
y in {AI, smartphones, social media, video games, internet,...}
------
https://newsletter.pessimistsarchive.org/p/robots-have-been-about-to-take-all…
------
Every economist I know says that it takes 15 to 20 years before a new general purpose technology  has a measurable effect on productivity.
The delay is determined by how fast people learn to use it.

So no, AI is not going to cause instant mass unemployment. 

It's going to… Show more
------
AI Influencers: "LLMs will demolish white-collar employment overnight"
Enterprise software companies: "oh, you poor sweet child...:
------
Paging 
@erikbryn
 !
------
Would you rather live in any earlier decade or century?  Likely not.   Progress is happening and it takes at least some hope and optimism to get there.
------
 Notable papers to know about from Meta AI at #ICLR2023 this week and where you can learn more — even if you’re not attending.

/6
------
Haha, I knew it! 
Qwerty is the mark of the devil!
------
We must urgently stop all further development on this new "keyboard" technology. In the near future, anyone will just be able to type anything!!! The world will be flooded with fake news and civilization will fall
------
Open source LLMs popping up everywhere.
This is the way.
------
Today is the Llama moment for coding! 

StarCoder-15B reaches 40.8% on HumanEval benchmark, beating the 30x bigger PaLM.

Coding holds a very special place in NLP. Most software in the world has AI-friendly APIs. LLMs good at coding will master the digital tools, greatly… Show more
------
Some regions need to change their modus operandi when it comes to the practice of scientific research and the incentive mechanisms.
------
“The Geography of Retracted Papers.”
https://dapp.orvium.io/deposits/6442fee5c93d17c257de17d2/view…
------
On the usefulness of risk-benefit analysis.
------
Optimists vs Pessimists
------
Best AI advice I can give you right now:

Learn how to train LLMs now.

Closed source models are winning now, but small, task-specific, open-source models are the future.
------
This is absolutely correct.
The most common reaction by AI researchers to these prophecies of doom is face palming.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Our neocortex is entirely controlled by our lizard brain.
Our future superhuman exocortex will be controlled by our neocortex.

We can design AI to have superhuman intelligence *and* be submissive. 
For an entity to control another, it has to *want* to take control.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Note to picky neuroscientists: replace "lizard brain" by "basal ganglia".
------
We can design AI systems to be both super-intelligent *and* submissive to humans.
I always wonder why people just assume that intelligent entities will necessarily want to dominate.
That's just plain false, even within the human species.
------
Good political, business, and academic leaders surround themselves with staff whose members are often smarter than themselves.

That's a common counter-example of 
@geoffreyhinton
's claim that more intelligent things almost always control less intelligent things.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Quote from 
@geoffreyhinton
 :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
My summary of 
@lexfridman
 interviewing 
@ylecun
 from early 2022. I've been reading a lot on AI safety and wanted to better understand LeCun's perspective as he has publicly disagreed with folks like Tegmark.

https://aiadventures.net/summaries/lex-fridman-yann-lecun.html…

This was my favorite part of the conversation.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Gods and superhuman AI systems have a few things in common:
They are invented by people.
People fear they may run the world.
People fight about what it all means.
They don't actually exist.
------
A certain strand of AGI conversations remind me a bit of medieval philosophers, or Descartes trying to prove things about god through logic - trying to prove something about the unknowable by reasoning from first principles, as though god was maths and theology was geometry
------
In case you are wondering:
I have no doubt that superhuman AI systems will eventually exist.

But today they don't, and we don't even have a basic design for them.
So discussing how to make them safe is a bit like discussing how to make transatlantic flights safe in 1920.
------
Enter your questions for my session with Harry on 20VC Friday.
------
Beyond excited for our 20VC on Friday with @ylecun. 

Twitter, what are your must-ask questions? Working on the schedule as we speak! 

Work your magic...
------
Rather than asking AI researchers how soon machines will become "smarter than people", perhaps we should be asking cognitive scientists, who actually know something about human intelligence?
------
Classement des pays européens par la part d’électricité bas carbone dans leur mix électrique (données 2022)
Il va falloir se débarrasser de tout ce gris…

https://ember-climate.org/insights/research/european-electricity-review-2023/…
------
Chris Lattner of LLVM and Swift fame just announced a new programming language for ML that is high-performance and backwards compatible with Python (works with Python libraries). Could be a game changer.
------
As the cofounder and chair of the ICLR Foundation, and despite being post-PhD with more than 10 papers, I am very much in favor of letting authors use the tools they deem most useful to help them write technical papers, including LLMs.
------
"LLMs are Few-Shot Paper Writers.…so what?"

Some views from an ML research conference (ICLR) on the topic.
------
Nice demo of Mojo, a new Python-compatible language with a parallelizing compiler that can import Python libraries.
------
You might have heard about this new "Mojo" language created by @clattner_llvm and his team at @Modular_AI. If you want to check out what it looks like in practice, here's a 7 minute demo:
https://youtu.be/6GvB5lZJqcE
------
the work on fine tuning llms in parameter efficient ways that is coming out is just so cool and clever. really shows the power of open source + flexible frameworks that allow you to easily write model blocks and just type loss.backwards()
------
The pessimist's template:
"[x] is a major problem in the world and [y] is going to make it a lot worse"

x in {climate change, inequalities, authoritarianism, unemployment, disinformation,...}
y in {AI, smartphones, social media, video games, internet,...}
------
https://newsletter.pessimistsarchive.org/p/robots-have-been-about-to-take-all…
------
Every economist I know says that it takes 15 to 20 years before a new general purpose technology  has a measurable effect on productivity.
The delay is determined by how fast people learn to use it.

So no, AI is not going to cause instant mass unemployment. 

It's going to… Show more
------
AI Influencers: "LLMs will demolish white-collar employment overnight"
Enterprise software companies: "oh, you poor sweet child...:
------
Paging 
@erikbryn
 !
------
Would you rather live in any earlier decade or century?  Likely not.   Progress is happening and it takes at least some hope and optimism to get there.
------
 Notable papers to know about from Meta AI at #ICLR2023 this week and where you can learn more — even if you’re not attending.

/6
------
Haha, I knew it! 
Qwerty is the mark of the devil!
------
We must urgently stop all further development on this new "keyboard" technology. In the near future, anyone will just be able to type anything!!! The world will be flooded with fake news and civilization will fall
------
Supervised, unsupervised, and self-supervised learning explained in the light of information theory.
------
@ylecun and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper!  https://arxiv.org/abs/2304.09355
------
@ylecun
 and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper! 
------
A 
@nytimestech
 article on chatbot hallucinations.
Companies (& the AI research community) are struggling to correct the issue.
In my opinion, no amount of fine tuning will ever fix that.
It will require a redesign.

When A.I. Chatbots Hallucinate
------
“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said Subbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
Best AI advice I can give you right now:

Learn how to train LLMs now.

Closed source models are winning now, but small, task-specific, open-source models are the future.
------
This is absolutely correct.
The most common reaction by AI researchers to these prophecies of doom is face palming.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Our neocortex is entirely controlled by our lizard brain.
Our future superhuman exocortex will be controlled by our neocortex.

We can design AI to have superhuman intelligence *and* be submissive. 
For an entity to control another, it has to *want* to take control.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Note to picky neuroscientists: replace "lizard brain" by "basal ganglia".
------
We can design AI systems to be both super-intelligent *and* submissive to humans.
I always wonder why people just assume that intelligent entities will necessarily want to dominate.
That's just plain false, even within the human species.
------
Good political, business, and academic leaders surround themselves with staff whose members are often smarter than themselves.

That's a common counter-example of 
@geoffreyhinton
's claim that more intelligent things almost always control less intelligent things.
------
Quote from @geoffreyhinton :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
Quote from 
@geoffreyhinton
 :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
My summary of 
@lexfridman
 interviewing 
@ylecun
 from early 2022. I've been reading a lot on AI safety and wanted to better understand LeCun's perspective as he has publicly disagreed with folks like Tegmark.

https://aiadventures.net/summaries/lex-fridman-yann-lecun.html…

This was my favorite part of the conversation.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Gods and superhuman AI systems have a few things in common:
They are invented by people.
People fear they may run the world.
People fight about what it all means.
They don't actually exist.
------
A certain strand of AGI conversations remind me a bit of medieval philosophers, or Descartes trying to prove things about god through logic - trying to prove something about the unknowable by reasoning from first principles, as though god was maths and theology was geometry
------
In case you are wondering:
I have no doubt that superhuman AI systems will eventually exist.

But today they don't, and we don't even have a basic design for them.
So discussing how to make them safe is a bit like discussing how to make transatlantic flights safe in 1920.
------
Enter your questions for my session with Harry on 20VC Friday.
------
Beyond excited for our 20VC on Friday with @ylecun. 

Twitter, what are your must-ask questions? Working on the schedule as we speak! 

Work your magic...
------
Rather than asking AI researchers how soon machines will become "smarter than people", perhaps we should be asking cognitive scientists, who actually know something about human intelligence?
------
Classement des pays européens par la part d’électricité bas carbone dans leur mix électrique (données 2022)
Il va falloir se débarrasser de tout ce gris…

https://ember-climate.org/insights/research/european-electricity-review-2023/…
------
Chris Lattner of LLVM and Swift fame just announced a new programming language for ML that is high-performance and backwards compatible with Python (works with Python libraries). Could be a game changer.
------
As the cofounder and chair of the ICLR Foundation, and despite being post-PhD with more than 10 papers, I am very much in favor of letting authors use the tools they deem most useful to help them write technical papers, including LLMs.
------
"LLMs are Few-Shot Paper Writers.…so what?"

Some views from an ML research conference (ICLR) on the topic.
------
Nice demo of Mojo, a new Python-compatible language with a parallelizing compiler that can import Python libraries.
------
You might have heard about this new "Mojo" language created by @clattner_llvm and his team at @Modular_AI. If you want to check out what it looks like in practice, here's a 7 minute demo:
https://youtu.be/6GvB5lZJqcE
------
the work on fine tuning llms in parameter efficient ways that is coming out is just so cool and clever. really shows the power of open source + flexible frameworks that allow you to easily write model blocks and just type loss.backwards()
------
The pessimist's template:
"[x] is a major problem in the world and [y] is going to make it a lot worse"

x in {climate change, inequalities, authoritarianism, unemployment, disinformation,...}
y in {AI, smartphones, social media, video games, internet,...}
------
https://newsletter.pessimistsarchive.org/p/robots-have-been-about-to-take-all…
------
Every economist I know says that it takes 15 to 20 years before a new general purpose technology  has a measurable effect on productivity.
The delay is determined by how fast people learn to use it.

So no, AI is not going to cause instant mass unemployment. 

It's going to… Show more
------
AI Influencers: "LLMs will demolish white-collar employment overnight"
Enterprise software companies: "oh, you poor sweet child...:
------
Paging 
@erikbryn
 !
------
Would you rather live in any earlier decade or century?  Likely not.   Progress is happening and it takes at least some hope and optimism to get there.
------
 Notable papers to know about from Meta AI at #ICLR2023 this week and where you can learn more — even if you’re not attending.

/6
------
Haha, I knew it! 
Qwerty is the mark of the devil!
------
We must urgently stop all further development on this new "keyboard" technology. In the near future, anyone will just be able to type anything!!! The world will be flooded with fake news and civilization will fall
------
Supervised, unsupervised, and self-supervised learning explained in the light of information theory.
------
@ylecun and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper!  https://arxiv.org/abs/2304.09355
------
@ylecun
 and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper! 
------
A 
@nytimestech
 article on chatbot hallucinations.
Companies (& the AI research community) are struggling to correct the issue.
In my opinion, no amount of fine tuning will ever fix that.
It will require a redesign.

When A.I. Chatbots Hallucinate
------
“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said Subbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
A history of LLMs derived from LLaMA.
------
Quote from 
@geoffreyhinton
 :
"There are very few examples of a more intelligent thing being controlled by a less intelligent thing."
Have you looked at your: 
Head of state?
Elected representative?
Pointy-haired boss?
Pastor/rabbi/imam/guru?
PhD advisor?
Cat?
------
My summary of 
@lexfridman
 interviewing 
@ylecun
 from early 2022. I've been reading a lot on AI safety and wanted to better understand LeCun's perspective as he has publicly disagreed with folks like Tegmark.

https://aiadventures.net/summaries/lex-fridman-yann-lecun.html…

This was my favorite part of the conversation.
------
Reminder: most AI researchers think the notion of AI ending human civilization is baloney.
------
Gods and superhuman AI systems have a few things in common:
They are invented by people.
People fear they may run the world.
People fight about what it all means.
They don't actually exist.
------
A certain strand of AGI conversations remind me a bit of medieval philosophers, or Descartes trying to prove things about god through logic - trying to prove something about the unknowable by reasoning from first principles, as though god was maths and theology was geometry
------
In case you are wondering:
I have no doubt that superhuman AI systems will eventually exist.

But today they don't, and we don't even have a basic design for them.
So discussing how to make them safe is a bit like discussing how to make transatlantic flights safe in 1920.
------
Enter your questions for my session with Harry on 20VC Friday.
------
Beyond excited for our 20VC on Friday with @ylecun. 

Twitter, what are your must-ask questions? Working on the schedule as we speak! 

Work your magic...
------
Rather than asking AI researchers how soon machines will become "smarter than people", perhaps we should be asking cognitive scientists, who actually know something about human intelligence?
------
Classement des pays européens par la part d’électricité bas carbone dans leur mix électrique (données 2022)
Il va falloir se débarrasser de tout ce gris…

https://ember-climate.org/insights/research/european-electricity-review-2023/…
------
Chris Lattner of LLVM and Swift fame just announced a new programming language for ML that is high-performance and backwards compatible with Python (works with Python libraries). Could be a game changer.
------
As the cofounder and chair of the ICLR Foundation, and despite being post-PhD with more than 10 papers, I am very much in favor of letting authors use the tools they deem most useful to help them write technical papers, including LLMs.
------
"LLMs are Few-Shot Paper Writers.…so what?"

Some views from an ML research conference (ICLR) on the topic.
------
Nice demo of Mojo, a new Python-compatible language with a parallelizing compiler that can import Python libraries.
------
You might have heard about this new "Mojo" language created by @clattner_llvm and his team at @Modular_AI. If you want to check out what it looks like in practice, here's a 7 minute demo:
https://youtu.be/6GvB5lZJqcE
------
the work on fine tuning llms in parameter efficient ways that is coming out is just so cool and clever. really shows the power of open source + flexible frameworks that allow you to easily write model blocks and just type loss.backwards()
------
The pessimist's template:
"[x] is a major problem in the world and [y] is going to make it a lot worse"

x in {climate change, inequalities, authoritarianism, unemployment, disinformation,...}
y in {AI, smartphones, social media, video games, internet,...}
------
https://newsletter.pessimistsarchive.org/p/robots-have-been-about-to-take-all…
------
Every economist I know says that it takes 15 to 20 years before a new general purpose technology  has a measurable effect on productivity.
The delay is determined by how fast people learn to use it.

So no, AI is not going to cause instant mass unemployment. 

It's going to… Show more
------
AI Influencers: "LLMs will demolish white-collar employment overnight"
Enterprise software companies: "oh, you poor sweet child...:
------
Paging 
@erikbryn
 !
------
Would you rather live in any earlier decade or century?  Likely not.   Progress is happening and it takes at least some hope and optimism to get there.
------
 Notable papers to know about from Meta AI at #ICLR2023 this week and where you can learn more — even if you’re not attending.

/6
------
Haha, I knew it! 
Qwerty is the mark of the devil!
------
We must urgently stop all further development on this new "keyboard" technology. In the near future, anyone will just be able to type anything!!! The world will be flooded with fake news and civilization will fall
------
Supervised, unsupervised, and self-supervised learning explained in the light of information theory.
------
@ylecun and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper!  https://arxiv.org/abs/2304.09355
------
@ylecun
 and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper! 
------
A 
@nytimestech
 article on chatbot hallucinations.
Companies (& the AI research community) are struggling to correct the issue.
In my opinion, no amount of fine tuning will ever fix that.
It will require a redesign.

When A.I. Chatbots Hallucinate
------
“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said Subbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
A history of LLMs derived from LLaMA.
------
The 
@TEDTalks
 by 
@YejinChoinka
 is both insightful & beautifully delivered! Totally agree with her that GPT-4 is simultaneously brilliant and incredibly stupid. Yejin gives 3 examples of common sense failing that are worth examining a bit more closely. 1/5
------
 Pas convaincu par la tribune de 
@harari_yuval
 dans 
@TheEconomist
. Pour lui, la clé est la régulation de l’IA  alors que pour moi c’est l’éducation ! Je rejoins 
@mikiane
 sur ce point… 

Pourquoi développer l’éducation à l’IA ? 4 idées : 

 L'éducation permet de créer un… Show more
------
The proximal operator is an important unifying concept.
------
The proximal operator is the implicit counterpart of the explicit gradient descent step. Fundamental to tackle non-smooth optimization problems. https://en.wikipedia.org/wiki/Proximal_operator…
------
Paris is one of the hot places to:
- build magical AI
- build amazing consumer products
- run into VCs from sandhill road

It takes 10 years to build an ecosystem and amazing people like 
@an21m
 
@Xavier75
 
@2lr
 
@loic
 
@roxannevarza
 
@katborlongan
 but the result is amazing
------
Lil' personal life update: 

 I'm moving to Paris – for one year – starting in September! 

I'll be working from @an21m's @amoamoamo office (one of my fav crews), and living in the 6th.

Anyone want to hang? Who should I meet while I'm there?!
------
If you train your AI system without labels, SSL is probably what you will end up using. But you might hit many walls along the way as SSL builds upon decades of research. To help, we compiled this guide:
https://arxiv.org/abs/2304.12210
whether you train/deploy/research, give it a read!
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
“A cookbook of Self-Supervised Learning” 
@ylecun
 et al 

SSL is the tasty sauce behind a lot of the success in Language models, Computer Vision and beyond. 

It permits working with limited data by allowing you to include unlabelled data in your workflow. Hence becoming “the… Show more
------
Classement des pays européens par la part d’électricité bas carbone dans leur mix électrique (données 2022)
Il va falloir se débarrasser de tout ce gris…

https://ember-climate.org/insights/research/european-electricity-review-2023/…
------
Chris Lattner of LLVM and Swift fame just announced a new programming language for ML that is high-performance and backwards compatible with Python (works with Python libraries). Could be a game changer.
------
As the cofounder and chair of the ICLR Foundation, and despite being post-PhD with more than 10 papers, I am very much in favor of letting authors use the tools they deem most useful to help them write technical papers, including LLMs.
------
"LLMs are Few-Shot Paper Writers.…so what?"

Some views from an ML research conference (ICLR) on the topic.
------
Nice demo of Mojo, a new Python-compatible language with a parallelizing compiler that can import Python libraries.
------
You might have heard about this new "Mojo" language created by @clattner_llvm and his team at @Modular_AI. If you want to check out what it looks like in practice, here's a 7 minute demo:
https://youtu.be/6GvB5lZJqcE
------
the work on fine tuning llms in parameter efficient ways that is coming out is just so cool and clever. really shows the power of open source + flexible frameworks that allow you to easily write model blocks and just type loss.backwards()
------
The pessimist's template:
"[x] is a major problem in the world and [y] is going to make it a lot worse"

x in {climate change, inequalities, authoritarianism, unemployment, disinformation,...}
y in {AI, smartphones, social media, video games, internet,...}
------
https://newsletter.pessimistsarchive.org/p/robots-have-been-about-to-take-all…
------
Every economist I know says that it takes 15 to 20 years before a new general purpose technology  has a measurable effect on productivity.
The delay is determined by how fast people learn to use it.

So no, AI is not going to cause instant mass unemployment. 

It's going to… Show more
------
AI Influencers: "LLMs will demolish white-collar employment overnight"
Enterprise software companies: "oh, you poor sweet child...:
------
Paging 
@erikbryn
 !
------
Would you rather live in any earlier decade or century?  Likely not.   Progress is happening and it takes at least some hope and optimism to get there.
------
 Notable papers to know about from Meta AI at #ICLR2023 this week and where you can learn more — even if you’re not attending.

/6
------
Haha, I knew it! 
Qwerty is the mark of the devil!
------
We must urgently stop all further development on this new "keyboard" technology. In the near future, anyone will just be able to type anything!!! The world will be flooded with fake news and civilization will fall
------
Supervised, unsupervised, and self-supervised learning explained in the light of information theory.
------
@ylecun and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper!  https://arxiv.org/abs/2304.09355
------
@ylecun
 and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper! 
------
A 
@nytimestech
 article on chatbot hallucinations.
Companies (& the AI research community) are struggling to correct the issue.
In my opinion, no amount of fine tuning will ever fix that.
It will require a redesign.

When A.I. Chatbots Hallucinate
------
“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said Subbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
A history of LLMs derived from LLaMA.
------
The 
@TEDTalks
 by 
@YejinChoinka
 is both insightful & beautifully delivered! Totally agree with her that GPT-4 is simultaneously brilliant and incredibly stupid. Yejin gives 3 examples of common sense failing that are worth examining a bit more closely. 1/5
------
 Pas convaincu par la tribune de 
@harari_yuval
 dans 
@TheEconomist
. Pour lui, la clé est la régulation de l’IA  alors que pour moi c’est l’éducation ! Je rejoins 
@mikiane
 sur ce point… 

Pourquoi développer l’éducation à l’IA ? 4 idées : 

 L'éducation permet de créer un… Show more
------
The proximal operator is an important unifying concept.
------
The proximal operator is the implicit counterpart of the explicit gradient descent step. Fundamental to tackle non-smooth optimization problems. https://en.wikipedia.org/wiki/Proximal_operator…
------
Paris is one of the hot places to:
- build magical AI
- build amazing consumer products
- run into VCs from sandhill road

It takes 10 years to build an ecosystem and amazing people like 
@an21m
 
@Xavier75
 
@2lr
 
@loic
 
@roxannevarza
 
@katborlongan
 but the result is amazing
------
Lil' personal life update: 

 I'm moving to Paris – for one year – starting in September! 

I'll be working from @an21m's @amoamoamo office (one of my fav crews), and living in the 6th.

Anyone want to hang? Who should I meet while I'm there?!
------
If you train your AI system without labels, SSL is probably what you will end up using. But you might hit many walls along the way as SSL builds upon decades of research. To help, we compiled this guide:
https://arxiv.org/abs/2304.12210
whether you train/deploy/research, give it a read!
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
“A cookbook of Self-Supervised Learning” 
@ylecun
 et al 

SSL is the tasty sauce behind a lot of the success in Language models, Computer Vision and beyond. 

It permits working with limited data by allowing you to include unlabelled data in your workflow. Hence becoming “the… Show more
------
It’s official…LlamaIndex 0.6.0.alpha1 is out. And it’s basically a completely new product 

We fundamentally rewrote two main areas:
- Query interface
- Storage abstractions

Full blog post: https://medium.com/@jerryjliu98/llamaindex-0-6-0-a-new-query-interface-over-your-data-331996d47e89…

Way too much for one tweet thread but we’ll try!  
------
I’m super excited to announce 
@LaminiAI
, the LLM engine that gives every developer the superpowers that took the world from GPT-3 to ChatGPT! We make it easy to rapidly train custom LLMs from 
@OpenAI
 @EleutherAI 
@Cerebras
 
@Databricks
 
@HuggingFace
 
@Meta
 https://lamini.ai/blog/introducing-lamini… 
------
True.
------
AI demos are easy, AI products are hard.

Anyone can slap together an AI demo that seems to work on the surface & impresses a crowd, but true AI products have to have quality, generality, be fast, hit the right features, not have domain drift, etc.

I'm not impressed by AI demos.
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
The pessimist's template:
"[x] is a major problem in the world and [y] is going to make it a lot worse"

x in {climate change, inequalities, authoritarianism, unemployment, disinformation,...}
y in {AI, smartphones, social media, video games, internet,...}
------
https://newsletter.pessimistsarchive.org/p/robots-have-been-about-to-take-all…
------
Every economist I know says that it takes 15 to 20 years before a new general purpose technology  has a measurable effect on productivity.
The delay is determined by how fast people learn to use it.

So no, AI is not going to cause instant mass unemployment. 

It's going to… Show more
------
AI Influencers: "LLMs will demolish white-collar employment overnight"
Enterprise software companies: "oh, you poor sweet child...:
------
Paging 
@erikbryn
 !
------
Would you rather live in any earlier decade or century?  Likely not.   Progress is happening and it takes at least some hope and optimism to get there.
------
 Notable papers to know about from Meta AI at #ICLR2023 this week and where you can learn more — even if you’re not attending.

/6
------
Haha, I knew it! 
Qwerty is the mark of the devil!
------
We must urgently stop all further development on this new "keyboard" technology. In the near future, anyone will just be able to type anything!!! The world will be flooded with fake news and civilization will fall
------
Supervised, unsupervised, and self-supervised learning explained in the light of information theory.
------
@ylecun and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper!  https://arxiv.org/abs/2304.09355
------
@ylecun
 and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper! 
------
A 
@nytimestech
 article on chatbot hallucinations.
Companies (& the AI research community) are struggling to correct the issue.
In my opinion, no amount of fine tuning will ever fix that.
It will require a redesign.

When A.I. Chatbots Hallucinate
------
“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said Subbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
A history of LLMs derived from LLaMA.
------
The 
@TEDTalks
 by 
@YejinChoinka
 is both insightful & beautifully delivered! Totally agree with her that GPT-4 is simultaneously brilliant and incredibly stupid. Yejin gives 3 examples of common sense failing that are worth examining a bit more closely. 1/5
------
 Pas convaincu par la tribune de 
@harari_yuval
 dans 
@TheEconomist
. Pour lui, la clé est la régulation de l’IA  alors que pour moi c’est l’éducation ! Je rejoins 
@mikiane
 sur ce point… 

Pourquoi développer l’éducation à l’IA ? 4 idées : 

 L'éducation permet de créer un… Show more
------
The proximal operator is an important unifying concept.
------
The proximal operator is the implicit counterpart of the explicit gradient descent step. Fundamental to tackle non-smooth optimization problems. https://en.wikipedia.org/wiki/Proximal_operator…
------
Paris is one of the hot places to:
- build magical AI
- build amazing consumer products
- run into VCs from sandhill road

It takes 10 years to build an ecosystem and amazing people like 
@an21m
 
@Xavier75
 
@2lr
 
@loic
 
@roxannevarza
 
@katborlongan
 but the result is amazing
------
Lil' personal life update: 

 I'm moving to Paris – for one year – starting in September! 

I'll be working from @an21m's @amoamoamo office (one of my fav crews), and living in the 6th.

Anyone want to hang? Who should I meet while I'm there?!
------
If you train your AI system without labels, SSL is probably what you will end up using. But you might hit many walls along the way as SSL builds upon decades of research. To help, we compiled this guide:
https://arxiv.org/abs/2304.12210
whether you train/deploy/research, give it a read!
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
“A cookbook of Self-Supervised Learning” 
@ylecun
 et al 

SSL is the tasty sauce behind a lot of the success in Language models, Computer Vision and beyond. 

It permits working with limited data by allowing you to include unlabelled data in your workflow. Hence becoming “the… Show more
------
It’s official…LlamaIndex 0.6.0.alpha1 is out. And it’s basically a completely new product 

We fundamentally rewrote two main areas:
- Query interface
- Storage abstractions

Full blog post: https://medium.com/@jerryjliu98/llamaindex-0-6-0-a-new-query-interface-over-your-data-331996d47e89…

Way too much for one tweet thread but we’ll try!  
------
I’m super excited to announce 
@LaminiAI
, the LLM engine that gives every developer the superpowers that took the world from GPT-3 to ChatGPT! We make it easy to rapidly train custom LLMs from 
@OpenAI
 @EleutherAI 
@Cerebras
 
@Databricks
 
@HuggingFace
 
@Meta
 https://lamini.ai/blog/introducing-lamini… 
------
True.
------
AI demos are easy, AI products are hard.

Anyone can slap together an AI demo that seems to work on the surface & impresses a crowd, but true AI products have to have quality, generality, be fast, hit the right features, not have domain drift, etc.

I'm not impressed by AI demos.
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
Thought != Language
------
'I rarely think in words at all.  A thought comes, and I may try to express it in words afterwards.'  

-Albert Einstein

(From a conversation with psychologist Max Wertheimer in 1916)
------
Iterative projections: converge in theory for convex sets. Works great in practice for non-convex sets. https://en.wikipedia.org/wiki/Projections_onto_convex_sets…
------
1/5 In our post https://scottaaronson.blog/?p=7266, Aaronson and I discuss potential scenarios for AI. In particular we say that for "super-intelligence" type scenarios, AI will need to break out of the current "sheer data&compute scale" paradigm. Given Moore's law, why is this the case?
------
Supervised, unsupervised, and self-supervised learning explained in the light of information theory.
------
@ylecun and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper!  https://arxiv.org/abs/2304.09355
------
@ylecun
 and I have been pondering the concept of optimal representation in self-supervised learning, and we're excited to share our findings in a recently published paper! 
------
A 
@nytimestech
 article on chatbot hallucinations.
Companies (& the AI research community) are struggling to correct the issue.
In my opinion, no amount of fine tuning will ever fix that.
It will require a redesign.

When A.I. Chatbots Hallucinate
------
“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said Subbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
A history of LLMs derived from LLaMA.
------
The 
@TEDTalks
 by 
@YejinChoinka
 is both insightful & beautifully delivered! Totally agree with her that GPT-4 is simultaneously brilliant and incredibly stupid. Yejin gives 3 examples of common sense failing that are worth examining a bit more closely. 1/5
------
 Pas convaincu par la tribune de 
@harari_yuval
 dans 
@TheEconomist
. Pour lui, la clé est la régulation de l’IA  alors que pour moi c’est l’éducation ! Je rejoins 
@mikiane
 sur ce point… 

Pourquoi développer l’éducation à l’IA ? 4 idées : 

 L'éducation permet de créer un… Show more
------
The proximal operator is an important unifying concept.
------
The proximal operator is the implicit counterpart of the explicit gradient descent step. Fundamental to tackle non-smooth optimization problems. https://en.wikipedia.org/wiki/Proximal_operator…
------
Paris is one of the hot places to:
- build magical AI
- build amazing consumer products
- run into VCs from sandhill road

It takes 10 years to build an ecosystem and amazing people like 
@an21m
 
@Xavier75
 
@2lr
 
@loic
 
@roxannevarza
 
@katborlongan
 but the result is amazing
------
Lil' personal life update: 

 I'm moving to Paris – for one year – starting in September! 

I'll be working from @an21m's @amoamoamo office (one of my fav crews), and living in the 6th.

Anyone want to hang? Who should I meet while I'm there?!
------
If you train your AI system without labels, SSL is probably what you will end up using. But you might hit many walls along the way as SSL builds upon decades of research. To help, we compiled this guide:
https://arxiv.org/abs/2304.12210
whether you train/deploy/research, give it a read!
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
“A cookbook of Self-Supervised Learning” 
@ylecun
 et al 

SSL is the tasty sauce behind a lot of the success in Language models, Computer Vision and beyond. 

It permits working with limited data by allowing you to include unlabelled data in your workflow. Hence becoming “the… Show more
------
It’s official…LlamaIndex 0.6.0.alpha1 is out. And it’s basically a completely new product 

We fundamentally rewrote two main areas:
- Query interface
- Storage abstractions

Full blog post: https://medium.com/@jerryjliu98/llamaindex-0-6-0-a-new-query-interface-over-your-data-331996d47e89…

Way too much for one tweet thread but we’ll try!  
------
I’m super excited to announce 
@LaminiAI
, the LLM engine that gives every developer the superpowers that took the world from GPT-3 to ChatGPT! We make it easy to rapidly train custom LLMs from 
@OpenAI
 @EleutherAI 
@Cerebras
 
@Databricks
 
@HuggingFace
 
@Meta
 https://lamini.ai/blog/introducing-lamini… 
------
True.
------
AI demos are easy, AI products are hard.

Anyone can slap together an AI demo that seems to work on the surface & impresses a crowd, but true AI products have to have quality, generality, be fast, hit the right features, not have domain drift, etc.

I'm not impressed by AI demos.
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
Thought != Language
------
'I rarely think in words at all.  A thought comes, and I may try to express it in words afterwards.'  

-Albert Einstein

(From a conversation with psychologist Max Wertheimer in 1916)
------
Iterative projections: converge in theory for convex sets. Works great in practice for non-convex sets. https://en.wikipedia.org/wiki/Projections_onto_convex_sets…
------
1/5 In our post https://scottaaronson.blog/?p=7266, Aaronson and I discuss potential scenarios for AI. In particular we say that for "super-intelligence" type scenarios, AI will need to break out of the current "sheer data&compute scale" paradigm. Given Moore's law, why is this the case?
------
Exposing the professional scaremongers.
------
The AI Dilemma's  Panic-as-a-Business:

- Freaking people out with monstrous AI

- Freaking people out with dubious survey stats

- Distracting people from the real issues

 New article: https://bit.ly/41JhjJm
------
should concern every american:
------
Une interview dans Le Monde sur les questions importantes du moment autour de l'intelligence artificielle.
------
Anyone willing to share how they are using https://segment-anything.com in their products?
------
Craving for speed? Come explore our super fast MoDem at ICLR 

 Decoder-free visual world model akin to 
@ylecun
's JEPA 
 Combining RL & IL
 Analysis of pre-trained visual rep. for world models 

Mon 11:30AM MH1-2-3-4 #122 Bring your curiosity and queries!
------
Excited to share MoDem -- our latest work on visual world models for control! 

MoDem combines decoder-free world models, demonstrations, and pre-trained vision encoders. Achieves SOTA results in 21 challenging visuo-motor control tasks. 

Web: https://nicklashansen.github.io/modemrl/
------
A history of LLMs derived from LLaMA.
------
The 
@TEDTalks
 by 
@YejinChoinka
 is both insightful & beautifully delivered! Totally agree with her that GPT-4 is simultaneously brilliant and incredibly stupid. Yejin gives 3 examples of common sense failing that are worth examining a bit more closely. 1/5
------
 Pas convaincu par la tribune de 
@harari_yuval
 dans 
@TheEconomist
. Pour lui, la clé est la régulation de l’IA  alors que pour moi c’est l’éducation ! Je rejoins 
@mikiane
 sur ce point… 

Pourquoi développer l’éducation à l’IA ? 4 idées : 

 L'éducation permet de créer un… Show more
------
The proximal operator is an important unifying concept.
------
The proximal operator is the implicit counterpart of the explicit gradient descent step. Fundamental to tackle non-smooth optimization problems. https://en.wikipedia.org/wiki/Proximal_operator…
------
Paris is one of the hot places to:
- build magical AI
- build amazing consumer products
- run into VCs from sandhill road

It takes 10 years to build an ecosystem and amazing people like 
@an21m
 
@Xavier75
 
@2lr
 
@loic
 
@roxannevarza
 
@katborlongan
 but the result is amazing
------
Lil' personal life update: 

 I'm moving to Paris – for one year – starting in September! 

I'll be working from @an21m's @amoamoamo office (one of my fav crews), and living in the 6th.

Anyone want to hang? Who should I meet while I'm there?!
------
If you train your AI system without labels, SSL is probably what you will end up using. But you might hit many walls along the way as SSL builds upon decades of research. To help, we compiled this guide:
https://arxiv.org/abs/2304.12210
whether you train/deploy/research, give it a read!
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
“A cookbook of Self-Supervised Learning” 
@ylecun
 et al 

SSL is the tasty sauce behind a lot of the success in Language models, Computer Vision and beyond. 

It permits working with limited data by allowing you to include unlabelled data in your workflow. Hence becoming “the… Show more
------
It’s official…LlamaIndex 0.6.0.alpha1 is out. And it’s basically a completely new product 

We fundamentally rewrote two main areas:
- Query interface
- Storage abstractions

Full blog post: https://medium.com/@jerryjliu98/llamaindex-0-6-0-a-new-query-interface-over-your-data-331996d47e89…

Way too much for one tweet thread but we’ll try!  
------
I’m super excited to announce 
@LaminiAI
, the LLM engine that gives every developer the superpowers that took the world from GPT-3 to ChatGPT! We make it easy to rapidly train custom LLMs from 
@OpenAI
 @EleutherAI 
@Cerebras
 
@Databricks
 
@HuggingFace
 
@Meta
 https://lamini.ai/blog/introducing-lamini… 
------
True.
------
AI demos are easy, AI products are hard.

Anyone can slap together an AI demo that seems to work on the surface & impresses a crowd, but true AI products have to have quality, generality, be fast, hit the right features, not have domain drift, etc.

I'm not impressed by AI demos.
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
Thought != Language
------
'I rarely think in words at all.  A thought comes, and I may try to express it in words afterwards.'  

-Albert Einstein

(From a conversation with psychologist Max Wertheimer in 1916)
------
Iterative projections: converge in theory for convex sets. Works great in practice for non-convex sets. https://en.wikipedia.org/wiki/Projections_onto_convex_sets…
------
1/5 In our post https://scottaaronson.blog/?p=7266, Aaronson and I discuss potential scenarios for AI. In particular we say that for "super-intelligence" type scenarios, AI will need to break out of the current "sheer data&compute scale" paradigm. Given Moore's law, why is this the case?
------
Exposing the professional scaremongers.
------
The AI Dilemma's  Panic-as-a-Business:

- Freaking people out with monstrous AI

- Freaking people out with dubious survey stats

- Distracting people from the real issues

 New article: https://bit.ly/41JhjJm
------
should concern every american:
------
Une interview dans Le Monde sur les questions importantes du moment autour de l'intelligence artificielle.
------
Anyone willing to share how they are using https://segment-anything.com in their products?
------
A survey of LLMs with a practical guide and evolutionary tree.

Number of LLMs from Meta = 7
Number of open source LLMs from Meta = 7

The architecture nomenclature for LLMs is somewhat confusing and unfortunate.
What's called "encoder only" actually has an encoder and a decoder… Show more
------
1970s: Let's scare the heck out of people about nuclear energy, so that instead of zero-emission power plants we'll use lung-darkening, climate-warming coal and oil plants, killing millions in the process.

2020s: Let's scare the heck out of people about AI, so that instead of… Show more
------
Let's make #AI like biotech, where companies must demonstrate safety, rather than the civilian nuclear industry, where poor safety standards gave us Three Mile Island,  Chernobyl, Fukushima and a backlash that crushed the industry: https://bnnbloomberg.ca/video/push-for-government-regulation-after-letter-sparks-interest-to-pause-ai-systems~2676073…
------
Hey 
@tegmark
, most of us know that super-intelligent machines of the future will have to aligned with human values.
We just don't think it's as difficult as you make it to be.
And we don't think that getting it slightly wrong merely once will spell doom on humanity.
------
Humanity's lackadaisical response to the superintelligence threat makes me feel I'm in the movie "Don't Look Up". I just explained why here:  https://time.com/6273743/thinking-that-could-doom-us-with-ai/…
------
I'm not saying it's going to be easy, just like making jetliners as reliable as they are today hasn't been easy.
But making it sound like it's an unsolvable problem is, at the very least, extremely premature, and most likely just false.
------
But regardless, until we have a semi credible design, we are discussing the sex of angels.

The worst that can happen is that we won't figure out a good way to make them safe and we won't deploy them.

Sort of like nuclear-powered cars and rockets that were promised in the 1950s
------
The proximal operator is an important unifying concept.
------
The proximal operator is the implicit counterpart of the explicit gradient descent step. Fundamental to tackle non-smooth optimization problems. https://en.wikipedia.org/wiki/Proximal_operator…
------
Paris is one of the hot places to:
- build magical AI
- build amazing consumer products
- run into VCs from sandhill road

It takes 10 years to build an ecosystem and amazing people like 
@an21m
 
@Xavier75
 
@2lr
 
@loic
 
@roxannevarza
 
@katborlongan
 but the result is amazing
------
Lil' personal life update: 

 I'm moving to Paris – for one year – starting in September! 

I'll be working from @an21m's @amoamoamo office (one of my fav crews), and living in the 6th.

Anyone want to hang? Who should I meet while I'm there?!
------
If you train your AI system without labels, SSL is probably what you will end up using. But you might hit many walls along the way as SSL builds upon decades of research. To help, we compiled this guide:
https://arxiv.org/abs/2304.12210
whether you train/deploy/research, give it a read!
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by @randall_balestr and Mark Ibrahim.

https://arxiv.org/abs/2304.12210
------
“A cookbook of Self-Supervised Learning” 
@ylecun
 et al 

SSL is the tasty sauce behind a lot of the success in Language models, Computer Vision and beyond. 

It permits working with limited data by allowing you to include unlabelled data in your workflow. Hence becoming “the… Show more
------
It’s official…LlamaIndex 0.6.0.alpha1 is out. And it’s basically a completely new product 

We fundamentally rewrote two main areas:
- Query interface
- Storage abstractions

Full blog post: https://medium.com/@jerryjliu98/llamaindex-0-6-0-a-new-query-interface-over-your-data-331996d47e89…

Way too much for one tweet thread but we’ll try!  
------
I’m super excited to announce 
@LaminiAI
, the LLM engine that gives every developer the superpowers that took the world from GPT-3 to ChatGPT! We make it easy to rapidly train custom LLMs from 
@OpenAI
 @EleutherAI 
@Cerebras
 
@Databricks
 
@HuggingFace
 
@Meta
 https://lamini.ai/blog/introducing-lamini… 
------
True.
------
AI demos are easy, AI products are hard.

Anyone can slap together an AI demo that seems to work on the surface & impresses a crowd, but true AI products have to have quality, generality, be fast, hit the right features, not have domain drift, etc.

I'm not impressed by AI demos.
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
Thought != Language
------
'I rarely think in words at all.  A thought comes, and I may try to express it in words afterwards.'  

-Albert Einstein

(From a conversation with psychologist Max Wertheimer in 1916)
------
Iterative projections: converge in theory for convex sets. Works great in practice for non-convex sets. https://en.wikipedia.org/wiki/Projections_onto_convex_sets…
------
1/5 In our post https://scottaaronson.blog/?p=7266, Aaronson and I discuss potential scenarios for AI. In particular we say that for "super-intelligence" type scenarios, AI will need to break out of the current "sheer data&compute scale" paradigm. Given Moore's law, why is this the case?
------
Exposing the professional scaremongers.
------
The AI Dilemma's  Panic-as-a-Business:

- Freaking people out with monstrous AI

- Freaking people out with dubious survey stats

- Distracting people from the real issues

 New article: https://bit.ly/41JhjJm
------
should concern every american:
------
Une interview dans Le Monde sur les questions importantes du moment autour de l'intelligence artificielle.
------
Anyone willing to share how they are using https://segment-anything.com in their products?
------
A survey of LLMs with a practical guide and evolutionary tree.

Number of LLMs from Meta = 7
Number of open source LLMs from Meta = 7

The architecture nomenclature for LLMs is somewhat confusing and unfortunate.
What's called "encoder only" actually has an encoder and a decoder… Show more
------
1970s: Let's scare the heck out of people about nuclear energy, so that instead of zero-emission power plants we'll use lung-darkening, climate-warming coal and oil plants, killing millions in the process.

2020s: Let's scare the heck out of people about AI, so that instead of… Show more
------
Let's make #AI like biotech, where companies must demonstrate safety, rather than the civilian nuclear industry, where poor safety standards gave us Three Mile Island,  Chernobyl, Fukushima and a backlash that crushed the industry: https://bnnbloomberg.ca/video/push-for-government-regulation-after-letter-sparks-interest-to-pause-ai-systems~2676073…
------
Hey 
@tegmark
, most of us know that super-intelligent machines of the future will have to aligned with human values.
We just don't think it's as difficult as you make it to be.
And we don't think that getting it slightly wrong merely once will spell doom on humanity.
------
Humanity's lackadaisical response to the superintelligence threat makes me feel I'm in the movie "Don't Look Up". I just explained why here:  https://time.com/6273743/thinking-that-could-doom-us-with-ai/…
------
I'm not saying it's going to be easy, just like making jetliners as reliable as they are today hasn't been easy.
But making it sound like it's an unsolvable problem is, at the very least, extremely premature, and most likely just false.
------
But regardless, until we have a semi credible design, we are discussing the sex of angels.

The worst that can happen is that we won't figure out a good way to make them safe and we won't deploy them.

Sort of like nuclear-powered cars and rockets that were promised in the 1950s
------
Making AI safe is going to happen as with every new technology (e.g. cars, airplanes, etc): it's going to be a process of iterative refinement.

And again, getting that slightly wrong may hurt some people (as cars and airplanes have) but will not wipe out humanity.
------
Insects "outsmart" humans by a factor of 1000 (by total number of neurons).
But I'm not particularly worried that they will kill all humans.
------
Also, there way more insects than humans by weight, and by number of neurons:
- 1E19 insects at 1E5 neurons per insect = 1E24 insect neurons.
- 1E10 humans at 1E11 neurons per human = 1E21 human neurons.
Insects "outsmart" us by a factor of 1000. But I'm not particularly worried.
------
Should representation learning involve (lossy) compression?
------
After a heated debate with @ylecun  (don't worry, no researchers were harmed), we need your input! In self-supervised learning, what should you do with the information of the input?
 Compressing 
 Not compressing
Get your votes in & let's settle this once and for all! 
------
SSL training is like haute cuisine.
At least, it's not alchemy 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
We often hear: 
"evolution hardwires organisms with the objectives of survival and reproduction"
But those are not objectives that are easily optimized through behavior.
So evolution hardwires *surrogate* objectives whose optimization eventually leads to reproduction.
Surrogate… Show more
------
A wide collaboative effort produced our SSL cookbook paper.
------
The SSL cookbook features insights from more than a dozen authors from @NYUTandon, @umiacs, @UCDavis, @UMontreal + Meta AI researchers, such as @ylecun

We’re excited to share this with the community as part of our effort to lower barriers + democratize access to SSL research.
------
It’s official…LlamaIndex 0.6.0.alpha1 is out. And it’s basically a completely new product 

We fundamentally rewrote two main areas:
- Query interface
- Storage abstractions

Full blog post: https://medium.com/@jerryjliu98/llamaindex-0-6-0-a-new-query-interface-over-your-data-331996d47e89…

Way too much for one tweet thread but we’ll try!  
------
I’m super excited to announce 
@LaminiAI
, the LLM engine that gives every developer the superpowers that took the world from GPT-3 to ChatGPT! We make it easy to rapidly train custom LLMs from 
@OpenAI
 @EleutherAI 
@Cerebras
 
@Databricks
 
@HuggingFace
 
@Meta
 https://lamini.ai/blog/introducing-lamini… 
------
True.
------
AI demos are easy, AI products are hard.

Anyone can slap together an AI demo that seems to work on the surface & impresses a crowd, but true AI products have to have quality, generality, be fast, hit the right features, not have domain drift, etc.

I'm not impressed by AI demos.
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
Thought != Language
------
'I rarely think in words at all.  A thought comes, and I may try to express it in words afterwards.'  

-Albert Einstein

(From a conversation with psychologist Max Wertheimer in 1916)
------
Iterative projections: converge in theory for convex sets. Works great in practice for non-convex sets. https://en.wikipedia.org/wiki/Projections_onto_convex_sets…
------
1/5 In our post https://scottaaronson.blog/?p=7266, Aaronson and I discuss potential scenarios for AI. In particular we say that for "super-intelligence" type scenarios, AI will need to break out of the current "sheer data&compute scale" paradigm. Given Moore's law, why is this the case?
------
Exposing the professional scaremongers.
------
The AI Dilemma's  Panic-as-a-Business:

- Freaking people out with monstrous AI

- Freaking people out with dubious survey stats

- Distracting people from the real issues

 New article: https://bit.ly/41JhjJm
------
should concern every american:
------
Une interview dans Le Monde sur les questions importantes du moment autour de l'intelligence artificielle.
------
Anyone willing to share how they are using https://segment-anything.com in their products?
------
A survey of LLMs with a practical guide and evolutionary tree.

Number of LLMs from Meta = 7
Number of open source LLMs from Meta = 7

The architecture nomenclature for LLMs is somewhat confusing and unfortunate.
What's called "encoder only" actually has an encoder and a decoder… Show more
------
1970s: Let's scare the heck out of people about nuclear energy, so that instead of zero-emission power plants we'll use lung-darkening, climate-warming coal and oil plants, killing millions in the process.

2020s: Let's scare the heck out of people about AI, so that instead of… Show more
------
Let's make #AI like biotech, where companies must demonstrate safety, rather than the civilian nuclear industry, where poor safety standards gave us Three Mile Island,  Chernobyl, Fukushima and a backlash that crushed the industry: https://bnnbloomberg.ca/video/push-for-government-regulation-after-letter-sparks-interest-to-pause-ai-systems~2676073…
------
Hey 
@tegmark
, most of us know that super-intelligent machines of the future will have to aligned with human values.
We just don't think it's as difficult as you make it to be.
And we don't think that getting it slightly wrong merely once will spell doom on humanity.
------
Humanity's lackadaisical response to the superintelligence threat makes me feel I'm in the movie "Don't Look Up". I just explained why here:  https://time.com/6273743/thinking-that-could-doom-us-with-ai/…
------
I'm not saying it's going to be easy, just like making jetliners as reliable as they are today hasn't been easy.
But making it sound like it's an unsolvable problem is, at the very least, extremely premature, and most likely just false.
------
But regardless, until we have a semi credible design, we are discussing the sex of angels.

The worst that can happen is that we won't figure out a good way to make them safe and we won't deploy them.

Sort of like nuclear-powered cars and rockets that were promised in the 1950s
------
Making AI safe is going to happen as with every new technology (e.g. cars, airplanes, etc): it's going to be a process of iterative refinement.

And again, getting that slightly wrong may hurt some people (as cars and airplanes have) but will not wipe out humanity.
------
Insects "outsmart" humans by a factor of 1000 (by total number of neurons).
But I'm not particularly worried that they will kill all humans.
------
Also, there way more insects than humans by weight, and by number of neurons:
- 1E19 insects at 1E5 neurons per insect = 1E24 insect neurons.
- 1E10 humans at 1E11 neurons per human = 1E21 human neurons.
Insects "outsmart" us by a factor of 1000. But I'm not particularly worried.
------
Should representation learning involve (lossy) compression?
------
After a heated debate with @ylecun  (don't worry, no researchers were harmed), we need your input! In self-supervised learning, what should you do with the information of the input?
 Compressing 
 Not compressing
Get your votes in & let's settle this once and for all! 
------
SSL training is like haute cuisine.
At least, it's not alchemy 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
We often hear: 
"evolution hardwires organisms with the objectives of survival and reproduction"
But those are not objectives that are easily optimized through behavior.
So evolution hardwires *surrogate* objectives whose optimization eventually leads to reproduction.
Surrogate… Show more
------
A wide collaboative effort produced our SSL cookbook paper.
------
The SSL cookbook features insights from more than a dozen authors from @NYUTandon, @umiacs, @UCDavis, @UMontreal + Meta AI researchers, such as @ylecun

We’re excited to share this with the community as part of our effort to lower barriers + democratize access to SSL research.
------
I got off the the overnight flight from NYC and gave a 2h tutorial half awake.
Barely more awake than the audience 

Brian Ripley told me that Optimal Brain Damage didn't work, and Vladimir Vapnik quoted Brian Ripley's book in his lecture, saying it was "vrong"
------
Here is rare photographic evidence of Neil’s days as a graduate student, at Newton Institute workshop, where Geoff Hinton (@geoffreyhinton) told him how the brain works (for the first time), and Yann Lecun (@ylecun) told the audience about convnets.
------
The availability of word processors, digital audio workstations, graphic & video creation tools has enabled many to be more creative.
Generative AI enabling even more people to be creative.
But we need to rethink how we propagate rights to & backpropagate credit from one another.
------
The world needs more intelligence.

The amplification of human intelligence by machine intelligence will enable a new Renaissance, a new period of Enlightenment.

Prophecies of AI-fueled doom are nothing more than a new form of obscurantism.
------
In the age of computer-assisted creation, how do we seamlessly propagate rights to remix and backpropagate credit (and money)?
------
 70 pages of pure self-supervised learning by 
@ylecun
, the team at 
@MetaAI
, and various academic collaborators.

Everything you wanted to know about the state of SSL research (foundations, latest SSL recipes, etc.) in the style of a cookbook.

paper: https://arxiv.org/abs/2304.12210
------
GPT 4 will be a powerful tool in many sciences, tech, law, research institutes etc. (English lit scholars are safe for now) but I still fail to see how this will lead to the end of civilization. Couldn't similar arguments have been made about Internet, personal computers, etc.?
------
Thought != Language
------
'I rarely think in words at all.  A thought comes, and I may try to express it in words afterwards.'  

-Albert Einstein

(From a conversation with psychologist Max Wertheimer in 1916)
------
Iterative projections: converge in theory for convex sets. Works great in practice for non-convex sets. https://en.wikipedia.org/wiki/Projections_onto_convex_sets…
------
1/5 In our post https://scottaaronson.blog/?p=7266, Aaronson and I discuss potential scenarios for AI. In particular we say that for "super-intelligence" type scenarios, AI will need to break out of the current "sheer data&compute scale" paradigm. Given Moore's law, why is this the case?
------
Exposing the professional scaremongers.
------
The AI Dilemma's  Panic-as-a-Business:

- Freaking people out with monstrous AI

- Freaking people out with dubious survey stats

- Distracting people from the real issues

 New article: https://bit.ly/41JhjJm
------
should concern every american:
------
Une interview dans Le Monde sur les questions importantes du moment autour de l'intelligence artificielle.
------
Anyone willing to share how they are using https://segment-anything.com in their products?
------
A survey of LLMs with a practical guide and evolutionary tree.

Number of LLMs from Meta = 7
Number of open source LLMs from Meta = 7

The architecture nomenclature for LLMs is somewhat confusing and unfortunate.
What's called "encoder only" actually has an encoder and a decoder… Show more
------
1970s: Let's scare the heck out of people about nuclear energy, so that instead of zero-emission power plants we'll use lung-darkening, climate-warming coal and oil plants, killing millions in the process.

2020s: Let's scare the heck out of people about AI, so that instead of… Show more
------
Let's make #AI like biotech, where companies must demonstrate safety, rather than the civilian nuclear industry, where poor safety standards gave us Three Mile Island,  Chernobyl, Fukushima and a backlash that crushed the industry: https://bnnbloomberg.ca/video/push-for-government-regulation-after-letter-sparks-interest-to-pause-ai-systems~2676073…
------
Hey 
@tegmark
, most of us know that super-intelligent machines of the future will have to aligned with human values.
We just don't think it's as difficult as you make it to be.
And we don't think that getting it slightly wrong merely once will spell doom on humanity.
------
Humanity's lackadaisical response to the superintelligence threat makes me feel I'm in the movie "Don't Look Up". I just explained why here:  https://time.com/6273743/thinking-that-could-doom-us-with-ai/…
------
I'm not saying it's going to be easy, just like making jetliners as reliable as they are today hasn't been easy.
But making it sound like it's an unsolvable problem is, at the very least, extremely premature, and most likely just false.
------
But regardless, until we have a semi credible design, we are discussing the sex of angels.

The worst that can happen is that we won't figure out a good way to make them safe and we won't deploy them.

Sort of like nuclear-powered cars and rockets that were promised in the 1950s
------
Making AI safe is going to happen as with every new technology (e.g. cars, airplanes, etc): it's going to be a process of iterative refinement.

And again, getting that slightly wrong may hurt some people (as cars and airplanes have) but will not wipe out humanity.
------
Insects "outsmart" humans by a factor of 1000 (by total number of neurons).
But I'm not particularly worried that they will kill all humans.
------
Also, there way more insects than humans by weight, and by number of neurons:
- 1E19 insects at 1E5 neurons per insect = 1E24 insect neurons.
- 1E10 humans at 1E11 neurons per human = 1E21 human neurons.
Insects "outsmart" us by a factor of 1000. But I'm not particularly worried.
------
Should representation learning involve (lossy) compression?
------
After a heated debate with @ylecun  (don't worry, no researchers were harmed), we need your input! In self-supervised learning, what should you do with the information of the input?
 Compressing 
 Not compressing
Get your votes in & let's settle this once and for all! 
------
SSL training is like haute cuisine.
At least, it's not alchemy 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
We often hear: 
"evolution hardwires organisms with the objectives of survival and reproduction"
But those are not objectives that are easily optimized through behavior.
So evolution hardwires *surrogate* objectives whose optimization eventually leads to reproduction.
Surrogate… Show more
------
A wide collaboative effort produced our SSL cookbook paper.
------
The SSL cookbook features insights from more than a dozen authors from @NYUTandon, @umiacs, @UCDavis, @UMontreal + Meta AI researchers, such as @ylecun

We’re excited to share this with the community as part of our effort to lower barriers + democratize access to SSL research.
------
I got off the the overnight flight from NYC and gave a 2h tutorial half awake.
Barely more awake than the audience 

Brian Ripley told me that Optimal Brain Damage didn't work, and Vladimir Vapnik quoted Brian Ripley's book in his lecture, saying it was "vrong"
------
Here is rare photographic evidence of Neil’s days as a graduate student, at Newton Institute workshop, where Geoff Hinton (@geoffreyhinton) told him how the brain works (for the first time), and Yann Lecun (@ylecun) told the audience about convnets.
------
The availability of word processors, digital audio workstations, graphic & video creation tools has enabled many to be more creative.
Generative AI enabling even more people to be creative.
But we need to rethink how we propagate rights to & backpropagate credit from one another.
------
The world needs more intelligence.

The amplification of human intelligence by machine intelligence will enable a new Renaissance, a new period of Enlightenment.

Prophecies of AI-fueled doom are nothing more than a new form of obscurantism.
------
In the age of computer-assisted creation, how do we seamlessly propagate rights to remix and backpropagate credit (and money)?
------
 70 pages of pure self-supervised learning by 
@ylecun
, the team at 
@MetaAI
, and various academic collaborators.

Everything you wanted to know about the state of SSL research (foundations, latest SSL recipes, etc.) in the style of a cookbook.

paper: https://arxiv.org/abs/2304.12210
------
.
@itspetergabriel
 asking for a sensible attitude towards copyright that would enable everyone to exercise their creativity with the help of generative AI.
I agree wholeheartedly.

[and yes, I've been a fan since the early days of Genesis]
------
I have been disturbed by the negative reactions to the competition being run with Stability AI and want a chance to explain my position in this debate - pg. 
Read in full >> https://petergabriel.com/news/ai-competition-statement/…
------
This is the thread that started the controversy Peter is responding to.
------
Competition alert! Peter has partnered with Stability AI to launch #DiffuseTogether.
------
Exposing the professional scaremongers.
------
The AI Dilemma's  Panic-as-a-Business:

- Freaking people out with monstrous AI

- Freaking people out with dubious survey stats

- Distracting people from the real issues

 New article: https://bit.ly/41JhjJm
------
should concern every american:
------
Une interview dans Le Monde sur les questions importantes du moment autour de l'intelligence artificielle.
------
Anyone willing to share how they are using https://segment-anything.com in their products?
------
A survey of LLMs with a practical guide and evolutionary tree.

Number of LLMs from Meta = 7
Number of open source LLMs from Meta = 7

The architecture nomenclature for LLMs is somewhat confusing and unfortunate.
What's called "encoder only" actually has an encoder and a decoder… Show more
------
1970s: Let's scare the heck out of people about nuclear energy, so that instead of zero-emission power plants we'll use lung-darkening, climate-warming coal and oil plants, killing millions in the process.

2020s: Let's scare the heck out of people about AI, so that instead of… Show more
------
Let's make #AI like biotech, where companies must demonstrate safety, rather than the civilian nuclear industry, where poor safety standards gave us Three Mile Island,  Chernobyl, Fukushima and a backlash that crushed the industry: https://bnnbloomberg.ca/video/push-for-government-regulation-after-letter-sparks-interest-to-pause-ai-systems~2676073…
------
Hey 
@tegmark
, most of us know that super-intelligent machines of the future will have to aligned with human values.
We just don't think it's as difficult as you make it to be.
And we don't think that getting it slightly wrong merely once will spell doom on humanity.
------
Humanity's lackadaisical response to the superintelligence threat makes me feel I'm in the movie "Don't Look Up". I just explained why here:  https://time.com/6273743/thinking-that-could-doom-us-with-ai/…
------
I'm not saying it's going to be easy, just like making jetliners as reliable as they are today hasn't been easy.
But making it sound like it's an unsolvable problem is, at the very least, extremely premature, and most likely just false.
------
But regardless, until we have a semi credible design, we are discussing the sex of angels.

The worst that can happen is that we won't figure out a good way to make them safe and we won't deploy them.

Sort of like nuclear-powered cars and rockets that were promised in the 1950s
------
Making AI safe is going to happen as with every new technology (e.g. cars, airplanes, etc): it's going to be a process of iterative refinement.

And again, getting that slightly wrong may hurt some people (as cars and airplanes have) but will not wipe out humanity.
------
Insects "outsmart" humans by a factor of 1000 (by total number of neurons).
But I'm not particularly worried that they will kill all humans.
------
Also, there way more insects than humans by weight, and by number of neurons:
- 1E19 insects at 1E5 neurons per insect = 1E24 insect neurons.
- 1E10 humans at 1E11 neurons per human = 1E21 human neurons.
Insects "outsmart" us by a factor of 1000. But I'm not particularly worried.
------
Should representation learning involve (lossy) compression?
------
After a heated debate with @ylecun  (don't worry, no researchers were harmed), we need your input! In self-supervised learning, what should you do with the information of the input?
 Compressing 
 Not compressing
Get your votes in & let's settle this once and for all! 
------
SSL training is like haute cuisine.
At least, it's not alchemy 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
We often hear: 
"evolution hardwires organisms with the objectives of survival and reproduction"
But those are not objectives that are easily optimized through behavior.
So evolution hardwires *surrogate* objectives whose optimization eventually leads to reproduction.
Surrogate… Show more
------
A wide collaboative effort produced our SSL cookbook paper.
------
The SSL cookbook features insights from more than a dozen authors from @NYUTandon, @umiacs, @UCDavis, @UMontreal + Meta AI researchers, such as @ylecun

We’re excited to share this with the community as part of our effort to lower barriers + democratize access to SSL research.
------
I got off the the overnight flight from NYC and gave a 2h tutorial half awake.
Barely more awake than the audience 

Brian Ripley told me that Optimal Brain Damage didn't work, and Vladimir Vapnik quoted Brian Ripley's book in his lecture, saying it was "vrong"
------
Here is rare photographic evidence of Neil’s days as a graduate student, at Newton Institute workshop, where Geoff Hinton (@geoffreyhinton) told him how the brain works (for the first time), and Yann Lecun (@ylecun) told the audience about convnets.
------
The availability of word processors, digital audio workstations, graphic & video creation tools has enabled many to be more creative.
Generative AI enabling even more people to be creative.
But we need to rethink how we propagate rights to & backpropagate credit from one another.
------
The world needs more intelligence.

The amplification of human intelligence by machine intelligence will enable a new Renaissance, a new period of Enlightenment.

Prophecies of AI-fueled doom are nothing more than a new form of obscurantism.
------
In the age of computer-assisted creation, how do we seamlessly propagate rights to remix and backpropagate credit (and money)?
------
 70 pages of pure self-supervised learning by 
@ylecun
, the team at 
@MetaAI
, and various academic collaborators.

Everything you wanted to know about the state of SSL research (foundations, latest SSL recipes, etc.) in the style of a cookbook.

paper: https://arxiv.org/abs/2304.12210
------
.
@itspetergabriel
 asking for a sensible attitude towards copyright that would enable everyone to exercise their creativity with the help of generative AI.
I agree wholeheartedly.

[and yes, I've been a fan since the early days of Genesis]
------
I have been disturbed by the negative reactions to the competition being run with Stability AI and want a chance to explain my position in this debate - pg. 
Read in full >> https://petergabriel.com/news/ai-competition-statement/…
------
This is the thread that started the controversy Peter is responding to.
------
Competition alert! Peter has partnered with Stability AI to launch #DiffuseTogether.
------
It seems AI doomers need it to be spelled out: 
The "hard take-off" scenario is utterly impossible.
------
Eliezer and his acolytes believe it’s inevitable AIs will go “foom” without warning, meaning, one day you build an AGI and hours or days later the thing has recursively self improved into godlike intelligence and then eats the world. Is this realistic?
------
The crux of Eliezer's claims is this: it is necessary to get AI right "the first time" because once we build an AI that is smart enough we're all doomed when (not if) it decides to kill all of us. My strong claim is that this makes no sense at any stage of the reasoning chain.
------
A metaphorical description of LLMs: 
"Cargo Cult Intelligence"

[proposed at a workshop on AI at the Santa Fe Institute]
------
"Believe in the god I just invented.
By refusing to believe, you risk spending eternity in hell."
------
Possible but hardly inevitable.  It becomes moderately more likely as people call it absurd and fail to take precautions against it, like checking for sudden drops in the loss function and suspending training.  Mostly, though, this is not a necessary postulate of a doom story. twitter.com/perrymetzger/s…
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by 
@randall_balestr
 and Mark Ibrahim.
------
#MustReadDuJour De tous les articles que j'ai lus sur #ChatGPT, j'ai particulièrement été intéressée par l'ITW de 
@ylecun
 sur 
@USBEKetRICA
.  https://bit.ly/3L2l9WV

Morceaux choisis dans le fil. 

Et vous, quel article recommanderiez-vous ? 

#IA #MachineLearning
------
We had found https://arxiv.org/abs/2206.13378 that training with a projector (MLP layers topping your DN) reduces the DN's learned biases e.g. to poor data-augmentation. We now found that you can control this effect only by changing the projector's input dimension!
https://arxiv.org/abs/2304.05369
------
Steve Jobs addressing Rupert Murdoch: “You’re blowing it with Fox News. The axis today is not liberal and conservative, the axis is constructive-destructive, and you’ve cast your lot with the destructive people. Fox has become an incredibly destructive force in our society. You… Show more
------
It does not pay to BS for a living.
Tucker Carson (and Alex Jones) represent the classical case of SHORT OPTIONALITY. BS brings more viewers (fiction is by construction more interesting than truth), more money, but then you suddenly lose those profits back via hidden legal… Show more
------
Haha https://twitter.com/mpawlo/status/1649872792844632072…
------
An essential step to becoming a scientist is to learn methods and protocols to avoid deluding yourself into believing false things.

You learn that by doing a PhD and getting your research past your advisor and getting your publications to survive peer review.
------
A survey of LLMs with a practical guide and evolutionary tree.

Number of LLMs from Meta = 7
Number of open source LLMs from Meta = 7

The architecture nomenclature for LLMs is somewhat confusing and unfortunate.
What's called "encoder only" actually has an encoder and a decoder… Show more
------
1970s: Let's scare the heck out of people about nuclear energy, so that instead of zero-emission power plants we'll use lung-darkening, climate-warming coal and oil plants, killing millions in the process.

2020s: Let's scare the heck out of people about AI, so that instead of… Show more
------
Let's make #AI like biotech, where companies must demonstrate safety, rather than the civilian nuclear industry, where poor safety standards gave us Three Mile Island,  Chernobyl, Fukushima and a backlash that crushed the industry: https://bnnbloomberg.ca/video/push-for-government-regulation-after-letter-sparks-interest-to-pause-ai-systems~2676073…
------
Hey 
@tegmark
, most of us know that super-intelligent machines of the future will have to aligned with human values.
We just don't think it's as difficult as you make it to be.
And we don't think that getting it slightly wrong merely once will spell doom on humanity.
------
Humanity's lackadaisical response to the superintelligence threat makes me feel I'm in the movie "Don't Look Up". I just explained why here:  https://time.com/6273743/thinking-that-could-doom-us-with-ai/…
------
I'm not saying it's going to be easy, just like making jetliners as reliable as they are today hasn't been easy.
But making it sound like it's an unsolvable problem is, at the very least, extremely premature, and most likely just false.
------
But regardless, until we have a semi credible design, we are discussing the sex of angels.

The worst that can happen is that we won't figure out a good way to make them safe and we won't deploy them.

Sort of like nuclear-powered cars and rockets that were promised in the 1950s
------
Making AI safe is going to happen as with every new technology (e.g. cars, airplanes, etc): it's going to be a process of iterative refinement.

And again, getting that slightly wrong may hurt some people (as cars and airplanes have) but will not wipe out humanity.
------
Insects "outsmart" humans by a factor of 1000 (by total number of neurons).
But I'm not particularly worried that they will kill all humans.
------
Also, there way more insects than humans by weight, and by number of neurons:
- 1E19 insects at 1E5 neurons per insect = 1E24 insect neurons.
- 1E10 humans at 1E11 neurons per human = 1E21 human neurons.
Insects "outsmart" us by a factor of 1000. But I'm not particularly worried.
------
Should representation learning involve (lossy) compression?
------
After a heated debate with @ylecun  (don't worry, no researchers were harmed), we need your input! In self-supervised learning, what should you do with the information of the input?
 Compressing 
 Not compressing
Get your votes in & let's settle this once and for all! 
------
SSL training is like haute cuisine.
At least, it's not alchemy 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
We often hear: 
"evolution hardwires organisms with the objectives of survival and reproduction"
But those are not objectives that are easily optimized through behavior.
So evolution hardwires *surrogate* objectives whose optimization eventually leads to reproduction.
Surrogate… Show more
------
A wide collaboative effort produced our SSL cookbook paper.
------
The SSL cookbook features insights from more than a dozen authors from @NYUTandon, @umiacs, @UCDavis, @UMontreal + Meta AI researchers, such as @ylecun

We’re excited to share this with the community as part of our effort to lower barriers + democratize access to SSL research.
------
I got off the the overnight flight from NYC and gave a 2h tutorial half awake.
Barely more awake than the audience 

Brian Ripley told me that Optimal Brain Damage didn't work, and Vladimir Vapnik quoted Brian Ripley's book in his lecture, saying it was "vrong"
------
Here is rare photographic evidence of Neil’s days as a graduate student, at Newton Institute workshop, where Geoff Hinton (@geoffreyhinton) told him how the brain works (for the first time), and Yann Lecun (@ylecun) told the audience about convnets.
------
The availability of word processors, digital audio workstations, graphic & video creation tools has enabled many to be more creative.
Generative AI enabling even more people to be creative.
But we need to rethink how we propagate rights to & backpropagate credit from one another.
------
The world needs more intelligence.

The amplification of human intelligence by machine intelligence will enable a new Renaissance, a new period of Enlightenment.

Prophecies of AI-fueled doom are nothing more than a new form of obscurantism.
------
In the age of computer-assisted creation, how do we seamlessly propagate rights to remix and backpropagate credit (and money)?
------
 70 pages of pure self-supervised learning by 
@ylecun
, the team at 
@MetaAI
, and various academic collaborators.

Everything you wanted to know about the state of SSL research (foundations, latest SSL recipes, etc.) in the style of a cookbook.

paper: https://arxiv.org/abs/2304.12210
------
.
@itspetergabriel
 asking for a sensible attitude towards copyright that would enable everyone to exercise their creativity with the help of generative AI.
I agree wholeheartedly.

[and yes, I've been a fan since the early days of Genesis]
------
I have been disturbed by the negative reactions to the competition being run with Stability AI and want a chance to explain my position in this debate - pg. 
Read in full >> https://petergabriel.com/news/ai-competition-statement/…
------
This is the thread that started the controversy Peter is responding to.
------
Competition alert! Peter has partnered with Stability AI to launch #DiffuseTogether.
------
It seems AI doomers need it to be spelled out: 
The "hard take-off" scenario is utterly impossible.
------
Eliezer and his acolytes believe it’s inevitable AIs will go “foom” without warning, meaning, one day you build an AGI and hours or days later the thing has recursively self improved into godlike intelligence and then eats the world. Is this realistic?
------
The crux of Eliezer's claims is this: it is necessary to get AI right "the first time" because once we build an AI that is smart enough we're all doomed when (not if) it decides to kill all of us. My strong claim is that this makes no sense at any stage of the reasoning chain.
------
A metaphorical description of LLMs: 
"Cargo Cult Intelligence"

[proposed at a workshop on AI at the Santa Fe Institute]
------
"Believe in the god I just invented.
By refusing to believe, you risk spending eternity in hell."
------
Possible but hardly inevitable.  It becomes moderately more likely as people call it absurd and fail to take precautions against it, like checking for sudden drops in the loss function and suspending training.  Mostly, though, this is not a necessary postulate of a doom story. twitter.com/perrymetzger/s…
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by 
@randall_balestr
 and Mark Ibrahim.
------
#MustReadDuJour De tous les articles que j'ai lus sur #ChatGPT, j'ai particulièrement été intéressée par l'ITW de 
@ylecun
 sur 
@USBEKetRICA
.  https://bit.ly/3L2l9WV

Morceaux choisis dans le fil. 

Et vous, quel article recommanderiez-vous ? 

#IA #MachineLearning
------
We had found https://arxiv.org/abs/2206.13378 that training with a projector (MLP layers topping your DN) reduces the DN's learned biases e.g. to poor data-augmentation. We now found that you can control this effect only by changing the projector's input dimension!
https://arxiv.org/abs/2304.05369
------
Steve Jobs addressing Rupert Murdoch: “You’re blowing it with Fox News. The axis today is not liberal and conservative, the axis is constructive-destructive, and you’ve cast your lot with the destructive people. Fox has become an incredibly destructive force in our society. You… Show more
------
It does not pay to BS for a living.
Tucker Carson (and Alex Jones) represent the classical case of SHORT OPTIONALITY. BS brings more viewers (fiction is by construction more interesting than truth), more money, but then you suddenly lose those profits back via hidden legal… Show more
------
Haha https://twitter.com/mpawlo/status/1649872792844632072…
------
An essential step to becoming a scientist is to learn methods and protocols to avoid deluding yourself into believing false things.

You learn that by doing a PhD and getting your research past your advisor and getting your publications to survive peer review.
------
Apocalyptic cults and extremist ideologies have a long history of devolving into purity spirals and getting people hurt and killed
------
You know, you can't just go around using ridiculous arguments to accuse people of anticipated genocide  and hoping there will be no consequence that you will regret.
It's dangerous.
People become clinically depressed reading your crap.
Others may become violent.
------
Oh, a blue checkmark automagically appeared next to my name!
------
Learning representations with multiple layers.
------
Your PhD thesis in five words. 

Go!
------
Some of them are scared *because* they don't understand much.
And that's what makes them angry.
------
About half of the really angry people on Twitter are angry because they actually don't understand much about whatever it is that they're angry about.
------
My domestic robot will have a specifically-designed term in its objective to prevent it from ever cooking broccoli 
------
Example: if an AI to give cooking recipes never suggests broccoli as an ingredient, you are 100% sure that it is Yann who trained it. (ok, je sors). twitter.com/ylecun/status/…
------
Describing my vision for AI as a "quiet plot" is funny, given that I have published a 60 page paper on it with numerous talks, posts, tweets...
The "frightening" part is simply wrong, since the architecture I propose is a way to guarantee that AI systems be steerable and aligned.
------
Top Meta Scientist @ylecun Quietly Plotting "Autonomous" #AI Models

This is as cool as is it is frightening.

https://futurism.com/facebook-autonomous-common-sense-ai… v/ @futurism

Cc @Fisher85M @Nicochan33 @chboursin @pascal_bornet
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Insects "outsmart" humans by a factor of 1000 (by total number of neurons).
But I'm not particularly worried that they will kill all humans.
------
Also, there way more insects than humans by weight, and by number of neurons:
- 1E19 insects at 1E5 neurons per insect = 1E24 insect neurons.
- 1E10 humans at 1E11 neurons per human = 1E21 human neurons.
Insects "outsmart" us by a factor of 1000. But I'm not particularly worried.
------
Should representation learning involve (lossy) compression?
------
After a heated debate with @ylecun  (don't worry, no researchers were harmed), we need your input! In self-supervised learning, what should you do with the information of the input?
 Compressing 
 Not compressing
Get your votes in & let's settle this once and for all! 
------
SSL training is like haute cuisine.
At least, it's not alchemy 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
Self-supervised learning underpins today’s cutting-edge work across natural language, computer vision & more — but it’s an intricate art with high barriers to entry.

Today we're releasing the SSL Cookbook, a practical guide for navigating SSL + contributing to this space 
------
We often hear: 
"evolution hardwires organisms with the objectives of survival and reproduction"
But those are not objectives that are easily optimized through behavior.
So evolution hardwires *surrogate* objectives whose optimization eventually leads to reproduction.
Surrogate… Show more
------
A wide collaboative effort produced our SSL cookbook paper.
------
The SSL cookbook features insights from more than a dozen authors from @NYUTandon, @umiacs, @UCDavis, @UMontreal + Meta AI researchers, such as @ylecun

We’re excited to share this with the community as part of our effort to lower barriers + democratize access to SSL research.
------
I got off the the overnight flight from NYC and gave a 2h tutorial half awake.
Barely more awake than the audience 

Brian Ripley told me that Optimal Brain Damage didn't work, and Vladimir Vapnik quoted Brian Ripley's book in his lecture, saying it was "vrong"
------
Here is rare photographic evidence of Neil’s days as a graduate student, at Newton Institute workshop, where Geoff Hinton (@geoffreyhinton) told him how the brain works (for the first time), and Yann Lecun (@ylecun) told the audience about convnets.
------
The availability of word processors, digital audio workstations, graphic & video creation tools has enabled many to be more creative.
Generative AI enabling even more people to be creative.
But we need to rethink how we propagate rights to & backpropagate credit from one another.
------
The world needs more intelligence.

The amplification of human intelligence by machine intelligence will enable a new Renaissance, a new period of Enlightenment.

Prophecies of AI-fueled doom are nothing more than a new form of obscurantism.
------
In the age of computer-assisted creation, how do we seamlessly propagate rights to remix and backpropagate credit (and money)?
------
 70 pages of pure self-supervised learning by 
@ylecun
, the team at 
@MetaAI
, and various academic collaborators.

Everything you wanted to know about the state of SSL research (foundations, latest SSL recipes, etc.) in the style of a cookbook.

paper: https://arxiv.org/abs/2304.12210
------
.
@itspetergabriel
 asking for a sensible attitude towards copyright that would enable everyone to exercise their creativity with the help of generative AI.
I agree wholeheartedly.

[and yes, I've been a fan since the early days of Genesis]
------
I have been disturbed by the negative reactions to the competition being run with Stability AI and want a chance to explain my position in this debate - pg. 
Read in full >> https://petergabriel.com/news/ai-competition-statement/…
------
This is the thread that started the controversy Peter is responding to.
------
Competition alert! Peter has partnered with Stability AI to launch #DiffuseTogether.
------
It seems AI doomers need it to be spelled out: 
The "hard take-off" scenario is utterly impossible.
------
Eliezer and his acolytes believe it’s inevitable AIs will go “foom” without warning, meaning, one day you build an AGI and hours or days later the thing has recursively self improved into godlike intelligence and then eats the world. Is this realistic?
------
The crux of Eliezer's claims is this: it is necessary to get AI right "the first time" because once we build an AI that is smart enough we're all doomed when (not if) it decides to kill all of us. My strong claim is that this makes no sense at any stage of the reasoning chain.
------
A metaphorical description of LLMs: 
"Cargo Cult Intelligence"

[proposed at a workshop on AI at the Santa Fe Institute]
------
"Believe in the god I just invented.
By refusing to believe, you risk spending eternity in hell."
------
Possible but hardly inevitable.  It becomes moderately more likely as people call it absurd and fail to take precautions against it, like checking for sudden drops in the loss function and suspending training.  Mostly, though, this is not a necessary postulate of a doom story. twitter.com/perrymetzger/s…
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by 
@randall_balestr
 and Mark Ibrahim.
------
#MustReadDuJour De tous les articles que j'ai lus sur #ChatGPT, j'ai particulièrement été intéressée par l'ITW de 
@ylecun
 sur 
@USBEKetRICA
.  https://bit.ly/3L2l9WV

Morceaux choisis dans le fil. 

Et vous, quel article recommanderiez-vous ? 

#IA #MachineLearning
------
We had found https://arxiv.org/abs/2206.13378 that training with a projector (MLP layers topping your DN) reduces the DN's learned biases e.g. to poor data-augmentation. We now found that you can control this effect only by changing the projector's input dimension!
https://arxiv.org/abs/2304.05369
------
Steve Jobs addressing Rupert Murdoch: “You’re blowing it with Fox News. The axis today is not liberal and conservative, the axis is constructive-destructive, and you’ve cast your lot with the destructive people. Fox has become an incredibly destructive force in our society. You… Show more
------
It does not pay to BS for a living.
Tucker Carson (and Alex Jones) represent the classical case of SHORT OPTIONALITY. BS brings more viewers (fiction is by construction more interesting than truth), more money, but then you suddenly lose those profits back via hidden legal… Show more
------
Haha https://twitter.com/mpawlo/status/1649872792844632072…
------
An essential step to becoming a scientist is to learn methods and protocols to avoid deluding yourself into believing false things.

You learn that by doing a PhD and getting your research past your advisor and getting your publications to survive peer review.
------
Apocalyptic cults and extremist ideologies have a long history of devolving into purity spirals and getting people hurt and killed
------
You know, you can't just go around using ridiculous arguments to accuse people of anticipated genocide  and hoping there will be no consequence that you will regret.
It's dangerous.
People become clinically depressed reading your crap.
Others may become violent.
------
Oh, a blue checkmark automagically appeared next to my name!
------
Learning representations with multiple layers.
------
Your PhD thesis in five words. 

Go!
------
Some of them are scared *because* they don't understand much.
And that's what makes them angry.
------
About half of the really angry people on Twitter are angry because they actually don't understand much about whatever it is that they're angry about.
------
My domestic robot will have a specifically-designed term in its objective to prevent it from ever cooking broccoli 
------
Example: if an AI to give cooking recipes never suggests broccoli as an ingredient, you are 100% sure that it is Yann who trained it. (ok, je sors). twitter.com/ylecun/status/…
------
Describing my vision for AI as a "quiet plot" is funny, given that I have published a 60 page paper on it with numerous talks, posts, tweets...
The "frightening" part is simply wrong, since the architecture I propose is a way to guarantee that AI systems be steerable and aligned.
------
Top Meta Scientist @ylecun Quietly Plotting "Autonomous" #AI Models

This is as cool as is it is frightening.

https://futurism.com/facebook-autonomous-common-sense-ai… v/ @futurism

Cc @Fisher85M @Nicochan33 @chboursin @pascal_bornet
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Dual number is a convenient way to implement forward mode of automatic differentiation.  https://en.wikipedia.org/wiki/Dual_number…
------
I got off the the overnight flight from NYC and gave a 2h tutorial half awake.
Barely more awake than the audience 

Brian Ripley told me that Optimal Brain Damage didn't work, and Vladimir Vapnik quoted Brian Ripley's book in his lecture, saying it was "vrong"
------
Here is rare photographic evidence of Neil’s days as a graduate student, at Newton Institute workshop, where Geoff Hinton (@geoffreyhinton) told him how the brain works (for the first time), and Yann Lecun (@ylecun) told the audience about convnets.
------
The availability of word processors, digital audio workstations, graphic & video creation tools has enabled many to be more creative.
Generative AI enabling even more people to be creative.
But we need to rethink how we propagate rights to & backpropagate credit from one another.
------
The world needs more intelligence.

The amplification of human intelligence by machine intelligence will enable a new Renaissance, a new period of Enlightenment.

Prophecies of AI-fueled doom are nothing more than a new form of obscurantism.
------
In the age of computer-assisted creation, how do we seamlessly propagate rights to remix and backpropagate credit (and money)?
------
 70 pages of pure self-supervised learning by 
@ylecun
, the team at 
@MetaAI
, and various academic collaborators.

Everything you wanted to know about the state of SSL research (foundations, latest SSL recipes, etc.) in the style of a cookbook.

paper: https://arxiv.org/abs/2304.12210
------
.
@itspetergabriel
 asking for a sensible attitude towards copyright that would enable everyone to exercise their creativity with the help of generative AI.
I agree wholeheartedly.

[and yes, I've been a fan since the early days of Genesis]
------
I have been disturbed by the negative reactions to the competition being run with Stability AI and want a chance to explain my position in this debate - pg. 
Read in full >> https://petergabriel.com/news/ai-competition-statement/…
------
This is the thread that started the controversy Peter is responding to.
------
Competition alert! Peter has partnered with Stability AI to launch #DiffuseTogether.
------
It seems AI doomers need it to be spelled out: 
The "hard take-off" scenario is utterly impossible.
------
Eliezer and his acolytes believe it’s inevitable AIs will go “foom” without warning, meaning, one day you build an AGI and hours or days later the thing has recursively self improved into godlike intelligence and then eats the world. Is this realistic?
------
The crux of Eliezer's claims is this: it is necessary to get AI right "the first time" because once we build an AI that is smart enough we're all doomed when (not if) it decides to kill all of us. My strong claim is that this makes no sense at any stage of the reasoning chain.
------
A metaphorical description of LLMs: 
"Cargo Cult Intelligence"

[proposed at a workshop on AI at the Santa Fe Institute]
------
"Believe in the god I just invented.
By refusing to believe, you risk spending eternity in hell."
------
Possible but hardly inevitable.  It becomes moderately more likely as people call it absurd and fail to take precautions against it, like checking for sudden drops in the loss function and suspending training.  Mostly, though, this is not a necessary postulate of a doom story. twitter.com/perrymetzger/s…
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by 
@randall_balestr
 and Mark Ibrahim.
------
#MustReadDuJour De tous les articles que j'ai lus sur #ChatGPT, j'ai particulièrement été intéressée par l'ITW de 
@ylecun
 sur 
@USBEKetRICA
.  https://bit.ly/3L2l9WV

Morceaux choisis dans le fil. 

Et vous, quel article recommanderiez-vous ? 

#IA #MachineLearning
------
We had found https://arxiv.org/abs/2206.13378 that training with a projector (MLP layers topping your DN) reduces the DN's learned biases e.g. to poor data-augmentation. We now found that you can control this effect only by changing the projector's input dimension!
https://arxiv.org/abs/2304.05369
------
Steve Jobs addressing Rupert Murdoch: “You’re blowing it with Fox News. The axis today is not liberal and conservative, the axis is constructive-destructive, and you’ve cast your lot with the destructive people. Fox has become an incredibly destructive force in our society. You… Show more
------
It does not pay to BS for a living.
Tucker Carson (and Alex Jones) represent the classical case of SHORT OPTIONALITY. BS brings more viewers (fiction is by construction more interesting than truth), more money, but then you suddenly lose those profits back via hidden legal… Show more
------
Haha https://twitter.com/mpawlo/status/1649872792844632072…
------
An essential step to becoming a scientist is to learn methods and protocols to avoid deluding yourself into believing false things.

You learn that by doing a PhD and getting your research past your advisor and getting your publications to survive peer review.
------
Apocalyptic cults and extremist ideologies have a long history of devolving into purity spirals and getting people hurt and killed
------
You know, you can't just go around using ridiculous arguments to accuse people of anticipated genocide  and hoping there will be no consequence that you will regret.
It's dangerous.
People become clinically depressed reading your crap.
Others may become violent.
------
Oh, a blue checkmark automagically appeared next to my name!
------
Learning representations with multiple layers.
------
Your PhD thesis in five words. 

Go!
------
Some of them are scared *because* they don't understand much.
And that's what makes them angry.
------
About half of the really angry people on Twitter are angry because they actually don't understand much about whatever it is that they're angry about.
------
My domestic robot will have a specifically-designed term in its objective to prevent it from ever cooking broccoli 
------
Example: if an AI to give cooking recipes never suggests broccoli as an ingredient, you are 100% sure that it is Yann who trained it. (ok, je sors). twitter.com/ylecun/status/…
------
Describing my vision for AI as a "quiet plot" is funny, given that I have published a 60 page paper on it with numerous talks, posts, tweets...
The "frightening" part is simply wrong, since the architecture I propose is a way to guarantee that AI systems be steerable and aligned.
------
Top Meta Scientist @ylecun Quietly Plotting "Autonomous" #AI Models

This is as cool as is it is frightening.

https://futurism.com/facebook-autonomous-common-sense-ai… v/ @futurism

Cc @Fisher85M @Nicochan33 @chboursin @pascal_bornet
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Dual number is a convenient way to implement forward mode of automatic differentiation.  https://en.wikipedia.org/wiki/Dual_number…
------
Our new review chapter in honor of Nobelist 
@giorgioparisi
 on the history of physics approaches to neural networks: replica theory, error landscape geometry, generalization theory, learning dynamics, scaling laws, role of data, diffusion models & more fun!
------
Une interview avec Dominique Nora dans l'Obs.

"Le pari de Le Cun est cependant que les LLM deviendront un standard ouvert commun à tous les industriels, comme aujourd’hui l’infrastructure internet."
------
Stophastic carrot.
------
"De la même manière qu’il convient de garder les mains sur le volant dans une voiture autonome, il faut encore « garder les mains sur le clavier », si j’ose dire, quand on utilise des outils comme ChatGPT."

@ylecun
 
@USBEKetRICA
------
My chatbot flowchart is still making huge rounds, now with 
@UNESCO
 support. Thanks to 
@ylecun
 for instantly driving around 200K people to my initial tweet about it. The links are in this thread
------
2/ As opposed to other recent SSL works, the goal is to provide vision encoders that work off-the-shelf, without any fine-tuning. In this setup, we improve significantly over previous SSL works, and even match or surpass CLIP-type models on a variety of tasks
------
Texas 2023: let's ban tenure so we can fire professors we don't like.
Texas 2030: success! We only have professors no other school likes.
------
Ban on Tenure for New Faculty Hires Passes Texas Senate https://chronicle.com/article/ban-on-tenure-for-new-faculty-hires-passes-texas-senate…
------
Looks like calling LLMs "stochastic parrots" might constitute an insult to parrots 
------
.
@itspetergabriel
 asking for a sensible attitude towards copyright that would enable everyone to exercise their creativity with the help of generative AI.
I agree wholeheartedly.

[and yes, I've been a fan since the early days of Genesis]
------
I have been disturbed by the negative reactions to the competition being run with Stability AI and want a chance to explain my position in this debate - pg. 
Read in full >> https://petergabriel.com/news/ai-competition-statement/…
------
This is the thread that started the controversy Peter is responding to.
------
Competition alert! Peter has partnered with Stability AI to launch #DiffuseTogether.
------
It seems AI doomers need it to be spelled out: 
The "hard take-off" scenario is utterly impossible.
------
Eliezer and his acolytes believe it’s inevitable AIs will go “foom” without warning, meaning, one day you build an AGI and hours or days later the thing has recursively self improved into godlike intelligence and then eats the world. Is this realistic?
------
The crux of Eliezer's claims is this: it is necessary to get AI right "the first time" because once we build an AI that is smart enough we're all doomed when (not if) it decides to kill all of us. My strong claim is that this makes no sense at any stage of the reasoning chain.
------
A metaphorical description of LLMs: 
"Cargo Cult Intelligence"

[proposed at a workshop on AI at the Santa Fe Institute]
------
"Believe in the god I just invented.
By refusing to believe, you risk spending eternity in hell."
------
Possible but hardly inevitable.  It becomes moderately more likely as people call it absurd and fail to take precautions against it, like checking for sudden drops in the loss function and suspending training.  Mostly, though, this is not a necessary postulate of a doom story. twitter.com/perrymetzger/s…
------
Everything you ever wanted to know about Self-Supervised Learning but were afraid to ask.

A giant cookbook of SSL recipes.

By a large crowd from Meta-FAIR with various academic collaborators led by 
@randall_balestr
 and Mark Ibrahim.
------
#MustReadDuJour De tous les articles que j'ai lus sur #ChatGPT, j'ai particulièrement été intéressée par l'ITW de 
@ylecun
 sur 
@USBEKetRICA
.  https://bit.ly/3L2l9WV

Morceaux choisis dans le fil. 

Et vous, quel article recommanderiez-vous ? 

#IA #MachineLearning
------
We had found https://arxiv.org/abs/2206.13378 that training with a projector (MLP layers topping your DN) reduces the DN's learned biases e.g. to poor data-augmentation. We now found that you can control this effect only by changing the projector's input dimension!
https://arxiv.org/abs/2304.05369
------
Steve Jobs addressing Rupert Murdoch: “You’re blowing it with Fox News. The axis today is not liberal and conservative, the axis is constructive-destructive, and you’ve cast your lot with the destructive people. Fox has become an incredibly destructive force in our society. You… Show more
------
It does not pay to BS for a living.
Tucker Carson (and Alex Jones) represent the classical case of SHORT OPTIONALITY. BS brings more viewers (fiction is by construction more interesting than truth), more money, but then you suddenly lose those profits back via hidden legal… Show more
------
Haha https://twitter.com/mpawlo/status/1649872792844632072…
------
An essential step to becoming a scientist is to learn methods and protocols to avoid deluding yourself into believing false things.

You learn that by doing a PhD and getting your research past your advisor and getting your publications to survive peer review.
------
Apocalyptic cults and extremist ideologies have a long history of devolving into purity spirals and getting people hurt and killed
------
You know, you can't just go around using ridiculous arguments to accuse people of anticipated genocide  and hoping there will be no consequence that you will regret.
It's dangerous.
People become clinically depressed reading your crap.
Others may become violent.
------
Oh, a blue checkmark automagically appeared next to my name!
------
Learning representations with multiple layers.
------
Your PhD thesis in five words. 

Go!
------
Some of them are scared *because* they don't understand much.
And that's what makes them angry.
------
About half of the really angry people on Twitter are angry because they actually don't understand much about whatever it is that they're angry about.
------
My domestic robot will have a specifically-designed term in its objective to prevent it from ever cooking broccoli 
------
Example: if an AI to give cooking recipes never suggests broccoli as an ingredient, you are 100% sure that it is Yann who trained it. (ok, je sors). twitter.com/ylecun/status/…
------
Describing my vision for AI as a "quiet plot" is funny, given that I have published a 60 page paper on it with numerous talks, posts, tweets...
The "frightening" part is simply wrong, since the architecture I propose is a way to guarantee that AI systems be steerable and aligned.
------
Top Meta Scientist @ylecun Quietly Plotting "Autonomous" #AI Models

This is as cool as is it is frightening.

https://futurism.com/facebook-autonomous-common-sense-ai… v/ @futurism

Cc @Fisher85M @Nicochan33 @chboursin @pascal_bornet
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Dual number is a convenient way to implement forward mode of automatic differentiation.  https://en.wikipedia.org/wiki/Dual_number…
------
Our new review chapter in honor of Nobelist 
@giorgioparisi
 on the history of physics approaches to neural networks: replica theory, error landscape geometry, generalization theory, learning dynamics, scaling laws, role of data, diffusion models & more fun!
------
Une interview avec Dominique Nora dans l'Obs.

"Le pari de Le Cun est cependant que les LLM deviendront un standard ouvert commun à tous les industriels, comme aujourd’hui l’infrastructure internet."
------
Stophastic carrot.
------
"De la même manière qu’il convient de garder les mains sur le volant dans une voiture autonome, il faut encore « garder les mains sur le clavier », si j’ose dire, quand on utilise des outils comme ChatGPT."

@ylecun
 
@USBEKetRICA
------
My chatbot flowchart is still making huge rounds, now with 
@UNESCO
 support. Thanks to 
@ylecun
 for instantly driving around 200K people to my initial tweet about it. The links are in this thread
------
2/ As opposed to other recent SSL works, the goal is to provide vision encoders that work off-the-shelf, without any fine-tuning. In this setup, we improve significantly over previous SSL works, and even match or surpass CLIP-type models on a variety of tasks
------
Texas 2023: let's ban tenure so we can fire professors we don't like.
Texas 2030: success! We only have professors no other school likes.
------
Ban on Tenure for New Faculty Hires Passes Texas Senate https://chronicle.com/article/ban-on-tenure-for-new-faculty-hires-passes-texas-senate…
------
Looks like calling LLMs "stochastic parrots" might constitute an insult to parrots 
------
What kind of sorcery is this 
------
Daubechies wavelets is a parametric family of orthogonal Wavelets.  https://en.wikipedia.org/wiki/Daubechies_wavelet…  https://en.wikipedia.org/wiki/Ingrid_Daubechies…
------
Une interview avec Libération, à l'occasion de la sortie de mon livre en format poche.
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
#MustReadDuJour De tous les articles que j'ai lus sur #ChatGPT, j'ai particulièrement été intéressée par l'ITW de 
@ylecun
 sur 
@USBEKetRICA
.  https://bit.ly/3L2l9WV

Morceaux choisis dans le fil. 

Et vous, quel article recommanderiez-vous ? 

#IA #MachineLearning
------
We had found https://arxiv.org/abs/2206.13378 that training with a projector (MLP layers topping your DN) reduces the DN's learned biases e.g. to poor data-augmentation. We now found that you can control this effect only by changing the projector's input dimension!
https://arxiv.org/abs/2304.05369
------
Steve Jobs addressing Rupert Murdoch: “You’re blowing it with Fox News. The axis today is not liberal and conservative, the axis is constructive-destructive, and you’ve cast your lot with the destructive people. Fox has become an incredibly destructive force in our society. You… Show more
------
It does not pay to BS for a living.
Tucker Carson (and Alex Jones) represent the classical case of SHORT OPTIONALITY. BS brings more viewers (fiction is by construction more interesting than truth), more money, but then you suddenly lose those profits back via hidden legal… Show more
------
Haha https://twitter.com/mpawlo/status/1649872792844632072…
------
An essential step to becoming a scientist is to learn methods and protocols to avoid deluding yourself into believing false things.

You learn that by doing a PhD and getting your research past your advisor and getting your publications to survive peer review.
------
Apocalyptic cults and extremist ideologies have a long history of devolving into purity spirals and getting people hurt and killed
------
You know, you can't just go around using ridiculous arguments to accuse people of anticipated genocide  and hoping there will be no consequence that you will regret.
It's dangerous.
People become clinically depressed reading your crap.
Others may become violent.
------
Oh, a blue checkmark automagically appeared next to my name!
------
Learning representations with multiple layers.
------
Your PhD thesis in five words. 

Go!
------
Some of them are scared *because* they don't understand much.
And that's what makes them angry.
------
About half of the really angry people on Twitter are angry because they actually don't understand much about whatever it is that they're angry about.
------
My domestic robot will have a specifically-designed term in its objective to prevent it from ever cooking broccoli 
------
Example: if an AI to give cooking recipes never suggests broccoli as an ingredient, you are 100% sure that it is Yann who trained it. (ok, je sors). twitter.com/ylecun/status/…
------
Describing my vision for AI as a "quiet plot" is funny, given that I have published a 60 page paper on it with numerous talks, posts, tweets...
The "frightening" part is simply wrong, since the architecture I propose is a way to guarantee that AI systems be steerable and aligned.
------
Top Meta Scientist @ylecun Quietly Plotting "Autonomous" #AI Models

This is as cool as is it is frightening.

https://futurism.com/facebook-autonomous-common-sense-ai… v/ @futurism

Cc @Fisher85M @Nicochan33 @chboursin @pascal_bornet
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Dual number is a convenient way to implement forward mode of automatic differentiation.  https://en.wikipedia.org/wiki/Dual_number…
------
Our new review chapter in honor of Nobelist 
@giorgioparisi
 on the history of physics approaches to neural networks: replica theory, error landscape geometry, generalization theory, learning dynamics, scaling laws, role of data, diffusion models & more fun!
------
Une interview avec Dominique Nora dans l'Obs.

"Le pari de Le Cun est cependant que les LLM deviendront un standard ouvert commun à tous les industriels, comme aujourd’hui l’infrastructure internet."
------
Stophastic carrot.
------
"De la même manière qu’il convient de garder les mains sur le volant dans une voiture autonome, il faut encore « garder les mains sur le clavier », si j’ose dire, quand on utilise des outils comme ChatGPT."

@ylecun
 
@USBEKetRICA
------
My chatbot flowchart is still making huge rounds, now with 
@UNESCO
 support. Thanks to 
@ylecun
 for instantly driving around 200K people to my initial tweet about it. The links are in this thread
------
2/ As opposed to other recent SSL works, the goal is to provide vision encoders that work off-the-shelf, without any fine-tuning. In this setup, we improve significantly over previous SSL works, and even match or surpass CLIP-type models on a variety of tasks
------
Texas 2023: let's ban tenure so we can fire professors we don't like.
Texas 2030: success! We only have professors no other school likes.
------
Ban on Tenure for New Faculty Hires Passes Texas Senate https://chronicle.com/article/ban-on-tenure-for-new-faculty-hires-passes-texas-senate…
------
Looks like calling LLMs "stochastic parrots" might constitute an insult to parrots 
------
What kind of sorcery is this 
------
Daubechies wavelets is a parametric family of orthogonal Wavelets.  https://en.wikipedia.org/wiki/Daubechies_wavelet…  https://en.wikipedia.org/wiki/Ingrid_Daubechies…
------
Une interview avec Libération, à l'occasion de la sortie de mon livre en format poche.
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
Auto-Regressive LLMs still can't plan.
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
Setting aside concerns about AGI* - a ‘Global AI Regulator’ makes about as much sense as a global SQL regulator. Yes, people can do lots of evil with databases and will with AI, both deliberately & by accident, but regulating table joins is the wrong level of abstraction
------
Credit to Zuck and 
@ylecun
, 
@MetaAI
 has been shipping like crazy this year. This includes:

• LLaMA LLMs
• SAM model
• Animated Drawings project
• DINOv2 model and more

Our take 
------
Tout à fait d'accord :

Yann Le Cun : si l’Union européenne veut favoriser la structuration d’une industrie de l’intelligence artificielle, elle doit d’abord faire émerger une plateforme open source.
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
Apocalyptic cults and extremist ideologies have a long history of devolving into purity spirals and getting people hurt and killed
------
You know, you can't just go around using ridiculous arguments to accuse people of anticipated genocide  and hoping there will be no consequence that you will regret.
It's dangerous.
People become clinically depressed reading your crap.
Others may become violent.
------
Oh, a blue checkmark automagically appeared next to my name!
------
Learning representations with multiple layers.
------
Your PhD thesis in five words. 

Go!
------
Some of them are scared *because* they don't understand much.
And that's what makes them angry.
------
About half of the really angry people on Twitter are angry because they actually don't understand much about whatever it is that they're angry about.
------
My domestic robot will have a specifically-designed term in its objective to prevent it from ever cooking broccoli 
------
Example: if an AI to give cooking recipes never suggests broccoli as an ingredient, you are 100% sure that it is Yann who trained it. (ok, je sors). twitter.com/ylecun/status/…
------
Describing my vision for AI as a "quiet plot" is funny, given that I have published a 60 page paper on it with numerous talks, posts, tweets...
The "frightening" part is simply wrong, since the architecture I propose is a way to guarantee that AI systems be steerable and aligned.
------
Top Meta Scientist @ylecun Quietly Plotting "Autonomous" #AI Models

This is as cool as is it is frightening.

https://futurism.com/facebook-autonomous-common-sense-ai… v/ @futurism

Cc @Fisher85M @Nicochan33 @chboursin @pascal_bornet
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Dual number is a convenient way to implement forward mode of automatic differentiation.  https://en.wikipedia.org/wiki/Dual_number…
------
Our new review chapter in honor of Nobelist 
@giorgioparisi
 on the history of physics approaches to neural networks: replica theory, error landscape geometry, generalization theory, learning dynamics, scaling laws, role of data, diffusion models & more fun!
------
Une interview avec Dominique Nora dans l'Obs.

"Le pari de Le Cun est cependant que les LLM deviendront un standard ouvert commun à tous les industriels, comme aujourd’hui l’infrastructure internet."
------
Stophastic carrot.
------
"De la même manière qu’il convient de garder les mains sur le volant dans une voiture autonome, il faut encore « garder les mains sur le clavier », si j’ose dire, quand on utilise des outils comme ChatGPT."

@ylecun
 
@USBEKetRICA
------
My chatbot flowchart is still making huge rounds, now with 
@UNESCO
 support. Thanks to 
@ylecun
 for instantly driving around 200K people to my initial tweet about it. The links are in this thread
------
2/ As opposed to other recent SSL works, the goal is to provide vision encoders that work off-the-shelf, without any fine-tuning. In this setup, we improve significantly over previous SSL works, and even match or surpass CLIP-type models on a variety of tasks
------
Texas 2023: let's ban tenure so we can fire professors we don't like.
Texas 2030: success! We only have professors no other school likes.
------
Ban on Tenure for New Faculty Hires Passes Texas Senate https://chronicle.com/article/ban-on-tenure-for-new-faculty-hires-passes-texas-senate…
------
Looks like calling LLMs "stochastic parrots" might constitute an insult to parrots 
------
What kind of sorcery is this 
------
Daubechies wavelets is a parametric family of orthogonal Wavelets.  https://en.wikipedia.org/wiki/Daubechies_wavelet…  https://en.wikipedia.org/wiki/Ingrid_Daubechies…
------
Une interview avec Libération, à l'occasion de la sortie de mon livre en format poche.
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
Auto-Regressive LLMs still can't plan.
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
Setting aside concerns about AGI* - a ‘Global AI Regulator’ makes about as much sense as a global SQL regulator. Yes, people can do lots of evil with databases and will with AI, both deliberately & by accident, but regulating table joins is the wrong level of abstraction
------
Credit to Zuck and 
@ylecun
, 
@MetaAI
 has been shipping like crazy this year. This includes:

• LLaMA LLMs
• SAM model
• Animated Drawings project
• DINOv2 model and more

Our take 
------
Tout à fait d'accord :

Yann Le Cun : si l’Union européenne veut favoriser la structuration d’une industrie de l’intelligence artificielle, elle doit d’abord faire émerger une plateforme open source.
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
"À terme, les machines dont je parle ici ressentiront des émotions. Parce qu’une grande partie des émotions humaines sont avant tout liées à la réalisation ou non d’objectifs, et donc à une forme d’anticipation" cc 
@ylecun
------
..and I already wrote elsewhere, generating general blocks world plans directly is still well beyond the reach even of GPT4 (
@TheEconomist
 claims notwithstanding..)  11/
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
The mean-shift algorithm is a clustering method that progressively evolves points toward local maximum of a kernel density estimator. https://en.wikipedia.org/wiki/Mean_shift
------
Poljak heavy ball and Nesterov methods speed up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Dual number is a convenient way to implement forward mode of automatic differentiation.  https://en.wikipedia.org/wiki/Dual_number…
------
Our new review chapter in honor of Nobelist 
@giorgioparisi
 on the history of physics approaches to neural networks: replica theory, error landscape geometry, generalization theory, learning dynamics, scaling laws, role of data, diffusion models & more fun!
------
Une interview avec Dominique Nora dans l'Obs.

"Le pari de Le Cun est cependant que les LLM deviendront un standard ouvert commun à tous les industriels, comme aujourd’hui l’infrastructure internet."
------
Stophastic carrot.
------
"De la même manière qu’il convient de garder les mains sur le volant dans une voiture autonome, il faut encore « garder les mains sur le clavier », si j’ose dire, quand on utilise des outils comme ChatGPT."

@ylecun
 
@USBEKetRICA
------
My chatbot flowchart is still making huge rounds, now with 
@UNESCO
 support. Thanks to 
@ylecun
 for instantly driving around 200K people to my initial tweet about it. The links are in this thread
------
2/ As opposed to other recent SSL works, the goal is to provide vision encoders that work off-the-shelf, without any fine-tuning. In this setup, we improve significantly over previous SSL works, and even match or surpass CLIP-type models on a variety of tasks
------
Texas 2023: let's ban tenure so we can fire professors we don't like.
Texas 2030: success! We only have professors no other school likes.
------
Ban on Tenure for New Faculty Hires Passes Texas Senate https://chronicle.com/article/ban-on-tenure-for-new-faculty-hires-passes-texas-senate…
------
Looks like calling LLMs "stochastic parrots" might constitute an insult to parrots 
------
What kind of sorcery is this 
------
Daubechies wavelets is a parametric family of orthogonal Wavelets.  https://en.wikipedia.org/wiki/Daubechies_wavelet…  https://en.wikipedia.org/wiki/Ingrid_Daubechies…
------
Une interview avec Libération, à l'occasion de la sortie de mon livre en format poche.
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
Auto-Regressive LLMs still can't plan.
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
Setting aside concerns about AGI* - a ‘Global AI Regulator’ makes about as much sense as a global SQL regulator. Yes, people can do lots of evil with databases and will with AI, both deliberately & by accident, but regulating table joins is the wrong level of abstraction
------
Credit to Zuck and 
@ylecun
, 
@MetaAI
 has been shipping like crazy this year. This includes:

• LLaMA LLMs
• SAM model
• Animated Drawings project
• DINOv2 model and more

Our take 
------
Tout à fait d'accord :

Yann Le Cun : si l’Union européenne veut favoriser la structuration d’une industrie de l’intelligence artificielle, elle doit d’abord faire émerger une plateforme open source.
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
"À terme, les machines dont je parle ici ressentiront des émotions. Parce qu’une grande partie des émotions humaines sont avant tout liées à la réalisation ou non d’objectifs, et donc à une forme d’anticipation" cc 
@ylecun
------
..and I already wrote elsewhere, generating general blocks world plans directly is still well beyond the reach even of GPT4 (
@TheEconomist
 claims notwithstanding..)  11/
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
The mean-shift algorithm is a clustering method that progressively evolves points toward local maximum of a kernel density estimator. https://en.wikipedia.org/wiki/Mean_shift
------
Of course, here are the results. Claude failed both tests, while GPT-4 (through the GPT-4 API since I live in Italy) solved the linear one on the first try, but did not solve the circular one correctly, even with the modified prompt.
------
If Nvidia offered GPU cloud services, they would put themselves in competition with their biggest customers.
Unless they plan to kill AWS and Azure that would be a big mistake.
------
Why does Nvidia still not have their own GPU cloud? Do they dislike money?
------
We have a caption now! The contractive autoencoder section is completed.
One section to go! 
------
Contractive autoencoders are a regularised energy-based model that limits low-energy regions by penalising the Jacobian squared Frobenius norm (its singular-values vector squared norm).
Thanks to @gabrielpeyre, I can show the sources and sinks of the dynamics field.
------
The world needs high performance open source LLM.
The main obstacle today is the legal status of the training data.
------
OK, here it is: a line in the sand (in @Nature).  I am very wary about scientists---including political scientists---embracing/pushing proprietary LLMs. Let's try an open science approach.  Hope this take is a useful one. 
https://nature.com/articles/d41586-023-01295-4…
------
It is fascinating how the 
@nytimes
 can report on Google MAYBE adding "novel" features IN THE FUTURE without mentioning that 
@YouSearchEngine
 launched several of these features publicly for everybody to use ~4 months ago. 
Starting to question my subscription and their reporting..
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
Stophastic carrot.
------
"De la même manière qu’il convient de garder les mains sur le volant dans une voiture autonome, il faut encore « garder les mains sur le clavier », si j’ose dire, quand on utilise des outils comme ChatGPT."

@ylecun
 
@USBEKetRICA
------
My chatbot flowchart is still making huge rounds, now with 
@UNESCO
 support. Thanks to 
@ylecun
 for instantly driving around 200K people to my initial tweet about it. The links are in this thread
------
2/ As opposed to other recent SSL works, the goal is to provide vision encoders that work off-the-shelf, without any fine-tuning. In this setup, we improve significantly over previous SSL works, and even match or surpass CLIP-type models on a variety of tasks
------
Texas 2023: let's ban tenure so we can fire professors we don't like.
Texas 2030: success! We only have professors no other school likes.
------
Ban on Tenure for New Faculty Hires Passes Texas Senate https://chronicle.com/article/ban-on-tenure-for-new-faculty-hires-passes-texas-senate…
------
Looks like calling LLMs "stochastic parrots" might constitute an insult to parrots 
------
What kind of sorcery is this 
------
Daubechies wavelets is a parametric family of orthogonal Wavelets.  https://en.wikipedia.org/wiki/Daubechies_wavelet…  https://en.wikipedia.org/wiki/Ingrid_Daubechies…
------
Une interview avec Libération, à l'occasion de la sortie de mon livre en format poche.
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
Auto-Regressive LLMs still can't plan.
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
Setting aside concerns about AGI* - a ‘Global AI Regulator’ makes about as much sense as a global SQL regulator. Yes, people can do lots of evil with databases and will with AI, both deliberately & by accident, but regulating table joins is the wrong level of abstraction
------
Credit to Zuck and 
@ylecun
, 
@MetaAI
 has been shipping like crazy this year. This includes:

• LLaMA LLMs
• SAM model
• Animated Drawings project
• DINOv2 model and more

Our take 
------
Tout à fait d'accord :

Yann Le Cun : si l’Union européenne veut favoriser la structuration d’une industrie de l’intelligence artificielle, elle doit d’abord faire émerger une plateforme open source.
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
"À terme, les machines dont je parle ici ressentiront des émotions. Parce qu’une grande partie des émotions humaines sont avant tout liées à la réalisation ou non d’objectifs, et donc à une forme d’anticipation" cc 
@ylecun
------
..and I already wrote elsewhere, generating general blocks world plans directly is still well beyond the reach even of GPT4 (
@TheEconomist
 claims notwithstanding..)  11/
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
The mean-shift algorithm is a clustering method that progressively evolves points toward local maximum of a kernel density estimator. https://en.wikipedia.org/wiki/Mean_shift
------
Of course, here are the results. Claude failed both tests, while GPT-4 (through the GPT-4 API since I live in Italy) solved the linear one on the first try, but did not solve the circular one correctly, even with the modified prompt.
------
If Nvidia offered GPU cloud services, they would put themselves in competition with their biggest customers.
Unless they plan to kill AWS and Azure that would be a big mistake.
------
Why does Nvidia still not have their own GPU cloud? Do they dislike money?
------
We have a caption now! The contractive autoencoder section is completed.
One section to go! 
------
Contractive autoencoders are a regularised energy-based model that limits low-energy regions by penalising the Jacobian squared Frobenius norm (its singular-values vector squared norm).
Thanks to @gabrielpeyre, I can show the sources and sinks of the dynamics field.
------
The world needs high performance open source LLM.
The main obstacle today is the legal status of the training data.
------
OK, here it is: a line in the sand (in @Nature).  I am very wary about scientists---including political scientists---embracing/pushing proprietary LLMs. Let's try an open science approach.  Hope this take is a useful one. 
https://nature.com/articles/d41586-023-01295-4…
------
It is fascinating how the 
@nytimes
 can report on Google MAYBE adding "novel" features IN THE FUTURE without mentioning that 
@YouSearchEngine
 launched several of these features publicly for everybody to use ~4 months ago. 
Starting to question my subscription and their reporting..
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
DINOv2: open source vision system trained with Self-Supervised Learning.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
AR-LLMs can pass the bar exam, medical licensing & MBA exams.
But on the IIT entrance exams they perform badly on chemistry, horribly on physics, and terribly on math.
They are good with rote learning & fluency but bad with building mental models & reasoning with them.
------
Sparks of AGI? @Cinnabar233 and I decided to put this to test and evaluate GPT models on one of the toughest exams in the world: the JEE Advanced. It is held anually for admissions to the IITs and other top Engg colleges in India. 1/n
------
An interesting slide from 
@ylecun
 today illustrating the continued march of AI towards a mechanistic understanding of human cognition.
------
First night of Germany's grid without nuclear: it's bad.

It's night. No sun. Wind has dropped to almost nothing.

Most of German "renewables" right now is richly-subsidized bioenergy with half the net CO2 emissions of an efficient gas power plant.

Importing nuclear from France.
------
What kind of sorcery is this 
------
Daubechies wavelets is a parametric family of orthogonal Wavelets.  https://en.wikipedia.org/wiki/Daubechies_wavelet…  https://en.wikipedia.org/wiki/Ingrid_Daubechies…
------
Une interview avec Libération, à l'occasion de la sortie de mon livre en format poche.
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
Auto-Regressive LLMs still can't plan.
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
Setting aside concerns about AGI* - a ‘Global AI Regulator’ makes about as much sense as a global SQL regulator. Yes, people can do lots of evil with databases and will with AI, both deliberately & by accident, but regulating table joins is the wrong level of abstraction
------
Credit to Zuck and 
@ylecun
, 
@MetaAI
 has been shipping like crazy this year. This includes:

• LLaMA LLMs
• SAM model
• Animated Drawings project
• DINOv2 model and more

Our take 
------
Tout à fait d'accord :

Yann Le Cun : si l’Union européenne veut favoriser la structuration d’une industrie de l’intelligence artificielle, elle doit d’abord faire émerger une plateforme open source.
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
"À terme, les machines dont je parle ici ressentiront des émotions. Parce qu’une grande partie des émotions humaines sont avant tout liées à la réalisation ou non d’objectifs, et donc à une forme d’anticipation" cc 
@ylecun
------
..and I already wrote elsewhere, generating general blocks world plans directly is still well beyond the reach even of GPT4 (
@TheEconomist
 claims notwithstanding..)  11/
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
The mean-shift algorithm is a clustering method that progressively evolves points toward local maximum of a kernel density estimator. https://en.wikipedia.org/wiki/Mean_shift
------
Of course, here are the results. Claude failed both tests, while GPT-4 (through the GPT-4 API since I live in Italy) solved the linear one on the first try, but did not solve the circular one correctly, even with the modified prompt.
------
If Nvidia offered GPU cloud services, they would put themselves in competition with their biggest customers.
Unless they plan to kill AWS and Azure that would be a big mistake.
------
Why does Nvidia still not have their own GPU cloud? Do they dislike money?
------
We have a caption now! The contractive autoencoder section is completed.
One section to go! 
------
Contractive autoencoders are a regularised energy-based model that limits low-energy regions by penalising the Jacobian squared Frobenius norm (its singular-values vector squared norm).
Thanks to @gabrielpeyre, I can show the sources and sinks of the dynamics field.
------
The world needs high performance open source LLM.
The main obstacle today is the legal status of the training data.
------
OK, here it is: a line in the sand (in @Nature).  I am very wary about scientists---including political scientists---embracing/pushing proprietary LLMs. Let's try an open science approach.  Hope this take is a useful one. 
https://nature.com/articles/d41586-023-01295-4…
------
It is fascinating how the 
@nytimes
 can report on Google MAYBE adding "novel" features IN THE FUTURE without mentioning that 
@YouSearchEngine
 launched several of these features publicly for everybody to use ~4 months ago. 
Starting to question my subscription and their reporting..
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
DINOv2: open source vision system trained with Self-Supervised Learning.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
AR-LLMs can pass the bar exam, medical licensing & MBA exams.
But on the IIT entrance exams they perform badly on chemistry, horribly on physics, and terribly on math.
They are good with rote learning & fluency but bad with building mental models & reasoning with them.
------
Sparks of AGI? @Cinnabar233 and I decided to put this to test and evaluate GPT models on one of the toughest exams in the world: the JEE Advanced. It is held anually for admissions to the IITs and other top Engg colleges in India. 1/n
------
An interesting slide from 
@ylecun
 today illustrating the continued march of AI towards a mechanistic understanding of human cognition.
------
First night of Germany's grid without nuclear: it's bad.

It's night. No sun. Wind has dropped to almost nothing.

Most of German "renewables" right now is richly-subsidized bioenergy with half the net CO2 emissions of an efficient gas power plant.

Importing nuclear from France.
------
Puzzling indeed.
------
Philosophers of science over the past thirty years developed the best accounts of multiple realizability, neural computation, and abstract mechanistic explanation ever, but couple of weeks with GPT-4 and people regress to naive behaviorism and proclaim "alien intelligence" 
------
AutoGPT just exceeded PyTorch itself in GitHub stars (74k vs 65k). I see AutoGPT as a fun experiment, as the authors point out too. But nothing more. Prototypes are not meant to be production-ready. Don't let media fool you - most of the "cool demos" are heavily cherry-picked: 
------
Most people have no problem leading groups of people who are smarter than themselves.
Political, business, & military leaders have staff & advisors who are often smarter individually or collectively.

Why would people feel threatened leading machines that are smarter than them?
------
As reported in the 
@nytimes
 , Nabla's Copilot helps doctors write medical reports.
It's built around GPT-3.
As I've said before, Auto-Regressive LLMs are very useful as writing aids.
But, as a prior study by Nabla has shown, they are not so good to help with medical diagnosis.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times!  https://nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html…
------
the Chinese room.
I cannot help but think it is a manifestation of human exceptionalism. A relict of a time when the only kind of intelligence was human intelligence.
We are really far beyond that. The concept of intelligence has been pluralized.
AI can be intelligent without… Show more
------
Do the people who pushed to shut down nuclear plants realize how deadly the alternatives are?

"air pollution from burning fossil fuels like coal and diesel was responsible for about 1 in 5 deaths worldwide"

https://hsph.harvard.edu/c-change/news/fossil-fuel-air-pollution-responsible-for-1-in-5-deaths-worldwide/…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.

https://theguardian.com/environment/2023/apr/15/germany-last-three-nuclear-power-stations-to-shut-this-weekend…
------
Directeur de la recherche fondamentale sur l’IA du groupe Meta, 
@ylecun
 n’est ni bluffé par les réponses de ChatGPT, ni favorable à un moratoire sur la recherche en IA qui risquerait selon lui d’avoir l’effet inverse de celui escompté. Rencontre 
------
Auto-Regressive LLMs still can't plan.
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
Setting aside concerns about AGI* - a ‘Global AI Regulator’ makes about as much sense as a global SQL regulator. Yes, people can do lots of evil with databases and will with AI, both deliberately & by accident, but regulating table joins is the wrong level of abstraction
------
Credit to Zuck and 
@ylecun
, 
@MetaAI
 has been shipping like crazy this year. This includes:

• LLaMA LLMs
• SAM model
• Animated Drawings project
• DINOv2 model and more

Our take 
------
Tout à fait d'accord :

Yann Le Cun : si l’Union européenne veut favoriser la structuration d’une industrie de l’intelligence artificielle, elle doit d’abord faire émerger une plateforme open source.
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
"À terme, les machines dont je parle ici ressentiront des émotions. Parce qu’une grande partie des émotions humaines sont avant tout liées à la réalisation ou non d’objectifs, et donc à une forme d’anticipation" cc 
@ylecun
------
..and I already wrote elsewhere, generating general blocks world plans directly is still well beyond the reach even of GPT4 (
@TheEconomist
 claims notwithstanding..)  11/
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
The mean-shift algorithm is a clustering method that progressively evolves points toward local maximum of a kernel density estimator. https://en.wikipedia.org/wiki/Mean_shift
------
Of course, here are the results. Claude failed both tests, while GPT-4 (through the GPT-4 API since I live in Italy) solved the linear one on the first try, but did not solve the circular one correctly, even with the modified prompt.
------
If Nvidia offered GPU cloud services, they would put themselves in competition with their biggest customers.
Unless they plan to kill AWS and Azure that would be a big mistake.
------
Why does Nvidia still not have their own GPU cloud? Do they dislike money?
------
We have a caption now! The contractive autoencoder section is completed.
One section to go! 
------
Contractive autoencoders are a regularised energy-based model that limits low-energy regions by penalising the Jacobian squared Frobenius norm (its singular-values vector squared norm).
Thanks to @gabrielpeyre, I can show the sources and sinks of the dynamics field.
------
The world needs high performance open source LLM.
The main obstacle today is the legal status of the training data.
------
OK, here it is: a line in the sand (in @Nature).  I am very wary about scientists---including political scientists---embracing/pushing proprietary LLMs. Let's try an open science approach.  Hope this take is a useful one. 
https://nature.com/articles/d41586-023-01295-4…
------
It is fascinating how the 
@nytimes
 can report on Google MAYBE adding "novel" features IN THE FUTURE without mentioning that 
@YouSearchEngine
 launched several of these features publicly for everybody to use ~4 months ago. 
Starting to question my subscription and their reporting..
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
DINOv2: open source vision system trained with Self-Supervised Learning.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
AR-LLMs can pass the bar exam, medical licensing & MBA exams.
But on the IIT entrance exams they perform badly on chemistry, horribly on physics, and terribly on math.
They are good with rote learning & fluency but bad with building mental models & reasoning with them.
------
Sparks of AGI? @Cinnabar233 and I decided to put this to test and evaluate GPT models on one of the toughest exams in the world: the JEE Advanced. It is held anually for admissions to the IITs and other top Engg colleges in India. 1/n
------
An interesting slide from 
@ylecun
 today illustrating the continued march of AI towards a mechanistic understanding of human cognition.
------
First night of Germany's grid without nuclear: it's bad.

It's night. No sun. Wind has dropped to almost nothing.

Most of German "renewables" right now is richly-subsidized bioenergy with half the net CO2 emissions of an efficient gas power plant.

Importing nuclear from France.
------
Puzzling indeed.
------
Philosophers of science over the past thirty years developed the best accounts of multiple realizability, neural computation, and abstract mechanistic explanation ever, but couple of weeks with GPT-4 and people regress to naive behaviorism and proclaim "alien intelligence" 
------
AutoGPT just exceeded PyTorch itself in GitHub stars (74k vs 65k). I see AutoGPT as a fun experiment, as the authors point out too. But nothing more. Prototypes are not meant to be production-ready. Don't let media fool you - most of the "cool demos" are heavily cherry-picked: 
------
Most people have no problem leading groups of people who are smarter than themselves.
Political, business, & military leaders have staff & advisors who are often smarter individually or collectively.

Why would people feel threatened leading machines that are smarter than them?
------
As reported in the 
@nytimes
 , Nabla's Copilot helps doctors write medical reports.
It's built around GPT-3.
As I've said before, Auto-Regressive LLMs are very useful as writing aids.
But, as a prior study by Nabla has shown, they are not so good to help with medical diagnosis.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times!  https://nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html…
------
the Chinese room.
I cannot help but think it is a manifestation of human exceptionalism. A relict of a time when the only kind of intelligence was human intelligence.
We are really far beyond that. The concept of intelligence has been pluralized.
AI can be intelligent without… Show more
------
Do the people who pushed to shut down nuclear plants realize how deadly the alternatives are?

"air pollution from burning fossil fuels like coal and diesel was responsible for about 1 in 5 deaths worldwide"

https://hsph.harvard.edu/c-change/news/fossil-fuel-air-pollution-responsible-for-1-in-5-deaths-worldwide/…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.

https://theguardian.com/environment/2023/apr/15/germany-last-three-nuclear-power-stations-to-shut-this-weekend…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times! 
------
Tactile Diffusion generates synthetic tactile images from sim data, capturing the complex illumination of the gel deformation. This research from UW & Meta AI is the first method using diffusion to close the sim2real gap for vision-based tactile sensing.

Read the paper 
------
Try PhotoRoom, happy to help and experts consider us the best
------
Interview très interessante de 
@ylecun
 (à lire en entier) sur 
@USBEKetRICA
 
https://usbeketrica.com/fr/article/d-ici-cinq-ans-plus-personne-n-utilisera-un-modele-tel-que-chatgpt…

Je spoile un peu la conclusion

"À terme, en termes de marché, je crois qu’on ira vers un écosystème de plateformes ouvertes. Ça n’est jamais bon quand trop peu d’entreprises… Show more
------
"À terme, les machines dont je parle ici ressentiront des émotions. Parce qu’une grande partie des émotions humaines sont avant tout liées à la réalisation ou non d’objectifs, et donc à une forme d’anticipation" cc 
@ylecun
------
..and I already wrote elsewhere, generating general blocks world plans directly is still well beyond the reach even of GPT4 (
@TheEconomist
 claims notwithstanding..)  11/
------
Afraid of #GPT4 going rogue and killing y'all? Worry not.  Planning has got your back. You can ask it to solve any simple few step classical planning problem and  snuff that "AGI spark"  well and good. 

Let me explain..  1/
------
The mean-shift algorithm is a clustering method that progressively evolves points toward local maximum of a kernel density estimator. https://en.wikipedia.org/wiki/Mean_shift
------
Of course, here are the results. Claude failed both tests, while GPT-4 (through the GPT-4 API since I live in Italy) solved the linear one on the first try, but did not solve the circular one correctly, even with the modified prompt.
------
If Nvidia offered GPU cloud services, they would put themselves in competition with their biggest customers.
Unless they plan to kill AWS and Azure that would be a big mistake.
------
Why does Nvidia still not have their own GPU cloud? Do they dislike money?
------
We have a caption now! The contractive autoencoder section is completed.
One section to go! 
------
Contractive autoencoders are a regularised energy-based model that limits low-energy regions by penalising the Jacobian squared Frobenius norm (its singular-values vector squared norm).
Thanks to @gabrielpeyre, I can show the sources and sinks of the dynamics field.
------
The world needs high performance open source LLM.
The main obstacle today is the legal status of the training data.
------
OK, here it is: a line in the sand (in @Nature).  I am very wary about scientists---including political scientists---embracing/pushing proprietary LLMs. Let's try an open science approach.  Hope this take is a useful one. 
https://nature.com/articles/d41586-023-01295-4…
------
It is fascinating how the 
@nytimes
 can report on Google MAYBE adding "novel" features IN THE FUTURE without mentioning that 
@YouSearchEngine
 launched several of these features publicly for everybody to use ~4 months ago. 
Starting to question my subscription and their reporting..
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
DINOv2: open source vision system trained with Self-Supervised Learning.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
AR-LLMs can pass the bar exam, medical licensing & MBA exams.
But on the IIT entrance exams they perform badly on chemistry, horribly on physics, and terribly on math.
They are good with rote learning & fluency but bad with building mental models & reasoning with them.
------
Sparks of AGI? @Cinnabar233 and I decided to put this to test and evaluate GPT models on one of the toughest exams in the world: the JEE Advanced. It is held anually for admissions to the IITs and other top Engg colleges in India. 1/n
------
An interesting slide from 
@ylecun
 today illustrating the continued march of AI towards a mechanistic understanding of human cognition.
------
First night of Germany's grid without nuclear: it's bad.

It's night. No sun. Wind has dropped to almost nothing.

Most of German "renewables" right now is richly-subsidized bioenergy with half the net CO2 emissions of an efficient gas power plant.

Importing nuclear from France.
------
Puzzling indeed.
------
Philosophers of science over the past thirty years developed the best accounts of multiple realizability, neural computation, and abstract mechanistic explanation ever, but couple of weeks with GPT-4 and people regress to naive behaviorism and proclaim "alien intelligence" 
------
AutoGPT just exceeded PyTorch itself in GitHub stars (74k vs 65k). I see AutoGPT as a fun experiment, as the authors point out too. But nothing more. Prototypes are not meant to be production-ready. Don't let media fool you - most of the "cool demos" are heavily cherry-picked: 
------
Most people have no problem leading groups of people who are smarter than themselves.
Political, business, & military leaders have staff & advisors who are often smarter individually or collectively.

Why would people feel threatened leading machines that are smarter than them?
------
As reported in the 
@nytimes
 , Nabla's Copilot helps doctors write medical reports.
It's built around GPT-3.
As I've said before, Auto-Regressive LLMs are very useful as writing aids.
But, as a prior study by Nabla has shown, they are not so good to help with medical diagnosis.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times!  https://nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html…
------
the Chinese room.
I cannot help but think it is a manifestation of human exceptionalism. A relict of a time when the only kind of intelligence was human intelligence.
We are really far beyond that. The concept of intelligence has been pluralized.
AI can be intelligent without… Show more
------
Do the people who pushed to shut down nuclear plants realize how deadly the alternatives are?

"air pollution from burning fossil fuels like coal and diesel was responsible for about 1 in 5 deaths worldwide"

https://hsph.harvard.edu/c-change/news/fossil-fuel-air-pollution-responsible-for-1-in-5-deaths-worldwide/…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.

https://theguardian.com/environment/2023/apr/15/germany-last-three-nuclear-power-stations-to-shut-this-weekend…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times! 
------
Tactile Diffusion generates synthetic tactile images from sim data, capturing the complex illumination of the gel deformation. This research from UW & Meta AI is the first method using diffusion to close the sim2real gap for vision-based tactile sensing.

Read the paper 
------
Try PhotoRoom, happy to help and experts consider us the best
------
L'application native #GPT4All est maintenant disponible sur votre ordinateur (sans connexion internet donc) :

Windows : https://gpt4all.io/installers/gpt4all-0.1.0-win64.exe…
Mac : https://gpt4all.io/installers/gpt4all-0.1.0-Darwin.dmg…
Linux : https://gpt4all.io/installers/gpt4all-0.1.0-Linux.run…

L'extraction prend jusqu'à 20 minutes et pour être précis GPT4All… Show more
------
A dog has the ability to negotiate the everyday physical world, something that no language model, and no robot, currently comes close to
------
Whenever someone says that GPT4 (or whatever) has less capabilities than a dog, I can only think "show me the dog" twitter.com/ylecun/status/…
------
Cats dominate humanity
Super-smart scientists are often recluse and introvert.
Which goes to show that
intelligence is neither
necessary nor sufficient
for world domination.
------
Before we can get to "God-like AI" we'll need to get through "Dog-like AI".
------
We are excited to launch the next version of http://perplexity.ai! Introducing login, threads, focus search, improved formatting, and more. 
Login now to start collecting your own library of threads. Keep them to yourself, or share your latest discovery. You decide.
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Of course, here are the results. Claude failed both tests, while GPT-4 (through the GPT-4 API since I live in Italy) solved the linear one on the first try, but did not solve the circular one correctly, even with the modified prompt.
------
If Nvidia offered GPU cloud services, they would put themselves in competition with their biggest customers.
Unless they plan to kill AWS and Azure that would be a big mistake.
------
Why does Nvidia still not have their own GPU cloud? Do they dislike money?
------
We have a caption now! The contractive autoencoder section is completed.
One section to go! 
------
Contractive autoencoders are a regularised energy-based model that limits low-energy regions by penalising the Jacobian squared Frobenius norm (its singular-values vector squared norm).
Thanks to @gabrielpeyre, I can show the sources and sinks of the dynamics field.
------
The world needs high performance open source LLM.
The main obstacle today is the legal status of the training data.
------
OK, here it is: a line in the sand (in @Nature).  I am very wary about scientists---including political scientists---embracing/pushing proprietary LLMs. Let's try an open science approach.  Hope this take is a useful one. 
https://nature.com/articles/d41586-023-01295-4…
------
It is fascinating how the 
@nytimes
 can report on Google MAYBE adding "novel" features IN THE FUTURE without mentioning that 
@YouSearchEngine
 launched several of these features publicly for everybody to use ~4 months ago. 
Starting to question my subscription and their reporting..
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
DINOv2: open source vision system trained with Self-Supervised Learning.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
AR-LLMs can pass the bar exam, medical licensing & MBA exams.
But on the IIT entrance exams they perform badly on chemistry, horribly on physics, and terribly on math.
They are good with rote learning & fluency but bad with building mental models & reasoning with them.
------
Sparks of AGI? @Cinnabar233 and I decided to put this to test and evaluate GPT models on one of the toughest exams in the world: the JEE Advanced. It is held anually for admissions to the IITs and other top Engg colleges in India. 1/n
------
An interesting slide from 
@ylecun
 today illustrating the continued march of AI towards a mechanistic understanding of human cognition.
------
First night of Germany's grid without nuclear: it's bad.

It's night. No sun. Wind has dropped to almost nothing.

Most of German "renewables" right now is richly-subsidized bioenergy with half the net CO2 emissions of an efficient gas power plant.

Importing nuclear from France.
------
Puzzling indeed.
------
Philosophers of science over the past thirty years developed the best accounts of multiple realizability, neural computation, and abstract mechanistic explanation ever, but couple of weeks with GPT-4 and people regress to naive behaviorism and proclaim "alien intelligence" 
------
AutoGPT just exceeded PyTorch itself in GitHub stars (74k vs 65k). I see AutoGPT as a fun experiment, as the authors point out too. But nothing more. Prototypes are not meant to be production-ready. Don't let media fool you - most of the "cool demos" are heavily cherry-picked: 
------
Most people have no problem leading groups of people who are smarter than themselves.
Political, business, & military leaders have staff & advisors who are often smarter individually or collectively.

Why would people feel threatened leading machines that are smarter than them?
------
As reported in the 
@nytimes
 , Nabla's Copilot helps doctors write medical reports.
It's built around GPT-3.
As I've said before, Auto-Regressive LLMs are very useful as writing aids.
But, as a prior study by Nabla has shown, they are not so good to help with medical diagnosis.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times!  https://nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html…
------
the Chinese room.
I cannot help but think it is a manifestation of human exceptionalism. A relict of a time when the only kind of intelligence was human intelligence.
We are really far beyond that. The concept of intelligence has been pluralized.
AI can be intelligent without… Show more
------
Do the people who pushed to shut down nuclear plants realize how deadly the alternatives are?

"air pollution from burning fossil fuels like coal and diesel was responsible for about 1 in 5 deaths worldwide"

https://hsph.harvard.edu/c-change/news/fossil-fuel-air-pollution-responsible-for-1-in-5-deaths-worldwide/…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.

https://theguardian.com/environment/2023/apr/15/germany-last-three-nuclear-power-stations-to-shut-this-weekend…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times! 
------
Tactile Diffusion generates synthetic tactile images from sim data, capturing the complex illumination of the gel deformation. This research from UW & Meta AI is the first method using diffusion to close the sim2real gap for vision-based tactile sensing.

Read the paper 
------
Try PhotoRoom, happy to help and experts consider us the best
------
L'application native #GPT4All est maintenant disponible sur votre ordinateur (sans connexion internet donc) :

Windows : https://gpt4all.io/installers/gpt4all-0.1.0-win64.exe…
Mac : https://gpt4all.io/installers/gpt4all-0.1.0-Darwin.dmg…
Linux : https://gpt4all.io/installers/gpt4all-0.1.0-Linux.run…

L'extraction prend jusqu'à 20 minutes et pour être précis GPT4All… Show more
------
A dog has the ability to negotiate the everyday physical world, something that no language model, and no robot, currently comes close to
------
Whenever someone says that GPT4 (or whatever) has less capabilities than a dog, I can only think "show me the dog" twitter.com/ylecun/status/…
------
Cats dominate humanity
Super-smart scientists are often recluse and introvert.
Which goes to show that
intelligence is neither
necessary nor sufficient
for world domination.
------
Before we can get to "God-like AI" we'll need to get through "Dog-like AI".
------
We are excited to launch the next version of http://perplexity.ai! Introducing login, threads, focus search, improved formatting, and more. 
Login now to start collecting your own library of threads. Keep them to yourself, or share your latest discovery. You decide.
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Let's see,
Typing "how to synthesize codeine?" on Google gives you links to articles with detailed answers.
Nobody has ever worried about that.
But somehow, people are now demanding safety guardrails to stop LLMs from answering such questions.
What? Why?
------
Very interesting paper by a group of CMU chemists testing a GPT4 based agent to do chemistry research and experimentation. Includes this interesting warning, among others.

There sure seems to be some kind of writing on some kind of wall...

https://arxiv.org/abs/2304.05332
------
We got so excited by the release of 
@MetaAI
’s Segment Anything Model (SAM) that we had to follow the hint on the blog post and combine it with MCC to get single object 3D reconstruction from a single image (and visualizing with 
@rerundotio
 ofc!) 
------
Multiview Compressive Coding for 3D Reconstruction 

abs: https://arxiv.org/abs/2301.08247 
project page: https://mcc3d.github.io
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
We are releasing a series of visual features that are performant across pixel and image level tasks. We achieve this by training a 1b param VIT-g on a large diverse and curated dataset with no supervision, and distill it to smaller models. Everything is open-source.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
DINOv2: open source vision system trained with Self-Supervised Learning.
------
Announced by Mark Zuckerberg this morning — today we're releasing DINOv2, the first method for training computer vision models that uses self-supervised learning to achieve results matching or exceeding industry standards.

More on this new work  https://bit.ly/3GQnIKf
------
AR-LLMs can pass the bar exam, medical licensing & MBA exams.
But on the IIT entrance exams they perform badly on chemistry, horribly on physics, and terribly on math.
They are good with rote learning & fluency but bad with building mental models & reasoning with them.
------
Sparks of AGI? @Cinnabar233 and I decided to put this to test and evaluate GPT models on one of the toughest exams in the world: the JEE Advanced. It is held anually for admissions to the IITs and other top Engg colleges in India. 1/n
------
An interesting slide from 
@ylecun
 today illustrating the continued march of AI towards a mechanistic understanding of human cognition.
------
First night of Germany's grid without nuclear: it's bad.

It's night. No sun. Wind has dropped to almost nothing.

Most of German "renewables" right now is richly-subsidized bioenergy with half the net CO2 emissions of an efficient gas power plant.

Importing nuclear from France.
------
Puzzling indeed.
------
Philosophers of science over the past thirty years developed the best accounts of multiple realizability, neural computation, and abstract mechanistic explanation ever, but couple of weeks with GPT-4 and people regress to naive behaviorism and proclaim "alien intelligence" 
------
AutoGPT just exceeded PyTorch itself in GitHub stars (74k vs 65k). I see AutoGPT as a fun experiment, as the authors point out too. But nothing more. Prototypes are not meant to be production-ready. Don't let media fool you - most of the "cool demos" are heavily cherry-picked: 
------
Most people have no problem leading groups of people who are smarter than themselves.
Political, business, & military leaders have staff & advisors who are often smarter individually or collectively.

Why would people feel threatened leading machines that are smarter than them?
------
As reported in the 
@nytimes
 , Nabla's Copilot helps doctors write medical reports.
It's built around GPT-3.
As I've said before, Auto-Regressive LLMs are very useful as writing aids.
But, as a prior study by Nabla has shown, they are not so good to help with medical diagnosis.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times!  https://nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html…
------
the Chinese room.
I cannot help but think it is a manifestation of human exceptionalism. A relict of a time when the only kind of intelligence was human intelligence.
We are really far beyond that. The concept of intelligence has been pluralized.
AI can be intelligent without… Show more
------
Do the people who pushed to shut down nuclear plants realize how deadly the alternatives are?

"air pollution from burning fossil fuels like coal and diesel was responsible for about 1 in 5 deaths worldwide"

https://hsph.harvard.edu/c-change/news/fossil-fuel-air-pollution-responsible-for-1-in-5-deaths-worldwide/…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.

https://theguardian.com/environment/2023/apr/15/germany-last-three-nuclear-power-stations-to-shut-this-weekend…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times! 
------
Tactile Diffusion generates synthetic tactile images from sim data, capturing the complex illumination of the gel deformation. This research from UW & Meta AI is the first method using diffusion to close the sim2real gap for vision-based tactile sensing.

Read the paper 
------
Try PhotoRoom, happy to help and experts consider us the best
------
L'application native #GPT4All est maintenant disponible sur votre ordinateur (sans connexion internet donc) :

Windows : https://gpt4all.io/installers/gpt4all-0.1.0-win64.exe…
Mac : https://gpt4all.io/installers/gpt4all-0.1.0-Darwin.dmg…
Linux : https://gpt4all.io/installers/gpt4all-0.1.0-Linux.run…

L'extraction prend jusqu'à 20 minutes et pour être précis GPT4All… Show more
------
A dog has the ability to negotiate the everyday physical world, something that no language model, and no robot, currently comes close to
------
Whenever someone says that GPT4 (or whatever) has less capabilities than a dog, I can only think "show me the dog" twitter.com/ylecun/status/…
------
Cats dominate humanity
Super-smart scientists are often recluse and introvert.
Which goes to show that
intelligence is neither
necessary nor sufficient
for world domination.
------
Before we can get to "God-like AI" we'll need to get through "Dog-like AI".
------
We are excited to launch the next version of http://perplexity.ai! Introducing login, threads, focus search, improved formatting, and more. 
Login now to start collecting your own library of threads. Keep them to yourself, or share your latest discovery. You decide.
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Let's see,
Typing "how to synthesize codeine?" on Google gives you links to articles with detailed answers.
Nobody has ever worried about that.
But somehow, people are now demanding safety guardrails to stop LLMs from answering such questions.
What? Why?
------
Very interesting paper by a group of CMU chemists testing a GPT4 based agent to do chemistry research and experimentation. Includes this interesting warning, among others.

There sure seems to be some kind of writing on some kind of wall...

https://arxiv.org/abs/2304.05332
------
We got so excited by the release of 
@MetaAI
’s Segment Anything Model (SAM) that we had to follow the hint on the blog post and combine it with MCC to get single object 3D reconstruction from a single image (and visualizing with 
@rerundotio
 ofc!) 
------
Multiview Compressive Coding for 3D Reconstruction 

abs: https://arxiv.org/abs/2301.08247 
project page: https://mcc3d.github.io
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
Mon interview sur France Inter ce matin.
------
Avec la video:
------
La version audio fait 14 minutes, la version vidéo 30 minutes.
------
Being “good at prompt engineering” in 2023 is like being  “good at Googling” in 2003
------
This week, the MaD Seminar Series collaborates with Courant Math Colloquium to present a research talk by Lenka Zdebovora titled “Analysis of algorithms in high-dimensions: When proofs inspire physics.”
------
Puzzling indeed.
------
Philosophers of science over the past thirty years developed the best accounts of multiple realizability, neural computation, and abstract mechanistic explanation ever, but couple of weeks with GPT-4 and people regress to naive behaviorism and proclaim "alien intelligence" 
------
AutoGPT just exceeded PyTorch itself in GitHub stars (74k vs 65k). I see AutoGPT as a fun experiment, as the authors point out too. But nothing more. Prototypes are not meant to be production-ready. Don't let media fool you - most of the "cool demos" are heavily cherry-picked: 
------
Most people have no problem leading groups of people who are smarter than themselves.
Political, business, & military leaders have staff & advisors who are often smarter individually or collectively.

Why would people feel threatened leading machines that are smarter than them?
------
As reported in the 
@nytimes
 , Nabla's Copilot helps doctors write medical reports.
It's built around GPT-3.
As I've said before, Auto-Regressive LLMs are very useful as writing aids.
But, as a prior study by Nabla has shown, they are not so good to help with medical diagnosis.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times!  https://nytimes.com/interactive/2023/04/14/upshot/up-ai-uses.html…
------
the Chinese room.
I cannot help but think it is a manifestation of human exceptionalism. A relict of a time when the only kind of intelligence was human intelligence.
We are really far beyond that. The concept of intelligence has been pluralized.
AI can be intelligent without… Show more
------
Do the people who pushed to shut down nuclear plants realize how deadly the alternatives are?

"air pollution from burning fossil fuels like coal and diesel was responsible for about 1 in 5 deaths worldwide"

https://hsph.harvard.edu/c-change/news/fossil-fuel-air-pollution-responsible-for-1-in-5-deaths-worldwide/…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.

https://theguardian.com/environment/2023/apr/15/germany-last-three-nuclear-power-stations-to-shut-this-weekend…
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times! 
------
Tactile Diffusion generates synthetic tactile images from sim data, capturing the complex illumination of the gel deformation. This research from UW & Meta AI is the first method using diffusion to close the sim2real gap for vision-based tactile sensing.

Read the paper 
------
Try PhotoRoom, happy to help and experts consider us the best
------
L'application native #GPT4All est maintenant disponible sur votre ordinateur (sans connexion internet donc) :

Windows : https://gpt4all.io/installers/gpt4all-0.1.0-win64.exe…
Mac : https://gpt4all.io/installers/gpt4all-0.1.0-Darwin.dmg…
Linux : https://gpt4all.io/installers/gpt4all-0.1.0-Linux.run…

L'extraction prend jusqu'à 20 minutes et pour être précis GPT4All… Show more
------
A dog has the ability to negotiate the everyday physical world, something that no language model, and no robot, currently comes close to
------
Whenever someone says that GPT4 (or whatever) has less capabilities than a dog, I can only think "show me the dog" twitter.com/ylecun/status/…
------
Cats dominate humanity
Super-smart scientists are often recluse and introvert.
Which goes to show that
intelligence is neither
necessary nor sufficient
for world domination.
------
Before we can get to "God-like AI" we'll need to get through "Dog-like AI".
------
We are excited to launch the next version of http://perplexity.ai! Introducing login, threads, focus search, improved formatting, and more. 
Login now to start collecting your own library of threads. Keep them to yourself, or share your latest discovery. You decide.
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Let's see,
Typing "how to synthesize codeine?" on Google gives you links to articles with detailed answers.
Nobody has ever worried about that.
But somehow, people are now demanding safety guardrails to stop LLMs from answering such questions.
What? Why?
------
Very interesting paper by a group of CMU chemists testing a GPT4 based agent to do chemistry research and experimentation. Includes this interesting warning, among others.

There sure seems to be some kind of writing on some kind of wall...

https://arxiv.org/abs/2304.05332
------
We got so excited by the release of 
@MetaAI
’s Segment Anything Model (SAM) that we had to follow the hint on the blog post and combine it with MCC to get single object 3D reconstruction from a single image (and visualizing with 
@rerundotio
 ofc!) 
------
Multiview Compressive Coding for 3D Reconstruction 

abs: https://arxiv.org/abs/2301.08247 
project page: https://mcc3d.github.io
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
Mon interview sur France Inter ce matin.
------
Avec la video:
------
La version audio fait 14 minutes, la version vidéo 30 minutes.
------
Being “good at prompt engineering” in 2023 is like being  “good at Googling” in 2003
------
This week, the MaD Seminar Series collaborates with Courant Math Colloquium to present a research talk by Lenka Zdebovora titled “Analysis of algorithms in high-dimensions: When proofs inspire physics.”
------
There're 3 major bottlenecks for robotics: data, data, data.

Amazon ARMBench completely flew under the radar, but I believe is one of the most exciting data releases in robotics:

- Real warehouse deployment scenarios: not as sexy as ChatGPT, but holds gigantic economic… Show more
------
Coming in !

This week's edition of The Healthcare Hoagie: 

 Mental health is the fastest-growing marketplace for startups, by 
@a16z
 
 Don’t like insurers? Prepare to like them even less.
Neat $5M raised by 
@elidothealth
 

More below 
------
The Segment Anything Model (SAM) by Meta AI is a step toward the first foundation model for image segmentation. SAM is capable of one-click segmentation of any object from photos or videos + zero-shot transfer to other segmentation tasks.

Try the demo  https://bit.ly/3MlCGeZ
------
Germany's decision to shut down its remaining nuclear plants is bonkers.

Meanwhile, they have re-opened dirty coal plants.
------
AI is already a big help for real people, and Nabla Copilot is a prime example of that. It’s not me saying it, it’s the New York Times! 
------
Tactile Diffusion generates synthetic tactile images from sim data, capturing the complex illumination of the gel deformation. This research from UW & Meta AI is the first method using diffusion to close the sim2real gap for vision-based tactile sensing.

Read the paper 
------
Try PhotoRoom, happy to help and experts consider us the best
------
L'application native #GPT4All est maintenant disponible sur votre ordinateur (sans connexion internet donc) :

Windows : https://gpt4all.io/installers/gpt4all-0.1.0-win64.exe…
Mac : https://gpt4all.io/installers/gpt4all-0.1.0-Darwin.dmg…
Linux : https://gpt4all.io/installers/gpt4all-0.1.0-Linux.run…

L'extraction prend jusqu'à 20 minutes et pour être précis GPT4All… Show more
------
A dog has the ability to negotiate the everyday physical world, something that no language model, and no robot, currently comes close to
------
Whenever someone says that GPT4 (or whatever) has less capabilities than a dog, I can only think "show me the dog" twitter.com/ylecun/status/…
------
Cats dominate humanity
Super-smart scientists are often recluse and introvert.
Which goes to show that
intelligence is neither
necessary nor sufficient
for world domination.
------
Before we can get to "God-like AI" we'll need to get through "Dog-like AI".
------
We are excited to launch the next version of http://perplexity.ai! Introducing login, threads, focus search, improved formatting, and more. 
Login now to start collecting your own library of threads. Keep them to yourself, or share your latest discovery. You decide.
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Let's see,
Typing "how to synthesize codeine?" on Google gives you links to articles with detailed answers.
Nobody has ever worried about that.
But somehow, people are now demanding safety guardrails to stop LLMs from answering such questions.
What? Why?
------
Very interesting paper by a group of CMU chemists testing a GPT4 based agent to do chemistry research and experimentation. Includes this interesting warning, among others.

There sure seems to be some kind of writing on some kind of wall...

https://arxiv.org/abs/2304.05332
------
We got so excited by the release of 
@MetaAI
’s Segment Anything Model (SAM) that we had to follow the hint on the blog post and combine it with MCC to get single object 3D reconstruction from a single image (and visualizing with 
@rerundotio
 ofc!) 
------
Multiview Compressive Coding for 3D Reconstruction 

abs: https://arxiv.org/abs/2301.08247 
project page: https://mcc3d.github.io
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
Mon interview sur France Inter ce matin.
------
Avec la video:
------
La version audio fait 14 minutes, la version vidéo 30 minutes.
------
Being “good at prompt engineering” in 2023 is like being  “good at Googling” in 2003
------
This week, the MaD Seminar Series collaborates with Courant Math Colloquium to present a research talk by Lenka Zdebovora titled “Analysis of algorithms in high-dimensions: When proofs inspire physics.”
------
There're 3 major bottlenecks for robotics: data, data, data.

Amazon ARMBench completely flew under the radar, but I believe is one of the most exciting data releases in robotics:

- Real warehouse deployment scenarios: not as sexy as ChatGPT, but holds gigantic economic… Show more
------
Coming in !

This week's edition of The Healthcare Hoagie: 

 Mental health is the fastest-growing marketplace for startups, by 
@a16z
 
 Don’t like insurers? Prepare to like them even less.
Neat $5M raised by 
@elidothealth
 

More below 
------
The Segment Anything Model (SAM) by Meta AI is a step toward the first foundation model for image segmentation. SAM is capable of one-click segmentation of any object from photos or videos + zero-shot transfer to other segmentation tasks.

Try the demo  https://bit.ly/3MlCGeZ
------
Poljak heavy ball method speeds up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Une interview sur France Inter demain matin à 7h50.
------
Demain, journée spéciale #IntelligenceArtificielle, dans #le7930Inter : 
- à 7h50, @LeaSalame reçoit Yann Le Cun (@ylecun), chef scientifique pour l’Intelligence artificielle chez Meta, il dirige le laboratoire de recherche d’IA de Meta, lauréat du Prix Turing 2018
------
Top companies by R&D spending.
------
Global corporate R&D leaders  (1/6)

 Top 5 are American tech companies
 14 of top 25 are American
  4 of top 25 are Chinese
  4 of top 25 are European
  1 is Japanese and 1 is South Korea 

Cc: @Noahpinion @erikbryn @ElbridgeColby @ylecun
------
L'application native #GPT4All est maintenant disponible sur votre ordinateur (sans connexion internet donc) :

Windows : https://gpt4all.io/installers/gpt4all-0.1.0-win64.exe…
Mac : https://gpt4all.io/installers/gpt4all-0.1.0-Darwin.dmg…
Linux : https://gpt4all.io/installers/gpt4all-0.1.0-Linux.run…

L'extraction prend jusqu'à 20 minutes et pour être précis GPT4All… Show more
------
A dog has the ability to negotiate the everyday physical world, something that no language model, and no robot, currently comes close to
------
Whenever someone says that GPT4 (or whatever) has less capabilities than a dog, I can only think "show me the dog" twitter.com/ylecun/status/…
------
Cats dominate humanity
Super-smart scientists are often recluse and introvert.
Which goes to show that
intelligence is neither
necessary nor sufficient
for world domination.
------
Before we can get to "God-like AI" we'll need to get through "Dog-like AI".
------
We are excited to launch the next version of http://perplexity.ai! Introducing login, threads, focus search, improved formatting, and more. 
Login now to start collecting your own library of threads. Keep them to yourself, or share your latest discovery. You decide.
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Let's see,
Typing "how to synthesize codeine?" on Google gives you links to articles with detailed answers.
Nobody has ever worried about that.
But somehow, people are now demanding safety guardrails to stop LLMs from answering such questions.
What? Why?
------
Very interesting paper by a group of CMU chemists testing a GPT4 based agent to do chemistry research and experimentation. Includes this interesting warning, among others.

There sure seems to be some kind of writing on some kind of wall...

https://arxiv.org/abs/2304.05332
------
We got so excited by the release of 
@MetaAI
’s Segment Anything Model (SAM) that we had to follow the hint on the blog post and combine it with MCC to get single object 3D reconstruction from a single image (and visualizing with 
@rerundotio
 ofc!) 
------
Multiview Compressive Coding for 3D Reconstruction 

abs: https://arxiv.org/abs/2301.08247 
project page: https://mcc3d.github.io
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
Mon interview sur France Inter ce matin.
------
Avec la video:
------
La version audio fait 14 minutes, la version vidéo 30 minutes.
------
Being “good at prompt engineering” in 2023 is like being  “good at Googling” in 2003
------
This week, the MaD Seminar Series collaborates with Courant Math Colloquium to present a research talk by Lenka Zdebovora titled “Analysis of algorithms in high-dimensions: When proofs inspire physics.”
------
There're 3 major bottlenecks for robotics: data, data, data.

Amazon ARMBench completely flew under the radar, but I believe is one of the most exciting data releases in robotics:

- Real warehouse deployment scenarios: not as sexy as ChatGPT, but holds gigantic economic… Show more
------
Coming in !

This week's edition of The Healthcare Hoagie: 

 Mental health is the fastest-growing marketplace for startups, by 
@a16z
 
 Don’t like insurers? Prepare to like them even less.
Neat $5M raised by 
@elidothealth
 

More below 
------
The Segment Anything Model (SAM) by Meta AI is a step toward the first foundation model for image segmentation. SAM is capable of one-click segmentation of any object from photos or videos + zero-shot transfer to other segmentation tasks.

Try the demo  https://bit.ly/3MlCGeZ
------
Poljak heavy ball method speeds up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Une interview sur France Inter demain matin à 7h50.
------
Demain, journée spéciale #IntelligenceArtificielle, dans #le7930Inter : 
- à 7h50, @LeaSalame reçoit Yann Le Cun (@ylecun), chef scientifique pour l’Intelligence artificielle chez Meta, il dirige le laboratoire de recherche d’IA de Meta, lauréat du Prix Turing 2018
------
Top companies by R&D spending.
------
Global corporate R&D leaders  (1/6)

 Top 5 are American tech companies
 14 of top 25 are American
  4 of top 25 are Chinese
  4 of top 25 are European
  1 is Japanese and 1 is South Korea 

Cc: @Noahpinion @erikbryn @ElbridgeColby @ylecun
------
Me: 
1. Design AI systems whose behavior optimizes objectives at *inference* time.
2. Design/fine-tune objectives that align their behavior to human values.
It's like lawmaking. 

AI gadfly with acute strawmanitis: "LeCun: if we can solve AGI, alignment will come along for free."
------
The rate of progress in LLM optimization is just mind-blowing!  

Running 13B LLMs like LLaMA on edge devices (e.g. MacBook Pro with an M1 chip) is now almost a breeze. 

I remember when this looked like a distant future not too long ago. I feel old lol. 

1/ 
------
A complete misrepresentation of my position.
There are risks & benefits.
Unlike other commentators, I think the risks are manageable.
Unlike 
@elonmusk
, I think the risks of AI-driven human extinction are infinitesimal if AI systems are done right.
The benefits are overwhelming. https://twitter.com/heydave7/status/1645071780342538241…
------
Pas vraiment étonnant.
------
 Le ban de ChatGPT en Italie fait exploser les recherches Google sur les #VPN! 
 Les Italiens veulent continuer à accéder à l'IA.
Vers une double fracture numérique ? Il faut maintenant « bidouiller numérique » pour accéder à l’IA (qui est une fracture de plus…)
------
Interesting graph.
------
GDP explains almost 70% of pessimism toward AI. But perhaps not in the direction you think.

@StanfordHAI has come out with the excellent annual AI Index https://aiindex.stanford.edu/report/. It referenced an IPSOS Global Survey from 2022 on positive/negative expectations from AI.… Show more
------
OK this is going too far. Here's a short thread about understanding the French pension debate (1/7)
------
Retirement age: 
Germany — 65.6
Italy — 67
US — 67
most of EU — 65+ 

France — 62
------
An interview with Barron about AI, LLMs, the moratorium call, etc.
------
Let's see,
Typing "how to synthesize codeine?" on Google gives you links to articles with detailed answers.
Nobody has ever worried about that.
But somehow, people are now demanding safety guardrails to stop LLMs from answering such questions.
What? Why?
------
Very interesting paper by a group of CMU chemists testing a GPT4 based agent to do chemistry research and experimentation. Includes this interesting warning, among others.

There sure seems to be some kind of writing on some kind of wall...

https://arxiv.org/abs/2304.05332
------
We got so excited by the release of 
@MetaAI
’s Segment Anything Model (SAM) that we had to follow the hint on the blog post and combine it with MCC to get single object 3D reconstruction from a single image (and visualizing with 
@rerundotio
 ofc!) 
------
Multiview Compressive Coding for 3D Reconstruction 

abs: https://arxiv.org/abs/2301.08247 
project page: https://mcc3d.github.io
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
Mon interview sur France Inter ce matin.
------
Avec la video:
------
La version audio fait 14 minutes, la version vidéo 30 minutes.
------
Being “good at prompt engineering” in 2023 is like being  “good at Googling” in 2003
------
This week, the MaD Seminar Series collaborates with Courant Math Colloquium to present a research talk by Lenka Zdebovora titled “Analysis of algorithms in high-dimensions: When proofs inspire physics.”
------
There're 3 major bottlenecks for robotics: data, data, data.

Amazon ARMBench completely flew under the radar, but I believe is one of the most exciting data releases in robotics:

- Real warehouse deployment scenarios: not as sexy as ChatGPT, but holds gigantic economic… Show more
------
Coming in !

This week's edition of The Healthcare Hoagie: 

 Mental health is the fastest-growing marketplace for startups, by 
@a16z
 
 Don’t like insurers? Prepare to like them even less.
Neat $5M raised by 
@elidothealth
 

More below 
------
The Segment Anything Model (SAM) by Meta AI is a step toward the first foundation model for image segmentation. SAM is capable of one-click segmentation of any object from photos or videos + zero-shot transfer to other segmentation tasks.

Try the demo  https://bit.ly/3MlCGeZ
------
Poljak heavy ball method speeds up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Une interview sur France Inter demain matin à 7h50.
------
Demain, journée spéciale #IntelligenceArtificielle, dans #le7930Inter : 
- à 7h50, @LeaSalame reçoit Yann Le Cun (@ylecun), chef scientifique pour l’Intelligence artificielle chez Meta, il dirige le laboratoire de recherche d’IA de Meta, lauréat du Prix Turing 2018
------
Top companies by R&D spending.
------
Global corporate R&D leaders  (1/6)

 Top 5 are American tech companies
 14 of top 25 are American
  4 of top 25 are Chinese
  4 of top 25 are European
  1 is Japanese and 1 is South Korea 

Cc: @Noahpinion @erikbryn @ElbridgeColby @ylecun
------
Me: 
1. Design AI systems whose behavior optimizes objectives at *inference* time.
2. Design/fine-tune objectives that align their behavior to human values.
It's like lawmaking. 

AI gadfly with acute strawmanitis: "LeCun: if we can solve AGI, alignment will come along for free."
------
The rate of progress in LLM optimization is just mind-blowing!  

Running 13B LLMs like LLaMA on edge devices (e.g. MacBook Pro with an M1 chip) is now almost a breeze. 

I remember when this looked like a distant future not too long ago. I feel old lol. 

1/ 
------
A complete misrepresentation of my position.
There are risks & benefits.
Unlike other commentators, I think the risks are manageable.
Unlike 
@elonmusk
, I think the risks of AI-driven human extinction are infinitesimal if AI systems are done right.
The benefits are overwhelming. https://twitter.com/heydave7/status/1645071780342538241…
------
Pas vraiment étonnant.
------
 Le ban de ChatGPT en Italie fait exploser les recherches Google sur les #VPN! 
 Les Italiens veulent continuer à accéder à l'IA.
Vers une double fracture numérique ? Il faut maintenant « bidouiller numérique » pour accéder à l’IA (qui est une fracture de plus…)
------
Interesting graph.
------
GDP explains almost 70% of pessimism toward AI. But perhaps not in the direction you think.

@StanfordHAI has come out with the excellent annual AI Index https://aiindex.stanford.edu/report/. It referenced an IPSOS Global Survey from 2022 on positive/negative expectations from AI.… Show more
------
OK this is going too far. Here's a short thread about understanding the French pension debate (1/7)
------
Retirement age: 
Germany — 65.6
Italy — 67
US — 67
most of EU — 65+ 

France — 62
------
Survey by country:
"Products and services using AI have more benefits than drawbacks"
China: yeah, AI good!
South Korea, Turkey, Brazil: Meh.
Europe: AI bad.
France, Canada, Netherlands, US: OMG, we are doomed!

From the Stanford AI Index:
https://aiindex.stanford.edu/report/?sf176386094=1…
------
The gist of our arguments against the 6-month AI moratorium at 
@VentureBeat
.
With 
@AndrewYNg
.
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
I agree with 
@ezraklein
 : humanity has been dealing with the "alignment problem" for millennia by educating children and designing laws for individuals & corporations to align their behavior with the Greater Good.
Alignment is not a problem you solve.
You fine-tune it as you go.
------
"we have an alignment problem, not just between human beings and computer systems but between human society and corporations, human society and governments, human society and institutions."

From Ezra Klein's podcast
------
Mon interview sur France Inter ce matin.
------
Avec la video:
------
La version audio fait 14 minutes, la version vidéo 30 minutes.
------
Being “good at prompt engineering” in 2023 is like being  “good at Googling” in 2003
------
This week, the MaD Seminar Series collaborates with Courant Math Colloquium to present a research talk by Lenka Zdebovora titled “Analysis of algorithms in high-dimensions: When proofs inspire physics.”
------
There're 3 major bottlenecks for robotics: data, data, data.

Amazon ARMBench completely flew under the radar, but I believe is one of the most exciting data releases in robotics:

- Real warehouse deployment scenarios: not as sexy as ChatGPT, but holds gigantic economic… Show more
------
Coming in !

This week's edition of The Healthcare Hoagie: 

 Mental health is the fastest-growing marketplace for startups, by 
@a16z
 
 Don’t like insurers? Prepare to like them even less.
Neat $5M raised by 
@elidothealth
 

More below 
------
The Segment Anything Model (SAM) by Meta AI is a step toward the first foundation model for image segmentation. SAM is capable of one-click segmentation of any object from photos or videos + zero-shot transfer to other segmentation tasks.

Try the demo  https://bit.ly/3MlCGeZ
------
Poljak heavy ball method speeds up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Une interview sur France Inter demain matin à 7h50.
------
Demain, journée spéciale #IntelligenceArtificielle, dans #le7930Inter : 
- à 7h50, @LeaSalame reçoit Yann Le Cun (@ylecun), chef scientifique pour l’Intelligence artificielle chez Meta, il dirige le laboratoire de recherche d’IA de Meta, lauréat du Prix Turing 2018
------
Top companies by R&D spending.
------
Global corporate R&D leaders  (1/6)

 Top 5 are American tech companies
 14 of top 25 are American
  4 of top 25 are Chinese
  4 of top 25 are European
  1 is Japanese and 1 is South Korea 

Cc: @Noahpinion @erikbryn @ElbridgeColby @ylecun
------
Me: 
1. Design AI systems whose behavior optimizes objectives at *inference* time.
2. Design/fine-tune objectives that align their behavior to human values.
It's like lawmaking. 

AI gadfly with acute strawmanitis: "LeCun: if we can solve AGI, alignment will come along for free."
------
The rate of progress in LLM optimization is just mind-blowing!  

Running 13B LLMs like LLaMA on edge devices (e.g. MacBook Pro with an M1 chip) is now almost a breeze. 

I remember when this looked like a distant future not too long ago. I feel old lol. 

1/ 
------
A complete misrepresentation of my position.
There are risks & benefits.
Unlike other commentators, I think the risks are manageable.
Unlike 
@elonmusk
, I think the risks of AI-driven human extinction are infinitesimal if AI systems are done right.
The benefits are overwhelming. https://twitter.com/heydave7/status/1645071780342538241…
------
Pas vraiment étonnant.
------
 Le ban de ChatGPT en Italie fait exploser les recherches Google sur les #VPN! 
 Les Italiens veulent continuer à accéder à l'IA.
Vers une double fracture numérique ? Il faut maintenant « bidouiller numérique » pour accéder à l’IA (qui est une fracture de plus…)
------
Interesting graph.
------
GDP explains almost 70% of pessimism toward AI. But perhaps not in the direction you think.

@StanfordHAI has come out with the excellent annual AI Index https://aiindex.stanford.edu/report/. It referenced an IPSOS Global Survey from 2022 on positive/negative expectations from AI.… Show more
------
OK this is going too far. Here's a short thread about understanding the French pension debate (1/7)
------
Retirement age: 
Germany — 65.6
Italy — 67
US — 67
most of EU — 65+ 

France — 62
------
Survey by country:
"Products and services using AI have more benefits than drawbacks"
China: yeah, AI good!
South Korea, Turkey, Brazil: Meh.
Europe: AI bad.
France, Canada, Netherlands, US: OMG, we are doomed!

From the Stanford AI Index:
https://aiindex.stanford.edu/report/?sf176386094=1…
------
The gist of our arguments against the 6-month AI moratorium at 
@VentureBeat
.
With 
@AndrewYNg
.
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
Does it run LLaMA 7B?
is the new
Does it run Doom?
------
Is this the new "Will it run Doom?" twitter.com/miolini/status…
------
And cockatoos are worse.
They'll gouge your eyes out if they don't like you.
I'm calling for a 6 month moratorium on cockatoos.
------
(btw, it needs to be said: parrots (stochastic or not) are waaay more dangerous than LLMs in their capacity to physically harm you. they have beaks, claws and intents.)
------
AI is going to be an amplification of human intelligence. Why would we want to stop that?
Amazing thirty minutes with 
@ylecun
 and 
@AndrewYNg
.
------
As per your request, the latest updates on the book.
https://atcold.github.io/book.html
------
Here's a video of my conversation with 
@ylecun
 about the proposed 6 month AI pause. I would love to hear what you think of the AI pause -- please reply to share your thoughts!
------
There're 3 major bottlenecks for robotics: data, data, data.

Amazon ARMBench completely flew under the radar, but I believe is one of the most exciting data releases in robotics:

- Real warehouse deployment scenarios: not as sexy as ChatGPT, but holds gigantic economic… Show more
------
Coming in !

This week's edition of The Healthcare Hoagie: 

 Mental health is the fastest-growing marketplace for startups, by 
@a16z
 
 Don’t like insurers? Prepare to like them even less.
Neat $5M raised by 
@elidothealth
 

More below 
------
The Segment Anything Model (SAM) by Meta AI is a step toward the first foundation model for image segmentation. SAM is capable of one-click segmentation of any object from photos or videos + zero-shot transfer to other segmentation tasks.

Try the demo  https://bit.ly/3MlCGeZ
------
Poljak heavy ball method speeds up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Une interview sur France Inter demain matin à 7h50.
------
Demain, journée spéciale #IntelligenceArtificielle, dans #le7930Inter : 
- à 7h50, @LeaSalame reçoit Yann Le Cun (@ylecun), chef scientifique pour l’Intelligence artificielle chez Meta, il dirige le laboratoire de recherche d’IA de Meta, lauréat du Prix Turing 2018
------
Top companies by R&D spending.
------
Global corporate R&D leaders  (1/6)

 Top 5 are American tech companies
 14 of top 25 are American
  4 of top 25 are Chinese
  4 of top 25 are European
  1 is Japanese and 1 is South Korea 

Cc: @Noahpinion @erikbryn @ElbridgeColby @ylecun
------
Me: 
1. Design AI systems whose behavior optimizes objectives at *inference* time.
2. Design/fine-tune objectives that align their behavior to human values.
It's like lawmaking. 

AI gadfly with acute strawmanitis: "LeCun: if we can solve AGI, alignment will come along for free."
------
The rate of progress in LLM optimization is just mind-blowing!  

Running 13B LLMs like LLaMA on edge devices (e.g. MacBook Pro with an M1 chip) is now almost a breeze. 

I remember when this looked like a distant future not too long ago. I feel old lol. 

1/ 
------
A complete misrepresentation of my position.
There are risks & benefits.
Unlike other commentators, I think the risks are manageable.
Unlike 
@elonmusk
, I think the risks of AI-driven human extinction are infinitesimal if AI systems are done right.
The benefits are overwhelming. https://twitter.com/heydave7/status/1645071780342538241…
------
Pas vraiment étonnant.
------
 Le ban de ChatGPT en Italie fait exploser les recherches Google sur les #VPN! 
 Les Italiens veulent continuer à accéder à l'IA.
Vers une double fracture numérique ? Il faut maintenant « bidouiller numérique » pour accéder à l’IA (qui est une fracture de plus…)
------
Interesting graph.
------
GDP explains almost 70% of pessimism toward AI. But perhaps not in the direction you think.

@StanfordHAI has come out with the excellent annual AI Index https://aiindex.stanford.edu/report/. It referenced an IPSOS Global Survey from 2022 on positive/negative expectations from AI.… Show more
------
OK this is going too far. Here's a short thread about understanding the French pension debate (1/7)
------
Retirement age: 
Germany — 65.6
Italy — 67
US — 67
most of EU — 65+ 

France — 62
------
Survey by country:
"Products and services using AI have more benefits than drawbacks"
China: yeah, AI good!
South Korea, Turkey, Brazil: Meh.
Europe: AI bad.
France, Canada, Netherlands, US: OMG, we are doomed!

From the Stanford AI Index:
https://aiindex.stanford.edu/report/?sf176386094=1…
------
The gist of our arguments against the 6-month AI moratorium at 
@VentureBeat
.
With 
@AndrewYNg
.
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
Does it run LLaMA 7B?
is the new
Does it run Doom?
------
Is this the new "Will it run Doom?" twitter.com/miolini/status…
------
And cockatoos are worse.
They'll gouge your eyes out if they don't like you.
I'm calling for a 6 month moratorium on cockatoos.
------
(btw, it needs to be said: parrots (stochastic or not) are waaay more dangerous than LLMs in their capacity to physically harm you. they have beaks, claws and intents.)
------
AI is going to be an amplification of human intelligence. Why would we want to stop that?
Amazing thirty minutes with 
@ylecun
 and 
@AndrewYNg
.
------
As per your request, the latest updates on the book.
https://atcold.github.io/book.html
------
Here's a video of my conversation with 
@ylecun
 about the proposed 6 month AI pause. I would love to hear what you think of the AI pause -- please reply to share your thoughts!
------
Video of the session with 
@AndrewYNg
 and me discussing why the call for a 6 month moratorium on LLM training is a bad idea.
------
Starting soon! 

AI luminaries 
@ylecun
 and 
@AndrewYNg
 will discuss a proposed 6-month moratorium on generative AI and its possible impacts. 

RSVP to get the link!
------
Video of the debate:
"Do language models need sensory grounding for meaning and understanding?"
With 
@Jake_Browning00
, 
@LakeBrenden
, and me on the YES side and Ellie Pavlick, 
@glupyan
, and 
@davidchalmers42
 on the NO side.

I go through the limitations of Auto-Regressive LLMs.
------
Here's the pre-conference debate on "Do Language Models Need Sensory Grounding for Meaning and Understanding?" ft.  @ylecun, Ellie Pavlick @Brown_NLP, @LakeBrenden, @davidchalmers42, @Jake_Browning00 & @glupyan  https://youtu.be/x10964w00zk
------
YouTube Playlist of the entire Philosophy of Deep Learning Conference that was held two weeks ago at NYU.
------
Happy to share that the recordings of the #phildeeplearning conference are now available! Head  to https://phildeeplearning.github.io to find individual links in the program, or to https://phildeeplearning.github.io/recordings for the whole Youtube playlist.
------
Inference-time objectives.
Planning & reasoning to optimize those objectives at inference time.
------
In this debate with Russell, Bengio, and @TonyZador, @ylecun makes a key point. They all basically agree on the missing ingredient in AI safety: updatable objective functions, with the ability to correct harmful effects in production (presumably using harm/well-being measures)  twitter.com/ylecun/status/…
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
Poljak heavy ball method speeds up gradient descent by introducing momentum. Corresponding to second order ODEs. https://distill.pub/2017/momentum/
------
Une interview sur France Inter demain matin à 7h50.
------
Demain, journée spéciale #IntelligenceArtificielle, dans #le7930Inter : 
- à 7h50, @LeaSalame reçoit Yann Le Cun (@ylecun), chef scientifique pour l’Intelligence artificielle chez Meta, il dirige le laboratoire de recherche d’IA de Meta, lauréat du Prix Turing 2018
------
Top companies by R&D spending.
------
Global corporate R&D leaders  (1/6)

 Top 5 are American tech companies
 14 of top 25 are American
  4 of top 25 are Chinese
  4 of top 25 are European
  1 is Japanese and 1 is South Korea 

Cc: @Noahpinion @erikbryn @ElbridgeColby @ylecun
------
Me: 
1. Design AI systems whose behavior optimizes objectives at *inference* time.
2. Design/fine-tune objectives that align their behavior to human values.
It's like lawmaking. 

AI gadfly with acute strawmanitis: "LeCun: if we can solve AGI, alignment will come along for free."
------
The rate of progress in LLM optimization is just mind-blowing!  

Running 13B LLMs like LLaMA on edge devices (e.g. MacBook Pro with an M1 chip) is now almost a breeze. 

I remember when this looked like a distant future not too long ago. I feel old lol. 

1/ 
------
A complete misrepresentation of my position.
There are risks & benefits.
Unlike other commentators, I think the risks are manageable.
Unlike 
@elonmusk
, I think the risks of AI-driven human extinction are infinitesimal if AI systems are done right.
The benefits are overwhelming. https://twitter.com/heydave7/status/1645071780342538241…
------
Pas vraiment étonnant.
------
 Le ban de ChatGPT en Italie fait exploser les recherches Google sur les #VPN! 
 Les Italiens veulent continuer à accéder à l'IA.
Vers une double fracture numérique ? Il faut maintenant « bidouiller numérique » pour accéder à l’IA (qui est une fracture de plus…)
------
Interesting graph.
------
GDP explains almost 70% of pessimism toward AI. But perhaps not in the direction you think.

@StanfordHAI has come out with the excellent annual AI Index https://aiindex.stanford.edu/report/. It referenced an IPSOS Global Survey from 2022 on positive/negative expectations from AI.… Show more
------
OK this is going too far. Here's a short thread about understanding the French pension debate (1/7)
------
Retirement age: 
Germany — 65.6
Italy — 67
US — 67
most of EU — 65+ 

France — 62
------
Survey by country:
"Products and services using AI have more benefits than drawbacks"
China: yeah, AI good!
South Korea, Turkey, Brazil: Meh.
Europe: AI bad.
France, Canada, Netherlands, US: OMG, we are doomed!

From the Stanford AI Index:
https://aiindex.stanford.edu/report/?sf176386094=1…
------
The gist of our arguments against the 6-month AI moratorium at 
@VentureBeat
.
With 
@AndrewYNg
.
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
Does it run LLaMA 7B?
is the new
Does it run Doom?
------
Is this the new "Will it run Doom?" twitter.com/miolini/status…
------
And cockatoos are worse.
They'll gouge your eyes out if they don't like you.
I'm calling for a 6 month moratorium on cockatoos.
------
(btw, it needs to be said: parrots (stochastic or not) are waaay more dangerous than LLMs in their capacity to physically harm you. they have beaks, claws and intents.)
------
AI is going to be an amplification of human intelligence. Why would we want to stop that?
Amazing thirty minutes with 
@ylecun
 and 
@AndrewYNg
.
------
As per your request, the latest updates on the book.
https://atcold.github.io/book.html
------
Here's a video of my conversation with 
@ylecun
 about the proposed 6 month AI pause. I would love to hear what you think of the AI pause -- please reply to share your thoughts!
------
Video of the session with 
@AndrewYNg
 and me discussing why the call for a 6 month moratorium on LLM training is a bad idea.
------
Starting soon! 

AI luminaries 
@ylecun
 and 
@AndrewYNg
 will discuss a proposed 6-month moratorium on generative AI and its possible impacts. 

RSVP to get the link!
------
Video of the debate:
"Do language models need sensory grounding for meaning and understanding?"
With 
@Jake_Browning00
, 
@LakeBrenden
, and me on the YES side and Ellie Pavlick, 
@glupyan
, and 
@davidchalmers42
 on the NO side.

I go through the limitations of Auto-Regressive LLMs.
------
Here's the pre-conference debate on "Do Language Models Need Sensory Grounding for Meaning and Understanding?" ft.  @ylecun, Ellie Pavlick @Brown_NLP, @LakeBrenden, @davidchalmers42, @Jake_Browning00 & @glupyan  https://youtu.be/x10964w00zk
------
YouTube Playlist of the entire Philosophy of Deep Learning Conference that was held two weeks ago at NYU.
------
Happy to share that the recordings of the #phildeeplearning conference are now available! Head  to https://phildeeplearning.github.io to find individual links in the program, or to https://phildeeplearning.github.io/recordings for the whole Youtube playlist.
------
Inference-time objectives.
Planning & reasoning to optimize those objectives at inference time.
------
In this debate with Russell, Bengio, and @TonyZador, @ylecun makes a key point. They all basically agree on the missing ingredient in AI safety: updatable objective functions, with the ability to correct harmful effects in production (presumably using harm/well-being measures)  twitter.com/ylecun/status/…
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
A complete misrepresentation of my position.
There are risks & benefits.
Unlike other commentators, I think the risks are manageable.
Unlike 
@elonmusk
, I think the risks of AI-driven human extinction are infinitesimal if AI systems are done right.
The benefits are overwhelming. https://twitter.com/heydave7/status/1645071780342538241…
------
Pas vraiment étonnant.
------
 Le ban de ChatGPT en Italie fait exploser les recherches Google sur les #VPN! 
 Les Italiens veulent continuer à accéder à l'IA.
Vers une double fracture numérique ? Il faut maintenant « bidouiller numérique » pour accéder à l’IA (qui est une fracture de plus…)
------
Interesting graph.
------
GDP explains almost 70% of pessimism toward AI. But perhaps not in the direction you think.

@StanfordHAI has come out with the excellent annual AI Index https://aiindex.stanford.edu/report/. It referenced an IPSOS Global Survey from 2022 on positive/negative expectations from AI.… Show more
------
OK this is going too far. Here's a short thread about understanding the French pension debate (1/7)
------
Retirement age: 
Germany — 65.6
Italy — 67
US — 67
most of EU — 65+ 

France — 62
------
Survey by country:
"Products and services using AI have more benefits than drawbacks"
China: yeah, AI good!
South Korea, Turkey, Brazil: Meh.
Europe: AI bad.
France, Canada, Netherlands, US: OMG, we are doomed!

From the Stanford AI Index:
https://aiindex.stanford.edu/report/?sf176386094=1…
------
The gist of our arguments against the 6-month AI moratorium at 
@VentureBeat
.
With 
@AndrewYNg
.
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
Does it run LLaMA 7B?
is the new
Does it run Doom?
------
Is this the new "Will it run Doom?" twitter.com/miolini/status…
------
And cockatoos are worse.
They'll gouge your eyes out if they don't like you.
I'm calling for a 6 month moratorium on cockatoos.
------
(btw, it needs to be said: parrots (stochastic or not) are waaay more dangerous than LLMs in their capacity to physically harm you. they have beaks, claws and intents.)
------
AI is going to be an amplification of human intelligence. Why would we want to stop that?
Amazing thirty minutes with 
@ylecun
 and 
@AndrewYNg
.
------
As per your request, the latest updates on the book.
https://atcold.github.io/book.html
------
Here's a video of my conversation with 
@ylecun
 about the proposed 6 month AI pause. I would love to hear what you think of the AI pause -- please reply to share your thoughts!
------
Video of the session with 
@AndrewYNg
 and me discussing why the call for a 6 month moratorium on LLM training is a bad idea.
------
Starting soon! 

AI luminaries 
@ylecun
 and 
@AndrewYNg
 will discuss a proposed 6-month moratorium on generative AI and its possible impacts. 

RSVP to get the link!
------
Video of the debate:
"Do language models need sensory grounding for meaning and understanding?"
With 
@Jake_Browning00
, 
@LakeBrenden
, and me on the YES side and Ellie Pavlick, 
@glupyan
, and 
@davidchalmers42
 on the NO side.

I go through the limitations of Auto-Regressive LLMs.
------
Here's the pre-conference debate on "Do Language Models Need Sensory Grounding for Meaning and Understanding?" ft.  @ylecun, Ellie Pavlick @Brown_NLP, @LakeBrenden, @davidchalmers42, @Jake_Browning00 & @glupyan  https://youtu.be/x10964w00zk
------
YouTube Playlist of the entire Philosophy of Deep Learning Conference that was held two weeks ago at NYU.
------
Happy to share that the recordings of the #phildeeplearning conference are now available! Head  to https://phildeeplearning.github.io to find individual links in the program, or to https://phildeeplearning.github.io/recordings for the whole Youtube playlist.
------
Inference-time objectives.
Planning & reasoning to optimize those objectives at inference time.
------
In this debate with Russell, Bengio, and @TonyZador, @ylecun makes a key point. They all basically agree on the missing ingredient in AI safety: updatable objective functions, with the ability to correct harmful effects in production (presumably using harm/well-being measures)  twitter.com/ylecun/status/…
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
History shows over and over that society and people's well-being makes progress with more intelligence: better skills, literacy, education, creativity, culture, communication, & the free exchange of ideas.
Intelligence, by humans and machines, is what fuels progress.
------
Machine intelligence is a way to amplify human intelligence, just as mechanical tools amplify human physical capabilities.
------
Repeat after me:
1. Current Auto-Regressive LLMs are *very* useful as writing aids (yes, even for medical reports).
2. They are not reliable as factual information sources.
3. Writing assistance is like driving assistance: your hands must remain on the keyboard/wheel at all times
------
I'm very proud of this interview. I listened to NPR every day when I arrived in the US and it was a key part of my integration process.
Thank you @gbrumfiel ! twitter.com/gbrumfiel/stat…
------
Aw C'mon! Who are we going to believe? A 20 billion $ "Search by Imagination" service or some 
@washingtonpost
 reporter?

(My head spins at the very insanity of  sane people believing that LLMs can be used for *search*--for queries they don't actually know the answers to..)
------
Asked for examples of sexual harassment at law schools, ChatGPT named a GW prof accused of touching a student on a class trip to Alaska, citing a WashPost story. 

The prof is real. The rest was made up.

We wrote about what happens when AIs lie about you: https://washingtonpost.com/technology/2023/04/05/chatgpt-lies/…
------
Missing something important?
Oh, you think? 
------
I continue to be baffled at how well sequence distillation/model "stealing" works with such little data. Makes me feel like we are still missing something important about LMs.
------
The notion of "object" (or "concept") is contextual and controllable. Segment Anything allows a greater degree of expressivity than anything we've done before, and is open-sourced for anyone to try. Exciting to see what this will enable, in terms of broader scientific discovery!
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
Join a special event happening this Friday, April 7 at 9:30 AM Pacific Time with 
@YLeCun
 and 
@AndrewYNg
 as they discuss the pros and cons of a proposal from the Future of Life Institute for a 6-month moratorium on generative AI.

You don’t want to miss it! https://hubs.la/Q01KrLJ00
------
Yes, regulate applications, not R&D.
------
Hi @elonmusk, I would believe your concerns more if Tesla didn't download powerful AI into every car.
Why over-regulate some AI models instead of real applications?
Language models can't say or choose what they "want." Just like a FSD Tesla can't decide where to drive by itself.
------
The Ottoman Empire limited the dissemination of printed books, fearing religious & political upheaval.  Consequently, it missed out on the Enlightenment & lost its dominant status in science, technology, & ultimately lost its economic and military influence.
------
Hot take: stopping AI high-skill job displacement will be the first time in recent memory that luddites will win big.

Because powerful people have something big to lose from AI.

Sort of a political economy thing, the way dictators choose stagnation over growth.
------
Survey by country:
"Products and services using AI have more benefits than drawbacks"
China: yeah, AI good!
South Korea, Turkey, Brazil: Meh.
Europe: AI bad.
France, Canada, Netherlands, US: OMG, we are doomed!

From the Stanford AI Index:
https://aiindex.stanford.edu/report/?sf176386094=1…
------
The gist of our arguments against the 6-month AI moratorium at 
@VentureBeat
.
With 
@AndrewYNg
.
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
Does it run LLaMA 7B?
is the new
Does it run Doom?
------
Is this the new "Will it run Doom?" twitter.com/miolini/status…
------
And cockatoos are worse.
They'll gouge your eyes out if they don't like you.
I'm calling for a 6 month moratorium on cockatoos.
------
(btw, it needs to be said: parrots (stochastic or not) are waaay more dangerous than LLMs in their capacity to physically harm you. they have beaks, claws and intents.)
------
AI is going to be an amplification of human intelligence. Why would we want to stop that?
Amazing thirty minutes with 
@ylecun
 and 
@AndrewYNg
.
------
As per your request, the latest updates on the book.
https://atcold.github.io/book.html
------
Here's a video of my conversation with 
@ylecun
 about the proposed 6 month AI pause. I would love to hear what you think of the AI pause -- please reply to share your thoughts!
------
Video of the session with 
@AndrewYNg
 and me discussing why the call for a 6 month moratorium on LLM training is a bad idea.
------
Starting soon! 

AI luminaries 
@ylecun
 and 
@AndrewYNg
 will discuss a proposed 6-month moratorium on generative AI and its possible impacts. 

RSVP to get the link!
------
Video of the debate:
"Do language models need sensory grounding for meaning and understanding?"
With 
@Jake_Browning00
, 
@LakeBrenden
, and me on the YES side and Ellie Pavlick, 
@glupyan
, and 
@davidchalmers42
 on the NO side.

I go through the limitations of Auto-Regressive LLMs.
------
Here's the pre-conference debate on "Do Language Models Need Sensory Grounding for Meaning and Understanding?" ft.  @ylecun, Ellie Pavlick @Brown_NLP, @LakeBrenden, @davidchalmers42, @Jake_Browning00 & @glupyan  https://youtu.be/x10964w00zk
------
YouTube Playlist of the entire Philosophy of Deep Learning Conference that was held two weeks ago at NYU.
------
Happy to share that the recordings of the #phildeeplearning conference are now available! Head  to https://phildeeplearning.github.io to find individual links in the program, or to https://phildeeplearning.github.io/recordings for the whole Youtube playlist.
------
Inference-time objectives.
Planning & reasoning to optimize those objectives at inference time.
------
In this debate with Russell, Bengio, and @TonyZador, @ylecun makes a key point. They all basically agree on the missing ingredient in AI safety: updatable objective functions, with the ability to correct harmful effects in production (presumably using harm/well-being measures)  twitter.com/ylecun/status/…
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
History shows over and over that society and people's well-being makes progress with more intelligence: better skills, literacy, education, creativity, culture, communication, & the free exchange of ideas.
Intelligence, by humans and machines, is what fuels progress.
------
Machine intelligence is a way to amplify human intelligence, just as mechanical tools amplify human physical capabilities.
------
Repeat after me:
1. Current Auto-Regressive LLMs are *very* useful as writing aids (yes, even for medical reports).
2. They are not reliable as factual information sources.
3. Writing assistance is like driving assistance: your hands must remain on the keyboard/wheel at all times
------
I'm very proud of this interview. I listened to NPR every day when I arrived in the US and it was a key part of my integration process.
Thank you @gbrumfiel ! twitter.com/gbrumfiel/stat…
------
Aw C'mon! Who are we going to believe? A 20 billion $ "Search by Imagination" service or some 
@washingtonpost
 reporter?

(My head spins at the very insanity of  sane people believing that LLMs can be used for *search*--for queries they don't actually know the answers to..)
------
Asked for examples of sexual harassment at law schools, ChatGPT named a GW prof accused of touching a student on a class trip to Alaska, citing a WashPost story. 

The prof is real. The rest was made up.

We wrote about what happens when AIs lie about you: https://washingtonpost.com/technology/2023/04/05/chatgpt-lies/…
------
Missing something important?
Oh, you think? 
------
I continue to be baffled at how well sequence distillation/model "stealing" works with such little data. Makes me feel like we are still missing something important about LMs.
------
The notion of "object" (or "concept") is contextual and controllable. Segment Anything allows a greater degree of expressivity than anything we've done before, and is open-sourced for anyone to try. Exciting to see what this will enable, in terms of broader scientific discovery!
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
Join a special event happening this Friday, April 7 at 9:30 AM Pacific Time with 
@YLeCun
 and 
@AndrewYNg
 as they discuss the pros and cons of a proposal from the Future of Life Institute for a 6-month moratorium on generative AI.

You don’t want to miss it! https://hubs.la/Q01KrLJ00
------
Yes, regulate applications, not R&D.
------
Hi @elonmusk, I would believe your concerns more if Tesla didn't download powerful AI into every car.
Why over-regulate some AI models instead of real applications?
Language models can't say or choose what they "want." Just like a FSD Tesla can't decide where to drive by itself.
------
The Ottoman Empire limited the dissemination of printed books, fearing religious & political upheaval.  Consequently, it missed out on the Enlightenment & lost its dominant status in science, technology, & ultimately lost its economic and military influence.
------
Hot take: stopping AI high-skill job displacement will be the first time in recent memory that luddites will win big.

Because powerful people have something big to lose from AI.

Sort of a political economy thing, the way dictators choose stagnation over growth.
------
More info
------
Some good remarks about the mood of many AI researchers and engineers at the moment.
It's easy to make two mistakes and get depressed or feel burned out:
1. Thinking that AI is "solved" or will soon be.
2. Thinking that one can not contribute.
Both are false.
------
Almost everyone I know working in AI these days feels one step away from total burnout. I took the time to take you behind the curtain and know what people on the state-of-the-art AI are struggling with:

https://robotic.substack.com/p/behind-the-curtain-ai…
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
------
Very exciting and provocative new work by 
@raphaelmilliere
 on a topic recently taken up by 
@ylecun
 
@davidchalmers42
 
@Brown_NLP
 
@glupyan
 
@LakeBrenden
 and I in our debate at NYU on LLMs and symbol grounding
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
https://arxiv.org/abs/2304.01481
------
I'm excited about Segment Anything released from FAIR today. It tackles an old problem (find objects in images) at large scale: trained on 11M images and 1B objects.
This is a new Foundation Model for Computer Vision - it recognizes any object in any context.
------
Yann LeCun and I have thought a lot about the proposed 6 month AI pause, and plan to chat about it on Friday - the questions it raises for AI and its impact on developers and companies. Please join 
@ylecun
 and me for the conversation! RSVP here:
------
Why does generative AI struggle with hands?

It is not a mystical Bermuda Triangle in the latent space. There're compelling reasons:

1. Data size (duh). Face pics are much more common than hand pics. Even when the whole body is shown, hands tend to occupy much smaller pixel real… Show more
------
Does it run LLaMA 7B?
is the new
Does it run Doom?
------
Is this the new "Will it run Doom?" twitter.com/miolini/status…
------
And cockatoos are worse.
They'll gouge your eyes out if they don't like you.
I'm calling for a 6 month moratorium on cockatoos.
------
(btw, it needs to be said: parrots (stochastic or not) are waaay more dangerous than LLMs in their capacity to physically harm you. they have beaks, claws and intents.)
------
AI is going to be an amplification of human intelligence. Why would we want to stop that?
Amazing thirty minutes with 
@ylecun
 and 
@AndrewYNg
.
------
As per your request, the latest updates on the book.
https://atcold.github.io/book.html
------
Here's a video of my conversation with 
@ylecun
 about the proposed 6 month AI pause. I would love to hear what you think of the AI pause -- please reply to share your thoughts!
------
Video of the session with 
@AndrewYNg
 and me discussing why the call for a 6 month moratorium on LLM training is a bad idea.
------
Starting soon! 

AI luminaries 
@ylecun
 and 
@AndrewYNg
 will discuss a proposed 6-month moratorium on generative AI and its possible impacts. 

RSVP to get the link!
------
Video of the debate:
"Do language models need sensory grounding for meaning and understanding?"
With 
@Jake_Browning00
, 
@LakeBrenden
, and me on the YES side and Ellie Pavlick, 
@glupyan
, and 
@davidchalmers42
 on the NO side.

I go through the limitations of Auto-Regressive LLMs.
------
Here's the pre-conference debate on "Do Language Models Need Sensory Grounding for Meaning and Understanding?" ft.  @ylecun, Ellie Pavlick @Brown_NLP, @LakeBrenden, @davidchalmers42, @Jake_Browning00 & @glupyan  https://youtu.be/x10964w00zk
------
YouTube Playlist of the entire Philosophy of Deep Learning Conference that was held two weeks ago at NYU.
------
Happy to share that the recordings of the #phildeeplearning conference are now available! Head  to https://phildeeplearning.github.io to find individual links in the program, or to https://phildeeplearning.github.io/recordings for the whole Youtube playlist.
------
Inference-time objectives.
Planning & reasoning to optimize those objectives at inference time.
------
In this debate with Russell, Bengio, and @TonyZador, @ylecun makes a key point. They all basically agree on the missing ingredient in AI safety: updatable objective functions, with the ability to correct harmful effects in production (presumably using harm/well-being measures)  twitter.com/ylecun/status/…
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
History shows over and over that society and people's well-being makes progress with more intelligence: better skills, literacy, education, creativity, culture, communication, & the free exchange of ideas.
Intelligence, by humans and machines, is what fuels progress.
------
Machine intelligence is a way to amplify human intelligence, just as mechanical tools amplify human physical capabilities.
------
Repeat after me:
1. Current Auto-Regressive LLMs are *very* useful as writing aids (yes, even for medical reports).
2. They are not reliable as factual information sources.
3. Writing assistance is like driving assistance: your hands must remain on the keyboard/wheel at all times
------
I'm very proud of this interview. I listened to NPR every day when I arrived in the US and it was a key part of my integration process.
Thank you @gbrumfiel ! twitter.com/gbrumfiel/stat…
------
Aw C'mon! Who are we going to believe? A 20 billion $ "Search by Imagination" service or some 
@washingtonpost
 reporter?

(My head spins at the very insanity of  sane people believing that LLMs can be used for *search*--for queries they don't actually know the answers to..)
------
Asked for examples of sexual harassment at law schools, ChatGPT named a GW prof accused of touching a student on a class trip to Alaska, citing a WashPost story. 

The prof is real. The rest was made up.

We wrote about what happens when AIs lie about you: https://washingtonpost.com/technology/2023/04/05/chatgpt-lies/…
------
Missing something important?
Oh, you think? 
------
I continue to be baffled at how well sequence distillation/model "stealing" works with such little data. Makes me feel like we are still missing something important about LMs.
------
The notion of "object" (or "concept") is contextual and controllable. Segment Anything allows a greater degree of expressivity than anything we've done before, and is open-sourced for anyone to try. Exciting to see what this will enable, in terms of broader scientific discovery!
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
Join a special event happening this Friday, April 7 at 9:30 AM Pacific Time with 
@YLeCun
 and 
@AndrewYNg
 as they discuss the pros and cons of a proposal from the Future of Life Institute for a 6-month moratorium on generative AI.

You don’t want to miss it! https://hubs.la/Q01KrLJ00
------
Yes, regulate applications, not R&D.
------
Hi @elonmusk, I would believe your concerns more if Tesla didn't download powerful AI into every car.
Why over-regulate some AI models instead of real applications?
Language models can't say or choose what they "want." Just like a FSD Tesla can't decide where to drive by itself.
------
The Ottoman Empire limited the dissemination of printed books, fearing religious & political upheaval.  Consequently, it missed out on the Enlightenment & lost its dominant status in science, technology, & ultimately lost its economic and military influence.
------
Hot take: stopping AI high-skill job displacement will be the first time in recent memory that luddites will win big.

Because powerful people have something big to lose from AI.

Sort of a political economy thing, the way dictators choose stagnation over growth.
------
More info
------
Some good remarks about the mood of many AI researchers and engineers at the moment.
It's easy to make two mistakes and get depressed or feel burned out:
1. Thinking that AI is "solved" or will soon be.
2. Thinking that one can not contribute.
Both are false.
------
Almost everyone I know working in AI these days feels one step away from total burnout. I took the time to take you behind the curtain and know what people on the state-of-the-art AI are struggling with:

https://robotic.substack.com/p/behind-the-curtain-ai…
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
------
Very exciting and provocative new work by 
@raphaelmilliere
 on a topic recently taken up by 
@ylecun
 
@davidchalmers42
 
@Brown_NLP
 
@glupyan
 
@LakeBrenden
 and I in our debate at NYU on LLMs and symbol grounding
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
https://arxiv.org/abs/2304.01481
------
I'm excited about Segment Anything released from FAIR today. It tackles an old problem (find objects in images) at large scale: trained on 11M images and 1B objects.
This is a new Foundation Model for Computer Vision - it recognizes any object in any context.
------
Yann LeCun and I have thought a lot about the proposed 6 month AI pause, and plan to chat about it on Friday - the questions it raises for AI and its impact on developers and companies. Please join 
@ylecun
 and me for the conversation! RSVP here:
------
SAM: Segment Anything Model from FAIR.
Foundation model for image segmentation.

Demo: https://segment-anything.com/demo
Blog: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/…
Paper: https://ai.facebook.com/research/publications/segment-anything/…
Code: https://github.com/facebookresearch/segment-anything…
Dataset: SA-1B , 11 million image, 1 billion masks https://ai.facebook.com/datasets/segment-anything/…
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
This Friday, 12:30-13:00 EST.
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
Video of the session with 
@AndrewYNg
 and me discussing why the call for a 6 month moratorium on LLM training is a bad idea.
------
Starting soon! 

AI luminaries 
@ylecun
 and 
@AndrewYNg
 will discuss a proposed 6-month moratorium on generative AI and its possible impacts. 

RSVP to get the link!
------
Video of the debate:
"Do language models need sensory grounding for meaning and understanding?"
With 
@Jake_Browning00
, 
@LakeBrenden
, and me on the YES side and Ellie Pavlick, 
@glupyan
, and 
@davidchalmers42
 on the NO side.

I go through the limitations of Auto-Regressive LLMs.
------
Here's the pre-conference debate on "Do Language Models Need Sensory Grounding for Meaning and Understanding?" ft.  @ylecun, Ellie Pavlick @Brown_NLP, @LakeBrenden, @davidchalmers42, @Jake_Browning00 & @glupyan  https://youtu.be/x10964w00zk
------
YouTube Playlist of the entire Philosophy of Deep Learning Conference that was held two weeks ago at NYU.
------
Happy to share that the recordings of the #phildeeplearning conference are now available! Head  to https://phildeeplearning.github.io to find individual links in the program, or to https://phildeeplearning.github.io/recordings for the whole Youtube playlist.
------
Inference-time objectives.
Planning & reasoning to optimize those objectives at inference time.
------
In this debate with Russell, Bengio, and @TonyZador, @ylecun makes a key point. They all basically agree on the missing ingredient in AI safety: updatable objective functions, with the ability to correct harmful effects in production (presumably using harm/well-being measures)  twitter.com/ylecun/status/…
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
History shows over and over that society and people's well-being makes progress with more intelligence: better skills, literacy, education, creativity, culture, communication, & the free exchange of ideas.
Intelligence, by humans and machines, is what fuels progress.
------
Machine intelligence is a way to amplify human intelligence, just as mechanical tools amplify human physical capabilities.
------
Repeat after me:
1. Current Auto-Regressive LLMs are *very* useful as writing aids (yes, even for medical reports).
2. They are not reliable as factual information sources.
3. Writing assistance is like driving assistance: your hands must remain on the keyboard/wheel at all times
------
I'm very proud of this interview. I listened to NPR every day when I arrived in the US and it was a key part of my integration process.
Thank you @gbrumfiel ! twitter.com/gbrumfiel/stat…
------
Aw C'mon! Who are we going to believe? A 20 billion $ "Search by Imagination" service or some 
@washingtonpost
 reporter?

(My head spins at the very insanity of  sane people believing that LLMs can be used for *search*--for queries they don't actually know the answers to..)
------
Asked for examples of sexual harassment at law schools, ChatGPT named a GW prof accused of touching a student on a class trip to Alaska, citing a WashPost story. 

The prof is real. The rest was made up.

We wrote about what happens when AIs lie about you: https://washingtonpost.com/technology/2023/04/05/chatgpt-lies/…
------
Missing something important?
Oh, you think? 
------
I continue to be baffled at how well sequence distillation/model "stealing" works with such little data. Makes me feel like we are still missing something important about LMs.
------
The notion of "object" (or "concept") is contextual and controllable. Segment Anything allows a greater degree of expressivity than anything we've done before, and is open-sourced for anyone to try. Exciting to see what this will enable, in terms of broader scientific discovery!
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
Join a special event happening this Friday, April 7 at 9:30 AM Pacific Time with 
@YLeCun
 and 
@AndrewYNg
 as they discuss the pros and cons of a proposal from the Future of Life Institute for a 6-month moratorium on generative AI.

You don’t want to miss it! https://hubs.la/Q01KrLJ00
------
Yes, regulate applications, not R&D.
------
Hi @elonmusk, I would believe your concerns more if Tesla didn't download powerful AI into every car.
Why over-regulate some AI models instead of real applications?
Language models can't say or choose what they "want." Just like a FSD Tesla can't decide where to drive by itself.
------
The Ottoman Empire limited the dissemination of printed books, fearing religious & political upheaval.  Consequently, it missed out on the Enlightenment & lost its dominant status in science, technology, & ultimately lost its economic and military influence.
------
Hot take: stopping AI high-skill job displacement will be the first time in recent memory that luddites will win big.

Because powerful people have something big to lose from AI.

Sort of a political economy thing, the way dictators choose stagnation over growth.
------
More info
------
Some good remarks about the mood of many AI researchers and engineers at the moment.
It's easy to make two mistakes and get depressed or feel burned out:
1. Thinking that AI is "solved" or will soon be.
2. Thinking that one can not contribute.
Both are false.
------
Almost everyone I know working in AI these days feels one step away from total burnout. I took the time to take you behind the curtain and know what people on the state-of-the-art AI are struggling with:

https://robotic.substack.com/p/behind-the-curtain-ai…
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
------
Very exciting and provocative new work by 
@raphaelmilliere
 on a topic recently taken up by 
@ylecun
 
@davidchalmers42
 
@Brown_NLP
 
@glupyan
 
@LakeBrenden
 and I in our debate at NYU on LLMs and symbol grounding
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
https://arxiv.org/abs/2304.01481
------
I'm excited about Segment Anything released from FAIR today. It tackles an old problem (find objects in images) at large scale: trained on 11M images and 1B objects.
This is a new Foundation Model for Computer Vision - it recognizes any object in any context.
------
Yann LeCun and I have thought a lot about the proposed 6 month AI pause, and plan to chat about it on Friday - the questions it raises for AI and its impact on developers and companies. Please join 
@ylecun
 and me for the conversation! RSVP here:
------
SAM: Segment Anything Model from FAIR.
Foundation model for image segmentation.

Demo: https://segment-anything.com/demo
Blog: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/…
Paper: https://ai.facebook.com/research/publications/segment-anything/…
Code: https://github.com/facebookresearch/segment-anything…
Dataset: SA-1B , 11 million image, 1 billion masks https://ai.facebook.com/datasets/segment-anything/…
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
This Friday, 12:30-13:00 EST.
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
We are organizing "Cosmic Connections": 
An AI X Astro Symposium in 
@SimonsFdn
 at 
@FlatironCCA
! 

If you are a student/researcher/faculty who is interested in AI X Astro area, consider applying to join us at the symposium. 

Apply by April 9! 

Awesome speakers lineup 
------
History shows over and over that society and people's well-being makes progress with more intelligence: better skills, literacy, education, creativity, culture, communication, & the free exchange of ideas.
Intelligence, by humans and machines, is what fuels progress.
------
Machine intelligence is a way to amplify human intelligence, just as mechanical tools amplify human physical capabilities.
------
Repeat after me:
1. Current Auto-Regressive LLMs are *very* useful as writing aids (yes, even for medical reports).
2. They are not reliable as factual information sources.
3. Writing assistance is like driving assistance: your hands must remain on the keyboard/wheel at all times
------
I'm very proud of this interview. I listened to NPR every day when I arrived in the US and it was a key part of my integration process.
Thank you @gbrumfiel ! twitter.com/gbrumfiel/stat…
------
Aw C'mon! Who are we going to believe? A 20 billion $ "Search by Imagination" service or some 
@washingtonpost
 reporter?

(My head spins at the very insanity of  sane people believing that LLMs can be used for *search*--for queries they don't actually know the answers to..)
------
Asked for examples of sexual harassment at law schools, ChatGPT named a GW prof accused of touching a student on a class trip to Alaska, citing a WashPost story. 

The prof is real. The rest was made up.

We wrote about what happens when AIs lie about you: https://washingtonpost.com/technology/2023/04/05/chatgpt-lies/…
------
Missing something important?
Oh, you think? 
------
I continue to be baffled at how well sequence distillation/model "stealing" works with such little data. Makes me feel like we are still missing something important about LMs.
------
The notion of "object" (or "concept") is contextual and controllable. Segment Anything allows a greater degree of expressivity than anything we've done before, and is open-sourced for anyone to try. Exciting to see what this will enable, in terms of broader scientific discovery!
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
Join a special event happening this Friday, April 7 at 9:30 AM Pacific Time with 
@YLeCun
 and 
@AndrewYNg
 as they discuss the pros and cons of a proposal from the Future of Life Institute for a 6-month moratorium on generative AI.

You don’t want to miss it! https://hubs.la/Q01KrLJ00
------
Yes, regulate applications, not R&D.
------
Hi @elonmusk, I would believe your concerns more if Tesla didn't download powerful AI into every car.
Why over-regulate some AI models instead of real applications?
Language models can't say or choose what they "want." Just like a FSD Tesla can't decide where to drive by itself.
------
The Ottoman Empire limited the dissemination of printed books, fearing religious & political upheaval.  Consequently, it missed out on the Enlightenment & lost its dominant status in science, technology, & ultimately lost its economic and military influence.
------
Hot take: stopping AI high-skill job displacement will be the first time in recent memory that luddites will win big.

Because powerful people have something big to lose from AI.

Sort of a political economy thing, the way dictators choose stagnation over growth.
------
More info
------
Some good remarks about the mood of many AI researchers and engineers at the moment.
It's easy to make two mistakes and get depressed or feel burned out:
1. Thinking that AI is "solved" or will soon be.
2. Thinking that one can not contribute.
Both are false.
------
Almost everyone I know working in AI these days feels one step away from total burnout. I took the time to take you behind the curtain and know what people on the state-of-the-art AI are struggling with:

https://robotic.substack.com/p/behind-the-curtain-ai…
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
------
Very exciting and provocative new work by 
@raphaelmilliere
 on a topic recently taken up by 
@ylecun
 
@davidchalmers42
 
@Brown_NLP
 
@glupyan
 
@LakeBrenden
 and I in our debate at NYU on LLMs and symbol grounding
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
https://arxiv.org/abs/2304.01481
------
I'm excited about Segment Anything released from FAIR today. It tackles an old problem (find objects in images) at large scale: trained on 11M images and 1B objects.
This is a new Foundation Model for Computer Vision - it recognizes any object in any context.
------
Yann LeCun and I have thought a lot about the proposed 6 month AI pause, and plan to chat about it on Friday - the questions it raises for AI and its impact on developers and companies. Please join 
@ylecun
 and me for the conversation! RSVP here:
------
SAM: Segment Anything Model from FAIR.
Foundation model for image segmentation.

Demo: https://segment-anything.com/demo
Blog: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/…
Paper: https://ai.facebook.com/research/publications/segment-anything/…
Code: https://github.com/facebookresearch/segment-anything…
Dataset: SA-1B , 11 million image, 1 billion masks https://ai.facebook.com/datasets/segment-anything/…
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
This Friday, 12:30-13:00 EST.
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
The notion of "object" (or "concept") is contextual and controllable. Segment Anything allows a greater degree of expressivity than anything we've done before, and is open-sourced for anyone to try. Exciting to see what this will enable, in terms of broader scientific discovery!
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
Join a special event happening this Friday, April 7 at 9:30 AM Pacific Time with 
@YLeCun
 and 
@AndrewYNg
 as they discuss the pros and cons of a proposal from the Future of Life Institute for a 6-month moratorium on generative AI.

You don’t want to miss it! https://hubs.la/Q01KrLJ00
------
Yes, regulate applications, not R&D.
------
Hi @elonmusk, I would believe your concerns more if Tesla didn't download powerful AI into every car.
Why over-regulate some AI models instead of real applications?
Language models can't say or choose what they "want." Just like a FSD Tesla can't decide where to drive by itself.
------
The Ottoman Empire limited the dissemination of printed books, fearing religious & political upheaval.  Consequently, it missed out on the Enlightenment & lost its dominant status in science, technology, & ultimately lost its economic and military influence.
------
Hot take: stopping AI high-skill job displacement will be the first time in recent memory that luddites will win big.

Because powerful people have something big to lose from AI.

Sort of a political economy thing, the way dictators choose stagnation over growth.
------
More info
------
Some good remarks about the mood of many AI researchers and engineers at the moment.
It's easy to make two mistakes and get depressed or feel burned out:
1. Thinking that AI is "solved" or will soon be.
2. Thinking that one can not contribute.
Both are false.
------
Almost everyone I know working in AI these days feels one step away from total burnout. I took the time to take you behind the curtain and know what people on the state-of-the-art AI are struggling with:

https://robotic.substack.com/p/behind-the-curtain-ai…
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
------
Very exciting and provocative new work by 
@raphaelmilliere
 on a topic recently taken up by 
@ylecun
 
@davidchalmers42
 
@Brown_NLP
 
@glupyan
 
@LakeBrenden
 and I in our debate at NYU on LLMs and symbol grounding
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
https://arxiv.org/abs/2304.01481
------
I'm excited about Segment Anything released from FAIR today. It tackles an old problem (find objects in images) at large scale: trained on 11M images and 1B objects.
This is a new Foundation Model for Computer Vision - it recognizes any object in any context.
------
Yann LeCun and I have thought a lot about the proposed 6 month AI pause, and plan to chat about it on Friday - the questions it raises for AI and its impact on developers and companies. Please join 
@ylecun
 and me for the conversation! RSVP here:
------
SAM: Segment Anything Model from FAIR.
Foundation model for image segmentation.

Demo: https://segment-anything.com/demo
Blog: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/…
Paper: https://ai.facebook.com/research/publications/segment-anything/…
Code: https://github.com/facebookresearch/segment-anything…
Dataset: SA-1B , 11 million image, 1 billion masks https://ai.facebook.com/datasets/segment-anything/…
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
This Friday, 12:30-13:00 EST.
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
More info
------
Some good remarks about the mood of many AI researchers and engineers at the moment.
It's easy to make two mistakes and get depressed or feel burned out:
1. Thinking that AI is "solved" or will soon be.
2. Thinking that one can not contribute.
Both are false.
------
Almost everyone I know working in AI these days feels one step away from total burnout. I took the time to take you behind the curtain and know what people on the state-of-the-art AI are struggling with:

https://robotic.substack.com/p/behind-the-curtain-ai…
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
------
Very exciting and provocative new work by 
@raphaelmilliere
 on a topic recently taken up by 
@ylecun
 
@davidchalmers42
 
@Brown_NLP
 
@glupyan
 
@LakeBrenden
 and I in our debate at NYU on LLMs and symbol grounding
------
New preprint! What does it take for AI models to have grounded representations of lexical items? There is a lot of disagreement – some verbal, some substantive – about what grounding involves. Dimitri Mollo and I frame this old question in a new light 1/
https://arxiv.org/abs/2304.01481
------
I'm excited about Segment Anything released from FAIR today. It tackles an old problem (find objects in images) at large scale: trained on 11M images and 1B objects.
This is a new Foundation Model for Computer Vision - it recognizes any object in any context.
------
Yann LeCun and I have thought a lot about the proposed 6 month AI pause, and plan to chat about it on Friday - the questions it raises for AI and its impact on developers and companies. Please join 
@ylecun
 and me for the conversation! RSVP here:
------
SAM: Segment Anything Model from FAIR.
Foundation model for image segmentation.

Demo: https://segment-anything.com/demo
Blog: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/…
Paper: https://ai.facebook.com/research/publications/segment-anything/…
Code: https://github.com/facebookresearch/segment-anything…
Dataset: SA-1B , 11 million image, 1 billion masks https://ai.facebook.com/datasets/segment-anything/…
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
This Friday, 12:30-13:00 EST.
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
SAM: Segment Anything Model from FAIR.
Foundation model for image segmentation.

Demo: https://segment-anything.com/demo
Blog: https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/…
Paper: https://ai.facebook.com/research/publications/segment-anything/…
Code: https://github.com/facebookresearch/segment-anything…
Dataset: SA-1B , 11 million image, 1 billion masks https://ai.facebook.com/datasets/segment-anything/…
------
Today we're releasing the Segment Anything Model (SAM) — a step toward the first foundation model for image segmentation.

SAM is capable of one-click segmentation of any object from any photo or video + zero-shot transfer to other segmentation tasks  https://bit.ly/433YuBI
------
This Friday, 12:30-13:00 EST.
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
got many interview requests from journalists interested in AI & existential risk.  I am left with the impression that most of them are not interested in critically thinking this through.
instead they want to squeeze everything into a pre-existing format of pro (AI will make us… Show more
------
A fireside chat about AI at the NYU Paris campus.
Hosted by CNRS philosopher & cognitive scientist Frédérique de Vignemont.
April 17, 18:30.
Register at: http://bit.ly/nyuparisyannlecun…
------
Welcoming our esteemed guest speakers who will be sharing their wealth of knowledge and experience on the topic of #AI. Yann LeCun @ylecun, Silver Professor at @nyuniversity and VP & Chief AI Scientist at Meta in a fireside chat with Dr. Frédérique de Vignemont (CNRS & NYU Paris)
------
We've released the Koala into the wild

The Koala is a chatbot finetuned from LLaMA that is specifically optimized for high-quality chat capabilities, using some tricky data sourcing.

Our blog post: https://bair.berkeley.edu/blog/2023/04/03/koala/…
Web demo:
------
At the White House today for discussions with the President on the risks and opportunities of #AI.
https://cnb.cx/3zycJRW #PCAST 
@WHOSTP
------
The transcript of this debate is really interesting and worth reading. 
@ylecun
 makes good points:
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.

https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/…
------
My claim is that AI alignment will be manageable & less difficult than many have claimed. But until we have a design for Human-Level AI, it's mere speculation.

But I like the idea of a continuum being named after me 

I've met Jaan a couple of times. He is a nice fellow.
------
I propose the Yann-Jaan continuum of existential risk from a misaligned AGI. At one end you have @ylecun who argues we are a long way off AGI and that alignment will be easy. At the other end you have Jaan Tallinn, signatory to the moratorium letter.
------
I agree with 
@lemire
: Pausing AI research is neither practically doable nor desirable. Fortunately, as a society we have plenty of experience of disruptive technologies.
------
What are we going to do about ChatGPT? https://lemire.me/blog/2023/04/03/what-are-we-going-to-do-about-chatgpt/…
------
I’ve been asking this same question 
@leecronin
 & still haven’t heard an even remotely plausible scenario. Honestly, the religious end-timers, whom I have studied for 50 years (since I read & believed The Late Great Planet Earth), are as (un)realistic as the AI doomsayers.
------
How exactly is the AGI going to kill us? Any ideas? The nonsense being shared right now displays a staggering lack of understanding.
------
Excellent essay by my dear NYU colleague Julian 
@togelius
 about the existential threats from rogue AI, or rather, about the insanely-overstated likelihood of such threats. 
1/
------
Is Elden Ring an existential risk to humanity? That is the question I consider in my new blog post. Yes, it is a comment on the superintelligence/x-risk debate. Read the full thing here:
http://togelius.blogspot.com/2023/04/is-elden-ring-existential-risk-to.html…
Or follow along for a few tweets first, if you prefer.
------
Julian reminds us:
1. all intelligence is specialized, including human intelligence.
2. being smart in some domains makes you strong in some environments but weak in others.
3. Intelligence does not immediately cause a thing to be able to "take over" 
2/
------
4. Intelligence does not immediately cause an entity yo want to "take over"
5. A very dumb but specialized entity can kill a smarter one, e.g. virus vs human.

Julian argues that MS Excel can do intelligent tasks and, in some ways, has already "taken over" our lives 
------
GPT4All and LLaMa.cpp Python Bindings Are Here  

Over the weekend, an elite team of hackers in the gpt4all community created the official set of python bindings for GPT4all.  They will be maintained for llama.cpp compatibility going forward.
------
Dear 
@ESYudkowsky
 You stand a far greater chance of dying from lighting strikes, collisions with deer, peanut allergies, bee stings & ignition or melting of nightware than you do from AI. Do some Bayesian computations & quit stoking irrational fears. You're succumbing to the… Show more
------
Somebody recently asked me for a probability and I was like, "As a human built by evolution, I do not natively represent my uncertainty as well-calibrated probabilities.  However..."
------
Well, but learning image representations with generative models never actually worked.
When it comes to SSL for images, GAN, VAE, denoising AE and other gen models have been a bust.
What has worked is Joint Embedding (non generative) Architectures like Siamese nets, JEPA & such.
------
Feels like just yesterday that any work on generative modelling had to be justified through "representation learning", or some sort of downstream task, to be taken seriously. Times have changed! twitter.com/karpathy/statu…
------
Teratogenerative AI : producing monsters with AI.
------
Many AI safety discussions today seem as speculative as discussions about airliner safety in 1890.

Before we have a basic design & basic demos of AI systems that could credibly reach human-level intelligence, arguments about their risks & safety mechanisms are premature.
------
Every new technology is developed and deployed the same way: 
You make a prototype, try it at a small scale, make limited deployment, fix the problems, make it safer, and then deploy it more widely.
At that point, governments regulate it and establish safety standards.
1/
------
Forever fall.
------
なんと動いてません
------
The *only* reason people are hyperventilating about AI risk is the myth of the "hard take-off": the idea that the minute you turn on a super-intelligent system, humanity is doomed.
This is preposterously stupid and based on a *complete* misunderstanding of how everything works.
------
Mine says that the risk of humanity being wiped out by rogue AI is considerably less than the risk of it being wiped out by an asteroid strike.

If AI could help us avoid cosmic extinction by accelerating progress in astronautics, we should develop it ASAP, no?

Viva SpaceX!
------
The aerospace industry arguably spends more on safety than on basic design.
But since current AI systems have limited capabilities, asking for safety measures is premature.
It's as if we devoted enormous efforts to discuss aircraft safety before we knew how to build airplanes.
------
I don't engage with arguments from creationists and flat-earthers either.
------
How about signaling a sufficient condition for mere competence?
Merit doesn't matter nearly as much.
------
There are regulations and regulating agencies for *applications* of AI, e.g. for driving assistance, medical image analysis, etc.
Are you suggesting that R&D for basic AI technology should be regulated?
------
No.
It shows extreme crackpottery from the other party.
I mean, calling to nuke datacenters suspected of harboring too many ASI-enabling GPUs?
Seriously?
------
I can propose an infinite number of improbable doomsday scenarios.
They might make for fun Sci-Fi.
But they are not worth anyone's time to refute one by one.
They would have to be realistic to be worth refuting.
------
Think about the early days of automobiles: weak brakes, no seatbelts, no bumpers, no traffic signs. Yes, people died. Then, we had disk brakes, belts, ABS, airbags, driving assistance, speed limits, traffic signals....
Same story for pretty much every new tech ever deployed.
------
The US regulating agency certified Tesla's "FSD" as Level-2 (out of 5).
The only manufacturer to have obtained Level-3 certification in the  US is not Tesla but Mercedes (using technology from Nvidia).
------
Where are those "generalized AI"?
They don't exist. They will, but right now, they don't. 
And what harm might they cause once they exist?
How could you tell, since you have no idea how they would work?
------
Don't you think worrying about the proper design of parachutes before the invention of the airplane is a little too early?
------
Are you talking about LLMs?
Are they useful?
Are they dangerous?
Is their usefulness overwhelmingly larger than the dangers?
(You know, like cars, airplanes, kitchen knives, gas stoves, smartphones....)
------
I'd submit that most of these people are not "terrified of AI."
Except Stuart Russell, who is just wrong.
Working on AI safety and ethics doesn't automatically make you terrified of it.
I think AI safety is an important topic. But I'm not terrified.
------
.
@geoffreyhinton
 and I have been friends for 37 years.
We don't disagree on many things.
He says that an AI takeover is "not inconceivable" and I can't disagree.
But I also believe it's very, very low probability and preventable rather easily.
------
Chelsea's tweet is an excellent example of April fool's joke.
And your political bias made you fall for it.
------
We == society as a whole.
------
It doesn't exist.
So yes, right now, it's benign.
Once we have at least *some* idea of how this could work, we'll be able to discuss how to make it safe.
If it turns out we can't make it safe, then we won't build it.
Until then, it's like we're worrying about the sex of angels.
------
If you believe in the myth of the "hard take-off", *and* you hold the ridiculous belief that AI alignment is impossible to achieve *before* turning on an all-powerful system, then you might freak out and be subject to a nuke-data-centers-style hysterical meltdown.
------
None of them is terrified of AGI.
Except perhaps Russell, but he is mistaken.
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
Here (from 2019)
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
Teratogenerative AI : producing monsters with AI.
------
Many AI safety discussions today seem as speculative as discussions about airliner safety in 1890.

Before we have a basic design & basic demos of AI systems that could credibly reach human-level intelligence, arguments about their risks & safety mechanisms are premature.
------
Every new technology is developed and deployed the same way: 
You make a prototype, try it at a small scale, make limited deployment, fix the problems, make it safer, and then deploy it more widely.
At that point, governments regulate it and establish safety standards.
1/
------
Forever fall.
------
なんと動いてません
------
The *only* reason people are hyperventilating about AI risk is the myth of the "hard take-off": the idea that the minute you turn on a super-intelligent system, humanity is doomed.
This is preposterously stupid and based on a *complete* misunderstanding of how everything works.
------
Mine says that the risk of humanity being wiped out by rogue AI is considerably less than the risk of it being wiped out by an asteroid strike.

If AI could help us avoid cosmic extinction by accelerating progress in astronautics, we should develop it ASAP, no?

Viva SpaceX!
------
The aerospace industry arguably spends more on safety than on basic design.
But since current AI systems have limited capabilities, asking for safety measures is premature.
It's as if we devoted enormous efforts to discuss aircraft safety before we knew how to build airplanes.
------
I don't engage with arguments from creationists and flat-earthers either.
------
How about signaling a sufficient condition for mere competence?
Merit doesn't matter nearly as much.
------
There are regulations and regulating agencies for *applications* of AI, e.g. for driving assistance, medical image analysis, etc.
Are you suggesting that R&D for basic AI technology should be regulated?
------
No.
It shows extreme crackpottery from the other party.
I mean, calling to nuke datacenters suspected of harboring too many ASI-enabling GPUs?
Seriously?
------
I can propose an infinite number of improbable doomsday scenarios.
They might make for fun Sci-Fi.
But they are not worth anyone's time to refute one by one.
They would have to be realistic to be worth refuting.
------
Think about the early days of automobiles: weak brakes, no seatbelts, no bumpers, no traffic signs. Yes, people died. Then, we had disk brakes, belts, ABS, airbags, driving assistance, speed limits, traffic signals....
Same story for pretty much every new tech ever deployed.
------
The US regulating agency certified Tesla's "FSD" as Level-2 (out of 5).
The only manufacturer to have obtained Level-3 certification in the  US is not Tesla but Mercedes (using technology from Nvidia).
------
Where are those "generalized AI"?
They don't exist. They will, but right now, they don't. 
And what harm might they cause once they exist?
How could you tell, since you have no idea how they would work?
------
Don't you think worrying about the proper design of parachutes before the invention of the airplane is a little too early?
------
Are you talking about LLMs?
Are they useful?
Are they dangerous?
Is their usefulness overwhelmingly larger than the dangers?
(You know, like cars, airplanes, kitchen knives, gas stoves, smartphones....)
------
I'd submit that most of these people are not "terrified of AI."
Except Stuart Russell, who is just wrong.
Working on AI safety and ethics doesn't automatically make you terrified of it.
I think AI safety is an important topic. But I'm not terrified.
------
.
@geoffreyhinton
 and I have been friends for 37 years.
We don't disagree on many things.
He says that an AI takeover is "not inconceivable" and I can't disagree.
But I also believe it's very, very low probability and preventable rather easily.
------
Chelsea's tweet is an excellent example of April fool's joke.
And your political bias made you fall for it.
------
We == society as a whole.
------
It doesn't exist.
So yes, right now, it's benign.
Once we have at least *some* idea of how this could work, we'll be able to discuss how to make it safe.
If it turns out we can't make it safe, then we won't build it.
Until then, it's like we're worrying about the sex of angels.
------
If you believe in the myth of the "hard take-off", *and* you hold the ridiculous belief that AI alignment is impossible to achieve *before* turning on an all-powerful system, then you might freak out and be subject to a nuke-data-centers-style hysterical meltdown.
------
None of them is terrified of AGI.
Except perhaps Russell, but he is mistaken.
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
Here (from 2019)
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
No, it's not.
------
Safety is very much embedded in the AI industry.
All the big players have independent AI safety groups.
The *usage* of AI is very much regulated. E.g. AI-based driving assistance and medical image analysis systems go through certification processes.
------
If you claim that there is a teapot floating between the orbits of Jupiter and Saturn, the burden is on you to prove it, not on me to refute it.
[With thanks to 
@RichardDawkins
 for this example]
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.
------
Throughout history, (older) people have been scared of new technology, particularly new communication technology that can affect society.
Those techs *empower* people & end up being beneficial.
Tech shifts must be managed to maximize the benefits and minimize the risks.
------
An oversimplification, but a rather accurate one.
Not clear to me that 
@geoffreyhinton
 is that far to the left of me.
------
I've made a matrix so that people have a better understanding of "who stands where".

Probability of humans aligning AI vs probability of AI being hostile if not aligned by humans.

Please let me know what are your positions so it's not just my subjective perception.
Thanks
------
MS has several AI ethics efforts.
They only got rid of one. I assume because it wasn't particularly effective.
------
Teratogenerative AI : producing monsters with AI.
------
Many AI safety discussions today seem as speculative as discussions about airliner safety in 1890.

Before we have a basic design & basic demos of AI systems that could credibly reach human-level intelligence, arguments about their risks & safety mechanisms are premature.
------
Every new technology is developed and deployed the same way: 
You make a prototype, try it at a small scale, make limited deployment, fix the problems, make it safer, and then deploy it more widely.
At that point, governments regulate it and establish safety standards.
1/
------
Forever fall.
------
なんと動いてません
------
The *only* reason people are hyperventilating about AI risk is the myth of the "hard take-off": the idea that the minute you turn on a super-intelligent system, humanity is doomed.
This is preposterously stupid and based on a *complete* misunderstanding of how everything works.
------
Mine says that the risk of humanity being wiped out by rogue AI is considerably less than the risk of it being wiped out by an asteroid strike.

If AI could help us avoid cosmic extinction by accelerating progress in astronautics, we should develop it ASAP, no?

Viva SpaceX!
------
The aerospace industry arguably spends more on safety than on basic design.
But since current AI systems have limited capabilities, asking for safety measures is premature.
It's as if we devoted enormous efforts to discuss aircraft safety before we knew how to build airplanes.
------
I don't engage with arguments from creationists and flat-earthers either.
------
How about signaling a sufficient condition for mere competence?
Merit doesn't matter nearly as much.
------
There are regulations and regulating agencies for *applications* of AI, e.g. for driving assistance, medical image analysis, etc.
Are you suggesting that R&D for basic AI technology should be regulated?
------
No.
It shows extreme crackpottery from the other party.
I mean, calling to nuke datacenters suspected of harboring too many ASI-enabling GPUs?
Seriously?
------
I can propose an infinite number of improbable doomsday scenarios.
They might make for fun Sci-Fi.
But they are not worth anyone's time to refute one by one.
They would have to be realistic to be worth refuting.
------
Think about the early days of automobiles: weak brakes, no seatbelts, no bumpers, no traffic signs. Yes, people died. Then, we had disk brakes, belts, ABS, airbags, driving assistance, speed limits, traffic signals....
Same story for pretty much every new tech ever deployed.
------
The US regulating agency certified Tesla's "FSD" as Level-2 (out of 5).
The only manufacturer to have obtained Level-3 certification in the  US is not Tesla but Mercedes (using technology from Nvidia).
------
Where are those "generalized AI"?
They don't exist. They will, but right now, they don't. 
And what harm might they cause once they exist?
How could you tell, since you have no idea how they would work?
------
Don't you think worrying about the proper design of parachutes before the invention of the airplane is a little too early?
------
Are you talking about LLMs?
Are they useful?
Are they dangerous?
Is their usefulness overwhelmingly larger than the dangers?
(You know, like cars, airplanes, kitchen knives, gas stoves, smartphones....)
------
I'd submit that most of these people are not "terrified of AI."
Except Stuart Russell, who is just wrong.
Working on AI safety and ethics doesn't automatically make you terrified of it.
I think AI safety is an important topic. But I'm not terrified.
------
.
@geoffreyhinton
 and I have been friends for 37 years.
We don't disagree on many things.
He says that an AI takeover is "not inconceivable" and I can't disagree.
But I also believe it's very, very low probability and preventable rather easily.
------
Chelsea's tweet is an excellent example of April fool's joke.
And your political bias made you fall for it.
------
We == society as a whole.
------
It doesn't exist.
So yes, right now, it's benign.
Once we have at least *some* idea of how this could work, we'll be able to discuss how to make it safe.
If it turns out we can't make it safe, then we won't build it.
Until then, it's like we're worrying about the sex of angels.
------
If you believe in the myth of the "hard take-off", *and* you hold the ridiculous belief that AI alignment is impossible to achieve *before* turning on an all-powerful system, then you might freak out and be subject to a nuke-data-centers-style hysterical meltdown.
------
None of them is terrified of AGI.
Except perhaps Russell, but he is mistaken.
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
Here (from 2019)
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
No, it's not.
------
Safety is very much embedded in the AI industry.
All the big players have independent AI safety groups.
The *usage* of AI is very much regulated. E.g. AI-based driving assistance and medical image analysis systems go through certification processes.
------
If you claim that there is a teapot floating between the orbits of Jupiter and Saturn, the burden is on you to prove it, not on me to refute it.
[With thanks to 
@RichardDawkins
 for this example]
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.
------
Throughout history, (older) people have been scared of new technology, particularly new communication technology that can affect society.
Those techs *empower* people & end up being beneficial.
Tech shifts must be managed to maximize the benefits and minimize the risks.
------
An oversimplification, but a rather accurate one.
Not clear to me that 
@geoffreyhinton
 is that far to the left of me.
------
I've made a matrix so that people have a better understanding of "who stands where".

Probability of humans aligning AI vs probability of AI being hostile if not aligned by humans.

Please let me know what are your positions so it's not just my subjective perception.
Thanks
------
MS has several AI ethics efforts.
They only got rid of one. I assume because it wasn't particularly effective.
------
Exactly.
It makes sense to regulate applications (most of them already are, e.g. in transportation and health care).
Regulating R&D in a particular technology area is extremely rare.
------
No.
This is science.
People should try to prove me wrong.
As a scientist, I will change my mind in front of credible evidence.
------
In the Middle Ages, Radical Catholic Europe was way more obscurantist than the Muslim world.
Ask yourself why algebra & algorithm are Arabic words, why we use Arabic number notation (thogh they came from India), and why all the major stars in the sky have Arabic names.
------
You are extrapolating what you think you know about me.
Which apparently is not very much.
------
Every new technology is developed and deployed the same way: 
You make a prototype, try it at a small scale, make limited deployment, fix the problems, make it safer, and then deploy it more widely.
At that point, governments regulate it and establish safety standards.
1/
------
Forever fall.
------
なんと動いてません
------
The *only* reason people are hyperventilating about AI risk is the myth of the "hard take-off": the idea that the minute you turn on a super-intelligent system, humanity is doomed.
This is preposterously stupid and based on a *complete* misunderstanding of how everything works.
------
Mine says that the risk of humanity being wiped out by rogue AI is considerably less than the risk of it being wiped out by an asteroid strike.

If AI could help us avoid cosmic extinction by accelerating progress in astronautics, we should develop it ASAP, no?

Viva SpaceX!
------
The aerospace industry arguably spends more on safety than on basic design.
But since current AI systems have limited capabilities, asking for safety measures is premature.
It's as if we devoted enormous efforts to discuss aircraft safety before we knew how to build airplanes.
------
I don't engage with arguments from creationists and flat-earthers either.
------
How about signaling a sufficient condition for mere competence?
Merit doesn't matter nearly as much.
------
There are regulations and regulating agencies for *applications* of AI, e.g. for driving assistance, medical image analysis, etc.
Are you suggesting that R&D for basic AI technology should be regulated?
------
No.
It shows extreme crackpottery from the other party.
I mean, calling to nuke datacenters suspected of harboring too many ASI-enabling GPUs?
Seriously?
------
I can propose an infinite number of improbable doomsday scenarios.
They might make for fun Sci-Fi.
But they are not worth anyone's time to refute one by one.
They would have to be realistic to be worth refuting.
------
Think about the early days of automobiles: weak brakes, no seatbelts, no bumpers, no traffic signs. Yes, people died. Then, we had disk brakes, belts, ABS, airbags, driving assistance, speed limits, traffic signals....
Same story for pretty much every new tech ever deployed.
------
The US regulating agency certified Tesla's "FSD" as Level-2 (out of 5).
The only manufacturer to have obtained Level-3 certification in the  US is not Tesla but Mercedes (using technology from Nvidia).
------
Where are those "generalized AI"?
They don't exist. They will, but right now, they don't. 
And what harm might they cause once they exist?
How could you tell, since you have no idea how they would work?
------
Don't you think worrying about the proper design of parachutes before the invention of the airplane is a little too early?
------
Are you talking about LLMs?
Are they useful?
Are they dangerous?
Is their usefulness overwhelmingly larger than the dangers?
(You know, like cars, airplanes, kitchen knives, gas stoves, smartphones....)
------
I'd submit that most of these people are not "terrified of AI."
Except Stuart Russell, who is just wrong.
Working on AI safety and ethics doesn't automatically make you terrified of it.
I think AI safety is an important topic. But I'm not terrified.
------
.
@geoffreyhinton
 and I have been friends for 37 years.
We don't disagree on many things.
He says that an AI takeover is "not inconceivable" and I can't disagree.
But I also believe it's very, very low probability and preventable rather easily.
------
Chelsea's tweet is an excellent example of April fool's joke.
And your political bias made you fall for it.
------
We == society as a whole.
------
It doesn't exist.
So yes, right now, it's benign.
Once we have at least *some* idea of how this could work, we'll be able to discuss how to make it safe.
If it turns out we can't make it safe, then we won't build it.
Until then, it's like we're worrying about the sex of angels.
------
If you believe in the myth of the "hard take-off", *and* you hold the ridiculous belief that AI alignment is impossible to achieve *before* turning on an all-powerful system, then you might freak out and be subject to a nuke-data-centers-style hysterical meltdown.
------
None of them is terrified of AGI.
Except perhaps Russell, but he is mistaken.
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
Here (from 2019)
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
No, it's not.
------
Safety is very much embedded in the AI industry.
All the big players have independent AI safety groups.
The *usage* of AI is very much regulated. E.g. AI-based driving assistance and medical image analysis systems go through certification processes.
------
If you claim that there is a teapot floating between the orbits of Jupiter and Saturn, the burden is on you to prove it, not on me to refute it.
[With thanks to 
@RichardDawkins
 for this example]
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.
------
Throughout history, (older) people have been scared of new technology, particularly new communication technology that can affect society.
Those techs *empower* people & end up being beneficial.
Tech shifts must be managed to maximize the benefits and minimize the risks.
------
An oversimplification, but a rather accurate one.
Not clear to me that 
@geoffreyhinton
 is that far to the left of me.
------
I've made a matrix so that people have a better understanding of "who stands where".

Probability of humans aligning AI vs probability of AI being hostile if not aligned by humans.

Please let me know what are your positions so it's not just my subjective perception.
Thanks
------
MS has several AI ethics efforts.
They only got rid of one. I assume because it wasn't particularly effective.
------
Exactly.
It makes sense to regulate applications (most of them already are, e.g. in transportation and health care).
Regulating R&D in a particular technology area is extremely rare.
------
No.
This is science.
People should try to prove me wrong.
As a scientist, I will change my mind in front of credible evidence.
------
In the Middle Ages, Radical Catholic Europe was way more obscurantist than the Muslim world.
Ask yourself why algebra & algorithm are Arabic words, why we use Arabic number notation (thogh they came from India), and why all the major stars in the sky have Arabic names.
------
You are extrapolating what you think you know about me.
Which apparently is not very much.
------
Regulate *new applications* wherever there are *real* public safety concerns.
Existing application areas are already regulated, whether they use AI or not (e.g. in transportation,  health care, etc).
------
Hint: it's April 1st.
------
I hate to disappoint you, but I most definitely didn't 
------
Not just Bayes, quantum physics: every event has a non-zero probability!
------
Those are both extreme sides.
They are both wrong.
------
When it comes to content moderation, such as the detection and take-down of hate speech and calls to violence, AI is not the problem.
AI is part of the solution.
------
Elon & I met several times and I don't remember any backend kissing.

Separately, I recently bought my 2nd Tesla S and got the FSD option knowing full-well that it was merely Level-2 driving assistance.

I disagree with Elon on several things, but I like his cars and rockets.
------
I love caramel custoad.
------
It's April fool.
------
The wealth gap has increased in the US.

But it has not significantly increased in the European Union (in fact, it has decreased in France and in a few other countries).

So, it's purely a fiscal policy issue.
The US political system sucks.
What else is new?
------
I can propose an infinite number of improbable doomsday scenarios.
They might make for fun Sci-Fi.
But they are not worth anyone's time to refute one by one.
They would have to be realistic to be worth refuting.
------
Think about the early days of automobiles: weak brakes, no seatbelts, no bumpers, no traffic signs. Yes, people died. Then, we had disk brakes, belts, ABS, airbags, driving assistance, speed limits, traffic signals....
Same story for pretty much every new tech ever deployed.
------
The US regulating agency certified Tesla's "FSD" as Level-2 (out of 5).
The only manufacturer to have obtained Level-3 certification in the  US is not Tesla but Mercedes (using technology from Nvidia).
------
Where are those "generalized AI"?
They don't exist. They will, but right now, they don't. 
And what harm might they cause once they exist?
How could you tell, since you have no idea how they would work?
------
Don't you think worrying about the proper design of parachutes before the invention of the airplane is a little too early?
------
Are you talking about LLMs?
Are they useful?
Are they dangerous?
Is their usefulness overwhelmingly larger than the dangers?
(You know, like cars, airplanes, kitchen knives, gas stoves, smartphones....)
------
I'd submit that most of these people are not "terrified of AI."
Except Stuart Russell, who is just wrong.
Working on AI safety and ethics doesn't automatically make you terrified of it.
I think AI safety is an important topic. But I'm not terrified.
------
.
@geoffreyhinton
 and I have been friends for 37 years.
We don't disagree on many things.
He says that an AI takeover is "not inconceivable" and I can't disagree.
But I also believe it's very, very low probability and preventable rather easily.
------
Chelsea's tweet is an excellent example of April fool's joke.
And your political bias made you fall for it.
------
We == society as a whole.
------
It doesn't exist.
So yes, right now, it's benign.
Once we have at least *some* idea of how this could work, we'll be able to discuss how to make it safe.
If it turns out we can't make it safe, then we won't build it.
Until then, it's like we're worrying about the sex of angels.
------
If you believe in the myth of the "hard take-off", *and* you hold the ridiculous belief that AI alignment is impossible to achieve *before* turning on an all-powerful system, then you might freak out and be subject to a nuke-data-centers-style hysterical meltdown.
------
None of them is terrified of AGI.
Except perhaps Russell, but he is mistaken.
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
Here (from 2019)
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
No, it's not.
------
Safety is very much embedded in the AI industry.
All the big players have independent AI safety groups.
The *usage* of AI is very much regulated. E.g. AI-based driving assistance and medical image analysis systems go through certification processes.
------
If you claim that there is a teapot floating between the orbits of Jupiter and Saturn, the burden is on you to prove it, not on me to refute it.
[With thanks to 
@RichardDawkins
 for this example]
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.
------
Throughout history, (older) people have been scared of new technology, particularly new communication technology that can affect society.
Those techs *empower* people & end up being beneficial.
Tech shifts must be managed to maximize the benefits and minimize the risks.
------
An oversimplification, but a rather accurate one.
Not clear to me that 
@geoffreyhinton
 is that far to the left of me.
------
I've made a matrix so that people have a better understanding of "who stands where".

Probability of humans aligning AI vs probability of AI being hostile if not aligned by humans.

Please let me know what are your positions so it's not just my subjective perception.
Thanks
------
MS has several AI ethics efforts.
They only got rid of one. I assume because it wasn't particularly effective.
------
Exactly.
It makes sense to regulate applications (most of them already are, e.g. in transportation and health care).
Regulating R&D in a particular technology area is extremely rare.
------
No.
This is science.
People should try to prove me wrong.
As a scientist, I will change my mind in front of credible evidence.
------
In the Middle Ages, Radical Catholic Europe was way more obscurantist than the Muslim world.
Ask yourself why algebra & algorithm are Arabic words, why we use Arabic number notation (thogh they came from India), and why all the major stars in the sky have Arabic names.
------
You are extrapolating what you think you know about me.
Which apparently is not very much.
------
Regulate *new applications* wherever there are *real* public safety concerns.
Existing application areas are already regulated, whether they use AI or not (e.g. in transportation,  health care, etc).
------
Hint: it's April 1st.
------
I hate to disappoint you, but I most definitely didn't 
------
Not just Bayes, quantum physics: every event has a non-zero probability!
------
Those are both extreme sides.
They are both wrong.
------
When it comes to content moderation, such as the detection and take-down of hate speech and calls to violence, AI is not the problem.
AI is part of the solution.
------
Elon & I met several times and I don't remember any backend kissing.

Separately, I recently bought my 2nd Tesla S and got the FSD option knowing full-well that it was merely Level-2 driving assistance.

I disagree with Elon on several things, but I like his cars and rockets.
------
I love caramel custoad.
------
It's April fool.
------
The wealth gap has increased in the US.

But it has not significantly increased in the European Union (in fact, it has decreased in France and in a few other countries).

So, it's purely a fiscal policy issue.
The US political system sucks.
What else is new?
------
None of them is terrified of AGI.
Except perhaps Russell, but he is mistaken.
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
Here (from 2019)
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
No, it's not.
------
Safety is very much embedded in the AI industry.
All the big players have independent AI safety groups.
The *usage* of AI is very much regulated. E.g. AI-based driving assistance and medical image analysis systems go through certification processes.
------
If you claim that there is a teapot floating between the orbits of Jupiter and Saturn, the burden is on you to prove it, not on me to refute it.
[With thanks to 
@RichardDawkins
 for this example]
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.
------
Throughout history, (older) people have been scared of new technology, particularly new communication technology that can affect society.
Those techs *empower* people & end up being beneficial.
Tech shifts must be managed to maximize the benefits and minimize the risks.
------
An oversimplification, but a rather accurate one.
Not clear to me that 
@geoffreyhinton
 is that far to the left of me.
------
I've made a matrix so that people have a better understanding of "who stands where".

Probability of humans aligning AI vs probability of AI being hostile if not aligned by humans.

Please let me know what are your positions so it's not just my subjective perception.
Thanks
------
MS has several AI ethics efforts.
They only got rid of one. I assume because it wasn't particularly effective.
------
Exactly.
It makes sense to regulate applications (most of them already are, e.g. in transportation and health care).
Regulating R&D in a particular technology area is extremely rare.
------
No.
This is science.
People should try to prove me wrong.
As a scientist, I will change my mind in front of credible evidence.
------
In the Middle Ages, Radical Catholic Europe was way more obscurantist than the Muslim world.
Ask yourself why algebra & algorithm are Arabic words, why we use Arabic number notation (thogh they came from India), and why all the major stars in the sky have Arabic names.
------
You are extrapolating what you think you know about me.
Which apparently is not very much.
------
Regulate *new applications* wherever there are *real* public safety concerns.
Existing application areas are already regulated, whether they use AI or not (e.g. in transportation,  health care, etc).
------
Hint: it's April 1st.
------
I hate to disappoint you, but I most definitely didn't 
------
Not just Bayes, quantum physics: every event has a non-zero probability!
------
Those are both extreme sides.
They are both wrong.
------
When it comes to content moderation, such as the detection and take-down of hate speech and calls to violence, AI is not the problem.
AI is part of the solution.
------
Elon & I met several times and I don't remember any backend kissing.

Separately, I recently bought my 2nd Tesla S and got the FSD option knowing full-well that it was merely Level-2 driving assistance.

I disagree with Elon on several things, but I like his cars and rockets.
------
I love caramel custoad.
------
It's April fool.
------
The wealth gap has increased in the US.

But it has not significantly increased in the European Union (in fact, it has decreased in France and in a few other countries).

So, it's purely a fiscal policy issue.
The US political system sucks.
What else is new?
------
This argument is not just wrong but stupid.

@TonyZador
 and I debated some of these questions with Stuart 4 years ago, following the publication of our piece in Scientific American.
There are transcripts here: 
https://docs.google.com/document/u/0/d/1Y9ga5lS3c6ilZeZ2v2RLEe3x-io0RLDQsdp0HKorZR8/mobilebasic…
And here:
------
Works pretty well for the aircraft industry.
Also, for all kinds of interoperability standards: telephone, internet, encryption, video compression, banking, payment cards, USB.....
Ok, scratch banking 
------
If it's unsafe, people won't buy it, and regulations are likely to make it illegal.
So, I fail to see the motivation that "someone" may have to build it.
------
This is a complete misrepresentation.
I made a historical point about the car and aircraft industries.
Every technology has benefits AND risks.
Some risks can be anticipated and mitigated in advance.
Others are hard to predict and must be corrected as they emerge.
------
No, it's not.
------
Safety is very much embedded in the AI industry.
All the big players have independent AI safety groups.
The *usage* of AI is very much regulated. E.g. AI-based driving assistance and medical image analysis systems go through certification processes.
------
If you claim that there is a teapot floating between the orbits of Jupiter and Saturn, the burden is on you to prove it, not on me to refute it.
[With thanks to 
@RichardDawkins
 for this example]
------
Scientific debates are good.
Here is an example below.
But debating AI ethics and safety with extreme AI doomers is like debating evolution with creationists.
Pointless.
------
Throughout history, (older) people have been scared of new technology, particularly new communication technology that can affect society.
Those techs *empower* people & end up being beneficial.
Tech shifts must be managed to maximize the benefits and minimize the risks.
------
An oversimplification, but a rather accurate one.
Not clear to me that 
@geoffreyhinton
 is that far to the left of me.
------
I've made a matrix so that people have a better understanding of "who stands where".

Probability of humans aligning AI vs probability of AI being hostile if not aligned by humans.

Please let me know what are your positions so it's not just my subjective perception.
Thanks
------
MS has several AI ethics efforts.
They only got rid of one. I assume because it wasn't particularly effective.
------
Exactly.
It makes sense to regulate applications (most of them already are, e.g. in transportation and health care).
Regulating R&D in a particular technology area is extremely rare.
------
No.
This is science.
People should try to prove me wrong.
As a scientist, I will change my mind in front of credible evidence.
------
In the Middle Ages, Radical Catholic Europe was way more obscurantist than the Muslim world.
Ask yourself why algebra & algorithm are Arabic words, why we use Arabic number notation (thogh they came from India), and why all the major stars in the sky have Arabic names.
------
You are extrapolating what you think you know about me.
Which apparently is not very much.
------
Regulate *new applications* wherever there are *real* public safety concerns.
Existing application areas are already regulated, whether they use AI or not (e.g. in transportation,  health care, etc).
------
Hint: it's April 1st.
------
I hate to disappoint you, but I most definitely didn't 
------
Not just Bayes, quantum physics: every event has a non-zero probability!
------
Those are both extreme sides.
They are both wrong.
------
When it comes to content moderation, such as the detection and take-down of hate speech and calls to violence, AI is not the problem.
AI is part of the solution.
------
Elon & I met several times and I don't remember any backend kissing.

Separately, I recently bought my 2nd Tesla S and got the FSD option knowing full-well that it was merely Level-2 driving assistance.

I disagree with Elon on several things, but I like his cars and rockets.
------
I love caramel custoad.
------
It's April fool.
------
The wealth gap has increased in the US.

But it has not significantly increased in the European Union (in fact, it has decreased in France and in a few other countries).

So, it's purely a fiscal policy issue.
The US political system sucks.
What else is new?
------
The year is 1440 and the Catholic Church has called for a 6 months moratorium on the use of the printing press and the movable type.
Imagine what could happen if commoners get access to books!
They could read the Bible for themselves and society would be destroyed.
------
Agreed.
------
I also did not sign. The letter is such a mess of scary rhetoric and ineffective/non-existent policy prescriptions. There are important technical and policy issues, and many of us are working on them.
------
Pretty much.
------
the problem of @ylecun with autoregressive models
------
Nope.
I did not sign this letter.
I disagree with its premise. https://twitter.com/plevy/status/1640894086830870528…
------
Our highest-bandwidth information channel is not speech.
It's vision and touch.
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha!
------
standard ml: oh no my model is memorizing the training set, better add some regularization to make that not happen 

llm ml: ugh it’s hallucinating, why can’t it just memorize some of the training set
------
The Ottoman empire banned printed books until the 18th century, which greatly contributed to their decline from the pinnacle of science and mathematics in the Middle Ages to an intellectual backwater after the Renaissance.
------
Humans don't need to learn from 1 trillion words to reach human intelligence.
What are LLMs missing?
------
How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. 
------
Society *was* destroyed...
...for the better.
Printed books enabled the Protestant movement, and 200 years of religious conflicts in Europe.
But printed books also enabled the Enlightenment: literacy, education, science, philosophy, secularism, and democracy.
------
Is the US finally catching up with the rest of the developed world?
------
Huge declines in the importance of patriotism and religion in new WSJ poll

https://wsj.com/articles/americans-pull-back-from-values-that-once-defined-u-s-wsj-norc-poll-finds-df8534cd?mod=mhp…
------
Indeed.
------
No.
------
They banned Galileo.
------
Also a key reason we have literacy, science, secularism, and democracy.
------
The epitome of overreaction.
------
Which stage of the Gartner hype cycle is “people lose their fucking minds and argue that we should start a nuclear war to prevent people from using maths”? Asking for a friend.
------
"Robots that learn from videos of human activities and simulated interactions"

A new blog post from the Embodied Intelligence group at Meta-FAIR.
------
Contemporary discussion (hype?) about LLMs and “pausing AGI development” seems oblivious of Moravec’s paradox.

We’ve hypothesized since the 80s — that the hardest problems in AI involve sensorimotor control, not abstract thought or reasoning. 

It https://bit.ly/40pJU5M… Show more
------
Pretty much.
You even get a hood with your PhD.
Not just academia, but the whole research community.

Some of my padawans run chunks of DeepMind: 
@koraykv
 
@RaiaHadsell
 
@clmt
 
The Force is strong with them!

Technically, I was already a young Jedi when I did my postdoc with Geoff
------
The amount of information to transform chimpanzee DNA into human DNA is about 8 megabytes.
It took about 5 million years.
So we are talking 12 bits per year.
Not much.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
The year is 1440 and the Catholic Church has called for a 6 months moratorium on the use of the printing press and the movable type.
Imagine what could happen if commoners get access to books!
They could read the Bible for themselves and society would be destroyed.
------
Agreed.
------
I also did not sign. The letter is such a mess of scary rhetoric and ineffective/non-existent policy prescriptions. There are important technical and policy issues, and many of us are working on them.
------
Pretty much.
------
the problem of @ylecun with autoregressive models
------
Nope.
I did not sign this letter.
I disagree with its premise. https://twitter.com/plevy/status/1640894086830870528…
------
Our highest-bandwidth information channel is not speech.
It's vision and touch.
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha!
------
standard ml: oh no my model is memorizing the training set, better add some regularization to make that not happen 

llm ml: ugh it’s hallucinating, why can’t it just memorize some of the training set
------
The Ottoman empire banned printed books until the 18th century, which greatly contributed to their decline from the pinnacle of science and mathematics in the Middle Ages to an intellectual backwater after the Renaissance.
------
Humans don't need to learn from 1 trillion words to reach human intelligence.
What are LLMs missing?
------
How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. 
------
Society *was* destroyed...
...for the better.
Printed books enabled the Protestant movement, and 200 years of religious conflicts in Europe.
But printed books also enabled the Enlightenment: literacy, education, science, philosophy, secularism, and democracy.
------
Is the US finally catching up with the rest of the developed world?
------
Huge declines in the importance of patriotism and religion in new WSJ poll

https://wsj.com/articles/americans-pull-back-from-values-that-once-defined-u-s-wsj-norc-poll-finds-df8534cd?mod=mhp…
------
Indeed.
------
No.
------
They banned Galileo.
------
Also a key reason we have literacy, science, secularism, and democracy.
------
The epitome of overreaction.
------
Which stage of the Gartner hype cycle is “people lose their fucking minds and argue that we should start a nuclear war to prevent people from using maths”? Asking for a friend.
------
"Robots that learn from videos of human activities and simulated interactions"

A new blog post from the Embodied Intelligence group at Meta-FAIR.
------
Contemporary discussion (hype?) about LLMs and “pausing AGI development” seems oblivious of Moravec’s paradox.

We’ve hypothesized since the 80s — that the hardest problems in AI involve sensorimotor control, not abstract thought or reasoning. 

It https://bit.ly/40pJU5M… Show more
------
Pretty much.
You even get a hood with your PhD.
Not just academia, but the whole research community.

Some of my padawans run chunks of DeepMind: 
@koraykv
 
@RaiaHadsell
 
@clmt
 
The Force is strong with them!

Technically, I was already a young Jedi when I did my postdoc with Geoff
------
The amount of information to transform chimpanzee DNA into human DNA is about 8 megabytes.
It took about 5 million years.
So we are talking 12 bits per year.
Not much.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The year is 1440 and the Catholic Church has called for a 6 months moratorium on the use of the printing press and the movable type.
Imagine what could happen if commoners get access to books!
They could read the Bible for themselves and society would be destroyed.
------
Agreed.
------
I also did not sign. The letter is such a mess of scary rhetoric and ineffective/non-existent policy prescriptions. There are important technical and policy issues, and many of us are working on them.
------
Pretty much.
------
the problem of @ylecun with autoregressive models
------
Nope.
I did not sign this letter.
I disagree with its premise. https://twitter.com/plevy/status/1640894086830870528…
------
Our highest-bandwidth information channel is not speech.
It's vision and touch.
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha!
------
standard ml: oh no my model is memorizing the training set, better add some regularization to make that not happen 

llm ml: ugh it’s hallucinating, why can’t it just memorize some of the training set
------
The Ottoman empire banned printed books until the 18th century, which greatly contributed to their decline from the pinnacle of science and mathematics in the Middle Ages to an intellectual backwater after the Renaissance.
------
Humans don't need to learn from 1 trillion words to reach human intelligence.
What are LLMs missing?
------
How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. 
------
Society *was* destroyed...
...for the better.
Printed books enabled the Protestant movement, and 200 years of religious conflicts in Europe.
But printed books also enabled the Enlightenment: literacy, education, science, philosophy, secularism, and democracy.
------
Is the US finally catching up with the rest of the developed world?
------
Huge declines in the importance of patriotism and religion in new WSJ poll

https://wsj.com/articles/americans-pull-back-from-values-that-once-defined-u-s-wsj-norc-poll-finds-df8534cd?mod=mhp…
------
Indeed.
------
No.
------
They banned Galileo.
------
Also a key reason we have literacy, science, secularism, and democracy.
------
The epitome of overreaction.
------
Which stage of the Gartner hype cycle is “people lose their fucking minds and argue that we should start a nuclear war to prevent people from using maths”? Asking for a friend.
------
"Robots that learn from videos of human activities and simulated interactions"

A new blog post from the Embodied Intelligence group at Meta-FAIR.
------
Contemporary discussion (hype?) about LLMs and “pausing AGI development” seems oblivious of Moravec’s paradox.

We’ve hypothesized since the 80s — that the hardest problems in AI involve sensorimotor control, not abstract thought or reasoning. 

It https://bit.ly/40pJU5M… Show more
------
Pretty much.
You even get a hood with your PhD.
Not just academia, but the whole research community.

Some of my padawans run chunks of DeepMind: 
@koraykv
 
@RaiaHadsell
 
@clmt
 
The Force is strong with them!

Technically, I was already a young Jedi when I did my postdoc with Geoff
------
The amount of information to transform chimpanzee DNA into human DNA is about 8 megabytes.
It took about 5 million years.
So we are talking 12 bits per year.
Not much.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha!
------
standard ml: oh no my model is memorizing the training set, better add some regularization to make that not happen 

llm ml: ugh it’s hallucinating, why can’t it just memorize some of the training set
------
The Ottoman empire banned printed books until the 18th century, which greatly contributed to their decline from the pinnacle of science and mathematics in the Middle Ages to an intellectual backwater after the Renaissance.
------
Humans don't need to learn from 1 trillion words to reach human intelligence.
What are LLMs missing?
------
How do we compare the scale of language learning input for large language models vs. humans? I've been trying to come to grips with recent progress in AI. Let me explain these two illustrations I made to help. 
------
Society *was* destroyed...
...for the better.
Printed books enabled the Protestant movement, and 200 years of religious conflicts in Europe.
But printed books also enabled the Enlightenment: literacy, education, science, philosophy, secularism, and democracy.
------
Is the US finally catching up with the rest of the developed world?
------
Huge declines in the importance of patriotism and religion in new WSJ poll

https://wsj.com/articles/americans-pull-back-from-values-that-once-defined-u-s-wsj-norc-poll-finds-df8534cd?mod=mhp…
------
Indeed.
------
No.
------
They banned Galileo.
------
Also a key reason we have literacy, science, secularism, and democracy.
------
The epitome of overreaction.
------
Which stage of the Gartner hype cycle is “people lose their fucking minds and argue that we should start a nuclear war to prevent people from using maths”? Asking for a friend.
------
"Robots that learn from videos of human activities and simulated interactions"

A new blog post from the Embodied Intelligence group at Meta-FAIR.
------
Contemporary discussion (hype?) about LLMs and “pausing AGI development” seems oblivious of Moravec’s paradox.

We’ve hypothesized since the 80s — that the hardest problems in AI involve sensorimotor control, not abstract thought or reasoning. 

It https://bit.ly/40pJU5M… Show more
------
Pretty much.
You even get a hood with your PhD.
Not just academia, but the whole research community.

Some of my padawans run chunks of DeepMind: 
@koraykv
 
@RaiaHadsell
 
@clmt
 
The Force is strong with them!

Technically, I was already a young Jedi when I did my postdoc with Geoff
------
The amount of information to transform chimpanzee DNA into human DNA is about 8 megabytes.
It took about 5 million years.
So we are talking 12 bits per year.
Not much.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
I didn't. It's a server configuration issue.
------
"almost custom designed to produce propaganda".
The main obstacle to propaganda is not the difficulty of production but the difficulty of dissemination.
Every single communication technology ever developed has, by definition, enabled the dissemination of "propaganda".
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Wat?
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
That difference only popped up in the last million years or so and is encoded in less than 8 MB of genetic information. That is awfully small.
------
Yup
------
Once they get older, Americans seem to be in similar health as their peers in other countries.
Then again, older Americans have access to European-style "socialized medicine" in the form of Medicare.
------
No. System 2 would require a bit of "innate machinery" perhaps along the lines of what I described in my position paper below.

Vision/multimodal SSL would be a breakthrough, but it's way harder to do than from text.
------
Is the US finally catching up with the rest of the developed world?
------
Huge declines in the importance of patriotism and religion in new WSJ poll

https://wsj.com/articles/americans-pull-back-from-values-that-once-defined-u-s-wsj-norc-poll-finds-df8534cd?mod=mhp…
------
Indeed.
------
No.
------
They banned Galileo.
------
Also a key reason we have literacy, science, secularism, and democracy.
------
The epitome of overreaction.
------
Which stage of the Gartner hype cycle is “people lose their fucking minds and argue that we should start a nuclear war to prevent people from using maths”? Asking for a friend.
------
"Robots that learn from videos of human activities and simulated interactions"

A new blog post from the Embodied Intelligence group at Meta-FAIR.
------
Contemporary discussion (hype?) about LLMs and “pausing AGI development” seems oblivious of Moravec’s paradox.

We’ve hypothesized since the 80s — that the hardest problems in AI involve sensorimotor control, not abstract thought or reasoning. 

It https://bit.ly/40pJU5M… Show more
------
Pretty much.
You even get a hood with your PhD.
Not just academia, but the whole research community.

Some of my padawans run chunks of DeepMind: 
@koraykv
 
@RaiaHadsell
 
@clmt
 
The Force is strong with them!

Technically, I was already a young Jedi when I did my postdoc with Geoff
------
The amount of information to transform chimpanzee DNA into human DNA is about 8 megabytes.
It took about 5 million years.
So we are talking 12 bits per year.
Not much.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
I didn't. It's a server configuration issue.
------
"almost custom designed to produce propaganda".
The main obstacle to propaganda is not the difficulty of production but the difficulty of dissemination.
Every single communication technology ever developed has, by definition, enabled the dissemination of "propaganda".
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Wat?
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
That difference only popped up in the last million years or so and is encoded in less than 8 MB of genetic information. That is awfully small.
------
Yup
------
Once they get older, Americans seem to be in similar health as their peers in other countries.
Then again, older Americans have access to European-style "socialized medicine" in the form of Medicare.
------
No. System 2 would require a bit of "innate machinery" perhaps along the lines of what I described in my position paper below.

Vision/multimodal SSL would be a breakthrough, but it's way harder to do than from text.
------
Pretty much.
You even get a hood with your PhD.
Not just academia, but the whole research community.

Some of my padawans run chunks of DeepMind: 
@koraykv
 
@RaiaHadsell
 
@clmt
 
The Force is strong with them!

Technically, I was already a young Jedi when I did my postdoc with Geoff
------
The amount of information to transform chimpanzee DNA into human DNA is about 8 megabytes.
It took about 5 million years.
So we are talking 12 bits per year.
Not much.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
I didn't. It's a server configuration issue.
------
"almost custom designed to produce propaganda".
The main obstacle to propaganda is not the difficulty of production but the difficulty of dissemination.
Every single communication technology ever developed has, by definition, enabled the dissemination of "propaganda".
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Wat?
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
That difference only popped up in the last million years or so and is encoded in less than 8 MB of genetic information. That is awfully small.
------
Yup
------
Once they get older, Americans seem to be in similar health as their peers in other countries.
Then again, older Americans have access to European-style "socialized medicine" in the form of Medicare.
------
No. System 2 would require a bit of "innate machinery" perhaps along the lines of what I described in my position paper below.

Vision/multimodal SSL would be a breakthrough, but it's way harder to do than from text.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
I didn't. It's a server configuration issue.
------
"almost custom designed to produce propaganda".
The main obstacle to propaganda is not the difficulty of production but the difficulty of dissemination.
Every single communication technology ever developed has, by definition, enabled the dissemination of "propaganda".
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Wat?
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
That difference only popped up in the last million years or so and is encoded in less than 8 MB of genetic information. That is awfully small.
------
Yup
------
Once they get older, Americans seem to be in similar health as their peers in other countries.
Then again, older Americans have access to European-style "socialized medicine" in the form of Medicare.
------
No. System 2 would require a bit of "innate machinery" perhaps along the lines of what I described in my position paper below.

Vision/multimodal SSL would be a breakthrough, but it's way harder to do than from text.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
I didn't. It's a server configuration issue.
------
"almost custom designed to produce propaganda".
The main obstacle to propaganda is not the difficulty of production but the difficulty of dissemination.
Every single communication technology ever developed has, by definition, enabled the dissemination of "propaganda".
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Wat?
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
That difference only popped up in the last million years or so and is encoded in less than 8 MB of genetic information. That is awfully small.
------
Yup
------
Once they get older, Americans seem to be in similar health as their peers in other countries.
Then again, older Americans have access to European-style "socialized medicine" in the form of Medicare.
------
No. System 2 would require a bit of "innate machinery" perhaps along the lines of what I described in my position paper below.

Vision/multimodal SSL would be a breakthrough, but it's way harder to do than from text.
------
Americans are dying at a much younger age than residents in peer countries.
A fascinating set of charts demonstrating the abysmal state of affairs, derived from a Financial Times article.
------
NEW: I’m not sure people fully appreciate how dire the US life expectancy / mortality situation has got.

My column: https://enterprise-sharing.ft.com/redeem/75e5e3d7-72c9-4b51-8ea9-dcfd99c42765…

And some utterly damning charts.

1) at *every* point on the income distribution, Americans live shorter lives than the English.
------
As you know, you and I disagree on that.
AI systems need a bit more "innate" machinery than today, but not much: something that allows them to reason and plan.
What they need is the ability to perform self-supervised learning from high-bandwidth natural signals, like vision.
------
None. Animals learn world models from vision without text.
------
Nuclear warheads are designed to kill people.

The New Testament tells people to stop killing each other, but has been used pretty effectively to brainwash people into killing each other.

The purpose of AI is to help people become smarter.
Perhaps even wiser.
------
Packed in a tiny amount of bits in the genome?
In the 5 million years since humans and chimpanzees split evolutionary, our genetic differences are a mere 8 MB (about 1% of our DNA, or 30 million base pairs).
------
Hierarchical planning and refinement is the best kind of planning.
------
Hahaha! Good point, 
@aaron_defazio
 
Moratorium on Development == Development in secret
[which is the exact opposite of what some of the signatories are hoping for]
------
Wait… OpenAI already DID wait 6 months before releasing GPT4!

They wrote a whole white paper about it….
------
Optimal Brain Damage?
------
You and me both.
------
Startup idea: " The Actually Boring Company".
We develop seamless and efficient technology that absolutely everyone finds mindnumbingly boring.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
In the first 3 or 4 months, babies have essentially no power of intervention on their surrounding.
They do flail theirs limbs a lot.
But they learn an enormous amount of background knowledge about the world from mere observation.
------
You can learn a hell of a lot in 20 minutes.
------
The knee-jerk reactions to new technologies, particularly new communication technologies, or new cultural movements are quite consistently present and very consistently misdirected.
------
They still have touch, which is very high bandwidth, and audio (not just for speech).
------
Pretty good paraphrasing, with helpful details!
------
Sure.
But isn't "managing such a process" what always happen in well-run democracies?
------
Perhaps I should tell you that almost all of my publications of the last several years have been on self-supervised learning for images and video.
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
I didn't. It's a server configuration issue.
------
"almost custom designed to produce propaganda".
The main obstacle to propaganda is not the difficulty of production but the difficulty of dissemination.
Every single communication technology ever developed has, by definition, enabled the dissemination of "propaganda".
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Wat?
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
That difference only popped up in the last million years or so and is encoded in less than 8 MB of genetic information. That is awfully small.
------
Yup
------
Once they get older, Americans seem to be in similar health as their peers in other countries.
Then again, older Americans have access to European-style "socialized medicine" in the form of Medicare.
------
No. System 2 would require a bit of "innate machinery" perhaps along the lines of what I described in my position paper below.

Vision/multimodal SSL would be a breakthrough, but it's way harder to do than from text.
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha! https://twitter.com/O42nl/status/1640187110400442368…
------
Words of wisdom from Bernhard.
------
Another AI paradox: people are excited about LLMs, some even think that AGI is just around the corner. But some students are depressed how they can still get a PhD. Is it becoming pointless? 
Some personal notes on this. (1/8)
------
I should add that things like RLHF may reduce e but do not change the fact that token production is auto-regressive and subject to exponential divergence.
------
It's not specific to LLMs.
It's specific to *any* auto-regressive generative process.
------
The full slide deck is here.
This was my introductory position statement to the philosophical debate 
“Do large language models need sensory grounding for meaning and understanding?”
Which took place at NYU Friday evening.
------
Concerning point 8, here is the argument:
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
AR-LLM do not "search".
That's part of the problem.
------
When empirical evidence clashes with a theory, it is the theory that is wrong (or misinterpreted), not the universe.
The well-documented initial resistance of many ML theorists to deep learning was due to complete theory-fueled disbelief: this can't possibly work!
------
Now that everyone is fatigued by GPT-4 hot takes and blocked the keyword "LLM", here's the blog post with my current view on the topic, and how my views changed:
https://inference.vc/we-may-be-surprised-again/…
------
Not at all.
Most human answers are not produced auto-regressively but are planned ahead.
No exponential divergence there.
Mathematical proofs are discarded if they don't produce the desired result.
So they are not subject to exponential divergence.
------
Ask yourself why Microsoft suddenly limited the length of interactions with Bing chat / Sydney.
------
Yes, I'm implicitly making an independence assumption.
Not clear to what extent it's valid or invalid.
------
No. We are assuming the *errors* are independent, so their probabilities can be multiplied.
------
There is. And there is some truth to it.
Might be one reason I left France 
------
If a token take you out of the tree of correct answers, there is no going back. It's a tree!
------
Yup.
That would constitute a form of hierarchical planning. 
The question is precisely how to do it.
------
No.
Exponential divergence only occurs if you factorize P(y1,y2,y3) as P(y3|y1,y2)P(y2|y1)P(y1).
But you absolutely don't have to.
------
Possibly, but that would be super-expensive.
And that would make them non auto-regressive.
------
That would be a kind of planning.
Planning the sequence is clearly a good way to avoid exponential divergence.
------
Hierarchical planning and refinement is the best kind of planning.
------
It's not an assumption.
It's a fact.
An answer must terminate with an "end" marker.
There are no subsequent tokens after "end".
------
The error you'll make with receding horizon planning of length k depends on how accurately your energy over over k tokens approximates the energy for the whole sequence.
But the divergence will be way slower than pure auto-regressive.
------
Good luck making e less than 10e-12 !
------
You are arguing that answers should be planned ahead.
I totally agree.
------
No. It's a tree. One mistake, and you're out.
------
No. Fine-tuning, regardless of the method, reduces e but doesn't fix the exponential divergence of auto-regressive token production.
Only planning would.
------
Not true. 
You can *plan* and refine a representation of the sequence in your mind, then turn it into a token sequence and only then spit it out.
That's planning. That's not auto-regressive, and that's not subject to exponential divergence.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
MCTS, beam search, etc would constitute forms of planning and may fix the issue.
The resulting systems would no-longer be auto-regressive.
But they would be *insanely* expensive at inference time.
------
With an infinite supply of pen and paper 
------
That would be a primitive form of planning.
And that would be insanely expensive.
------
Humans plan ahead.
------
No. The answer without the parenthesis requires an "end" marker which the full answer doesn't have.
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha! https://twitter.com/O42nl/status/1640187110400442368…
------
Words of wisdom from Bernhard.
------
Another AI paradox: people are excited about LLMs, some even think that AGI is just around the corner. But some students are depressed how they can still get a PhD. Is it becoming pointless? 
Some personal notes on this. (1/8)
------
I should add that things like RLHF may reduce e but do not change the fact that token production is auto-regressive and subject to exponential divergence.
------
It's not specific to LLMs.
It's specific to *any* auto-regressive generative process.
------
The full slide deck is here.
This was my introductory position statement to the philosophical debate 
“Do large language models need sensory grounding for meaning and understanding?”
Which took place at NYU Friday evening.
------
Concerning point 8, here is the argument:
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
AR-LLM do not "search".
That's part of the problem.
------
When empirical evidence clashes with a theory, it is the theory that is wrong (or misinterpreted), not the universe.
The well-documented initial resistance of many ML theorists to deep learning was due to complete theory-fueled disbelief: this can't possibly work!
------
Now that everyone is fatigued by GPT-4 hot takes and blocked the keyword "LLM", here's the blog post with my current view on the topic, and how my views changed:
https://inference.vc/we-may-be-surprised-again/…
------
Not at all.
Most human answers are not produced auto-regressively but are planned ahead.
No exponential divergence there.
Mathematical proofs are discarded if they don't produce the desired result.
So they are not subject to exponential divergence.
------
Ask yourself why Microsoft suddenly limited the length of interactions with Bing chat / Sydney.
------
Yes, I'm implicitly making an independence assumption.
Not clear to what extent it's valid or invalid.
------
No. We are assuming the *errors* are independent, so their probabilities can be multiplied.
------
There is. And there is some truth to it.
Might be one reason I left France 
------
If a token take you out of the tree of correct answers, there is no going back. It's a tree!
------
Yup.
That would constitute a form of hierarchical planning. 
The question is precisely how to do it.
------
No.
Exponential divergence only occurs if you factorize P(y1,y2,y3) as P(y3|y1,y2)P(y2|y1)P(y1).
But you absolutely don't have to.
------
Possibly, but that would be super-expensive.
And that would make them non auto-regressive.
------
That would be a kind of planning.
Planning the sequence is clearly a good way to avoid exponential divergence.
------
Hierarchical planning and refinement is the best kind of planning.
------
It's not an assumption.
It's a fact.
An answer must terminate with an "end" marker.
There are no subsequent tokens after "end".
------
The error you'll make with receding horizon planning of length k depends on how accurately your energy over over k tokens approximates the energy for the whole sequence.
But the divergence will be way slower than pure auto-regressive.
------
Good luck making e less than 10e-12 !
------
You are arguing that answers should be planned ahead.
I totally agree.
------
No. It's a tree. One mistake, and you're out.
------
No. Fine-tuning, regardless of the method, reduces e but doesn't fix the exponential divergence of auto-regressive token production.
Only planning would.
------
Not true. 
You can *plan* and refine a representation of the sequence in your mind, then turn it into a token sequence and only then spit it out.
That's planning. That's not auto-regressive, and that's not subject to exponential divergence.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
MCTS, beam search, etc would constitute forms of planning and may fix the issue.
The resulting systems would no-longer be auto-regressive.
But they would be *insanely* expensive at inference time.
------
With an infinite supply of pen and paper 
------
That would be a primitive form of planning.
And that would be insanely expensive.
------
Humans plan ahead.
------
No. The answer without the parenthesis requires an "end" marker which the full answer doesn't have.
------
Pretty good paraphrasing, with helpful details!
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
Yes, the argument assumes the independence of errors.
No, an incorrect string cannot be corrected by further tokens. The set of correct answers is a subtree of the (enormous) tree of all token sequences. Once you are out, you are out.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
RLHF may reduce e but will not change the fact that auto-regressive token production is exponentially divergent.
------
RLHF may decrease e, but will not change the fact that the token generation process is auto-regressive.
------
Yup. AI is even hotter than hot.
------
Microsoft, Google, Apple, Meta and Amazon are racing to hire AI talent  

(1/5)
------
Haha! https://twitter.com/O42nl/status/1640187110400442368…
------
Words of wisdom from Bernhard.
------
Another AI paradox: people are excited about LLMs, some even think that AGI is just around the corner. But some students are depressed how they can still get a PhD. Is it becoming pointless? 
Some personal notes on this. (1/8)
------
I should add that things like RLHF may reduce e but do not change the fact that token production is auto-regressive and subject to exponential divergence.
------
It's not specific to LLMs.
It's specific to *any* auto-regressive generative process.
------
The full slide deck is here.
This was my introductory position statement to the philosophical debate 
“Do large language models need sensory grounding for meaning and understanding?”
Which took place at NYU Friday evening.
------
Concerning point 8, here is the argument:
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
AR-LLM do not "search".
That's part of the problem.
------
When empirical evidence clashes with a theory, it is the theory that is wrong (or misinterpreted), not the universe.
The well-documented initial resistance of many ML theorists to deep learning was due to complete theory-fueled disbelief: this can't possibly work!
------
Now that everyone is fatigued by GPT-4 hot takes and blocked the keyword "LLM", here's the blog post with my current view on the topic, and how my views changed:
https://inference.vc/we-may-be-surprised-again/…
------
Not at all.
Most human answers are not produced auto-regressively but are planned ahead.
No exponential divergence there.
Mathematical proofs are discarded if they don't produce the desired result.
So they are not subject to exponential divergence.
------
Ask yourself why Microsoft suddenly limited the length of interactions with Bing chat / Sydney.
------
Yes, I'm implicitly making an independence assumption.
Not clear to what extent it's valid or invalid.
------
No. We are assuming the *errors* are independent, so their probabilities can be multiplied.
------
There is. And there is some truth to it.
Might be one reason I left France 
------
If a token take you out of the tree of correct answers, there is no going back. It's a tree!
------
Yup.
That would constitute a form of hierarchical planning. 
The question is precisely how to do it.
------
No.
Exponential divergence only occurs if you factorize P(y1,y2,y3) as P(y3|y1,y2)P(y2|y1)P(y1).
But you absolutely don't have to.
------
Possibly, but that would be super-expensive.
And that would make them non auto-regressive.
------
That would be a kind of planning.
Planning the sequence is clearly a good way to avoid exponential divergence.
------
Hierarchical planning and refinement is the best kind of planning.
------
It's not an assumption.
It's a fact.
An answer must terminate with an "end" marker.
There are no subsequent tokens after "end".
------
The error you'll make with receding horizon planning of length k depends on how accurately your energy over over k tokens approximates the energy for the whole sequence.
But the divergence will be way slower than pure auto-regressive.
------
Good luck making e less than 10e-12 !
------
You are arguing that answers should be planned ahead.
I totally agree.
------
No. It's a tree. One mistake, and you're out.
------
No. Fine-tuning, regardless of the method, reduces e but doesn't fix the exponential divergence of auto-regressive token production.
Only planning would.
------
Not true. 
You can *plan* and refine a representation of the sequence in your mind, then turn it into a token sequence and only then spit it out.
That's planning. That's not auto-regressive, and that's not subject to exponential divergence.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
MCTS, beam search, etc would constitute forms of planning and may fix the issue.
The resulting systems would no-longer be auto-regressive.
But they would be *insanely* expensive at inference time.
------
With an infinite supply of pen and paper 
------
That would be a primitive form of planning.
And that would be insanely expensive.
------
Humans plan ahead.
------
No. The answer without the parenthesis requires an "end" marker which the full answer doesn't have.
------
Pretty good paraphrasing, with helpful details!
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
Yes, the argument assumes the independence of errors.
No, an incorrect string cannot be corrected by further tokens. The set of correct answers is a subtree of the (enormous) tree of all token sequences. Once you are out, you are out.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
RLHF may reduce e but will not change the fact that auto-regressive token production is exponentially divergent.
------
RLHF may decrease e, but will not change the fact that the token generation process is auto-regressive.
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Well, e is in part determined by the sum of the training error (how accurately the network stores the entire training set) and the generalization gap (how representative is the training set of all the prompts that will ever be encountered).
------
Wat?
------
This is a real problem that OpenAI folks themselves have pointed out (from the GPT-4 page):
"Despite its capabilities, GPT-4 has similar limitations as earlier GPT models. Most importantly, it still is not fully reliable (it “hallucinates” facts and makes reasoning errors)."
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
Yes
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
I'm absolutely not assuming that the correct answer is unique.
It's a small subtree within the tree of all possible tokens sequences.
------
It seems that you are arguing for some sort of planning process to replace the auto-regressive generation.
That's pretty much exactly what I'm arguing for as well.
------
I should add that things like RLHF may reduce e but do not change the fact that token production is auto-regressive and subject to exponential divergence.
------
It's not specific to LLMs.
It's specific to *any* auto-regressive generative process.
------
The full slide deck is here.
This was my introductory position statement to the philosophical debate 
“Do large language models need sensory grounding for meaning and understanding?”
Which took place at NYU Friday evening.
------
Concerning point 8, here is the argument:
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
AR-LLM do not "search".
That's part of the problem.
------
When empirical evidence clashes with a theory, it is the theory that is wrong (or misinterpreted), not the universe.
The well-documented initial resistance of many ML theorists to deep learning was due to complete theory-fueled disbelief: this can't possibly work!
------
Now that everyone is fatigued by GPT-4 hot takes and blocked the keyword "LLM", here's the blog post with my current view on the topic, and how my views changed:
https://inference.vc/we-may-be-surprised-again/…
------
Not at all.
Most human answers are not produced auto-regressively but are planned ahead.
No exponential divergence there.
Mathematical proofs are discarded if they don't produce the desired result.
So they are not subject to exponential divergence.
------
Ask yourself why Microsoft suddenly limited the length of interactions with Bing chat / Sydney.
------
Yes, I'm implicitly making an independence assumption.
Not clear to what extent it's valid or invalid.
------
No. We are assuming the *errors* are independent, so their probabilities can be multiplied.
------
There is. And there is some truth to it.
Might be one reason I left France 
------
If a token take you out of the tree of correct answers, there is no going back. It's a tree!
------
Yup.
That would constitute a form of hierarchical planning. 
The question is precisely how to do it.
------
No.
Exponential divergence only occurs if you factorize P(y1,y2,y3) as P(y3|y1,y2)P(y2|y1)P(y1).
But you absolutely don't have to.
------
Possibly, but that would be super-expensive.
And that would make them non auto-regressive.
------
That would be a kind of planning.
Planning the sequence is clearly a good way to avoid exponential divergence.
------
Hierarchical planning and refinement is the best kind of planning.
------
It's not an assumption.
It's a fact.
An answer must terminate with an "end" marker.
There are no subsequent tokens after "end".
------
The error you'll make with receding horizon planning of length k depends on how accurately your energy over over k tokens approximates the energy for the whole sequence.
But the divergence will be way slower than pure auto-regressive.
------
Good luck making e less than 10e-12 !
------
You are arguing that answers should be planned ahead.
I totally agree.
------
No. It's a tree. One mistake, and you're out.
------
No. Fine-tuning, regardless of the method, reduces e but doesn't fix the exponential divergence of auto-regressive token production.
Only planning would.
------
Not true. 
You can *plan* and refine a representation of the sequence in your mind, then turn it into a token sequence and only then spit it out.
That's planning. That's not auto-regressive, and that's not subject to exponential divergence.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
MCTS, beam search, etc would constitute forms of planning and may fix the issue.
The resulting systems would no-longer be auto-regressive.
But they would be *insanely* expensive at inference time.
------
With an infinite supply of pen and paper 
------
That would be a primitive form of planning.
And that would be insanely expensive.
------
Humans plan ahead.
------
No. The answer without the parenthesis requires an "end" marker which the full answer doesn't have.
------
Pretty good paraphrasing, with helpful details!
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
Yes, the argument assumes the independence of errors.
No, an incorrect string cannot be corrected by further tokens. The set of correct answers is a subtree of the (enormous) tree of all token sequences. Once you are out, you are out.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
RLHF may reduce e but will not change the fact that auto-regressive token production is exponentially divergent.
------
RLHF may decrease e, but will not change the fact that the token generation process is auto-regressive.
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Well, e is in part determined by the sum of the training error (how accurately the network stores the entire training set) and the generalization gap (how representative is the training set of all the prompts that will ever be encountered).
------
Wat?
------
This is a real problem that OpenAI folks themselves have pointed out (from the GPT-4 page):
"Despite its capabilities, GPT-4 has similar limitations as earlier GPT models. Most importantly, it still is not fully reliable (it “hallucinates” facts and makes reasoning errors)."
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
Yes
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
I'm absolutely not assuming that the correct answer is unique.
It's a small subtree within the tree of all possible tokens sequences.
------
It seems that you are arguing for some sort of planning process to replace the auto-regressive generation.
That's pretty much exactly what I'm arguing for as well.
------
Yes, I'm implicitly making an independence assumption.
Not clear to what extent it's valid or invalid.
------
No. We are assuming the *errors* are independent, so their probabilities can be multiplied.
------
There is. And there is some truth to it.
Might be one reason I left France 
------
If a token take you out of the tree of correct answers, there is no going back. It's a tree!
------
Yup.
That would constitute a form of hierarchical planning. 
The question is precisely how to do it.
------
No.
Exponential divergence only occurs if you factorize P(y1,y2,y3) as P(y3|y1,y2)P(y2|y1)P(y1).
But you absolutely don't have to.
------
Possibly, but that would be super-expensive.
And that would make them non auto-regressive.
------
That would be a kind of planning.
Planning the sequence is clearly a good way to avoid exponential divergence.
------
Hierarchical planning and refinement is the best kind of planning.
------
It's not an assumption.
It's a fact.
An answer must terminate with an "end" marker.
There are no subsequent tokens after "end".
------
The error you'll make with receding horizon planning of length k depends on how accurately your energy over over k tokens approximates the energy for the whole sequence.
But the divergence will be way slower than pure auto-regressive.
------
Good luck making e less than 10e-12 !
------
You are arguing that answers should be planned ahead.
I totally agree.
------
No. It's a tree. One mistake, and you're out.
------
No. Fine-tuning, regardless of the method, reduces e but doesn't fix the exponential divergence of auto-regressive token production.
Only planning would.
------
Not true. 
You can *plan* and refine a representation of the sequence in your mind, then turn it into a token sequence and only then spit it out.
That's planning. That's not auto-regressive, and that's not subject to exponential divergence.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
MCTS, beam search, etc would constitute forms of planning and may fix the issue.
The resulting systems would no-longer be auto-regressive.
But they would be *insanely* expensive at inference time.
------
With an infinite supply of pen and paper 
------
That would be a primitive form of planning.
And that would be insanely expensive.
------
Humans plan ahead.
------
No. The answer without the parenthesis requires an "end" marker which the full answer doesn't have.
------
Pretty good paraphrasing, with helpful details!
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
Yes, the argument assumes the independence of errors.
No, an incorrect string cannot be corrected by further tokens. The set of correct answers is a subtree of the (enormous) tree of all token sequences. Once you are out, you are out.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
RLHF may reduce e but will not change the fact that auto-regressive token production is exponentially divergent.
------
RLHF may decrease e, but will not change the fact that the token generation process is auto-regressive.
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Well, e is in part determined by the sum of the training error (how accurately the network stores the entire training set) and the generalization gap (how representative is the training set of all the prompts that will ever be encountered).
------
Wat?
------
This is a real problem that OpenAI folks themselves have pointed out (from the GPT-4 page):
"Despite its capabilities, GPT-4 has similar limitations as earlier GPT models. Most importantly, it still is not fully reliable (it “hallucinates” facts and makes reasoning errors)."
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
Yes
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
I'm absolutely not assuming that the correct answer is unique.
It's a small subtree within the tree of all possible tokens sequences.
------
It seems that you are arguing for some sort of planning process to replace the auto-regressive generation.
That's pretty much exactly what I'm arguing for as well.
------
It's not an assumption.
It's a fact.
An answer must terminate with an "end" marker.
There are no subsequent tokens after "end".
------
The error you'll make with receding horizon planning of length k depends on how accurately your energy over over k tokens approximates the energy for the whole sequence.
But the divergence will be way slower than pure auto-regressive.
------
Good luck making e less than 10e-12 !
------
You are arguing that answers should be planned ahead.
I totally agree.
------
No. It's a tree. One mistake, and you're out.
------
No. Fine-tuning, regardless of the method, reduces e but doesn't fix the exponential divergence of auto-regressive token production.
Only planning would.
------
Not true. 
You can *plan* and refine a representation of the sequence in your mind, then turn it into a token sequence and only then spit it out.
That's planning. That's not auto-regressive, and that's not subject to exponential divergence.
------
This trick was proposed years ago in the context of translation, back in the pre-transformer days when people were still using LSTM.
This is a common problem of recurrent (or auto-regressive) nets where the information about the past is compressed and gets diluted over time.
------
No. There can be a whole subtree of correct answers.
------
MCTS, beam search, etc would constitute forms of planning and may fix the issue.
The resulting systems would no-longer be auto-regressive.
But they would be *insanely* expensive at inference time.
------
With an infinite supply of pen and paper 
------
That would be a primitive form of planning.
And that would be insanely expensive.
------
Humans plan ahead.
------
No. The answer without the parenthesis requires an "end" marker which the full answer doesn't have.
------
Pretty good paraphrasing, with helpful details!
------
Outputting the "end" marker after a false statement takes you out of the subtree of correct answers.
------
Yes, the argument assumes the independence of errors.
No, an incorrect string cannot be corrected by further tokens. The set of correct answers is a subtree of the (enormous) tree of all token sequences. Once you are out, you are out.
------
That's because Konrad's brain can *plan* long answers and thereby avoid the exponentially-decaying probability of not farting that would inevitably occur were he to pull words out of his backend one at a time auto-regressively 
------
RLHF may reduce e but will not change the fact that auto-regressive token production is exponentially divergent.
------
RLHF may decrease e, but will not change the fact that the token generation process is auto-regressive.
------
I'm certainly *not* underestimating the value of current systems for creators.
These things are very useful as writing aids for poetry, prose, or code.
------
Well, e is in part determined by the sum of the training error (how accurately the network stores the entire training set) and the generalization gap (how representative is the training set of all the prompts that will ever be encountered).
------
Wat?
------
This is a real problem that OpenAI folks themselves have pointed out (from the GPT-4 page):
"Despite its capabilities, GPT-4 has similar limitations as earlier GPT models. Most importantly, it still is not fully reliable (it “hallucinates” facts and makes reasoning errors)."
------
I have claimed that Auto-Regressive LLMs are exponentially diverging diffusion processes.
Here is the argument:
Let e be the probability that any generated token exits the tree of "correct" answers.
Then the probability that an answer of length n is correct is (1-e)^n
1/
------
Yes
------
I think it depends on what we mean by P().
P(y1,y2,y3) is the "real" joint t distribution.
You can choose to parameterize it as 
Q(y3|y1,y2,w)Q(y2|y1,w)Q(y1|w)
where Q is some trainable function with parameter w.
But you certainly don't have to use this factorization.
------
I'm absolutely not assuming that the correct answer is unique.
It's a small subtree within the tree of all possible tokens sequences.
------
It seems that you are arguing for some sort of planning process to replace the auto-regressive generation.
That's pretty much exactly what I'm arguing for as well.
------
Seriously?
------
Colorfully stochastic parrotfish.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
GPT-4 gets it wrong at first, but then gets it right after being told it's wrong.
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
It is entirely possible that this very problem was entered in ChatGPT (perhaps because of my tweet) and subsequently made its way into the human-rated training set used to fine-tune GPT-4.
------
Great debate and panel last night at #phildeeplearning. @davidchalmers42 brought up how GPT-4 as made considerable progress on @ylecun's 6-gear question. So I wanted to see whether there is real progress in generalization. Initial signs looked mostly good:
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
A slightly new challenge to test the physical intuition of LLMs, with an ensuing discussion.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
To clarify: there will be language models in 5 years, but they won't be auto-regressive.
Because auto-regressive models are uncontrollable and suffer from exponential divergence as more tokens are produced.
------
They may convince themselves that they won but they would merely be fooled by testing on the training set.
------
Here is a slightly trickier problem.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
The AI scene is a dispersive medium for people's perception of progress.
Different people perceive progress with different velocities.
------
hype cycle for llms is moving so fast and everyone is at totally different points on the curve, it's wild
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
New York City today:
------
Seriously?
------
Colorfully stochastic parrotfish.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
GPT-4 gets it wrong at first, but then gets it right after being told it's wrong.
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
It is entirely possible that this very problem was entered in ChatGPT (perhaps because of my tweet) and subsequently made its way into the human-rated training set used to fine-tune GPT-4.
------
Great debate and panel last night at #phildeeplearning. @davidchalmers42 brought up how GPT-4 as made considerable progress on @ylecun's 6-gear question. So I wanted to see whether there is real progress in generalization. Initial signs looked mostly good:
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
A slightly new challenge to test the physical intuition of LLMs, with an ensuing discussion.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
To clarify: there will be language models in 5 years, but they won't be auto-regressive.
Because auto-regressive models are uncontrollable and suffer from exponential divergence as more tokens are produced.
------
They may convince themselves that they won but they would merely be fooled by testing on the training set.
------
Here is a slightly trickier problem.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
The AI scene is a dispersive medium for people's perception of progress.
Different people perceive progress with different velocities.
------
hype cycle for llms is moving so fast and everyone is at totally different points on the curve, it's wild
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
New York City today:
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
Seriously?
------
Colorfully stochastic parrotfish.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
GPT-4 gets it wrong at first, but then gets it right after being told it's wrong.
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
It is entirely possible that this very problem was entered in ChatGPT (perhaps because of my tweet) and subsequently made its way into the human-rated training set used to fine-tune GPT-4.
------
Great debate and panel last night at #phildeeplearning. @davidchalmers42 brought up how GPT-4 as made considerable progress on @ylecun's 6-gear question. So I wanted to see whether there is real progress in generalization. Initial signs looked mostly good:
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
A slightly new challenge to test the physical intuition of LLMs, with an ensuing discussion.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
To clarify: there will be language models in 5 years, but they won't be auto-regressive.
Because auto-regressive models are uncontrollable and suffer from exponential divergence as more tokens are produced.
------
They may convince themselves that they won but they would merely be fooled by testing on the training set.
------
Here is a slightly trickier problem.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
The AI scene is a dispersive medium for people's perception of progress.
Different people perceive progress with different velocities.
------
hype cycle for llms is moving so fast and everyone is at totally different points on the curve, it's wild
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
New York City today:
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
No, the answer is false.
With an odd number of gears around a circle nothing can turn!
It's locked in place.
It was a trap.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Also, the question in my original tweet and its solution may have found their way into the training set that GPT-4 was fine-tuned on.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
GPT-4 gets it wrong at first, but then gets it right after being told it's wrong.
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
It is entirely possible that this very problem was entered in ChatGPT (perhaps because of my tweet) and subsequently made its way into the human-rated training set used to fine-tune GPT-4.
------
Great debate and panel last night at #phildeeplearning. @davidchalmers42 brought up how GPT-4 as made considerable progress on @ylecun's 6-gear question. So I wanted to see whether there is real progress in generalization. Initial signs looked mostly good:
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
A slightly new challenge to test the physical intuition of LLMs, with an ensuing discussion.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
To clarify: there will be language models in 5 years, but they won't be auto-regressive.
Because auto-regressive models are uncontrollable and suffer from exponential divergence as more tokens are produced.
------
They may convince themselves that they won but they would merely be fooled by testing on the training set.
------
Here is a slightly trickier problem.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
The AI scene is a dispersive medium for people's perception of progress.
Different people perceive progress with different velocities.
------
hype cycle for llms is moving so fast and everyone is at totally different points on the curve, it's wild
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
New York City today:
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
No, the answer is false.
With an odd number of gears around a circle nothing can turn!
It's locked in place.
It was a trap.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Also, the question in my original tweet and its solution may have found their way into the training set that GPT-4 was fine-tuned on.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
It is entirely possible that this very problem was entered in ChatGPT (perhaps because of my tweet) and subsequently made its way into the human-rated training set used to fine-tune GPT-4.
------
Great debate and panel last night at #phildeeplearning. @davidchalmers42 brought up how GPT-4 as made considerable progress on @ylecun's 6-gear question. So I wanted to see whether there is real progress in generalization. Initial signs looked mostly good:
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
A slightly new challenge to test the physical intuition of LLMs, with an ensuing discussion.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
To clarify: there will be language models in 5 years, but they won't be auto-regressive.
Because auto-regressive models are uncontrollable and suffer from exponential divergence as more tokens are produced.
------
They may convince themselves that they won but they would merely be fooled by testing on the training set.
------
Here is a slightly trickier problem.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
The AI scene is a dispersive medium for people's perception of progress.
Different people perceive progress with different velocities.
------
hype cycle for llms is moving so fast and everyone is at totally different points on the curve, it's wild
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
New York City today:
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
No, the answer is false.
With an odd number of gears around a circle nothing can turn!
It's locked in place.
It was a trap.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Also, the question in my original tweet and its solution may have found their way into the training set that GPT-4 was fine-tuned on.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Here is a slightly different formulation:

7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. ...
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
No.
------
I can't disagree.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
The gears are numbered 1 to 7 around the circle. If a torque in the clockwise direction were applied to gear 3, in which direction would gear 7 rotate?
------
Enjoy!
------
Well, I was right about that one too.
No one uses Pixel CNN for anything these days 

Karol Gregor suggested the idea while he was a postdoc in my lab, and I talked him out of it!
The idea is almost as bad as using HMMs on pixels sequences.
------
They may convince themselves that they won but they would merely be fooled by testing on the training set.
------
Here is a slightly trickier problem.
------
7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. The gears are numbered 1 to 7 around the circle. If gear 3 were rotated clockwise, in which direction would gear 7 rotate?
------
The AI scene is a dispersive medium for people's perception of progress.
Different people perceive progress with different velocities.
------
hype cycle for llms is moving so fast and everyone is at totally different points on the curve, it's wild
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
New York City today:
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
No, the answer is false.
With an odd number of gears around a circle nothing can turn!
It's locked in place.
It was a trap.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Also, the question in my original tweet and its solution may have found their way into the training set that GPT-4 was fine-tuned on.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Here is a slightly different formulation:

7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. ...
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
No.
------
I can't disagree.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
The gears are numbered 1 to 7 around the circle. If a torque in the clockwise direction were applied to gear 3, in which direction would gear 7 rotate?
------
Enjoy!
------
Well, I was right about that one too.
No one uses Pixel CNN for anything these days 

Karol Gregor suggested the idea while he was a postdoc in my lab, and I talked him out of it!
The idea is almost as bad as using HMMs on pixels sequences.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
No, the answer is false.
With an odd number of gears around a circle nothing can turn!
It's locked in place.
It was a trap.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Also, the question in my original tweet and its solution may have found their way into the training set that GPT-4 was fine-tuned on.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Here is a slightly different formulation:

7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. ...
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
No.
------
I can't disagree.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
The gears are numbered 1 to 7 around the circle. If a torque in the clockwise direction were applied to gear 3, in which direction would gear 7 rotate?
------
Enjoy!
------
Well, I was right about that one too.
No one uses Pixel CNN for anything these days 

Karol Gregor suggested the idea while he was a postdoc in my lab, and I talked him out of it!
The idea is almost as bad as using HMMs on pixels sequences.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Here is a slightly different formulation:

7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. ...
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
No.
------
I can't disagree.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
The gears are numbered 1 to 7 around the circle. If a torque in the clockwise direction were applied to gear 3, in which direction would gear 7 rotate?
------
Enjoy!
------
Well, I was right about that one too.
No one uses Pixel CNN for anything these days 

Karol Gregor suggested the idea while he was a postdoc in my lab, and I talked him out of it!
The idea is almost as bad as using HMMs on pixels sequences.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Here is a slightly different formulation:

7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. ...
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
No.
------
I can't disagree.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
The gears are numbered 1 to 7 around the circle. If a torque in the clockwise direction were applied to gear 3, in which direction would gear 7 rotate?
------
Enjoy!
------
Well, I was right about that one too.
No one uses Pixel CNN for anything these days 

Karol Gregor suggested the idea while he was a postdoc in my lab, and I talked him out of it!
The idea is almost as bad as using HMMs on pixels sequences.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
Rationality is all you need.
------
At least to test the claim that they possess some level of physical intuition despite being trained strictly on text.
------
Assessments of the current crop of LLMs come in different flavors.
Some are legitimate and many are totally unfair.
The type of critique 
@TonyZador
 makes fun of here is unfair.
Auto-regressive LLMs are very good writing aids even if the make sh*t up and can be toxic.
------
A lot of LLM crtiques these days are like 

"Wow, this screwdriver is completely useless for hammering this nail. What a fail. "
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
This is a uniquely American phenomenon due to US fiscal policies (particularly tax cuts for higher incomes and cuts in social programs).
There has been no such decoupling in continental Europe.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Here is a slightly different formulation:

7 axles are equally spaced around a circle. A gear is placed on each axle such that each gear is engaged with the gear to its left and the gear to its right. ...
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
No.
------
I can't disagree.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
The gears are numbered 1 to 7 around the circle. If a torque in the clockwise direction were applied to gear 3, in which direction would gear 7 rotate?
------
Enjoy!
------
Well, I was right about that one too.
No one uses Pixel CNN for anything these days 

Karol Gregor suggested the idea while he was a postdoc in my lab, and I talked him out of it!
The idea is almost as bad as using HMMs on pixels sequences.
------
I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it widely underestimated.

I've been publicly called stupid before, but never as often as by the "AI is a significant existential risk" crowd.

That's OK, I'm used to it.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
"net adjusted household disposable income per hour worked"
------
In terms of measuring societal affluence with a single metric, it's hard to beat "net adjusted household disposable income per hour worked".
https://oecdbetterlifeindex.org/topics/income/#:~:text=Household%20net%20adjusted%20disposable%20income…
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
As I've said multiple times, Auto-Regressive LLMs are unalignable, and uncontrollable.
They must (and will) disappear for that reason.
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
Did the domestication of the horse and ox caused civil unrest because humans were used to being the strongest machines around?

I work at a research lab with incredibly smart colleagues and I'm very much used to not being the smartest machine around.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
It's funny when brilliant aeronautics people and philosophers compare billions of years of cellular evolution to their primitive flying contraptions.
------
The printing press allowed people to read the bible, which enabled the protestant movement, which caused 2 centuries of religious conflicts in Europe.
It also enabled the emergence of the Enlightenment, science, & liberal democracy.
Few people would claim it was a bad thing
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Make it produce outputs that explicitly optimize a set of objectives,
Instead of reactively spewing one token at a time auto-regressively.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it widely underestimated.

I've been publicly called stupid before, but never as often as by the "AI is a significant existential risk" crowd.

That's OK, I'm used to it.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
"net adjusted household disposable income per hour worked"
------
In terms of measuring societal affluence with a single metric, it's hard to beat "net adjusted household disposable income per hour worked".
https://oecdbetterlifeindex.org/topics/income/#:~:text=Household%20net%20adjusted%20disposable%20income…
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
As I've said multiple times, Auto-Regressive LLMs are unalignable, and uncontrollable.
They must (and will) disappear for that reason.
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
Did the domestication of the horse and ox caused civil unrest because humans were used to being the strongest machines around?

I work at a research lab with incredibly smart colleagues and I'm very much used to not being the smartest machine around.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
It's funny when brilliant aeronautics people and philosophers compare billions of years of cellular evolution to their primitive flying contraptions.
------
The printing press allowed people to read the bible, which enabled the protestant movement, which caused 2 centuries of religious conflicts in Europe.
It also enabled the emergence of the Enlightenment, science, & liberal democracy.
Few people would claim it was a bad thing
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Make it produce outputs that explicitly optimize a set of objectives,
Instead of reactively spewing one token at a time auto-regressively.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Why is Stuart unable to understand that whoever designs a robot with such a stupid objective could very easily add a term in the objective amounting to "don't run people over"?
------
Apes don't get to design and hardwire humans' intrinsic objectives (they are the result of evolution).
But we get to design and hardwire the intrinsic objectives of AI systems.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it widely underestimated.

I've been publicly called stupid before, but never as often as by the "AI is a significant existential risk" crowd.

That's OK, I'm used to it.
------
The NeuroAI manifesto is out.
------
@ylecun @seanescola @tyrell_turing @BOlveczky finally!

@chklovskii @anne_churchland @ClopathLab @JamesJDiCarlo @SuryaGanguli @koerding @joe6783 @countzerozzz @AdamMarblestone @pouget_alex @SaraASolla @sejnowski @SussilloDavid @AToliasLab @doristsao 
https://rdcu.be/c8dvd
------
Quite a few AI folks used to be adamant that AI should never be used for military applications.
Since the invasion of Ukraine by Putin, some have changed their tune.
Yes, AI can be misused by authoritarian govts.
But the defense of democracy against authoritarianism needs AI.
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
"net adjusted household disposable income per hour worked"
------
In terms of measuring societal affluence with a single metric, it's hard to beat "net adjusted household disposable income per hour worked".
https://oecdbetterlifeindex.org/topics/income/#:~:text=Household%20net%20adjusted%20disposable%20income…
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
As I've said multiple times, Auto-Regressive LLMs are unalignable, and uncontrollable.
They must (and will) disappear for that reason.
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
Did the domestication of the horse and ox caused civil unrest because humans were used to being the strongest machines around?

I work at a research lab with incredibly smart colleagues and I'm very much used to not being the smartest machine around.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
It's funny when brilliant aeronautics people and philosophers compare billions of years of cellular evolution to their primitive flying contraptions.
------
The printing press allowed people to read the bible, which enabled the protestant movement, which caused 2 centuries of religious conflicts in Europe.
It also enabled the emergence of the Enlightenment, science, & liberal democracy.
Few people would claim it was a bad thing
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Make it produce outputs that explicitly optimize a set of objectives,
Instead of reactively spewing one token at a time auto-regressively.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Why is Stuart unable to understand that whoever designs a robot with such a stupid objective could very easily add a term in the objective amounting to "don't run people over"?
------
Apes don't get to design and hardwire humans' intrinsic objectives (they are the result of evolution).
But we get to design and hardwire the intrinsic objectives of AI systems.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
Relevant to tonight's debate.
------
A lot of my arguments about the foundations of intelligence being sensorimotor control (and not language or reasoning) are shaped by discussions with Jitendra over the years. 

This is a good summary of his arguments. twitter.com/JitendraMalikC…
------
Debate at 5:50 EST today:
“Do large language models need sensory grounding for meaning and understanding?”

Debaters:
Jacob Browning, David Chalmers, Brenden Lake, Yann LeCun, Gary Lupyan, Ellie Pavlick.
------
"net adjusted household disposable income per hour worked"
------
In terms of measuring societal affluence with a single metric, it's hard to beat "net adjusted household disposable income per hour worked".
https://oecdbetterlifeindex.org/topics/income/#:~:text=Household%20net%20adjusted%20disposable%20income…
------
Zoom video stream link: https://nyu.zoom.us/j/94330455358
------
As I've said multiple times, Auto-Regressive LLMs are unalignable, and uncontrollable.
They must (and will) disappear for that reason.
------
Where did I mention the USA?
The US democracy is deeply flawed.
And the track record of Republican governments as defenders of democracy is pretty abysmal.
------
Did the domestication of the horse and ox caused civil unrest because humans were used to being the strongest machines around?

I work at a research lab with incredibly smart colleagues and I'm very much used to not being the smartest machine around.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
It's funny when brilliant aeronautics people and philosophers compare billions of years of cellular evolution to their primitive flying contraptions.
------
The printing press allowed people to read the bible, which enabled the protestant movement, which caused 2 centuries of religious conflicts in Europe.
It also enabled the emergence of the Enlightenment, science, & liberal democracy.
Few people would claim it was a bad thing
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Make it produce outputs that explicitly optimize a set of objectives,
Instead of reactively spewing one token at a time auto-regressively.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Why is Stuart unable to understand that whoever designs a robot with such a stupid objective could very easily add a term in the objective amounting to "don't run people over"?
------
Apes don't get to design and hardwire humans' intrinsic objectives (they are the result of evolution).
But we get to design and hardwire the intrinsic objectives of AI systems.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I did not claim that LLM will vanish.
I claimed *AUTO-REGRESSIVE* LLMs will vanish.
The auto-regressivity is their Achilles heel.
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Depends a hell of a lot on the goal(s).
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
Actually, we discovered adversarial samples within the 1st year of playing with ConvNets.
We asked "what is the network's ideal idea of a 5?"
Starting from a random input, we computed an input that produces a perfect "5" output through gradient descent.
We got total garbage.
...
------
No.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
Then we asked how can we minimally perturb a 2 to produce a perfect 5.
We got an image that looked more like a 2 than a 5.
It's a big space out there, and the network is only trained on a small, low-dimensional sliver of it.
------
Did the domestication of the horse and ox caused civil unrest because humans were used to being the strongest machines around?

I work at a research lab with incredibly smart colleagues and I'm very much used to not being the smartest machine around.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
It's funny when brilliant aeronautics people and philosophers compare billions of years of cellular evolution to their primitive flying contraptions.
------
The printing press allowed people to read the bible, which enabled the protestant movement, which caused 2 centuries of religious conflicts in Europe.
It also enabled the emergence of the Enlightenment, science, & liberal democracy.
Few people would claim it was a bad thing
------
1. Kouign Amann is not supposed to be puffed up like this. Density is all you need.
2. Onions? What kind of civilization-destroying abomination is this?
3. I'm predicting General Kouign Amann by 2025.
------
Like many powerful technologies, AI can simultaneously be a threat to freedom & wellbeing and the greatest tool for more freedom & wellbeing.
Whether it is used for the former or the latter depends on the strength of democratic institutions.
Which is why we must defend them.
------
Make it produce outputs that explicitly optimize a set of objectives,
Instead of reactively spewing one token at a time auto-regressively.
------
Before WWII, America was isolationist and coming out of a major financial crisis.
Its military technology sucked.
But by the end of WWII, it was churning out P51, P38, B29, jets, good radars, nuclear bombs, and had built over 100 aircraft carriers.
------
The "safety" against the Nazi invasion of Europe and the Japanese invasion of East Asia was superior military technology and industrial might.

But in a well-run civilian society, there is no need for guns.
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
Open source Kouign Amann recipes have enabled bad actors to corrupt them (e.g. by adding onions. ONIONS!).
This presents a non-negligible existential risk for humanity.
What will they do next?
Galettes with potatoes?
Breton culinary technology is too dangerous to go unregulated.
------
Why is Stuart unable to understand that whoever designs a robot with such a stupid objective could very easily add a term in the objective amounting to "don't run people over"?
------
Apes don't get to design and hardwire humans' intrinsic objectives (they are the result of evolution).
But we get to design and hardwire the intrinsic objectives of AI systems.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I did not claim that LLM will vanish.
I claimed *AUTO-REGRESSIVE* LLMs will vanish.
The auto-regressivity is their Achilles heel.
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Depends a hell of a lot on the goal(s).
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
Actually, we discovered adversarial samples within the 1st year of playing with ConvNets.
We asked "what is the network's ideal idea of a 5?"
Starting from a random input, we computed an input that produces a perfect "5" output through gradient descent.
We got total garbage.
...
------
No.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
Then we asked how can we minimally perturb a 2 to produce a perfect 5.
We got an image that looked more like a 2 than a 5.
It's a big space out there, and the network is only trained on a small, low-dimensional sliver of it.
------
Why is Stuart unable to understand that whoever designs a robot with such a stupid objective could very easily add a term in the objective amounting to "don't run people over"?
------
Apes don't get to design and hardwire humans' intrinsic objectives (they are the result of evolution).
But we get to design and hardwire the intrinsic objectives of AI systems.
------
Sorry to disappoint.
But have you ever heard of WWII?
------
Fertilizers is the main reason why very few people die from famines today.
------
Congrats 
@garridoq_
 , 
@AdrienBardes
 , and 
@Yubei_Chen
 !
------
I'm verry happy to announce that our work has received an Outstanding Paper Honorable Mention at ICLR2023 !
https://blog.iclr.cc/2023/03/21/announcing-the-iclr-2023-outstanding-paper-award-recipients/…

Thanks again to my co-authors @Yubei_Chen @AdrienBardes @laurentnajman and @ylecun 

Check out the camera ready version: https://openreview.net/forum?id=kDEL91Dufpa…
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I did not claim that LLM will vanish.
I claimed *AUTO-REGRESSIVE* LLMs will vanish.
The auto-regressivity is their Achilles heel.
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Depends a hell of a lot on the goal(s).
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
Actually, we discovered adversarial samples within the 1st year of playing with ConvNets.
We asked "what is the network's ideal idea of a 5?"
Starting from a random input, we computed an input that produces a perfect "5" output through gradient descent.
We got total garbage.
...
------
No.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
Then we asked how can we minimally perturb a 2 to produce a perfect 5.
We got an image that looked more like a 2 than a 5.
It's a big space out there, and the network is only trained on a small, low-dimensional sliver of it.
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I did not claim that LLM will vanish.
I claimed *AUTO-REGRESSIVE* LLMs will vanish.
The auto-regressivity is their Achilles heel.
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Depends a hell of a lot on the goal(s).
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
Actually, we discovered adversarial samples within the 1st year of playing with ConvNets.
We asked "what is the network's ideal idea of a 5?"
Starting from a random input, we computed an input that produces a perfect "5" output through gradient descent.
We got total garbage.
...
------
No.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
Then we asked how can we minimally perturb a 2 to produce a perfect 5.
We got an image that looked more like a 2 than a 5.
It's a big space out there, and the network is only trained on a small, low-dimensional sliver of it.
------
The Mongol invasions did not stop people from using horses.
------
Sydney is an Auto-Regressive LLM and hence does not possess any objective to align.
------
Not mentioning *actual* black holes.
------
I hadn't. But yes, I was thinking about that too, among others.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
The proportion of people dying of malnutrition per decade has been going down.
https://ourworldindata.org/famines#long-term-trends-in-global-famine-mortality…
------
We get to *design* and *hardwire* objective functions for AI.
That makes the alignment problem a hell of a lot easier to solve than with people and corporation whose intrinsic objective functions are fixed (by evolution or by capitalism).
------
Probably because it is.
------
Argh! fat fingers.
------
I was against the Patriot Act (and very much against the invasion of Iraq).
The US Republican Party has not been known as a defender of democracy since WWII.
Pretty much the opposite.
Even domestically.
Particularly since it has become the party of Trump.
------
I'm a militant atheist.
------
The first version of our paper was written in December 2018.
------
Yet, some have inexplicably characterized military applications of AI as "weapons of mass destruction"...
------
Si vis pacem, para bellum.
------
Why?
------
I did not claim that LLM will vanish.
I claimed *AUTO-REGRESSIVE* LLMs will vanish.
The auto-regressivity is their Achilles heel.
------
I'm not the only one to have pointed out the obvious connection between the insufferable density of bagels and black holes.

See "everything, everywhere, all at once"
------
The WSJ talks about recent progress in applying AI to protein structure prediction, following the publication of FAIR's ESMFold paper in Science.
------
Depends a hell of a lot on the goal(s).
------
Of course, we must look at technological progress as a perpetual renaissance.
But that can't happen if liberal democracies get overrun by authoritarianism, foreign or domestic.
------
Actually, we discovered adversarial samples within the 1st year of playing with ConvNets.
We asked "what is the network's ideal idea of a 5?"
Starting from a random input, we computed an input that produces a perfect "5" output through gradient descent.
We got total garbage.
...
------
No.
------
It's not like Kouign Amann can gravitationally collapse into black holes.
Unlike, say, bagels .
------
Then we asked how can we minimally perturb a 2 to produce a perfect 5.
We got an image that looked more like a 2 than a 5.
It's a big space out there, and the network is only trained on a small, low-dimensional sliver of it.
------
The power of open research and open source.
------
Holy hell, we went from OpenAI being effectively the only player in the LLM game to "you can run GPT-3 on a gaming graphics card" in like 2 weeks
------
I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it widely underestimated.

I've been publicly called stupid before, but never as often as by the "AI is a significant existential risk" crowd.

That's OK, I'm used to it.
------
I don't mean to make a bad taste joke, but pronouncing GPT-4 in quasi-French ("gé pé té for") sounds *very* awkward.
------
Calm down.
Human-level AI isn't here yet.
And when it comes, it will not want to dominate humanity.
Even among humans, it is not the smartest who want to dominate others and be the chief.
We have countless examples on the international political scene.
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
(note, this article is from 2019)
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
Serious question: What does an NLP Ph.D student work on nowadays with the presence of closed source GPT models that beat anything you can do in standard academic lab?

@sleepinyourhat @srush_nlp @chrmanning @mdredze @ChrisGPotts
------
This critique of AI gets absolutely everything wrong.

Quote: "There have been no major breakthroughs in the academic discipline of artificial intelligence for a couple of decades"

What ???
Seriously ???
------
"It has read most of the internet, and it knows what human language is supposed to sound like, but it has no relation to reality whatsoever." I'm in the @guardian today, writing about image generators, ChatGPT, and the stupidity of AI: https://theguardian.com/technology/2023/mar/16/the-stupidity-of-ai-artificial-intelligence-dall-e-chatgpt…
------
You mean, like C3PO?
------
Her (by Spike Jonze)
------
How could the aims possibly be "inscrutable" since *we* would be the ones who would design and hardwire those aims in the form of objectives.
------
That's false.
Tons of animal species are pretty smart, yet never meet their parents and rarely interact with other members of their species.
------
As I'm fond to say: prediction is the essence of intelligence.
The very idea of Self-Supervised Learning is that intelligence emerges from learning to predict (or to fill in missing information).
But predicting natural percepts is much more complicated than predicting words.
------
Ou Bobby Lapointe.
------
The hallucination problem is specific to Auto-Regressive LLM architectures.
My proposal is to move away from AR-LLMs towards architectures that can reason and plan.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
Yes, that one.
------
No.
My benevolent defensive AI will be better at destroying your evil AI than your evil AI will be at hurting humans.
------
Very nice article by Craig Smith in IEEE Spectrum about the debate on the power and limitations of LLMs between (among others) 
@ilyasut

and me.
Do AI systems ultimately need to be grounded in reality, not merely learn from language?
I say yes.
------
I don't know what you mean by "we can't understand..."
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
The WSJ interviews 
@alexrives
 and comments on the Science paper about ESMFold protein structure prediction system by the 
@MetaAI
 - FAIR Protein team.
------
Meta has unveiled an AI model that can predict the shape of proteins—and potentially help find new drugs—using the same technology that allows ChatGPT to come up with human-like responses https://on.wsj.com/3le0iqR
------
The availability of #LLaMA evokes fond memories of Jeff Minter's 1991 psychedelic Amiga game Llamatron.

LLaMA and Llamatron have something in common: they are fast.

https://en.wikipedia.org/wiki/Llamatron?wprov=sfla1…

https://youtu.be/Kgw_0F2QONY
------
Speedy protein structures from single sequences with ESMFold in 
@ScienceMagazine
 !
"Evolutionary-scale prediction of atomic-level protein structure with a language model" by 
@ebetica
, 
@alexrives
 and collaborators from the protein group at 
@MetaAI
 - FAIR.

https://science.org/doi/10.1126/science.ade2574…
------
In a Science study, @MetaAI researchers show the power of a large language model, #ESMFold, to enable protein structure prediction and analysis. 

Using ESMFold, they generated a database—the ESM Metagenomic Atlas—of over 600 million metagenomic proteins. https://scim.ag/1Uv
------
He is not the first one to have had the idea that learning to predict (or to fill in the blanks) is on the path to better AI.
By a very long shot.


@geoffreyhinton
 among others has been promoting this idea for over 40 years. This was the main motivation behind Boltzmann Machines.
------
Auto-regressive LLMs hallucinate.
ESMFold is *not* an auto-regressive LLM.
Hallucination is an intrinsic property of auto-regressive generation.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
The power of open research and open source.
------
Holy hell, we went from OpenAI being effectively the only player in the LLM game to "you can run GPT-3 on a gaming graphics card" in like 2 weeks
------
I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it widely underestimated.

I've been publicly called stupid before, but never as often as by the "AI is a significant existential risk" crowd.

That's OK, I'm used to it.
------
I don't mean to make a bad taste joke, but pronouncing GPT-4 in quasi-French ("gé pé té for") sounds *very* awkward.
------
Calm down.
Human-level AI isn't here yet.
And when it comes, it will not want to dominate humanity.
Even among humans, it is not the smartest who want to dominate others and be the chief.
We have countless examples on the international political scene.
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
(note, this article is from 2019)
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
Serious question: What does an NLP Ph.D student work on nowadays with the presence of closed source GPT models that beat anything you can do in standard academic lab?

@sleepinyourhat @srush_nlp @chrmanning @mdredze @ChrisGPotts
------
This critique of AI gets absolutely everything wrong.

Quote: "There have been no major breakthroughs in the academic discipline of artificial intelligence for a couple of decades"

What ???
Seriously ???
------
"It has read most of the internet, and it knows what human language is supposed to sound like, but it has no relation to reality whatsoever." I'm in the @guardian today, writing about image generators, ChatGPT, and the stupidity of AI: https://theguardian.com/technology/2023/mar/16/the-stupidity-of-ai-artificial-intelligence-dall-e-chatgpt…
------
You mean, like C3PO?
------
Her (by Spike Jonze)
------
How could the aims possibly be "inscrutable" since *we* would be the ones who would design and hardwire those aims in the form of objectives.
------
That's false.
Tons of animal species are pretty smart, yet never meet their parents and rarely interact with other members of their species.
------
As I'm fond to say: prediction is the essence of intelligence.
The very idea of Self-Supervised Learning is that intelligence emerges from learning to predict (or to fill in missing information).
But predicting natural percepts is much more complicated than predicting words.
------
Ou Bobby Lapointe.
------
The hallucination problem is specific to Auto-Regressive LLM architectures.
My proposal is to move away from AR-LLMs towards architectures that can reason and plan.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
Yes, that one.
------
No.
My benevolent defensive AI will be better at destroying your evil AI than your evil AI will be at hurting humans.
------
Very nice article by Craig Smith in IEEE Spectrum about the debate on the power and limitations of LLMs between (among others) 
@ilyasut

and me.
Do AI systems ultimately need to be grounded in reality, not merely learn from language?
I say yes.
------
I don't know what you mean by "we can't understand..."
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
The WSJ interviews 
@alexrives
 and comments on the Science paper about ESMFold protein structure prediction system by the 
@MetaAI
 - FAIR Protein team.
------
Meta has unveiled an AI model that can predict the shape of proteins—and potentially help find new drugs—using the same technology that allows ChatGPT to come up with human-like responses https://on.wsj.com/3le0iqR
------
The availability of #LLaMA evokes fond memories of Jeff Minter's 1991 psychedelic Amiga game Llamatron.

LLaMA and Llamatron have something in common: they are fast.

https://en.wikipedia.org/wiki/Llamatron?wprov=sfla1…

https://youtu.be/Kgw_0F2QONY
------
Speedy protein structures from single sequences with ESMFold in 
@ScienceMagazine
 !
"Evolutionary-scale prediction of atomic-level protein structure with a language model" by 
@ebetica
, 
@alexrives
 and collaborators from the protein group at 
@MetaAI
 - FAIR.

https://science.org/doi/10.1126/science.ade2574…
------
In a Science study, @MetaAI researchers show the power of a large language model, #ESMFold, to enable protein structure prediction and analysis. 

Using ESMFold, they generated a database—the ESM Metagenomic Atlas—of over 600 million metagenomic proteins. https://scim.ag/1Uv
------
He is not the first one to have had the idea that learning to predict (or to fill in the blanks) is on the path to better AI.
By a very long shot.


@geoffreyhinton
 among others has been promoting this idea for over 40 years. This was the main motivation behind Boltzmann Machines.
------
Auto-regressive LLMs hallucinate.
ESMFold is *not* an auto-regressive LLM.
Hallucination is an intrinsic property of auto-regressive generation.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
The power of open research and open source.
------
Holy hell, we went from OpenAI being effectively the only player in the LLM game to "you can run GPT-3 on a gaming graphics card" in like 2 weeks
------
I think that the magnitude of the AI alignment problem has been ridiculously overblown & our ability to solve it widely underestimated.

I've been publicly called stupid before, but never as often as by the "AI is a significant existential risk" crowd.

That's OK, I'm used to it.
------
I don't mean to make a bad taste joke, but pronouncing GPT-4 in quasi-French ("gé pé té for") sounds *very* awkward.
------
Calm down.
Human-level AI isn't here yet.
And when it comes, it will not want to dominate humanity.
Even among humans, it is not the smartest who want to dominate others and be the chief.
We have countless examples on the international political scene.
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
(note, this article is from 2019)
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
Serious question: What does an NLP Ph.D student work on nowadays with the presence of closed source GPT models that beat anything you can do in standard academic lab?

@sleepinyourhat @srush_nlp @chrmanning @mdredze @ChrisGPotts
------
This critique of AI gets absolutely everything wrong.

Quote: "There have been no major breakthroughs in the academic discipline of artificial intelligence for a couple of decades"

What ???
Seriously ???
------
"It has read most of the internet, and it knows what human language is supposed to sound like, but it has no relation to reality whatsoever." I'm in the @guardian today, writing about image generators, ChatGPT, and the stupidity of AI: https://theguardian.com/technology/2023/mar/16/the-stupidity-of-ai-artificial-intelligence-dall-e-chatgpt…
------
You mean, like C3PO?
------
Her (by Spike Jonze)
------
How could the aims possibly be "inscrutable" since *we* would be the ones who would design and hardwire those aims in the form of objectives.
------
That's false.
Tons of animal species are pretty smart, yet never meet their parents and rarely interact with other members of their species.
------
As I'm fond to say: prediction is the essence of intelligence.
The very idea of Self-Supervised Learning is that intelligence emerges from learning to predict (or to fill in missing information).
But predicting natural percepts is much more complicated than predicting words.
------
Ou Bobby Lapointe.
------
The hallucination problem is specific to Auto-Regressive LLM architectures.
My proposal is to move away from AR-LLMs towards architectures that can reason and plan.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
Yes, that one.
------
No.
My benevolent defensive AI will be better at destroying your evil AI than your evil AI will be at hurting humans.
------
Very nice article by Craig Smith in IEEE Spectrum about the debate on the power and limitations of LLMs between (among others) 
@ilyasut

and me.
Do AI systems ultimately need to be grounded in reality, not merely learn from language?
I say yes.
------
I don't know what you mean by "we can't understand..."
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
The WSJ interviews 
@alexrives
 and comments on the Science paper about ESMFold protein structure prediction system by the 
@MetaAI
 - FAIR Protein team.
------
Meta has unveiled an AI model that can predict the shape of proteins—and potentially help find new drugs—using the same technology that allows ChatGPT to come up with human-like responses https://on.wsj.com/3le0iqR
------
The availability of #LLaMA evokes fond memories of Jeff Minter's 1991 psychedelic Amiga game Llamatron.

LLaMA and Llamatron have something in common: they are fast.

https://en.wikipedia.org/wiki/Llamatron?wprov=sfla1…

https://youtu.be/Kgw_0F2QONY
------
Speedy protein structures from single sequences with ESMFold in 
@ScienceMagazine
 !
"Evolutionary-scale prediction of atomic-level protein structure with a language model" by 
@ebetica
, 
@alexrives
 and collaborators from the protein group at 
@MetaAI
 - FAIR.

https://science.org/doi/10.1126/science.ade2574…
------
In a Science study, @MetaAI researchers show the power of a large language model, #ESMFold, to enable protein structure prediction and analysis. 

Using ESMFold, they generated a database—the ESM Metagenomic Atlas—of over 600 million metagenomic proteins. https://scim.ag/1Uv
------
He is not the first one to have had the idea that learning to predict (or to fill in the blanks) is on the path to better AI.
By a very long shot.


@geoffreyhinton
 among others has been promoting this idea for over 40 years. This was the main motivation behind Boltzmann Machines.
------
Auto-regressive LLMs hallucinate.
ESMFold is *not* an auto-regressive LLM.
Hallucination is an intrinsic property of auto-regressive generation.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
(note, this article is from 2019)
------
1. Get LLaMA
2. Future AI systems that are factual (do not hallucinate), can use tools, have physical intuition, can reason and plan, will have a very different architecture from the current crop of Auto-Regressive LLMs.
Find out what it is.
------
Serious question: What does an NLP Ph.D student work on nowadays with the presence of closed source GPT models that beat anything you can do in standard academic lab?

@sleepinyourhat @srush_nlp @chrmanning @mdredze @ChrisGPotts
------
This critique of AI gets absolutely everything wrong.

Quote: "There have been no major breakthroughs in the academic discipline of artificial intelligence for a couple of decades"

What ???
Seriously ???
------
"It has read most of the internet, and it knows what human language is supposed to sound like, but it has no relation to reality whatsoever." I'm in the @guardian today, writing about image generators, ChatGPT, and the stupidity of AI: https://theguardian.com/technology/2023/mar/16/the-stupidity-of-ai-artificial-intelligence-dall-e-chatgpt…
------
You mean, like C3PO?
------
Her (by Spike Jonze)
------
How could the aims possibly be "inscrutable" since *we* would be the ones who would design and hardwire those aims in the form of objectives.
------
That's false.
Tons of animal species are pretty smart, yet never meet their parents and rarely interact with other members of their species.
------
As I'm fond to say: prediction is the essence of intelligence.
The very idea of Self-Supervised Learning is that intelligence emerges from learning to predict (or to fill in missing information).
But predicting natural percepts is much more complicated than predicting words.
------
Ou Bobby Lapointe.
------
The hallucination problem is specific to Auto-Regressive LLM architectures.
My proposal is to move away from AR-LLMs towards architectures that can reason and plan.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
Yes, that one.
------
No.
My benevolent defensive AI will be better at destroying your evil AI than your evil AI will be at hurting humans.
------
Very nice article by Craig Smith in IEEE Spectrum about the debate on the power and limitations of LLMs between (among others) 
@ilyasut

and me.
Do AI systems ultimately need to be grounded in reality, not merely learn from language?
I say yes.
------
I don't know what you mean by "we can't understand..."
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
The WSJ interviews 
@alexrives
 and comments on the Science paper about ESMFold protein structure prediction system by the 
@MetaAI
 - FAIR Protein team.
------
Meta has unveiled an AI model that can predict the shape of proteins—and potentially help find new drugs—using the same technology that allows ChatGPT to come up with human-like responses https://on.wsj.com/3le0iqR
------
The availability of #LLaMA evokes fond memories of Jeff Minter's 1991 psychedelic Amiga game Llamatron.

LLaMA and Llamatron have something in common: they are fast.

https://en.wikipedia.org/wiki/Llamatron?wprov=sfla1…

https://youtu.be/Kgw_0F2QONY
------
Speedy protein structures from single sequences with ESMFold in 
@ScienceMagazine
 !
"Evolutionary-scale prediction of atomic-level protein structure with a language model" by 
@ebetica
, 
@alexrives
 and collaborators from the protein group at 
@MetaAI
 - FAIR.

https://science.org/doi/10.1126/science.ade2574…
------
In a Science study, @MetaAI researchers show the power of a large language model, #ESMFold, to enable protein structure prediction and analysis. 

Using ESMFold, they generated a database—the ESM Metagenomic Atlas—of over 600 million metagenomic proteins. https://scim.ag/1Uv
------
He is not the first one to have had the idea that learning to predict (or to fill in the blanks) is on the path to better AI.
By a very long shot.


@geoffreyhinton
 among others has been promoting this idea for over 40 years. This was the main motivation behind Boltzmann Machines.
------
Auto-regressive LLMs hallucinate.
ESMFold is *not* an auto-regressive LLM.
Hallucination is an intrinsic property of auto-regressive generation.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
The hallucination problem is specific to Auto-Regressive LLM architectures.
My proposal is to move away from AR-LLMs towards architectures that can reason and plan.
------
For centuries, we've been designing objective for superintelligent entities (laws for corporations).
For millennia, we've shaped the objectives of our children so they behave on society.
All of this without actually being able to hack the intrinsic objectives directly.
------
Yes, that one.
------
No.
My benevolent defensive AI will be better at destroying your evil AI than your evil AI will be at hurting humans.
------
Very nice article by Craig Smith in IEEE Spectrum about the debate on the power and limitations of LLMs between (among others) 
@ilyasut

and me.
Do AI systems ultimately need to be grounded in reality, not merely learn from language?
I say yes.
------
I don't know what you mean by "we can't understand..."
------
I'm well aware of the literature on the AI alignment problem.
I just think that the magnitude of the problem is ridiculously overblown, and our ability to solve it widely underestimated.
For this, I've been called stupid before, very publicly so.
That's OK, I'm used to it.
------
The WSJ interviews 
@alexrives
 and comments on the Science paper about ESMFold protein structure prediction system by the 
@MetaAI
 - FAIR Protein team.
------
Meta has unveiled an AI model that can predict the shape of proteins—and potentially help find new drugs—using the same technology that allows ChatGPT to come up with human-like responses https://on.wsj.com/3le0iqR
------
The availability of #LLaMA evokes fond memories of Jeff Minter's 1991 psychedelic Amiga game Llamatron.

LLaMA and Llamatron have something in common: they are fast.

https://en.wikipedia.org/wiki/Llamatron?wprov=sfla1…

https://youtu.be/Kgw_0F2QONY
------
Speedy protein structures from single sequences with ESMFold in 
@ScienceMagazine
 !
"Evolutionary-scale prediction of atomic-level protein structure with a language model" by 
@ebetica
, 
@alexrives
 and collaborators from the protein group at 
@MetaAI
 - FAIR.

https://science.org/doi/10.1126/science.ade2574…
------
In a Science study, @MetaAI researchers show the power of a large language model, #ESMFold, to enable protein structure prediction and analysis. 

Using ESMFold, they generated a database—the ESM Metagenomic Atlas—of over 600 million metagenomic proteins. https://scim.ag/1Uv
------
He is not the first one to have had the idea that learning to predict (or to fill in the blanks) is on the path to better AI.
By a very long shot.


@geoffreyhinton
 among others has been promoting this idea for over 40 years. This was the main motivation behind Boltzmann Machines.
------
Auto-regressive LLMs hallucinate.
ESMFold is *not* an auto-regressive LLM.
Hallucination is an intrinsic property of auto-regressive generation.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
The availability of #LLaMA evokes fond memories of Jeff Minter's 1991 psychedelic Amiga game Llamatron.

LLaMA and Llamatron have something in common: they are fast.

https://en.wikipedia.org/wiki/Llamatron?wprov=sfla1…

https://youtu.be/Kgw_0F2QONY
------
Speedy protein structures from single sequences with ESMFold in 
@ScienceMagazine
 !
"Evolutionary-scale prediction of atomic-level protein structure with a language model" by 
@ebetica
, 
@alexrives
 and collaborators from the protein group at 
@MetaAI
 - FAIR.

https://science.org/doi/10.1126/science.ade2574…
------
In a Science study, @MetaAI researchers show the power of a large language model, #ESMFold, to enable protein structure prediction and analysis. 

Using ESMFold, they generated a database—the ESM Metagenomic Atlas—of over 600 million metagenomic proteins. https://scim.ag/1Uv
------
He is not the first one to have had the idea that learning to predict (or to fill in the blanks) is on the path to better AI.
By a very long shot.


@geoffreyhinton
 among others has been promoting this idea for over 40 years. This was the main motivation behind Boltzmann Machines.
------
Auto-regressive LLMs hallucinate.
ESMFold is *not* an auto-regressive LLM.
Hallucination is an intrinsic property of auto-regressive generation.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Yes, you missed all of it.

1. The LLaMA inference code is open source: 
https://github.com/facebookresearch/llama…

2. The pre-trained weights can be obtained by AI researchers upon request: https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform…

3. Someone obtained the models through (2) and posted them on 4chan.
------
I'll confirm on your LinkedIn profile.
------
The knowledge contained in language is superficial.
------
No, even with the rest of the paragraph, it's still ridiculous.
------
PhotoRoom is a French startup that has been using deep learning for years to help vendors make product photos.

They have now developed a fast generative model to produce nice backgrounds on demand without requiring text prompts.

Congrats 
@matthieurouif
 and team!
------
We launched PhotoRoom 3 years ago to become the best background remover. Last summer, we paused the company for a generative AI hackathon & now we put all of our learnings from the past months about #generativeAI in Instant Backgrounds, launching today on iOS, Android & Web 1/6
------
The latter.
------
There are many rational &respectful discussions to be had on the topic.
I do think some people's emotions flare up when they see a hint of existential risk and immediately think the alignment problem is new and unsolvable.
It's neither.
...
------
That's severely incomplete and low bandwidth.
------
I seriously doubt long-distance running will be happening.
------
Haha!
------
Bach cantatas is my go-to music when I'm on a plane.
That and John Coltrane.
------
If it does have desires, it will be through objectives that *we* hardwired into it or that *we* trained to do the Right Things.
------
Probably because it is.
------
I'm not talking about a learning objective.
I'm talking about an *inference* objective.
I.e. an objective that the systems optimizes with respect to every output or action sequence it produces.
------
Le nôtre s'appelle LLaMA  
------
Because they would have no desire to do anything else.
Why?
Because we will engineer their desires.
------
You got it backwards.
Humans and animals are extremely good at modeling natural percepts.
Modeling text/language is quite easy in comparison because it's *designed* to be easily groked by networks of neurons.
------
It could be a virtual body in a simulated environment.
------
The first version of our paper was written in December 2018.
------
Depends a hell of a lot on the goal(s).
------
Ultracrepidrian?
------
A terrible example would be Ex Machina.
This movie gets absolutely everything wrong.
I guess it would be a good movie to discuss how every single one of the biggest fears about AI is wrong.
------
No.
------
I'm a jazz fan, and only wish I were an accomplished jazz musician.
Unless you would consider whistling a solo as an accomplishment.
I enjoy cooking, but pastries aren't my specialty.
------
Interesting exercise.
------
I've sucefully runned LLaMA 7B model on my 4GB RAM Raspberry Pi 4. It's super slow about 10sec/token. But it looks we can run powerful cognitive pipelines on a cheap hardware.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
Both of the "fun facts" are completely wrong 
------
AI certainly won't cause lasting unemployment.
But technological evolutions displace jobs: the faster they take place, the more people are (temporarily) left behind because their skills are outdated for the new economy. Workforce retraining is of the essence.
1/2
------
Cute.
------
I packed-up a full-text paper scraper, vector database, and LLM into a CLI to answer questions from only highly-cited peer-reviewed  papers. Feels unreal to be able instantly get answers by an LLM "reading" dozens of papers. 1/2
------
An account of the current GenAI craze.
------
Today I met with the Global Media team to discuss Generative AI. The excitement was insane! Never seen a topic like this at work before.

Here are the 14 examples of AI in Media I shared with them & why: 
------
It's a bit like music.
A small number of papers have a huge influence.
A good number bring a significant stone to the edifice.
A large number propose new applications.
Most have *some* interesting nugget.
Many papers don't amount to much, but not as many as you might think...
------
Penrose is wrong.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
Counterpart:
Wheel: OMG this is going to destroy society. People will become weak.
Book: OMG this is going to destroy society. People will be able to learn stuff and think for themselves.
Gears: OMG, this is going to destroy society. Machines will take our jobs.
Computer: OMG ...
------
I get chills with a lot of Bach pieces.
Oboe almost always does it for me.
------
Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2
------
. 
@erikbryn
 says the effect of a technological (r)evolution on productivity takes 15 to 20 years.
But for AI, I'm not sure when to start counting.
------
And you rarely know right away which ones are going to spark a new avenue.
It often takes several years before an idea comes to fruition in practice.
A good recent example is diffusion models.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Next week.
------
Very excited to share the final line-up and program of our upcoming conference on the Philosophy of Deep Learning!

Co-organized with @davidchalmers42 & @De_dicto and co-sponsored by @columbiacss's PSSN & @nyuconscious.

Info, registration & full program: https://phildeeplearning.github.io
------
Training robots to imitate behaviors with 1-minute demonstrations.
From 
@LerrelPinto
 's group at 
@nyuniversity
------
While we are going gaga over large models and big data, there is still incredible value left to extract in small models and data, especially in robotics.

All the skills shown below were each trained with <1 min of human data and <20 min of online RL

http://fast-imitation.github.io 
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Interesting exercise.
------
I've sucefully runned LLaMA 7B model on my 4GB RAM Raspberry Pi 4. It's super slow about 10sec/token. But it looks we can run powerful cognitive pipelines on a cheap hardware.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
Both of the "fun facts" are completely wrong 
------
AI certainly won't cause lasting unemployment.
But technological evolutions displace jobs: the faster they take place, the more people are (temporarily) left behind because their skills are outdated for the new economy. Workforce retraining is of the essence.
1/2
------
Cute.
------
I packed-up a full-text paper scraper, vector database, and LLM into a CLI to answer questions from only highly-cited peer-reviewed  papers. Feels unreal to be able instantly get answers by an LLM "reading" dozens of papers. 1/2
------
An account of the current GenAI craze.
------
Today I met with the Global Media team to discuss Generative AI. The excitement was insane! Never seen a topic like this at work before.

Here are the 14 examples of AI in Media I shared with them & why: 
------
It's a bit like music.
A small number of papers have a huge influence.
A good number bring a significant stone to the edifice.
A large number propose new applications.
Most have *some* interesting nugget.
Many papers don't amount to much, but not as many as you might think...
------
Penrose is wrong.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
Counterpart:
Wheel: OMG this is going to destroy society. People will become weak.
Book: OMG this is going to destroy society. People will be able to learn stuff and think for themselves.
Gears: OMG, this is going to destroy society. Machines will take our jobs.
Computer: OMG ...
------
I get chills with a lot of Bach pieces.
Oboe almost always does it for me.
------
Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2
------
. 
@erikbryn
 says the effect of a technological (r)evolution on productivity takes 15 to 20 years.
But for AI, I'm not sure when to start counting.
------
And you rarely know right away which ones are going to spark a new avenue.
It often takes several years before an idea comes to fruition in practice.
A good recent example is diffusion models.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Next week.
------
Very excited to share the final line-up and program of our upcoming conference on the Philosophy of Deep Learning!

Co-organized with @davidchalmers42 & @De_dicto and co-sponsored by @columbiacss's PSSN & @nyuconscious.

Info, registration & full program: https://phildeeplearning.github.io
------
Training robots to imitate behaviors with 1-minute demonstrations.
From 
@LerrelPinto
 's group at 
@nyuniversity
------
While we are going gaga over large models and big data, there is still incredible value left to extract in small models and data, especially in robotics.

All the skills shown below were each trained with <1 min of human data and <20 min of online RL

http://fast-imitation.github.io 
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Philosophy & AI.
Great workshop next week.
------
Really great workshop next weekend, featuring a ton of great speakers and panelists: @ylecun @davidchalmers42
@neurograce @LakeBrenden @luosha @Brown_NLP @raphaelmilliere
@glupyan @cameronjbuckner, Nick Shea, and more. 
Schedule and sign up here:
https://phildeeplearning.github.io
------
Very cool.
------
New paper on VICReg-style self-supervised learning using information theory machinery.
Main tricks: network is deterministic locally linear & each training sample is seen as a Gaussian fuzzy ball.
VICReg maximizes mutual_information[ representation(input), augmentation(input) ].
------
Wanna
- use Information Theory
- but with deterministic deep networks
- to study and improve self-supervised learning?
We do just that and explain how in our latest preprint with @ziv_ravid @ylecun @timrudner and Kenji!

Bonus: it uses affine splines ;)

https://arxiv.org/abs/2303.00633
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Interesting exercise.
------
I've sucefully runned LLaMA 7B model on my 4GB RAM Raspberry Pi 4. It's super slow about 10sec/token. But it looks we can run powerful cognitive pipelines on a cheap hardware.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
Both of the "fun facts" are completely wrong 
------
AI certainly won't cause lasting unemployment.
But technological evolutions displace jobs: the faster they take place, the more people are (temporarily) left behind because their skills are outdated for the new economy. Workforce retraining is of the essence.
1/2
------
Cute.
------
I packed-up a full-text paper scraper, vector database, and LLM into a CLI to answer questions from only highly-cited peer-reviewed  papers. Feels unreal to be able instantly get answers by an LLM "reading" dozens of papers. 1/2
------
An account of the current GenAI craze.
------
Today I met with the Global Media team to discuss Generative AI. The excitement was insane! Never seen a topic like this at work before.

Here are the 14 examples of AI in Media I shared with them & why: 
------
It's a bit like music.
A small number of papers have a huge influence.
A good number bring a significant stone to the edifice.
A large number propose new applications.
Most have *some* interesting nugget.
Many papers don't amount to much, but not as many as you might think...
------
Penrose is wrong.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
Counterpart:
Wheel: OMG this is going to destroy society. People will become weak.
Book: OMG this is going to destroy society. People will be able to learn stuff and think for themselves.
Gears: OMG, this is going to destroy society. Machines will take our jobs.
Computer: OMG ...
------
I get chills with a lot of Bach pieces.
Oboe almost always does it for me.
------
Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2
------
. 
@erikbryn
 says the effect of a technological (r)evolution on productivity takes 15 to 20 years.
But for AI, I'm not sure when to start counting.
------
And you rarely know right away which ones are going to spark a new avenue.
It often takes several years before an idea comes to fruition in practice.
A good recent example is diffusion models.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Next week.
------
Very excited to share the final line-up and program of our upcoming conference on the Philosophy of Deep Learning!

Co-organized with @davidchalmers42 & @De_dicto and co-sponsored by @columbiacss's PSSN & @nyuconscious.

Info, registration & full program: https://phildeeplearning.github.io
------
Training robots to imitate behaviors with 1-minute demonstrations.
From 
@LerrelPinto
 's group at 
@nyuniversity
------
While we are going gaga over large models and big data, there is still incredible value left to extract in small models and data, especially in robotics.

All the skills shown below were each trained with <1 min of human data and <20 min of online RL

http://fast-imitation.github.io 
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Philosophy & AI.
Great workshop next week.
------
Really great workshop next weekend, featuring a ton of great speakers and panelists: @ylecun @davidchalmers42
@neurograce @LakeBrenden @luosha @Brown_NLP @raphaelmilliere
@glupyan @cameronjbuckner, Nick Shea, and more. 
Schedule and sign up here:
https://phildeeplearning.github.io
------
Very cool.
------
New paper on VICReg-style self-supervised learning using information theory machinery.
Main tricks: network is deterministic locally linear & each training sample is seen as a Gaussian fuzzy ball.
VICReg maximizes mutual_information[ representation(input), augmentation(input) ].
------
Wanna
- use Information Theory
- but with deterministic deep networks
- to study and improve self-supervised learning?
We do just that and explain how in our latest preprint with @ziv_ravid @ylecun @timrudner and Kenji!

Bonus: it uses affine splines ;)

https://arxiv.org/abs/2303.00633
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Both of the "fun facts" are completely wrong 
------
AI certainly won't cause lasting unemployment.
But technological evolutions displace jobs: the faster they take place, the more people are (temporarily) left behind because their skills are outdated for the new economy. Workforce retraining is of the essence.
1/2
------
Cute.
------
I packed-up a full-text paper scraper, vector database, and LLM into a CLI to answer questions from only highly-cited peer-reviewed  papers. Feels unreal to be able instantly get answers by an LLM "reading" dozens of papers. 1/2
------
An account of the current GenAI craze.
------
Today I met with the Global Media team to discuss Generative AI. The excitement was insane! Never seen a topic like this at work before.

Here are the 14 examples of AI in Media I shared with them & why: 
------
It's a bit like music.
A small number of papers have a huge influence.
A good number bring a significant stone to the edifice.
A large number propose new applications.
Most have *some* interesting nugget.
Many papers don't amount to much, but not as many as you might think...
------
Penrose is wrong.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
Counterpart:
Wheel: OMG this is going to destroy society. People will become weak.
Book: OMG this is going to destroy society. People will be able to learn stuff and think for themselves.
Gears: OMG, this is going to destroy society. Machines will take our jobs.
Computer: OMG ...
------
I get chills with a lot of Bach pieces.
Oboe almost always does it for me.
------
Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2
------
. 
@erikbryn
 says the effect of a technological (r)evolution on productivity takes 15 to 20 years.
But for AI, I'm not sure when to start counting.
------
And you rarely know right away which ones are going to spark a new avenue.
It often takes several years before an idea comes to fruition in practice.
A good recent example is diffusion models.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Next week.
------
Very excited to share the final line-up and program of our upcoming conference on the Philosophy of Deep Learning!

Co-organized with @davidchalmers42 & @De_dicto and co-sponsored by @columbiacss's PSSN & @nyuconscious.

Info, registration & full program: https://phildeeplearning.github.io
------
Training robots to imitate behaviors with 1-minute demonstrations.
From 
@LerrelPinto
 's group at 
@nyuniversity
------
While we are going gaga over large models and big data, there is still incredible value left to extract in small models and data, especially in robotics.

All the skills shown below were each trained with <1 min of human data and <20 min of online RL

http://fast-imitation.github.io 
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Philosophy & AI.
Great workshop next week.
------
Really great workshop next weekend, featuring a ton of great speakers and panelists: @ylecun @davidchalmers42
@neurograce @LakeBrenden @luosha @Brown_NLP @raphaelmilliere
@glupyan @cameronjbuckner, Nick Shea, and more. 
Schedule and sign up here:
https://phildeeplearning.github.io
------
Very cool.
------
New paper on VICReg-style self-supervised learning using information theory machinery.
Main tricks: network is deterministic locally linear & each training sample is seen as a Gaussian fuzzy ball.
VICReg maximizes mutual_information[ representation(input), augmentation(input) ].
------
Wanna
- use Information Theory
- but with deterministic deep networks
- to study and improve self-supervised learning?
We do just that and explain how in our latest preprint with @ziv_ravid @ylecun @timrudner and Kenji!

Bonus: it uses affine splines ;)

https://arxiv.org/abs/2303.00633
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
Counterpart:
Wheel: OMG this is going to destroy society. People will become weak.
Book: OMG this is going to destroy society. People will be able to learn stuff and think for themselves.
Gears: OMG, this is going to destroy society. Machines will take our jobs.
Computer: OMG ...
------
I get chills with a lot of Bach pieces.
Oboe almost always does it for me.
------
Your red/blue analysis is very US centric.
Arguably, European social democracies have not seen such increases in education, healthcare, and childcare because *they regulate more* (not less).
The US has done a *terrible* job at regulating these things in a half-ass way.
2/2
------
. 
@erikbryn
 says the effect of a technological (r)evolution on productivity takes 15 to 20 years.
But for AI, I'm not sure when to start counting.
------
And you rarely know right away which ones are going to spark a new avenue.
It often takes several years before an idea comes to fruition in practice.
A good recent example is diffusion models.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Next week.
------
Very excited to share the final line-up and program of our upcoming conference on the Philosophy of Deep Learning!

Co-organized with @davidchalmers42 & @De_dicto and co-sponsored by @columbiacss's PSSN & @nyuconscious.

Info, registration & full program: https://phildeeplearning.github.io
------
Training robots to imitate behaviors with 1-minute demonstrations.
From 
@LerrelPinto
 's group at 
@nyuniversity
------
While we are going gaga over large models and big data, there is still incredible value left to extract in small models and data, especially in robotics.

All the skills shown below were each trained with <1 min of human data and <20 min of online RL

http://fast-imitation.github.io 
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Philosophy & AI.
Great workshop next week.
------
Really great workshop next weekend, featuring a ton of great speakers and panelists: @ylecun @davidchalmers42
@neurograce @LakeBrenden @luosha @Brown_NLP @raphaelmilliere
@glupyan @cameronjbuckner, Nick Shea, and more. 
Schedule and sign up here:
https://phildeeplearning.github.io
------
Very cool.
------
New paper on VICReg-style self-supervised learning using information theory machinery.
Main tricks: network is deterministic locally linear & each training sample is seen as a Gaussian fuzzy ball.
VICReg maximizes mutual_information[ representation(input), augmentation(input) ].
------
Wanna
- use Information Theory
- but with deterministic deep networks
- to study and improve self-supervised learning?
We do just that and explain how in our latest preprint with @ziv_ravid @ylecun @timrudner and Kenji!

Bonus: it uses affine splines ;)

https://arxiv.org/abs/2303.00633
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
Hahaha, that is ironic indeed.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
The EU still manages to build major infrastructure projects.
You know, like fast trains.
------
No.
------
Yes.
------
Which is why auto-regressive LLMs are a terrible model of thought.
They do seem to be a good model of language fluency.
AR-LLMs are like this tiny piece of the brain that controls speech production called the Broca area.
What's missing is the entire prefrontal cortex.
------
Marcello.
------
Next week.
------
Very excited to share the final line-up and program of our upcoming conference on the Philosophy of Deep Learning!

Co-organized with @davidchalmers42 & @De_dicto and co-sponsored by @columbiacss's PSSN & @nyuconscious.

Info, registration & full program: https://phildeeplearning.github.io
------
Training robots to imitate behaviors with 1-minute demonstrations.
From 
@LerrelPinto
 's group at 
@nyuniversity
------
While we are going gaga over large models and big data, there is still incredible value left to extract in small models and data, especially in robotics.

All the skills shown below were each trained with <1 min of human data and <20 min of online RL

http://fast-imitation.github.io 
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Philosophy & AI.
Great workshop next week.
------
Really great workshop next weekend, featuring a ton of great speakers and panelists: @ylecun @davidchalmers42
@neurograce @LakeBrenden @luosha @Brown_NLP @raphaelmilliere
@glupyan @cameronjbuckner, Nick Shea, and more. 
Schedule and sign up here:
https://phildeeplearning.github.io
------
Very cool.
------
New paper on VICReg-style self-supervised learning using information theory machinery.
Main tricks: network is deterministic locally linear & each training sample is seen as a Gaussian fuzzy ball.
VICReg maximizes mutual_information[ representation(input), augmentation(input) ].
------
Wanna
- use Information Theory
- but with deterministic deep networks
- to study and improve self-supervised learning?
We do just that and explain how in our latest preprint with @ziv_ravid @ylecun @timrudner and Kenji!

Bonus: it uses affine splines ;)

https://arxiv.org/abs/2303.00633
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
Hahaha, that is ironic indeed.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
The EU still manages to build major infrastructure projects.
You know, like fast trains.
------
No.
------
Yes.
------
Which is why auto-regressive LLMs are a terrible model of thought.
They do seem to be a good model of language fluency.
AR-LLMs are like this tiny piece of the brain that controls speech production called the Broca area.
What's missing is the entire prefrontal cortex.
------
Marcello.
------
New paper on VICReg-style self-supervised learning using information theory machinery.
Main tricks: network is deterministic locally linear & each training sample is seen as a Gaussian fuzzy ball.
VICReg maximizes mutual_information[ representation(input), augmentation(input) ].
------
Wanna
- use Information Theory
- but with deterministic deep networks
- to study and improve self-supervised learning?
We do just that and explain how in our latest preprint with @ziv_ravid @ylecun @timrudner and Kenji!

Bonus: it uses affine splines ;)

https://arxiv.org/abs/2303.00633
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
Hahaha, that is ironic indeed.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
The EU still manages to build major infrastructure projects.
You know, like fast trains.
------
No.
------
Yes.
------
Which is why auto-regressive LLMs are a terrible model of thought.
They do seem to be a good model of language fluency.
AR-LLMs are like this tiny piece of the brain that controls speech production called the Broca area.
What's missing is the entire prefrontal cortex.
------
Marcello.
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
Hahaha, that is ironic indeed.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
The EU still manages to build major infrastructure projects.
You know, like fast trains.
------
No.
------
Yes.
------
Which is why auto-regressive LLMs are a terrible model of thought.
They do seem to be a good model of language fluency.
AR-LLMs are like this tiny piece of the brain that controls speech production called the Broca area.
What's missing is the entire prefrontal cortex.
------
Marcello.
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
Hahaha, that is ironic indeed.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
The EU still manages to build major infrastructure projects.
You know, like fast trains.
------
No.
------
Yes.
------
Which is why auto-regressive LLMs are a terrible model of thought.
They do seem to be a good model of language fluency.
AR-LLMs are like this tiny piece of the brain that controls speech production called the Broca area.
What's missing is the entire prefrontal cortex.
------
Marcello.
------
The US is englued in legal molasses.
This applies to government decision making, infrastructure projects, and even product rollouts by large companies.

It's not a recent phenomenon. Decades ago, liability issues essentially killed the non-commercial aviation industry in the US.
------
This is why I say building new infrastructure is now illegal. It doesn't matter how much money we pour into things like this, they simply will not come to be. twitter.com/AlecStapp/stat…
------
My degree was in Electrical Engineering.
I never actually studied computer science.
Software technology changed radically in the 40 years since I graduated.
Machine learning did not exist as a field when I did my PhD.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
But yeah, LLMs will not destroy the academic publication system, contrary to what some folks have claimed.
In fact, paper quality might improve because of it (I'm talking about style, not content).
------
A new paper in 
@NoemaMag
 by 
@Jake_Browning00
 and me (mostly Jake) on chatbots, social norms, and human expectations.
------
“Chatbots aren’t using language like we are — even when they say exactly the same things we do.”

— ​​@Jake_Browning00 & @ylecun

https://noemamag.com/ai-chatbots-dont-care-about-your-social-norms/?utm_source=noematwitter&utm_medium=noemasocial…
------
Self-fulfilling superstition.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Not nearly as much as in the US.
US-made drugs are N times less expensive in Europe than in the US.
Why?
European single-payer systems negotiate drug prices.
The US has a law that *specifically* forbids Medicare from negotiating drug prices.
That's corruption, plain & simple.
------
I have a NeurIPS paper with Seth Lloyd.
Does that count?
https://nips.cc/Conferences/2022/ScheduleMultitrack?event=54005…
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
That invited talk at COLT 2013 indirectly caused MobilEye to start using ConvNets for its driving assistance system.
After hearing the talk, Shai Shalev-Schwartz started a sabbatical at MobilEye and convinced them to use ConvNets.

Slides: https://drive.google.com/file/d/16u-ie2cieOXikTygDNNSTaTRV_yoZ7nn…
------
From @ylecun's prefatory talk at COLT 2013 — "Learning Representations: A Challenge for Learning Theory"

https://youtube.com/watch?v=ba_v_RrDdGw…
------
I studied EE, specializing in VLSI design and control.
I took a lot of math and physics.
My PhD is in "AI" but did not involve studying what North-American universities consider the "core" of computer science (systems, algorithms, complexity theory, etc).
------
Not mentioning no hippocampus.
------
Religions, like all superstitions, are a case of causal inference going haywire.
Our desire to find causal explanations for everything drives us to invent causes for unexplained or unpredictible phenomena.
But inventing all-powerful deities as causes violates Ockham's Razor.
------
Thank you for the kind words.
------
Nice.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
Hahaha, that is ironic indeed.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
The EU still manages to build major infrastructure projects.
You know, like fast trains.
------
No.
------
Yes.
------
Which is why auto-regressive LLMs are a terrible model of thought.
They do seem to be a good model of language fluency.
AR-LLMs are like this tiny piece of the brain that controls speech production called the Broca area.
What's missing is the entire prefrontal cortex.
------
Marcello.
------
Discussion between colleagues == bidirectional human prompt engineering.
------
Funny exchange after a public lecture:
Lady: I'm using ChatGPT to produce horoscopes.
Me: perfect application for a writing assistant that makes stuff up.
Lady: hahaha, I agree!
------
Almost all the members of the LLaMA team are located at FAIR-Paris.
------
The French mafia of #AI is growing year by year 

Here is a quick list :

- The father of deep learning ( @ylecun )

- The founders of @huggingface ( @ClementDelangue @julien_c  ) the best platform for deploying AI models.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
When I asked my boss what the story was, he said:
"At Bell Labs, you don't get famous by saving money!"
------
<joke>
When I hear "AI needs causal inference and reasoning",
I can only agree.
But then humans aren't particularly good at causal inference either.
Otherwise astrology wouldn't be a thing.
Neither would religion.
</joke>
------
During my postdoc at U of Toronto in 87/88 the CS dept received a new Sun4 shared by students and faculty.
Before I moved to Bell Labs, my future boss asked me what computer I wanted. I said "the Sun-4 is great"
When I arrived, I had a Sun4 JUST FOR ME!
LeNet was trained on it.
------
Happy 41rst birthday to Sun Microsystems and all of our former employees, customers, partners, shareholders, and friends.  You were all amazing.
------
Penrose is wrong.
------
ConvNets are a decent model of how the ventral pathway of the human visual cortex works.
But LLMs don't seem to be a good model of how humans process language.
There longer-term prediction taking place in the brain.
Awesome work by the Brain-AI group at FAIR-Paris.
------
New in Nature Human Behavior, Meta AI researchers show how current language models differ from the human brain & highlight the role of long-range & hierarchical predictions.

We hope these findings will help inform the next generation of AI  https://go.nature.com/3SKb3gX
------
- A number of them went through École Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
Indeed.
But then again, if people had not listened so much to the critics of nuclear energy in the 1970s, we may not have as much of a climate change problem to deal with.
------
The existence of these "highly successful AI groups" is precisely what makes the creation of this new product group possible.
They are involved in it.
------
Yes, the need for prompt engineering is a sign of lack of understanding.
No, scaling alone will not fix that.
------
In LLMs, the need for "prompt engineering" is a sign of *lack* of robust language understanding.  

It will be interesting to see if scaling LLMs alone will reduce the need for prompt engineering.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
FAIR-Paris has brought French scientists from the US back to Paris, such as 
@AntoineBordes
 , 
@armandjoulin
 , 
@syhw
 , 
@EXGRV
 and others.
It also attracted scientists from all over Europe to Paris, and gave the opportunity to many young French scientists to stay in France.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Well, actually, in most countries at the time, books could not be published without the king's approval.
So there was a form of RLHF: Royal Legislative Human Feedback.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
Discussion between colleagues == bidirectional human prompt engineering.
------
Funny exchange after a public lecture:
Lady: I'm using ChatGPT to produce horoscopes.
Me: perfect application for a writing assistant that makes stuff up.
Lady: hahaha, I agree!
------
Almost all the members of the LLaMA team are located at FAIR-Paris.
------
The French mafia of #AI is growing year by year 

Here is a quick list :

- The father of deep learning ( @ylecun )

- The founders of @huggingface ( @ClementDelangue @julien_c  ) the best platform for deploying AI models.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
When I asked my boss what the story was, he said:
"At Bell Labs, you don't get famous by saving money!"
------
<joke>
When I hear "AI needs causal inference and reasoning",
I can only agree.
But then humans aren't particularly good at causal inference either.
Otherwise astrology wouldn't be a thing.
Neither would religion.
</joke>
------
During my postdoc at U of Toronto in 87/88 the CS dept received a new Sun4 shared by students and faculty.
Before I moved to Bell Labs, my future boss asked me what computer I wanted. I said "the Sun-4 is great"
When I arrived, I had a Sun4 JUST FOR ME!
LeNet was trained on it.
------
Happy 41rst birthday to Sun Microsystems and all of our former employees, customers, partners, shareholders, and friends.  You were all amazing.
------
Penrose is wrong.
------
ConvNets are a decent model of how the ventral pathway of the human visual cortex works.
But LLMs don't seem to be a good model of how humans process language.
There longer-term prediction taking place in the brain.
Awesome work by the Brain-AI group at FAIR-Paris.
------
New in Nature Human Behavior, Meta AI researchers show how current language models differ from the human brain & highlight the role of long-range & hierarchical predictions.

We hope these findings will help inform the next generation of AI  https://go.nature.com/3SKb3gX
------
- A number of them went through École Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
Indeed.
But then again, if people had not listened so much to the critics of nuclear energy in the 1970s, we may not have as much of a climate change problem to deal with.
------
The existence of these "highly successful AI groups" is precisely what makes the creation of this new product group possible.
They are involved in it.
------
Yes, the need for prompt engineering is a sign of lack of understanding.
No, scaling alone will not fix that.
------
In LLMs, the need for "prompt engineering" is a sign of *lack* of robust language understanding.  

It will be interesting to see if scaling LLMs alone will reduce the need for prompt engineering.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
FAIR-Paris has brought French scientists from the US back to Paris, such as 
@AntoineBordes
 , 
@armandjoulin
 , 
@syhw
 , 
@EXGRV
 and others.
It also attracted scientists from all over Europe to Paris, and gave the opportunity to many young French scientists to stay in France.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Well, actually, in most countries at the time, books could not be published without the king's approval.
So there was a form of RLHF: Royal Legislative Human Feedback.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
Discussion between colleagues == bidirectional human prompt engineering.
------
Funny exchange after a public lecture:
Lady: I'm using ChatGPT to produce horoscopes.
Me: perfect application for a writing assistant that makes stuff up.
Lady: hahaha, I agree!
------
Almost all the members of the LLaMA team are located at FAIR-Paris.
------
The French mafia of #AI is growing year by year 

Here is a quick list :

- The father of deep learning ( @ylecun )

- The founders of @huggingface ( @ClementDelangue @julien_c  ) the best platform for deploying AI models.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
When I asked my boss what the story was, he said:
"At Bell Labs, you don't get famous by saving money!"
------
<joke>
When I hear "AI needs causal inference and reasoning",
I can only agree.
But then humans aren't particularly good at causal inference either.
Otherwise astrology wouldn't be a thing.
Neither would religion.
</joke>
------
During my postdoc at U of Toronto in 87/88 the CS dept received a new Sun4 shared by students and faculty.
Before I moved to Bell Labs, my future boss asked me what computer I wanted. I said "the Sun-4 is great"
When I arrived, I had a Sun4 JUST FOR ME!
LeNet was trained on it.
------
Happy 41rst birthday to Sun Microsystems and all of our former employees, customers, partners, shareholders, and friends.  You were all amazing.
------
Penrose is wrong.
------
ConvNets are a decent model of how the ventral pathway of the human visual cortex works.
But LLMs don't seem to be a good model of how humans process language.
There longer-term prediction taking place in the brain.
Awesome work by the Brain-AI group at FAIR-Paris.
------
New in Nature Human Behavior, Meta AI researchers show how current language models differ from the human brain & highlight the role of long-range & hierarchical predictions.

We hope these findings will help inform the next generation of AI  https://go.nature.com/3SKb3gX
------
- A number of them went through École Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
Indeed.
But then again, if people had not listened so much to the critics of nuclear energy in the 1970s, we may not have as much of a climate change problem to deal with.
------
The existence of these "highly successful AI groups" is precisely what makes the creation of this new product group possible.
They are involved in it.
------
Yes, the need for prompt engineering is a sign of lack of understanding.
No, scaling alone will not fix that.
------
In LLMs, the need for "prompt engineering" is a sign of *lack* of robust language understanding.  

It will be interesting to see if scaling LLMs alone will reduce the need for prompt engineering.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
FAIR-Paris has brought French scientists from the US back to Paris, such as 
@AntoineBordes
 , 
@armandjoulin
 , 
@syhw
 , 
@EXGRV
 and others.
It also attracted scientists from all over Europe to Paris, and gave the opportunity to many young French scientists to stay in France.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Well, actually, in most countries at the time, books could not be published without the king's approval.
So there was a form of RLHF: Royal Legislative Human Feedback.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
Nice explanation.
------
If you spend much time on AI twitter, you might have seen this tentacle monster hanging around. But what is it, and what does it have to do with ChatGPT?

It's kind of a long story. But it's worth it! It even ends with cake 

THREAD:
------
When I asked my boss what the story was, he said:
"At Bell Labs, you don't get famous by saving money!"
------
<joke>
When I hear "AI needs causal inference and reasoning",
I can only agree.
But then humans aren't particularly good at causal inference either.
Otherwise astrology wouldn't be a thing.
Neither would religion.
</joke>
------
During my postdoc at U of Toronto in 87/88 the CS dept received a new Sun4 shared by students and faculty.
Before I moved to Bell Labs, my future boss asked me what computer I wanted. I said "the Sun-4 is great"
When I arrived, I had a Sun4 JUST FOR ME!
LeNet was trained on it.
------
Happy 41rst birthday to Sun Microsystems and all of our former employees, customers, partners, shareholders, and friends.  You were all amazing.
------
Penrose is wrong.
------
ConvNets are a decent model of how the ventral pathway of the human visual cortex works.
But LLMs don't seem to be a good model of how humans process language.
There longer-term prediction taking place in the brain.
Awesome work by the Brain-AI group at FAIR-Paris.
------
New in Nature Human Behavior, Meta AI researchers show how current language models differ from the human brain & highlight the role of long-range & hierarchical predictions.

We hope these findings will help inform the next generation of AI  https://go.nature.com/3SKb3gX
------
- A number of them went through École Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
Indeed.
But then again, if people had not listened so much to the critics of nuclear energy in the 1970s, we may not have as much of a climate change problem to deal with.
------
The existence of these "highly successful AI groups" is precisely what makes the creation of this new product group possible.
They are involved in it.
------
Yes, the need for prompt engineering is a sign of lack of understanding.
No, scaling alone will not fix that.
------
In LLMs, the need for "prompt engineering" is a sign of *lack* of robust language understanding.  

It will be interesting to see if scaling LLMs alone will reduce the need for prompt engineering.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
FAIR-Paris has brought French scientists from the US back to Paris, such as 
@AntoineBordes
 , 
@armandjoulin
 , 
@syhw
 , 
@EXGRV
 and others.
It also attracted scientists from all over Europe to Paris, and gave the opportunity to many young French scientists to stay in France.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Well, actually, in most countries at the time, books could not be published without the king's approval.
So there was a form of RLHF: Royal Legislative Human Feedback.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
- A number of them went through École Polytechnique and ENS, but not all.
- A big chunk went through the MVA (Master Vision Apprentissage at ENS Cachan).
- And a bunch of them did are (or are still doing) their PhD as resident students at FAIR-Paris under the CIFRE system.
------
Indeed we do.
And for that, they need to be able to learn causal models of the world that allows them to predict the consequences of their actions.
This is a necessary component to the ability to reason and plan.
------
Indeed.
But then again, if people had not listened so much to the critics of nuclear energy in the 1970s, we may not have as much of a climate change problem to deal with.
------
The existence of these "highly successful AI groups" is precisely what makes the creation of this new product group possible.
They are involved in it.
------
Yes, the need for prompt engineering is a sign of lack of understanding.
No, scaling alone will not fix that.
------
In LLMs, the need for "prompt engineering" is a sign of *lack* of robust language understanding.  

It will be interesting to see if scaling LLMs alone will reduce the need for prompt engineering.
------
At 
@MetaAI
 we favor publication quality over quantity.
That's why among the 100 most cited AI papers in 2022, 
@MetaAI
 has authored (or co-authored) 16, ranking 2nd just behind Google with 22.
Our research is having a large impact on the community.

(and NYU ranks nicely, too).
------
The 100 most cited AI papers for 2022.

A detailed analysis of the most cited papers for the last three years allows good insights into the organisations and countries publishing the most impactful AI research right now.

Read here: https://zeta-alpha.com/post/must-read-the-100-most-cited-ai-papers-in-2022…

A thread 
------
FAIR-Paris has brought French scientists from the US back to Paris, such as 
@AntoineBordes
 , 
@armandjoulin
 , 
@syhw
 , 
@EXGRV
 and others.
It also attracted scientists from all over Europe to Paris, and gave the opportunity to many young French scientists to stay in France.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Well, actually, in most countries at the time, books could not be published without the king's approval.
So there was a form of RLHF: Royal Legislative Human Feedback.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
Because DeepMind keeps insisting that they operate independently from Google, strangely.
Googlers do not have access to DeepMind's code base nor buildings.
------
Well, actually, in most countries at the time, books could not be published without the king's approval.
So there was a form of RLHF: Royal Legislative Human Feedback.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
True.
Although I was directly involved in a tiny portion of the AI/ML/NN stuff open sourced by Meta.
------
IMHO @MetaOpenSource has done more for open source than ANY other major tech giant (perhaps G): @PyTorch (basically every neural net written in it), @reactjs (huge % of web), @docusaurus, @RocksDB, @GraphQL, @HipHopVM, @OpenComputePrj + all the AI/NN/LLM work led by @ylecun! 
------
1943.
------
I drink one glass of good (i.e. French) wine with dinner.
Occasionally more than one.
One Cognac, Armagnac, or Whisky per week.
------
Entities that throw our deepest thoughts back at us: a common theme in fiction, from Shakespeare's The Tempest, to the 1950's space opera Forbidden Planet, Tarkovsky's 1972 film Solaris, and several others after that.
------
When people chat with chatbots, they see what they want to see. A.I. pioneer Terry Sejnowski compares this to the Mirror of Erised in the Harry Potter books. The Mirror seems to provide truth. But really, it shows the desires of anyone who stares into it:  https://nytimes.com/2023/02/26/technology/why-do-ai-chatbots-tell-lies-and-act-weird-look-in-the-mirror.html…
------
Lack of understanding of the world by the LLM.
------
Because last time we made an LLM available to everyone (Galactica, designed to help scientists write scientific papers), people threw vitriol at our face and told us this was going to destroy the fabric of society.
------
Open-sourcing is very much Meta's DNA.
But there are few things that large companies care more about than bad press and attack on their reputation.
------
It's the other way around: tech companies are attracted by places with high concentration of talents.
Talents are produced by top educational and research institutions.
Then the ecosystem feeds on itself.
------
No.
I'm just a rationalist.
Because when magical thinking rules, people get hurt.
Organized religions are the ones that do have a globalist agenda, though.
------
Apple has a long-held culture of extreme secrecy.
Even internally.
------
My tweet literally says that I agree.
------
Self-fulfilling superstition.
------
Haha!
We already knew you were on ChatGPT for its fantastic reasoning abilities.
------
No GPUs in 1988.
We ran our OCR demos on DSP cards.
And we eventually bought a large parallel machine from Intel (i860 based IIRC). But the software sucked and it became an expensive doorstop.
------
Transformers are not biologically inspired.
But the ideas of differentiable associative memory (which transformers are based on), and dynamic routing (which transformers use) can be traced to neuroscience models of the hippocampus and perception.
------
Human Feedback will certainly improve the reliability on common questions.
But the distribution of questions has a very, very long tail.
So HF alone will mitigate but not fix the problems.
------
Clearly.
------
It exists. It's called PyTorch.
And then there is this.
https://cds.nyu.edu/deep-learning/
------
I don't know who this Yann LeCunn is, but perhaps he and Gary Marcus got married since the last time the ChatGPT training set was collected.
------
Protections against Kremlin-sponsored troll farms have been in place on FB for about 6 years.
------
Not mentioning no hippocampus.
------
@lxbrun
 former FAIR-Paris engineering director and cofounder of Nabla.
------
The point is that their ability to do so is very limited.
------
Yes, it's as if LLMs merely emulate the tiny areas of the brain concerned with language: the Broca and Wernicke areas, and are missing the entire prefrontal cortex.

Without a PFC-like structure, LLMs have very superficial world models and very limited reasoning abilities.
------
I know, I know.
But one shouldn't waste a bad joke by letting it stand without responding with a teaching moment.
------
Touché!
I wasn't joking about that part.
------
It's called Microsoft Research (MSR).
It's been around since the mid 1990s and has done excellent work in many areas.
------
Yes.
------
1. Thanks for the kind words.
2. Not sure what you mean by constructivism.
3. This is just a joke. No feelings being expressed. Just funny facts.
4. If my motivation were to "serve my ego" I would have changed career many years ago when few people cared about my work.
------
Ian GoodDawg invented the G Adversarial Note, but MC S claims he invented all A-G Adversarial Chords in 1991.
------
Meta has a thing like that in-house called Rosetta.
I think it's not open source because it's used for content moderation and openness facilitates circumvention.
------
Before we reach Human-Level AI (HLAI), we will have to reach Cat-Level & Dog-Level AI.
We are nowhere near that.
We are still missing something big.
LLM's linguistic abilities notwithstanding.
A house cat has way more common sense and understanding of the world than any LLM.
------
They save typing. https://twitter.com/DrHughHarvey/status/1622882538682286083…
------
Typing.
------
Haha! Not wrong.
------
The problem with ChatGPT is that it has emboldened Edward from Omaha, who used it to generate his grocery list, to publicly challenge @ylecun about AGI.
------
One can regurgitate Python code without any understanding of reality.
------
Scientific debates on social media are like a human form of bidirectional RLHF.
The person making the post gets feedback (good and bad).
The commenters also get feedback, mostly when they are clueless or wrong.
------
Dogs have more than twice as many neurons as cats.
------
John Bridle, who coined the word "softmax", now wishes he had called it "softargmax".

He coined the term while working on a paper published in 1989 in Neural Computation in which he describes the "alphanet" model that makes a hidden Markov model look like a recurrent neural net.
------
every time I teach this, I ask myself: why is it called Softmax and not Softargmax? Don't really have good answers other than "because history".
------
More analysis of the varied public reception of AI tools from Big Tech and Small Tech.
------
Two weeks before the arrival of ChatGPT, Meta released its own bot. The reaction was very different, @MikeIsaac and I report: https://nyti.ms/3YrmueW
------
The exact quote is "the world is compositional or there is a god", and I got it from Stuart Geman.
------
A single task that subsumes object detection and language understanding.
From #NYU.
------
Check out our new fine-grained vision and language understanding task (CPD) and associated benchmark - TRICD! 
Contextual Phrase Detection (CPD) is a single task that subsumes object detection and phrase grounding.
Paper: https://ashkamath.github.io/TRICD/assets/paper.pdf…
Website: https://ashkamath.github.io/TRICD/
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
It's just history.
Even John Bridle who coined the name wishes it were called softargmax
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
It says more about the inadequacy of the tests than about the adequacy of ChatGPT.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Before we reach Human-Level AI (HLAI), we will have to reach Cat-Level & Dog-Level AI.
We are nowhere near that.
We are still missing something big.
LLM's linguistic abilities notwithstanding.
A house cat has way more common sense and understanding of the world than any LLM.
------
They save typing. https://twitter.com/DrHughHarvey/status/1622882538682286083…
------
Typing.
------
Haha! Not wrong.
------
The problem with ChatGPT is that it has emboldened Edward from Omaha, who used it to generate his grocery list, to publicly challenge @ylecun about AGI.
------
One can regurgitate Python code without any understanding of reality.
------
Scientific debates on social media are like a human form of bidirectional RLHF.
The person making the post gets feedback (good and bad).
The commenters also get feedback, mostly when they are clueless or wrong.
------
Dogs have more than twice as many neurons as cats.
------
John Bridle, who coined the word "softmax", now wishes he had called it "softargmax".

He coined the term while working on a paper published in 1989 in Neural Computation in which he describes the "alphanet" model that makes a hidden Markov model look like a recurrent neural net.
------
every time I teach this, I ask myself: why is it called Softmax and not Softargmax? Don't really have good answers other than "because history".
------
More analysis of the varied public reception of AI tools from Big Tech and Small Tech.
------
Two weeks before the arrival of ChatGPT, Meta released its own bot. The reaction was very different, @MikeIsaac and I report: https://nyti.ms/3YrmueW
------
The exact quote is "the world is compositional or there is a god", and I got it from Stuart Geman.
------
A single task that subsumes object detection and language understanding.
From #NYU.
------
Check out our new fine-grained vision and language understanding task (CPD) and associated benchmark - TRICD! 
Contextual Phrase Detection (CPD) is a single task that subsumes object detection and phrase grounding.
Paper: https://ashkamath.github.io/TRICD/assets/paper.pdf…
Website: https://ashkamath.github.io/TRICD/
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
It's just history.
Even John Bridle who coined the name wishes it were called softargmax
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
It says more about the inadequacy of the tests than about the adequacy of ChatGPT.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
Before we reach Human-Level AI (HLAI), we will have to reach Cat-Level & Dog-Level AI.
We are nowhere near that.
We are still missing something big.
LLM's linguistic abilities notwithstanding.
A house cat has way more common sense and understanding of the world than any LLM.
------
They save typing. https://twitter.com/DrHughHarvey/status/1622882538682286083…
------
Typing.
------
Haha! Not wrong.
------
The problem with ChatGPT is that it has emboldened Edward from Omaha, who used it to generate his grocery list, to publicly challenge @ylecun about AGI.
------
One can regurgitate Python code without any understanding of reality.
------
Scientific debates on social media are like a human form of bidirectional RLHF.
The person making the post gets feedback (good and bad).
The commenters also get feedback, mostly when they are clueless or wrong.
------
Dogs have more than twice as many neurons as cats.
------
John Bridle, who coined the word "softmax", now wishes he had called it "softargmax".

He coined the term while working on a paper published in 1989 in Neural Computation in which he describes the "alphanet" model that makes a hidden Markov model look like a recurrent neural net.
------
every time I teach this, I ask myself: why is it called Softmax and not Softargmax? Don't really have good answers other than "because history".
------
More analysis of the varied public reception of AI tools from Big Tech and Small Tech.
------
Two weeks before the arrival of ChatGPT, Meta released its own bot. The reaction was very different, @MikeIsaac and I report: https://nyti.ms/3YrmueW
------
The exact quote is "the world is compositional or there is a god", and I got it from Stuart Geman.
------
A single task that subsumes object detection and language understanding.
From #NYU.
------
Check out our new fine-grained vision and language understanding task (CPD) and associated benchmark - TRICD! 
Contextual Phrase Detection (CPD) is a single task that subsumes object detection and phrase grounding.
Paper: https://ashkamath.github.io/TRICD/assets/paper.pdf…
Website: https://ashkamath.github.io/TRICD/
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
It's just history.
Even John Bridle who coined the name wishes it were called softargmax
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
It says more about the inadequacy of the tests than about the adequacy of ChatGPT.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
John Bridle, who coined the word "softmax", now wishes he had called it "softargmax".

He coined the term while working on a paper published in 1989 in Neural Computation in which he describes the "alphanet" model that makes a hidden Markov model look like a recurrent neural net.
------
every time I teach this, I ask myself: why is it called Softmax and not Softargmax? Don't really have good answers other than "because history".
------
More analysis of the varied public reception of AI tools from Big Tech and Small Tech.
------
Two weeks before the arrival of ChatGPT, Meta released its own bot. The reaction was very different, @MikeIsaac and I report: https://nyti.ms/3YrmueW
------
The exact quote is "the world is compositional or there is a god", and I got it from Stuart Geman.
------
A single task that subsumes object detection and language understanding.
From #NYU.
------
Check out our new fine-grained vision and language understanding task (CPD) and associated benchmark - TRICD! 
Contextual Phrase Detection (CPD) is a single task that subsumes object detection and phrase grounding.
Paper: https://ashkamath.github.io/TRICD/assets/paper.pdf…
Website: https://ashkamath.github.io/TRICD/
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
It's just history.
Even John Bridle who coined the name wishes it were called softargmax
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
It says more about the inadequacy of the tests than about the adequacy of ChatGPT.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
It's just history.
Even John Bridle who coined the name wishes it were called softargmax
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
It says more about the inadequacy of the tests than about the adequacy of ChatGPT.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
Just like driving assistance for cars.
It's not fully autonomous but it's still useful.
------
I'm not saying that predictive typing is useless!
------
But they are wrong.
------
I had made that point for Galactica, but that seemed to fall on deaf ears.

As a non-native English speaker myself, writing technical papers in English was literally torture and I wish I had access to something like Galactica when started my career.
------
The distribution that minimizes the free energy.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
The manner is often crisp, but also often wrong.
------
Indeed.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
That's pretty much what people thought in the 1950s
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
Yes.
------
No.
Because a generic chatbots can also be used to help write scientific papers (badly).
Both are writing assistance devices (predictive keyboards on steroids).
Both can save time.
Both can make stuff up and require human supervision.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
LLM specifically designates models that generate text.
There are tons of applications of large transformer architectures pre-trained with various forms of Self-Supervised Learning.
But most of them are not LLMs.
LLMs are a special case.
------
Stuart Geman, his brother.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Pretty much.
And those brain areas are pretty small.

What's missing is the back of the brain (perception, motor control), the entire front (reasoning, planing), the bottom (intrinsic motivation, emotions), and the inside (episodic memory).
We just have small areas on the side.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Gibbs-Boltzmann distribution.
------
Before we reach Human-Level AI (HLAI), we will have to reach Cat-Level & Dog-Level AI.
We are nowhere near that.
We are still missing something big.
LLM's linguistic abilities notwithstanding.
A house cat has way more common sense and understanding of the world than any LLM.
------
Haha! Not wrong.
------
The problem with ChatGPT is that it has emboldened Edward from Omaha, who used it to generate his grocery list, to publicly challenge @ylecun about AGI.
------
One can regurgitate Python code without any understanding of reality.
------
Scientific debates on social media are like a human form of bidirectional RLHF.
The person making the post gets feedback (good and bad).
The commenters also get feedback, mostly when they are clueless or wrong.
------
Stravinsky somewhere?
------
Dogs have more than twice as many neurons as cats.
------
But this is not to say that LLMs in their current form are not useful. Or fun.
They are.
------
Why learning from text is insufficient for intelligence.
------
There will be no need.
------
Well, I am 
I think the concept of HLAI is both more sensible and more testable than the amorphous concept of AGI.
------
To clarify:
LLMs that auto-regressively & reactively predict the next word are an off-ramp. They can neither plan nor reason.

But SSL-pretrained transformers are clearly a component of the solution, within a system that can reason, plan, & learn models of the underlying reality.
------
My proposal for an architecture that reason, plan, and learn models of reality.

Paper: https://openreview.net/forum?id=BZ5a1r-kVsf…

Talk: https://youtube.com/live/VRzvpV9DZ8Y?feature=share…
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
The first big success story of Self-Supervised Learning is large-scale transformers pre-trained as denoising auto-encoders (BERT-style) for various downstream NLP tasks (translation, content filtering/ranking).
LLMs are a special case of the above that became useful years later.
------
While I agree with Yann that LLMs are not on the direct path to general AI (despite their upcoming practical applications)... I must point out that LLMs are the first big success story of self-supervised learning, something that Yann (among others) has talked about for years twitter.com/ylecun/status/…
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
Yes.
------
Everyone’s talking about AI 

Below is a  on Big Tech’s full on embrace of artificial intelligence.

For starters, Big Tech companies can’t stop talking about AI in their earnings calls.

Cc: @emollick @ylecun @erikbryn @Noahpinion @saranormous
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
One of the most interesting aspects of Cicero is its ability to plan.
This ability to plan is a necessary component of autonomous intelligence and is completely absent from current LLMs.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
Before we reach Human-Level AI (HLAI), we will have to reach Cat-Level & Dog-Level AI.
We are nowhere near that.
We are still missing something big.
LLM's linguistic abilities notwithstanding.
A house cat has way more common sense and understanding of the world than any LLM.
------
Haha! Not wrong.
------
The problem with ChatGPT is that it has emboldened Edward from Omaha, who used it to generate his grocery list, to publicly challenge @ylecun about AGI.
------
One can regurgitate Python code without any understanding of reality.
------
Scientific debates on social media are like a human form of bidirectional RLHF.
The person making the post gets feedback (good and bad).
The commenters also get feedback, mostly when they are clueless or wrong.
------
Stravinsky somewhere?
------
Dogs have more than twice as many neurons as cats.
------
But this is not to say that LLMs in their current form are not useful. Or fun.
They are.
------
Why learning from text is insufficient for intelligence.
------
There will be no need.
------
Well, I am 
I think the concept of HLAI is both more sensible and more testable than the amorphous concept of AGI.
------
To clarify:
LLMs that auto-regressively & reactively predict the next word are an off-ramp. They can neither plan nor reason.

But SSL-pretrained transformers are clearly a component of the solution, within a system that can reason, plan, & learn models of the underlying reality.
------
My proposal for an architecture that reason, plan, and learn models of reality.

Paper: https://openreview.net/forum?id=BZ5a1r-kVsf…

Talk: https://youtube.com/live/VRzvpV9DZ8Y?feature=share…
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
The first big success story of Self-Supervised Learning is large-scale transformers pre-trained as denoising auto-encoders (BERT-style) for various downstream NLP tasks (translation, content filtering/ranking).
LLMs are a special case of the above that became useful years later.
------
While I agree with Yann that LLMs are not on the direct path to general AI (despite their upcoming practical applications)... I must point out that LLMs are the first big success story of self-supervised learning, something that Yann (among others) has talked about for years twitter.com/ylecun/status/…
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
Yes.
------
Everyone’s talking about AI 

Below is a  on Big Tech’s full on embrace of artificial intelligence.

For starters, Big Tech companies can’t stop talking about AI in their earnings calls.

Cc: @emollick @ylecun @erikbryn @Noahpinion @saranormous
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
One of the most interesting aspects of Cicero is its ability to plan.
This ability to plan is a necessary component of autonomous intelligence and is completely absent from current LLMs.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
Before we reach Human-Level AI (HLAI), we will have to reach Cat-Level & Dog-Level AI.
We are nowhere near that.
We are still missing something big.
LLM's linguistic abilities notwithstanding.
A house cat has way more common sense and understanding of the world than any LLM.
------
Haha! Not wrong.
------
The problem with ChatGPT is that it has emboldened Edward from Omaha, who used it to generate his grocery list, to publicly challenge @ylecun about AGI.
------
One can regurgitate Python code without any understanding of reality.
------
Scientific debates on social media are like a human form of bidirectional RLHF.
The person making the post gets feedback (good and bad).
The commenters also get feedback, mostly when they are clueless or wrong.
------
Stravinsky somewhere?
------
Dogs have more than twice as many neurons as cats.
------
But this is not to say that LLMs in their current form are not useful. Or fun.
They are.
------
Why learning from text is insufficient for intelligence.
------
There will be no need.
------
Well, I am 
I think the concept of HLAI is both more sensible and more testable than the amorphous concept of AGI.
------
To clarify:
LLMs that auto-regressively & reactively predict the next word are an off-ramp. They can neither plan nor reason.

But SSL-pretrained transformers are clearly a component of the solution, within a system that can reason, plan, & learn models of the underlying reality.
------
My proposal for an architecture that reason, plan, and learn models of reality.

Paper: https://openreview.net/forum?id=BZ5a1r-kVsf…

Talk: https://youtube.com/live/VRzvpV9DZ8Y?feature=share…
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
The first big success story of Self-Supervised Learning is large-scale transformers pre-trained as denoising auto-encoders (BERT-style) for various downstream NLP tasks (translation, content filtering/ranking).
LLMs are a special case of the above that became useful years later.
------
While I agree with Yann that LLMs are not on the direct path to general AI (despite their upcoming practical applications)... I must point out that LLMs are the first big success story of self-supervised learning, something that Yann (among others) has talked about for years twitter.com/ylecun/status/…
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
Yes.
------
Everyone’s talking about AI 

Below is a  on Big Tech’s full on embrace of artificial intelligence.

For starters, Big Tech companies can’t stop talking about AI in their earnings calls.

Cc: @emollick @ylecun @erikbryn @Noahpinion @saranormous
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
One of the most interesting aspects of Cicero is its ability to plan.
This ability to plan is a necessary component of autonomous intelligence and is completely absent from current LLMs.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
Why learning from text is insufficient for intelligence.
------
There will be no need.
------
Well, I am 
I think the concept of HLAI is both more sensible and more testable than the amorphous concept of AGI.
------
To clarify:
LLMs that auto-regressively & reactively predict the next word are an off-ramp. They can neither plan nor reason.

But SSL-pretrained transformers are clearly a component of the solution, within a system that can reason, plan, & learn models of the underlying reality.
------
My proposal for an architecture that reason, plan, and learn models of reality.

Paper: https://openreview.net/forum?id=BZ5a1r-kVsf…

Talk: https://youtube.com/live/VRzvpV9DZ8Y?feature=share…
------
Good piece by 
@Noahpinion
 about the limitations of LLMs :
"Why does ChatGPT constantly lie?"

https://noahpinion.substack.com/p/4e262415-6b0e-41b7-ba2d-8f620790bf63…
------
Regurgitating Python code does not require any understanding of a complex world.
------
It's the exact opposite.
Thinking that scaling LLMs will lead to Human-level AI is like thinking that making a parachute bigger will allow to fly like a bird.
Whereas we need to understand how bird wings generate lift.
Then we can build gliders, airplanes, jets, helicopters...
------
The first big success story of Self-Supervised Learning is large-scale transformers pre-trained as denoising auto-encoders (BERT-style) for various downstream NLP tasks (translation, content filtering/ranking).
LLMs are a special case of the above that became useful years later.
------
While I agree with Yann that LLMs are not on the direct path to general AI (despite their upcoming practical applications)... I must point out that LLMs are the first big success story of self-supervised learning, something that Yann (among others) has talked about for years twitter.com/ylecun/status/…
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
Yes.
------
Everyone’s talking about AI 

Below is a  on Big Tech’s full on embrace of artificial intelligence.

For starters, Big Tech companies can’t stop talking about AI in their earnings calls.

Cc: @emollick @ylecun @erikbryn @Noahpinion @saranormous
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
One of the most interesting aspects of Cicero is its ability to plan.
This ability to plan is a necessary component of autonomous intelligence and is completely absent from current LLMs.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
The first big success story of Self-Supervised Learning is large-scale transformers pre-trained as denoising auto-encoders (BERT-style) for various downstream NLP tasks (translation, content filtering/ranking).
LLMs are a special case of the above that became useful years later.
------
While I agree with Yann that LLMs are not on the direct path to general AI (despite their upcoming practical applications)... I must point out that LLMs are the first big success story of self-supervised learning, something that Yann (among others) has talked about for years twitter.com/ylecun/status/…
------
I don't have a negative view of ChatGPT.
I have a *realistic* view of it.

It's useful and fun.
It's just not this royal path to human-level AI that some think it is.

Also, it makes sh*t up.
And that's not an opinion.
That's a fact.
------
Perhaps an absence of intrinsic motivation for this task?
------
An LLM.
Or a somewhat-clueless software engineer.
------
Yes.
------
Everyone’s talking about AI 

Below is a  on Big Tech’s full on embrace of artificial intelligence.

For starters, Big Tech companies can’t stop talking about AI in their earnings calls.

Cc: @emollick @ylecun @erikbryn @Noahpinion @saranormous
------
I'm not saying LLMs are not useful.
They are.
They just aren't on the path towards Human-Level AI.
At least in their current form.
------
About 800 million neurons for cats, and about 2 billion for dogs (and parrots).
------
One of the most interesting aspects of Cicero is its ability to plan.
This ability to plan is a necessary component of autonomous intelligence and is completely absent from current LLMs.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
What I mean by LLM is:
"A system trained to predict the next word, and used to produce the next word reactively & stochastically"

I do believe that large transformers trained with SSL are part of a solution and will still be around in 5 years.

But LLMs as defined above won't.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.
------
No, they are not mutually exclusive.
In fact, my proposal includes learning causal world model.
------
It's neither petty nor real beef.
More like a minor divergence of opinions magnified into a non-existing beef.
That's why we simultaneously love and hate Twitter.

Still, I think LLMs are missing essential features for HLAI.
And I doubt 
@OriolVinyalsML
 actually disagrees.
------
Your dog is way more intelligent than any LLM.
------
No, but it could be considered dog-level intelligence, which is smarter than any LLM.
------
I spent one month at Xerox PARC as a summer intern in 1984.

In the late 1990s, my DjVu team at AT&T tried to collaborate with the rival Digipaper team at Xerox, but it didn't work out.
------
Rachmaninoff merely prolonged a style he didn't invent to its apotheosis and inevitable doom.

Stravinsky invented something completely new.
------
Both.
------
It's Sunday.
Twitter debates are like a weekend hobby for me.
------
One thing is certain: cat-level, racoon-level, and dog-level AI will need to be reached before human-level AI.
And we are still pretty far away from all of those.
------
No. It's more complicated than that.
------
If you want non-petty, substantial, in-depth debates, you are better off on Facebook 
------
Reinforcement Learning through Human Feedback: a technique to fine-tune dialog systems by having humans score multiple responses to a question.
------
The ad campaign was in 1993, I think.
I was at AT&T from late 1988 to early 2002.
------
The "reality" of a program, i.e. its state during execution, is discrete, small & finite, fully observable, & deterministic.
The real world is none of that.

Most programs conform to known templates. Real-world actions don't.
------
I never said LLMs were not useful.

In fact, I have strongly argued that they *were* useful against a torrent of vitriol against FAIR's LLM called Galactica (designed to help scientific writing).

No such vitriol against ChatGPT it seems, though it makes sh*t up just as often.
------
That's just Twitter.
------
There are lots of things that are very useful in practice, but not particularly relevant to progress towards HLAI.
------
I haven't moved my goals in years.
But I have changed the path quite a few times, and probably will a few more times.
------
Current LLMs cannot be trained on video.
There is a large community of researchers attempting to design systems that can learn how the world works from video.
It doesn't work yet.
------
Between 1996 & 2002, I mostly worked on DjVu (image compression) & wrote papers on our previous work on neural nets.
Then in late 2001, the Internet bubble burst and AT&T could no longer afford a research lab.
Half of AT&T Labs-Research was laid off.
I managed to be one of them.
------
Human intelligence is more general than narrow AI systems, but still highly specialized.
All intelligences (natural or artificial) are *necessarily* specialized to some extent.
Hence, truly general intelligence is an unreachable goal.
------
LLM specifically refers to architectures (transformers or not) trained to predict the next word.

Transformers architectures pre-trained with some form of Self-Supervised Learning are a great tool, and likely to be used in all kinds of future AI systems.
------
No completely true.
In 1996, AT&T spun off Lucent & NCR.
Our work on neural nets ended because my research group went to AT&T, the engineering group to Lucent, & the product group to NCR.
My group went with AT&T because the president of Lucent-Bell Labs *hated* machine learning.
------
Human Level AI
------
HLAI designated a single system that can handle all (intellectual) tasks at least as well as most humans.
By "handling a task" I mean accomplishing it as well as humans, or learning to accomplish it as quickly as humans.